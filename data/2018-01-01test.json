{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"0811.2853","title":"Generating Random Networks Without Short Cycles","abstract":"Random graph generation is an important tool for studying large complex\nnetworks. Despite abundance of random graph models, constructing models with\napplication-driven constraints is poorly understood. In order to advance\nstate-of-the-art in this area, we focus on random graphs without short cycles\nas a stylized family of graphs, and propose the RandGraph algorithm for\nrandomly generating them. For any constant k, when m=O(n^{1+1\/[2k(k+3)]}),\nRandGraph generates an asymptotically uniform random graph with n vertices, m\nedges, and no cycle of length at most k using O(n^2m) operations. We also\ncharacterize the approximation error for finite values of n. To the best of our\nknowledge, this is the first polynomial-time algorithm for the problem.\nRandGraph works by sequentially adding $m$ edges to an empty graph with n\nvertices. Recently, such sequential algorithms have been successful for random\nsampling problems. Our main contributions to this line of research includes\nintroducing a new approach for sequentially approximating edge-specific\nprobabilities at each step of the algorithm, and providing a new method for\nanalyzing such algorithms.","primary_category":"cs","categories":["cs.DS","cs.IT","math.IT"],"authors":["Bayati Mohsen","Montanari Andrea","Saberi Amin"],"created":"2008-11-18","updated":"2017-12-29","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1003.1628","title":"Having Fun with Lambert W(x) Function","abstract":"This short note presents the Lambert W(x) function and its possible\napplication in the framework of physics related to the Pierre Auger\nObservatory. The actual numerical implementation in C++ consists of Halley's\nand Fritsch's iteration with branch-point expansion, asymptotic series and\nrational fits as initial approximations.","primary_category":"cs","categories":["cs.MS","cs.NA","math.NA"],"authors":["Veberic Darko"],"created":"2010-03-08","updated":"2018-01-07","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1106.1445","title":"From Classical to Quantum Shannon Theory","abstract":"The aim of this book is to develop \"from the ground up\" many of the major,\nexciting, pre- and post-millenium developments in the general area of study\nknown as quantum Shannon theory. As such, we spend a significant amount of time\non quantum mechanics for quantum information theory (Part II), we give a\ncareful study of the important unit protocols of teleportation, super-dense\ncoding, and entanglement distribution (Part III), and we develop many of the\ntools necessary for understanding information transmission or compression (Part\nIV). Parts V and VI are the culmination of this book, where all of the tools\ndeveloped come into play for understanding many of the important results in\nquantum Shannon theory.","primary_category":"cs","categories":["quant-ph","cs.IT","math.IT"],"authors":["Wilde Mark M."],"created":"2011-06-07","updated":"2016-03-22","doi":"10.1017\/9781316809976.001"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1201.5921","title":"An iterative algorithm for parametrization of shortest length shift\n  registers over finite rings","abstract":"The construction of shortest feedback shift registers for a finite sequence\nS_1,...,S_N is considered over the finite ring Z_{p^r}. A novel algorithm is\npresented that yields a parametrization of all shortest feedback shift\nregisters for the sequence of numbers S_1,...,S_N, thus solving an open problem\nin the literature. The algorithm iteratively processes each number, starting\nwith S_1, and constructs at each step a particular type of minimal Gr\\\"obner\nbasis. The construction involves a simple update rule at each step which leads\nto computational efficiency. It is shown that the algorithm simultaneously\ncomputes a similar parametrization for the reciprocal sequence S_N,...,S_1.","primary_category":"cs","categories":["cs.IT","cs.SC","math.IT"],"authors":["Kuijper M.","Pinto R."],"created":"2012-01-27","updated":" ","doi":"10.1007\/s10623-016-0226-3"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1204.6445","title":"A Complete Dichotomy Rises from the Capture of Vanishing Signatures","abstract":"We prove a complexity dichotomy theorem for Holant problems over an arbitrary\nset of complex-valued symmetric constraint functions F on Boolean variables.\nThis extends and unifies all previous dichotomies for Holant problems on\nsymmetric constraint functions (taking values without a finite modulus). We\ndefine and characterize all symmetric vanishing signatures. They turned out to\nbe essential to the complete classification of Holant problems. The dichotomy\ntheorem has an explicit tractability criterion expressible in terms of\nholographic transformations. A Holant problem defined by a set of constraint\nfunctions F is solvable in polynomial time if it satisfies this tractability\ncriterion, and is #P-hard otherwise. The tractability criterion can be\nintuitively stated as follows: A set F is tractable if (1) every function in F\nhas arity at most two, or (2) F is transformable to an affine type, or (3) F is\ntransformable to a product type, or (4) F is vanishing, combined with the right\ntype of binary functions, or (5) F belongs to a special category of vanishing\ntype Fibonacci gates. The proof of this theorem utilizes many previous\ndichotomy theorems on Holant problems and Boolean #CSP. Holographic\ntransformations play an indispensable role as both a proof technique and in the\nstatement of the tractability criterion.","primary_category":"cs","categories":["cs.CC"],"authors":["Cai Jin-Yi","Guo Heng","Williams Tyson"],"created":"2012-04-28","updated":"2018-01-10","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1208.0713","title":"On logical hierarchies within FO^2-definable languages","abstract":"We consider the class of languages defined in the 2-variable fragment of the\nfirst-order logic of the linear order. Many interesting characterizations of\nthis class are known, as well as the fact that restricting the number of\nquantifier alternations yields an infinite hierarchy whose levels are varieties\nof languages (and hence admit an algebraic characterization). Using this\nalgebraic approach, we show that the quantifier alternation hierarchy inside\nFO^{2}[<] is decidable within one unit. For this purpose, we relate each level\nof the hierarchy with decidable varieties of languages, which can be defined in\nterms of iterated deterministic and co-deterministic products. A crucial notion\nin this process is that of condensed rankers, a refinement of the rankers of\nWeis and Immerman and the turtle languages of Schwentick, Th\\'erien and\nVollmer.","primary_category":"cs","categories":["cs.LO","cs.FL"],"authors":["Kufleitner Manfred","Weil Pascal"],"created":"2012-08-03","updated":"2012-08-14","doi":"10.2168\/LMCS-8(3:11)2012"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1209.0521","title":"Efficient EM Training of Gaussian Mixtures with Missing Data","abstract":"In data-mining applications, we are frequently faced with a large fraction of\nmissing entries in the data matrix, which is problematic for most discriminant\nmachine learning algorithms. A solution that we explore in this paper is the\nuse of a generative model (a mixture of Gaussians) to compute the conditional\nexpectation of the missing variables given the observed variables. Since\ntraining a Gaussian mixture with many different patterns of missing values can\nbe computationally very expensive, we introduce a spanning-tree based algorithm\nthat significantly speeds up training in these conditions. We also observe that\ngood results can be obtained by using the generative model to fill-in the\nmissing values for a separate discriminant learning algorithm.","primary_category":"cs","categories":["cs.LG","stat.ML"],"authors":["Delalleau Olivier","Courville Aaron","Bengio Yoshua"],"created":"2012-09-03","updated":"2018-01-08","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1209.0735","title":"Lambert W Function for Applications in Physics","abstract":"The Lambert W(x) function and its possible applications in physics are\npresented. The actual numerical implementation in C++ consists of Halley's and\nFritsch's iterations with initial approximations based on branch-point\nexpansion, asymptotic series, rational fits, and continued-logarithm recursion.","primary_category":"cs","categories":["cs.MS","cs.NA","physics.comp-ph"],"authors":["Veberic Darko"],"created":"2012-08-31","updated":"2018-01-07","doi":"10.1016\/j.cpc.2012.07.008"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1209.1711","title":"Programming Languages for Scientific Computing","abstract":"Scientific computation is a discipline that combines numerical analysis,\nphysical understanding, algorithm development, and structured programming.\nSeveral yottacycles per year on the world's largest computers are spent\nsimulating problems as diverse as weather prediction, the properties of\nmaterial composites, the behavior of biomolecules in solution, and the quantum\nnature of chemical compounds. This article is intended to review specfic\nlanguages features and their use in computational science. We will review the\nstrengths and weaknesses of different programming styles, with examples taken\nfrom widely used scientific codes.","primary_category":"cs","categories":["cs.PL","cs.CE","cs.MS"],"authors":["Knepley Matthew G."],"created":"2012-09-08","updated":"2018-01-09","doi":"10.1007\/978-3-540-70529-1"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1212.1710","title":"The information and its observer: external and internal information\n  processes, information cooperation, and the origin of the observer intellect","abstract":"In observing interactive processes, conversion of observed uncertainty to\nobserver certainty is natural phenomenon creating Yes-No actions of information\nBit and its information observer. Observer emerges from interacting random\nfield of Kolmogorov probabilities which link Kolmogorov 0-1 law probabilities\nand Bayesian probabilities observing Markov diffusion process by probabilistic\n0-1 impulses. Each No-0 action cuts maximum of impulse minimal entropy while\nfollowing Yes-1 action transfers maxim between impulses performing dual\nprinciple of converting process entropy to information. Merging Yes-No actions\ngenerate microprocess within bordered impulse producing Bit with free\ninformation when the microprocess probability approaches 1. Interacting bits\nmemorizes each impulse free information which attracts multiple Bits moving\nmacroprocess that self-joins triplet macrounits. Each memorized information\nbinds reversible microprocess within impulse with irreversible macroprocess.\nThe observation automatically converts cutting entropy to information\nmacrounits. Macrounits logically self-organize information networks IN encoding\nthe units in geometrical structures enclosing triplet code. Multiple IN binds\ntheir ending triplets which encloses observer information cognition and\nintelligence. The observer cognition assembles common units through multiple\nattraction and resonances at forming IN triplet hierarchy which accept only\nunits that recognizes each IN node. Maximal number of accepted triplet levels\nin multiple IN measures the observer maximum comparative information\nintelligence. The observation process carries probabilistic and certain wave\nfunction which self-organizes the space hierarchical structures.These\ninformation regularities create integral logic and intelligence self-operating\nmultiple IN up to physical reality matter.","primary_category":"cs","categories":["nlin.AO","cs.IT","math.IT"],"authors":["Lerner Vladimir S."],"created":"2012-12-09","updated":"2018-01-10","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1301.1071","title":"Direct QR factorizations for tall-and-skinny matrices in MapReduce\n  architectures","abstract":"The QR factorization and the SVD are two fundamental matrix decompositions\nwith applications throughout scientific computing and data analysis. For\nmatrices with many more rows than columns, so-called \"tall-and-skinny\nmatrices,\" there is a numerically stable, efficient, communication-avoiding\nalgorithm for computing the QR factorization. It has been used in traditional\nhigh performance computing and grid computing environments. For MapReduce\nenvironments, existing methods to compute the QR decomposition use a\nnumerically unstable approach that relies on indirectly computing the Q factor.\nIn the best case, these methods require only two passes over the data. In this\npaper, we describe how to compute a stable tall-and-skinny QR factorization on\na MapReduce architecture in only slightly more than 2 passes over the data. We\ncan compute the SVD with only a small change and no difference in performance.\nWe present a performance comparison between our new direct TSQR method, a\nstandard unstable implementation for MapReduce (Cholesky QR), and the classic\nstable algorithm implemented for MapReduce (Householder QR). We find that our\nnew stable method has a large performance advantage over the Householder QR\nmethod. This holds both in a theoretical performance model as well as in an\nactual implementation.","primary_category":"cs","categories":["cs.DC","cs.NA"],"authors":["Benson Austin R.","Gleich David F.","Demmel James"],"created":"2013-01-06","updated":" ","doi":"10.1109\/BigData.2013.6691583"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1301.3451","title":"Eigenstructure of Maximum Likelihood from Counts Data","abstract":"The MLE (Maximum Likelihood Estimate) for a multinomial model is proportional\nto the data. We call such estimate an eigenestimate and the relationship of it\nto the data as the eigenstructure. When the multinomial model is generalized to\ndeal with data arise from incomplete or censored categorical counts, we would\nnaturally look for this eigenstructure between MLE and data. The paper finds\nthe algebraic representation of the eigenstructure (put as Eqn (2.1)), with\nwhich the intuition is visualized geometrically (Figures 2.2 and 4.3) and\nelaborated in a theory (Section 4). The eigenestimate constructed from the\neigenstructure must be a stationary point of the likelihood, a result proved in\nTheorem 4.42. On the bridge between the algebraic definition of Eqn (2.1) and\nthe Proof of Theorem 4.42, we have exploited an elementary inequality (Lemma\n3.1) that governs the primitive cases, defined the thick objects of fragment\nand slice which can be assembled like mechanical parts (Definition 4.1), proved\na few intermediary results that help build up the intuition (Section 4),\nconjectured the universal existence of an eigenestimate (Conjecture 4.32),\nestablished a criterion for boundary regularity (Criterion 4.37), and paved way\n(the Trivial Slicing Algorithm (TSA)) for the derivation of the Weaver\nalgorithms (Section 5) that finds the eigenestimate by using it to reconstruct\nthe observed counts through the eigenstructure, the reconstruction is iterative\nbut derivative-free and matrix-inversion-free. As new addition to the current\nbody of algorithmic methods, the Weaver algorithms craftily tighten threads\nthat are weaved on a rectangular grid (Figure 2.3), and is one incarnation of\nthe TSA. Finally, we put our method in the context of some existing methods\n(Section 6). Softwares are pseudocoded and put online. Visit\nhttp:\/\/hku.hk\/jdong\/eigenstruct2013a.html for demonstrations and download.","primary_category":"cs","categories":["stat.ME","cs.DS","math.OC","math.ST","stat.TH"],"authors":["Dong Fanghu"],"created":"2013-01-15","updated":"2017-12-31","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1305.2494","title":"Computing Solution Operators of Boundary-value Problems for Some Linear\n  Hyperbolic Systems of PDEs","abstract":"We discuss possibilities of application of Numerical Analysis methods to\nproving computability, in the sense of the TTE approach, of solution operators\nof boundary-value problems for systems of PDEs. We prove computability of the\nsolution operator for a symmetric hyperbolic system with computable real\ncoefficients and dissipative boundary conditions, and of the Cauchy problem for\nthe same system (we also prove computable dependence on the coefficients) in a\ncube $Q\\subseteq\\mathbb R^m$. Such systems describe a wide variety of physical\nprocesses (e.g. elasticity, acoustics, Maxwell equations). Moreover, many\nboundary-value problems for the wave equation also can be reduced to this case,\nthus we partially answer a question raised in Weihrauch and Zhong (2002).\nCompared with most of other existing methods of proving computability for PDEs,\nthis method does not require existence of explicit solution formulas and is\nthus applicable to a broader class of (systems of) equations.","primary_category":"cs","categories":["cs.NA","math.NA"],"authors":["Selivanova Svetlana","Selivanov Victor"],"created":"2013-05-11","updated":"2017-11-20","doi":"10.23638\/LMCS-13(4:13)2017"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1306.1167","title":"A Graphical Transformation for Belief Propagation: Maximum Weight\n  Matchings and Odd-Sized Cycles","abstract":"We study the Maximum Weight Matching (MWM) problem for general graphs through\nthe max-product Belief Propagation (BP) and related Linear Programming (LP).\nThe BP approach provides distributed heuristics for finding the Maximum A\nPosteriori (MAP) assignment in a joint probability distribution represented by\na Graphical Model (GM) and respective LPs can be considered as continuous\nrelaxations of the discrete MAP problem. It was recently shown that a BP\nalgorithm converges to the correct MWM assignment under a simple GM formulation\nof MAP\/MWM as long as the corresponding LP relaxation is tight. First, under\nthe motivation for forcing the tightness condition, we consider a new GM\nformulation of MWM, say C-GM, using non-intersecting odd-sized cycles in the\ngraph: the new corresponding LP relaxation, say C-LP, becomes tight for more\nMWM instances. However, the tightness of C-LP now does not guarantee such\nconvergence and correctness of the new BP on C-GM. To address the issue, we\nintroduce a novel graph transformation applied to C-GM, which results in\nanother GM formulation of MWM, and prove that the respective BP on it converges\nto the correct MAP\/MWM assignment as long as C-LP is tight. Finally, we also\nshow that C-LP always has half-integral solutions, which leads to an efficient\nBP-based MWM heuristic consisting of making sequential, `cutting plane',\nmodifications to the underlying GM. Our experiments show that this BP-based\ncutting plane heuristic performs as well as that based on traditional LP\nsolvers.","primary_category":"cs","categories":["cs.DS"],"authors":["Ahn Sungsoo","Chertkov Michael","Gelfand Andrew E.","Park Sejun","Shin Jinwoo"],"created":"2013-06-05","updated":"2017-12-31","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1306.5720","title":"On the Resilience of Bipartite Networks","abstract":"Motivated by problems modeling the spread of infections in networks, in this\npaper we explore which bipartite graphs are most resilient to widespread\ninfections under various parameter settings. Namely, we study bipartite\nnetworks with a requirement of a minimum degree $d$ on one side under an\nindependent infection, independent transmission model. We completely\ncharacterize the optimal graphs in the case $d=1$, which already produces\nnon-trivial behavior, and we give extremal results for the more general cases.\nWe show that in the case $d=2$, surprisingly, the optimally resilient set of\ngraphs includes a graph that is not one of the two \"extremes\" found in the case\n$d=1$.\n  Then, we briefly examine the case where we force a connectivity requirement\ninstead of a one-sided degree requirement and again, we find that the set of\nthe most resilient graphs contains more than the two \"extremes.\" We also show\nthat determining the subgraph of an arbitrary bipartite graph most resilient to\ninfection is NP-hard for any one-sided minimal degree $d \\ge 1$.","primary_category":"cs","categories":["cs.DS","cs.SI"],"authors":["Heinecke Shelby","Perkins Will","Reyzin Lev"],"created":"2013-06-24","updated":"2018-01-08","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1307.7430","title":"Holographic Algorithms Beyond Matchgates","abstract":"Holographic algorithms introduced by Valiant are composed of two ingredients:\nmatchgates, which are gadgets realizing local constraint functions by weighted\nplanar perfect matchings, and holographic reductions, which show equivalences\namong problems with different descriptions via certain basis transformations.\nIn this paper, we replace matchgates in the paradigm above by the affine type\nand the product type constraint functions, which are known to be tractable in\ngeneral (not necessarily planar) graphs. More specifically, we present\npolynomial-time algorithms to decide if a given counting problem has a\nholographic reduction to another problem defined by the affine or product-type\nfunctions. Our algorithms also find a holographic transformation when one\nexists. We further present polynomial-time algorithms of the same decision and\nsearch problems for symmetric functions, where the complexity is measured in\nterms of the (exponentially more) succinct representations. The algorithm for\nthe symmetric case also shows that the recent dichotomy theorem for Holant\nproblems with symmetric constraints is efficiently decidable. Our proof\ntechniques are mainly algebraic, e.g., using stabilizers and orbits of group\nactions.","primary_category":"cs","categories":["cs.DS","cs.CC"],"authors":["Cai Jin-Yi","Guo Heng","Williams Tyson"],"created":"2013-07-28","updated":"2018-01-10","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1308.1391","title":"Low-Dimensional Reconciliation for Continuous-Variable Quantum Key\n  Distribution","abstract":"We propose an efficient logical layer-based reconciliation method for\ncontinuous-variable quantum key distribution (CVQKD) to extract binary\ninformation from correlated Gaussian variables. We demonstrate that by\noperating on the raw-data level, the noise of the quantum channel can be\ncorrected in the low-dimensional (scalar) space and the reconciliation can be\nextended to arbitrary dimensions. The CVQKD systems allow an unconditionally\nsecret communication over standard telecommunication networks. To exploit the\nreal potential of CVQKD a robust reconciliation technique is needed. It is\ncurrently unavailable, which makes it impossible to reach the real performance\nof the CVQKD protocols. The reconciliation is a post-processing step separated\nfrom the transmission of quantum states, which is aimed to derive the secret\nkey from the raw data. The reconciliation process of correlated Gaussian\nvariables is a complex problem that requires either tomography in the physical\nlayer that is intractable in a practical scenario, or high-cost calculations in\nthe multidimensional spherical space with strict dimensional limitations. To\navoid these issues we define the low-dimensional reconciliation. We prove that\nthe error probability of one-dimensional reconciliation is zero in any\npractical CVQKD scenario, and provides unconditional security. The results\nallow to significantly improve the currently available key rates and\ntransmission distances of CVQKD.","primary_category":"cs","categories":["quant-ph","cs.IT","math.IT"],"authors":["Gyongyosi Laszlo","Imre Sandor"],"created":"2013-08-06","updated":"2018-01-07","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1309.2348","title":"An Overview of Nominal-Typing versus Structural-Typing in OOP","abstract":"NOOP is a mathematical model of nominally-typed OOP that proves the\nidentification of inheritance and subtyping in mainstream nominally-typed OO\nprogramming languages and the validity of this identification. This report\ngives an overview of the main notions in OOP relevant to constructing a\nmathematical model of OOP such as NOOP. The emphasis in this report is on\ndefining nominality, nominal typing and nominal subtyping of mainstream\nnominally-typed OO languages, and on contrasting the three notions with their\ncounterparts in structurally-typed OO languages, i.e., with structurality,\nstructural typing and structural subtyping, respectively. An additional\nappendix demonstrates these notions and other related notions, and the\ndifferences between them, using some simple code examples. A detailed, more\ntechnical comparison between nominal typing and structural typing in OOP is\npresented in other publications.","primary_category":"cs","categories":["cs.PL"],"authors":["AbdelGawad Moez A."],"created":"2013-09-09","updated":"2017-12-29","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1311.4257","title":"A parallel directional Fast Multipole Method","abstract":"This paper introduces a parallel directional fast multipole method (FMM) for\nsolving N-body problems with highly oscillatory kernels, with a focus on the\nHelmholtz kernel in three dimensions. This class of oscillatory kernels\nrequires a more restrictive low-rank criterion than that of the low-frequency\nregime, and thus effective parallelizations must adapt to the modified data\ndependencies. We propose a simple partition at a fixed level of the octree and\nshow that, if the partitions are properly balanced between p processes, the\noverall runtime is essentially O(N log N\/p+ p). By the structure of the\nlow-rank criterion, we are able to avoid communication at the top of the\noctree. We demonstrate the effectiveness of our parallelization on several\nchallenging models.","primary_category":"cs","categories":["math.NA","cs.NA"],"authors":["Benson Austin R.","Poulson Jack","Tran Kenneth","Engquist Bj\u00f6rn","Ying Lexing"],"created":"2013-11-17","updated":" ","doi":"10.1137\/130945569"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1312.2674","title":"Silent error detection in numerical time-stepping schemes","abstract":"Errors due to hardware or low level software problems, if detected, can be\nfixed by various schemes, such as recomputation from a checkpoint. Silent\nerrors are errors in application state that have escaped low-level error\ndetection. At extreme scale, where machines can perform astronomically many\noperations per second, silent errors threaten the validity of computed results.\n  We propose a new paradigm for detecting silent errors at the application\nlevel. Our central idea is to frequently compare computed values to those\nprovided by a cheap checking computation, and to build error detectors based on\nthe difference between the two output sequences. Numerical analysis provides us\nwith usable checking computations for the solution of initial-value problems in\nODEs and PDEs, arguably the most common problems in computational science.\nHere, we provide, optimize, and test methods based on Runge-Kutta and linear\nmultistep methods for ODEs, and on implicit and explicit finite difference\nschemes for PDEs. We take the heat equation and Navier-Stokes equations as\nexamples. In tests with artificially injected errors, this approach effectively\ndetects almost all meaningful errors, without significant slowdown.","primary_category":"cs","categories":["cs.NA","cs.MS","math.NA"],"authors":["Benson Austin R.","Schmit Sven","Schreiber Robert"],"created":"2013-12-10","updated":" ","doi":"10.1177\/1094342014532297"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1402.0485","title":"Local algorithms for independent sets are half-optimal","abstract":"We show that the largest density of factor of i.i.d. independent sets on the\nd-regular tree is asymptotically at most (log d)\/d as d tends to infinity. This\nmatches the lower bound given by previous constructions. It follows that the\nlargest independent sets given by local algorithms on random d-regular graphs\nhave the same asymptotic density. In contrast, the density of the largest\nindependent sets on these graphs is asymptotically 2(log d)\/d. We also prove\nanalogous results for Poisson-Galton-Watson trees, which yield bounds for local\nalgorithms on sparse Erdos-Renyi graphs.","primary_category":"cs","categories":["math.PR","cs.DC","math.CO"],"authors":["Rahman Mustazee","Virag Balint"],"created":"2014-02-03","updated":"2015-12-09","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1402.6787","title":"Learning multifractal structure in large networks","abstract":"Generating random graphs to model networks has a rich history. In this paper,\nwe analyze and improve upon the multifractal network generator (MFNG)\nintroduced by Palla et al. We provide a new result on the probability of\nsubgraphs existing in graphs generated with MFNG. From this result it follows\nthat we can quickly compute moments of an important set of graph properties,\nsuch as the expected number of edges, stars, and cliques. Specifically, we show\nhow to compute these moments in time complexity independent of the size of the\ngraph and the number of recursive levels in the generative model. We leverage\nthis theory to a new method of moments algorithm for fitting large networks to\nMFNG. Empirically, this new approach effectively simulates properties of\nseveral social and information networks. In terms of matching subgraph counts,\nour method outperforms similar algorithms used with the Stochastic Kronecker\nGraph model. Furthermore, we present a fast approximation algorithm to generate\ngraph instances following the multi- fractal structure. The approximation\nscheme is an improvement over previous methods, which ran in time complexity\nquadratic in the number of vertices. Combined, our method of moments and fast\nsampling scheme provide the first scalable framework for effectively modeling\nlarge networks with MFNG.","primary_category":"cs","categories":["cs.SI"],"authors":["Benson Austin R.","Riquelme Carlos","Schmit Sven"],"created":"2014-02-26","updated":" ","doi":"10.1145\/2623330.2623718"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1402.6964","title":"Scalable methods for nonnegative matrix factorizations of near-separable\n  tall-and-skinny matrices","abstract":"Numerous algorithms are used for nonnegative matrix factorization under the\nassumption that the matrix is nearly separable. In this paper, we show how to\nmake these algorithms efficient for data matrices that have many more rows than\ncolumns, so-called \"tall-and-skinny matrices\". One key component to these\nimproved methods is an orthogonal matrix transformation that preserves the\nseparability of the NMF problem. Our final methods need a single pass over the\ndata matrix and are suitable for streaming, multi-core, and MapReduce\narchitectures. We demonstrate the efficacy of these algorithms on\nterabyte-sized synthetic matrices and real-world matrices from scientific\ncomputing and bioinformatics.","primary_category":"cs","categories":["cs.LG","cs.DC","cs.NA","stat.ML"],"authors":["Benson Austin R.","Lee Jason D.","Rajwa Bartek","Gleich David F."],"created":"2014-02-27","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1404.5123","title":"Security Risk Analysis in Peer 2 Peer System; An Approach towards\n  Surmounting Security Challenges","abstract":"P2P networking has become a promising technology and has achieved popularity\nas a mechanism for users to share files without the need for centralized\nservers. The rapid growth of P2P networks beginning with Kaza, Lime wire,\nNapsters, E-donkey, Gnutella etc makes them an attractive target to the\ncreators of viruses and other security threats. This paper describes the major\nsecurity issues on P2P networks (Viruses and worms) and presents the study of\npropagation mechanisms. In particular, the paper explores different P2P viruses\nand worms, their propagation methodology, outlines the challenges, and\nevaluates how P2P worms affect the network. The experimental results obtained\nwill provide new direction in surmounting the security concerns in P2P Networks","primary_category":"cs","categories":["cs.CR"],"authors":["Ebrahim Mansoor","Khan Shujaat","Khalid UmerBin"],"created":"2014-04-21","updated":"2018-01-01","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1405.6397","title":"Efficient Evaluation of the Probability Density Function of a Wrapped\n  Normal Distribution","abstract":"The wrapped normal distribution arises when a the density of a\none-dimensional normal distribution is wrapped around the circle infinitely\nmany times. At first look, evaluation of its probability density function\nappears tedious as an infinite series is involved. In this paper, we\ninvestigate the evaluation of two truncated series representations. As one\nrepresentation performs well for small uncertainties whereas the other performs\nwell for large uncertainties, we show that in all cases a small number of\nsummands is sufficient to achieve high accuracy.","primary_category":"cs","categories":["stat.CO","cs.SY","math.NA"],"authors":["Kurz Gerhard","Gilitschenski Igor","Hanebeck Uwe D."],"created":"2014-05-25","updated":" ","doi":"10.1109\/SDF.2014.6954713"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1406.7373","title":"How to Achieve the Capacity of Asymmetric Channels","abstract":"We survey coding techniques that enable reliable transmission at rates that\napproach the capacity of an arbitrary discrete memoryless channel. In\nparticular, we take the point of view of modern coding theory and discuss how\nrecent advances in coding for symmetric channels help provide more efficient\nsolutions for the asymmetric case. We consider, in more detail, three basic\ncoding paradigms.\n  The first one is Gallager's scheme that consists of concatenating a linear\ncode with a non-linear mapping so that the input distribution can be\nappropriately shaped. We explicitly show that both polar codes and spatially\ncoupled codes can be employed in this scenario. Furthermore, we derive a\nscaling law between the gap to capacity, the cardinality of the input and\noutput alphabets, and the required size of the mapper.\n  The second one is an integrated scheme in which the code is used both for\nsource coding, in order to create codewords distributed according to the\ncapacity-achieving input distribution, and for channel coding, in order to\nprovide error protection. Such a technique has been recently introduced by\nHonda and Yamamoto in the context of polar codes, and we show how to apply it\nalso to the design of sparse graph codes.\n  The third paradigm is based on an idea of B\\\"ocherer and Mathar, and\nseparates the two tasks of source coding and channel coding by a chaining\nconstruction that binds together several codewords. We present conditions for\nthe source code and the channel code, and we describe how to combine any source\ncode with any channel code that fulfill those conditions, in order to provide\ncapacity-achieving schemes for asymmetric channels. In particular, we show that\npolar codes, spatially coupled codes, and homophonic codes are suitable as\nbasic building blocks of the proposed coding strategy.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Mondelli Marco","Hassani S. Hamed","Urbanke R\u00fcdiger"],"created":"2014-06-28","updated":"2018-01-03","doi":"10.1109\/ALLERTON.2014.7028535,"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1407.0756","title":"Geometrical Localization Algorithm for 3-D Wireless Sensor Networks","abstract":"In this paper, we propose an efficient range free localization scheme for\nlarge scale three dimensional wireless sensor networks. Our system environment\nconsists of two type of sensors, randomly deployed static sensors and global\npositioning system equipped moving sensors. These moving anchors travels across\nthe network field and broadcast their current locations on specified intervals.\nAs soon as the sensors which are deployed in random fashion receives three\nbeacon messages (known locations broadcasted by anchors), they computes their\nlocations automatically by using our proposed algorithm. One of our significant\ncontributions is, we use only three different beacon messages to localize one\nsensor, while in the best of our knowledge, all previously proposed methods use\nat least four different known locations. The ability of our method to localize\nby using only three known locations not only saves computation, time, energy,\nbut also reduces the number of anchors needed to be deployed and more\nimportantly reduces the communication overheads. Experimental results\ndemonstrate that our proposed scheme improves the overall efficiency of\nlocalization process significantly.\n  Important Note: Final version of this paper is accepted and published by\nJournal of Wireless Personal Communication, Springer : June, 2014 The final\nversion of publication is available at link.springer.com Link:\nhttp:\/\/link.springer.com\/article\/10.1007\\%2Fs11277-014-1852-6","primary_category":"cs","categories":["cs.NI"],"authors":["Kumar Rajesh","Kumar Sushil","Shukla Diksha","Raw Ram Shringar"],"created":"2014-07-02","updated":" ","doi":"10.1007\/s11277-014-1852-6"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1407.5374","title":"Acyclic Edge Coloring through the Lov\\'asz Local Lemma","abstract":"We give a probabilistic analysis of a Moser-type algorithm for the Lov\\'{a}sz\nLocal Lemma (LLL), adjusted to search for acyclic edge colorings of a graph. We\nthus improve the best known upper bound to acyclic chromatic index, also\nobtained by analyzing a similar algorithm, but through the entropic method\n(basically counting argument). Specifically we show that a graph with maximum\ndegree $\\Delta$ has an acyclic proper edge coloring with at most $\\lceil\n3.74(\\Delta-1)\\rceil+1 $ colors, whereas, previously, the best bound was\n$4(\\Delta-1)$. The main contribution of this work is that it comprises a\nprobabilistic analysis of a Moser-type algorithm applied to events pertaining\nto dependent variables.","primary_category":"cs","categories":["cs.DM","cs.DS","math.CO","math.PR"],"authors":["Giotis Ioannis","Kirousis Lefteris","Psaromiligkos Kostas I.","Thilikos Dimitrios M."],"created":"2014-07-21","updated":"2018-01-07","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1407.6116","title":"A Genetic Algorithm for Software Design Migration from Structured to\n  Object Oriented Paradigm","abstract":"The potential benefit of migrating software design from Structured to Object\nOriented Paradigm is manifolded including modularity, manageability and\nextendability. This design migration should be automated as it will reduce the\ntime required in manual process. Our previous work has addressed this issue in\nterms of optimal graph clustering problem formulated by a quadratic Integer\nProgram (IP). However, it has been realized that solution to the IP is\ncomputationally hard and thus heuristic based methods are required to get a\nnear optimal solution. This paper presents a Genetic Algorithm (GA) for optimal\nclustering with an objective of maximizing intra-cluster edges whereas\nminimizing the inter-cluster ones. The proposed algorithm relies on fitness\nbased parent selection and cross-overing cluster elements to reach an optimal\nsolution step by step. The scheme was implemented and tested against a set of\nreal and synthetic data. The experimental results show that GA outperforms our\nprevious works based on Greedy and Monte Carlo approaches by 40% and 49.5%.","primary_category":"cs","categories":["cs.SE","cs.NE"],"authors":["Selim Md.","Siddik Saeed","Gias Alim Ul","Abdullah-Al-Wadud M.","Khaled Shah Mostafa"],"created":"2014-07-23","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1409.2908","title":"A Framework for Practical Parallel Fast Matrix Multiplication","abstract":"Matrix multiplication is a fundamental computation in many scientific\ndisciplines. In this paper, we show that novel fast matrix multiplication\nalgorithms can significantly outperform vendor implementations of the classical\nalgorithm and Strassen's fast algorithm on modest problem sizes and shapes.\nFurthermore, we show that the best choice of fast algorithm depends not only on\nthe size of the matrices but also the shape. We develop a code generation tool\nto automatically implement multiple sequential and shared-memory parallel\nvariants of each fast algorithm, including our novel parallelization scheme.\nThis allows us to rapidly benchmark over 20 fast algorithms on several problem\nsizes. Furthermore, we discuss a number of practical implementation issues for\nthese algorithms on shared-memory machines that can direct further research on\nmaking fast algorithms practical.","primary_category":"cs","categories":["cs.DC","cs.MS","cs.NA"],"authors":["Benson Austin R.","Ballard Grey"],"created":"2014-09-09","updated":" ","doi":"10.1145\/2858788.2688513"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1411.3444","title":"Growing Scale-free Networks by a Mediation-Driven Attachment Rule","abstract":"We propose a model that generates a new class of networks exhibiting\npower-law degree distribution with a spectrum of exponents depending on the\nnumber of links ($m$) with which incoming nodes join the existing network.\nUnlike the Barab\\'{a}si-Albert (BA) model, each new node first picks an\nexisting node at random, and connects not with this but with $m$ of its\nneighbors also picked at random. Counterintuitively enough, such a\nmediation-driven attachment rule results not only in preferential but\nsuper-preferential attachment, albeit in disguise. We show that for small $m$,\nthe dynamics of our model is governed by winners take all phenomenon, and for\nhigher $m$ it is governed by winners take some. Besides, we show that the mean\nof the inverse harmonic mean of degrees of the neighborhood of all existing\nnodes is a measure that can well qualify how straight the degree distribution\nis.","primary_category":"cs","categories":["physics.soc-ph","cond-mat.stat-mech","cs.SI"],"authors":["Hassan Kamrul","Islam Liana"],"created":"2014-11-12","updated":"2014-12-01","doi":"10.1016\/j.physa.2016.11.001"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1411.5166","title":"Subtyping in Java is a Fractal","abstract":"While developing their software, professional object-oriented (OO) software\ndevelopers keep in their minds an image of the subtyping relation between types\nin their software. The goal of this paper is to present an observation about\nthe graph of the subtyping relation in Java, namely the observation that, after\nthe addition of generics---and of wildcards, in particular---to Java, the graph\nof the subtyping relation is no longer a simple directed-acyclic graph (DAG),\nas in pre-generics Java, but is rather a fractal. Further, this observation\nequally applies to other mainstream nominally-typed OO languages (such as C#,\nC++ and Scala) where generics and wildcards (or some other form of 'variance\nannotations') are standard features. Accordingly, the shape of the subtyping\nrelation in these OO languages is more complex than a tree or a simple DAG, and\nindeed is also a fractal. Given the popularity of fractals, the fractal\nobservation may help OO software developers keep a useful and intuitive mental\nimage of their software's subtyping relation, even if it is a little more\nfrightening, and more amazing one than before. With proper support from IDEs,\nthe fractal observation can help OO developers in resolving type errors they\nmay find in their code in lesser time, and with more confidence.","primary_category":"cs","categories":["cs.PL","math.GT"],"authors":["AbdelGawad Moez A."],"created":"2014-11-19","updated":"2017-12-29","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1412.5204","title":"How many queries are needed to distinguish a truncated random\n  permutation from a random function?","abstract":"An oracle chooses a function $f$ from the set of $n$ bits strings to itself,\nwhich is either a randomly chosen permutation or a randomly chosen function.\nWhen queried by an $n$-bit string $w$, the oracle computes $f(w)$, truncates\nthe $m$ last bits, and returns only the first $n-m$ bits of $f(w)$. How many\nqueries does a querying adversary need to submit in order to distinguish the\ntruncated permutation from the (truncated) function?\n  In 1998, Hall et al. showed an algorithm for determining (with high\nprobability) whether or not $f$ is a permutation, using $O(2^{\\frac{m+n}{2}})$\nqueries. They also showed that if $m < n\/7$, a smaller number of queries will\nnot suffice. For $m > n\/7$, their method gives a weaker bound. In this note, we\nfirst show how a modification of the approximation method used by Hall et al.\ncan solve the problem completely. It extends the result to practically any $m$,\nshowing that $\\Omega(2^{\\frac{m+n}{2}})$ queries are needed to get a\nnon-negligible distinguishing advantage. However, more surprisingly, a better\nbound for the distinguishing advantage can be obtained from a result of Stam\npublished, in a different context, already in 1978. We also show that, at least\nin some cases, Stam's bound is tight.","primary_category":"cs","categories":["cs.CR"],"authors":["Gilboa Shoni","Gueron Shay","Morris Ben"],"created":"2014-12-16","updated":" ","doi":"10.1007\/s00145-017-9253-0"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1412.5669","title":"The Timestamp of Timed Automata","abstract":"Given a member A of the class of non-deterministic timed automata with silent\ntransitions (eNTA), we show how one can effectively compute its timestamp: the\nset of all pairs of time values and the corresponding actions of all observable\ntimed traces of A, and also a deterministic timed automaton with the same\ntimestamp as that of A. The timestamp is eventually periodic and is constructed\nvia a finite periodic augmented region automaton. A consequence of this\nconstruction is the periodicity of the language of timed automata with respect\nto suffixes. Applications include the decidability of the 1-bounded language\ninclusion problem for the class eNTA, and a partial method, not bounded by time\nor number of steps, for the general language non-inclusion problem for eNTA.","primary_category":"cs","categories":["cs.FL"],"authors":["Rosenmann Amnon"],"created":"2014-12-17","updated":"2018-01-01","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1501.05151","title":"Recursive Bayesian Filtering in Circular State Spaces","abstract":"For recursive circular filtering based on circular statistics, we introduce a\ngeneral framework for estimation of a circular state based on different\ncircular distributions, specifically the wrapped normal distribution and the\nvon Mises distribution. We propose an estimation method for circular systems\nwith nonlinear system and measurement functions. This is achieved by relying on\nefficient deterministic sampling techniques. Furthermore, we show how the\ncalculations can be simplified in a variety of important special cases, such as\nsystems with additive noise as well as identity system or measurement\nfunctions. We introduce several novel key components, particularly a\ndistribution-free prediction algorithm, a new and superior formula for the\nmultiplication of wrapped normal densities, and the ability to deal with\nnon-additive system noise. All proposed methods are thoroughly evaluated and\ncompared to several state-of-the-art solutions.","primary_category":"cs","categories":["cs.SY","cs.RO"],"authors":["Kurz Gerhard","Gilitschenski Igor","Hanebeck Uwe D."],"created":"2015-01-21","updated":" ","doi":"10.1109\/MAES.2016.150083"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1501.06654","title":"Compressive Sampling of Ensembles of Correlated Signals","abstract":"We propose several sampling architectures for the efficient acquisition of an\nensemble of correlated signals. We show that without prior knowledge of the\ncorrelation structure, each of our architectures (under different sets of\nassumptions) can acquire the ensemble at a sub-Nyquist rate. Prior to sampling,\nthe analog signals are diversified using simple, implementable components. The\ndiversification is achieved by injecting types of \"structured randomness\" into\nthe ensemble, the result of which is subsampled. For reconstruction, the\nensemble is modeled as a low-rank matrix that we have observed through an\n(undetermined) set of linear equations. Our main results show that this matrix\ncan be recovered using standard convex programming techniques when the total\nnumber of samples is on the order of the intrinsic degree of freedom of the\nensemble --- the more heavily correlated the ensemble, the fewer samples are\nneeded.\n  To motivate this study, we discuss how such ensembles arise in the context of\narray processing.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Ahmed Ali","Romberg Justin"],"created":"2015-01-27","updated":"2018-01-01","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1502.05058","title":"Tensor Spectral Clustering for Partitioning Higher-order Network\n  Structures","abstract":"Spectral graph theory-based methods represent an important class of tools for\nstudying the structure of networks. Spectral methods are based on a first-order\nMarkov chain derived from a random walk on the graph and thus they cannot take\nadvantage of important higher-order network substructures such as triangles,\ncycles, and feed-forward loops. Here we propose a Tensor Spectral Clustering\n(TSC) algorithm that allows for modeling higher-order network structures in a\ngraph partitioning framework. Our TSC algorithm allows the user to specify\nwhich higher-order network structures (cycles, feed-forward loops, etc.) should\nbe preserved by the network clustering. Higher-order network structures of\ninterest are represented using a tensor, which we then partition by developing\na multilinear spectral method. Our framework can be applied to discovering\nlayered flows in networks as well as graph anomaly detection, which we\nillustrate on synthetic networks. In directed networks, a higher-order\nstructure of particular interest is the directed 3-cycle, which captures\nfeedback loops in networks. We demonstrate that our TSC algorithm produces\nlarge partitions that cut fewer directed 3-cycles than standard spectral\nclustering algorithms.","primary_category":"cs","categories":["cs.SI","physics.soc-ph"],"authors":["Benson Austin R.","Gleich David F.","Leskovec Jure"],"created":"2015-02-17","updated":" ","doi":"10.1137\/1.9781611974010.14"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1503.01404","title":"Complete intersection vanishing ideals on sets of clutter type over\n  finite fields","abstract":"In this paper we give a classification of complete intersection vanishing\nideals on parameterized sets of clutter type over finite fields.","primary_category":"cs","categories":["math.AC","cs.IT","math.AG","math.CO","math.IT"],"authors":["Tochimani Azucena","Villarreal Rafael H."],"created":"2015-03-04","updated":" ","doi":"10.1007\/s40840-015-0239-5"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1503.03605","title":"An improved return-mapping scheme for nonsmooth yield surfaces: PART I -\n  the Haigh-Westergaard coordinates","abstract":"The paper is devoted to the numerical solution of elastoplastic constitutive\ninitial value problems. An improved form of the implicit return-mapping scheme\nfor nonsmooth yield surfaces is proposed that systematically builds on a\nsubdifferential formulation of the flow rule. The main advantage of this\napproach is that the treatment of singular points, such as apices or edges at\nwhich the flow direction is multivalued involves only a uniquely defined set of\nnon-linear equations, similarly to smooth yield surfaces. This paper (PART I)\nis focused on isotropic models containing: $a)$ yield surfaces with one or two\napices (singular points) laying on the hydrostatic axis; $b)$ plastic\npseudo-potentials that are independent of the Lode angle; $c)$ nonlinear\nisotropic hardening (optionally). It is shown that for some models the improved\nintegration scheme also enables to a priori decide about a type of the return\nand investigate existence, uniqueness and semismoothness of discretized\nconstitutive operators in implicit form. Further, the semismooth Newton method\nis introduced to solve incremental boundary-value problems. The paper also\ncontains numerical examples related to slope stability with available Matlab\nimplementation.","primary_category":"cs","categories":["cs.CE"],"authors":["Sysala Stanislav","Cermak Martin","Koudelka Tomas","Kruis Jaroslav","Zeman Jan","Blaheta Radim"],"created":"2015-03-12","updated":"2015-12-21","doi":"10.1002\/zamm.201500305"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1503.05656","title":"Cost-Effective Conceptual Design Using Taxonomies","abstract":"It is known that annotating named entities in unstructured and\nsemi-structured data sets by their concepts improves the effectiveness of\nanswering queries over these data sets. As every enterprise has a limited\nbudget of time or computational resources, it has to annotate a subset of\nconcepts in a given domain whose costs of annotation do not exceed the budget.\nWe call such a subset of concepts a {\\it conceptual design} for the annotated\ndata set. We focus on finding a conceptual design that provides the most\neffective answers to queries over the annotated data set, i.e., a {\\it\ncost-effective conceptual design}. Since, it is often less time-consuming and\ncostly to annotate general concepts than specific concepts, we use information\non superclass\/subclass relationships between concepts in taxonomies to find a\ncost-effective conceptual design. We quantify the amount by which a conceptual\ndesign with concepts from a taxonomy improves the effectiveness of answering\nqueries over an annotated data set. If the taxonomy is a tree, we prove that\nthe problem is NP-hard and propose an efficient approximation and\npseudo-polynomial time algorithms for the problem. We further prove that if the\ntaxonomy is a directed acyclic graph, given some generally accepted hypothesis,\nit is not possible to find any approximation algorithm with reasonably small\napproximation ratio for the problem. Our empirical study using real-world data\nsets, taxonomies, and query workloads shows that our framework effectively\nquantifies the amount by which a conceptual design improves the effectiveness\nof answering queries. It also indicates that our algorithms are efficient for a\ndesign-time task with pseudo-polynomial algorithm being generally more\neffective than the approximation algorithm.","primary_category":"cs","categories":["cs.DB"],"authors":["Vakilian Ali","Chodpathumwan Yodsawalai","Termehchy Arash","Nayyeri Amir"],"created":"2015-03-19","updated":"2018-01-06","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1503.06822","title":"Tree spanners of bounded degree graphs","abstract":"A tree $t$-spanner of a graph $G$ is a spanning tree of $G$ such that the\ndistance between pairs of vertices in the tree is at most $t$ times their\ndistance in $G$. Deciding tree $t$-spanner admissible graphs has been proved to\nbe tractable for $t<3$ and NP-complete for $t>3$, while the complexity status\nof this problem is unresolved when $t=3$. For every $t>2$ and $b>0$, an\nefficient dynamic programming algorithm to decide tree $t$-spanner\nadmissibility of graphs with vertex degrees less than $b$ is presented. Only\nfor $t=3$, the algorithm remains efficient, when graphs $G$ with degrees less\nthan $b\\log |V(G)|$ are examined.","primary_category":"cs","categories":["cs.DM","cs.DS"],"authors":["Papoutsakis Ioannis"],"created":"2015-03-23","updated":"2016-05-09","doi":"10.1016\/j.dam.2017.10.025"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1505.00199","title":"Theory of Optimizing Pseudolinear Performance Measures: Application to\n  F-measure","abstract":"Non-linear performance measures are widely used for the evaluation of\nlearning algorithms. For example, $F$-measure is a commonly used performance\nmeasure for classification problems in machine learning and information\nretrieval community. We study the theoretical properties of a subset of\nnon-linear performance measures called pseudo-linear performance measures which\nincludes $F$-measure, \\emph{Jaccard Index}, among many others. We establish\nthat many notions of $F$-measures and \\emph{Jaccard Index} are pseudo-linear\nfunctions of the per-class false negatives and false positives for binary,\nmulticlass and multilabel classification. Based on this observation, we present\na general reduction of such performance measure optimization problem to\ncost-sensitive classification problem with unknown costs. We then propose an\nalgorithm with provable guarantees to obtain an approximately optimal\nclassifier for the $F$-measure by solving a series of cost-sensitive\nclassification problems. The strength of our analysis is to be valid on any\ndataset and any class of classifiers, extending the existing theoretical\nresults on pseudo-linear measures, which are asymptotic in nature. We also\nestablish the multi-objective nature of the $F$-score maximization problem by\nlinking the algorithm with the weighted-sum approach used in multi-objective\noptimization. We present numerical experiments to illustrate the relative\nimportance of cost asymmetry and thresholding when learning linear classifiers\non various $F$-measure optimization tasks.","primary_category":"cs","categories":["cs.LG"],"authors":["Parambath Shameem A Puthiya","Usunier Nicolas","Grandvalet Yves"],"created":"2015-05-01","updated":"2018-01-01","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1505.06036","title":"VPG and EPG bend-numbers of Halin Graphs","abstract":"A piecewise linear curve in the plane made up of $k+1$ line segments, each of\nwhich is either horizontal or vertical, with consecutive segments being of\ndifferent orientation is called a $k$-bend path. Given a graph $G$, a\ncollection of $k$-bend paths in which each path corresponds to a vertex in $G$\nand two paths have a common point if and only if the vertices corresponding to\nthem are adjacent in $G$ is called a $B_k$-VPG representation of $G$.\nSimilarly, a collection of $k$-bend paths each of which corresponds to a vertex\nin $G$ is called an $B_k$-EPG representation of $G$ if any two paths have a\nline segment of non-zero length in common if and only if their corresponding\nvertices are adjacent in $G$. The VPG bend-number $b_v(G)$ of a graph $G$ is\nthe minimum $k$ such that $G$ has a $B_k$-VPG representation. Similarly, the\nEPG bend-number $b_e(G)$ of a graph $G$ is the minimum $k$ such that $G$ has a\n$B_k$-EPG representation. Halin graphs are the graphs formed by taking a tree\nwith no degree $2$ vertex and then connecting its leaves to form a cycle in\nsuch a way that the graph has a planar embedding. We prove that if $G$ is a\nHalin graph then $b_v(G) \\leq 1$ and $b_e(G) \\leq 2$. These bounds are tight.\nIn fact, we prove the stronger result that if $G$ is a planar graph formed by\nconnecting the leaves of any tree to form a simple cycle, then it has a\nVPG-representation using only one type of 1-bend paths and an\nEPG-representation using only one type of 2-bend paths.","primary_category":"cs","categories":["math.CO","cs.DM"],"authors":["Francis Mathew C.","Lahiri Abhiruk"],"created":"2015-05-22","updated":"2016-01-04","doi":"10.1016\/j.dam.2016.07.007"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1506.00529","title":"Desirability and the birth of incomplete preferences","abstract":"We establish an equivalence between two seemingly different theories: one is\nthe traditional axiomatisation of incomplete preferences on horse lotteries\nbased on the mixture independence axiom; the other is the theory of desirable\ngambles developed in the context of imprecise probability. The equivalence\nallows us to revisit incomplete preferences from the viewpoint of desirability\nand through the derived notion of coherent lower previsions. On this basis, we\nobtain new results and insights: in particular, we show that the theory of\nincomplete preferences can be developed assuming only the existence of a worst\nact---no best act is needed---, and that a weakened Archimedean axiom suffices\ntoo; this axiom allows us also to address some controversy about the regularity\nassumption (that probabilities should be positive---they need not), which\nenables us also to deal with uncountable possibility spaces; we show that it is\nalways possible to extend in a minimal way a preference relation to one with a\nworst act, and yet the resulting relation is never Archimedean, except in a\ntrivial case; we show that the traditional notion of state independence\ncoincides with the notion called strong independence in imprecise\nprobability---this leads us to give much a weaker definition of state\nindependence than the traditional one; we rework and uniform the notions of\ncomplete preferences, beliefs, values; we argue that Archimedeanity does not\ncapture all the problems that can be modelled with sets of expected utilities\nand we provide a new notion that does precisely that. Perhaps most importantly,\nwe argue throughout that desirability is a powerful and natural setting to\nmodel, and work with, incomplete preferences, even in case of non-Archimedean\nproblems. This leads us to suggest that desirability, rather than preference,\nshould be the primitive notion at the basis of decision-theoretic\naxiomatisations.","primary_category":"cs","categories":["cs.AI"],"authors":["Zaffalon Marco","Miranda Enrique"],"created":"2015-06-01","updated":" ","doi":"10.1613\/jair.5230"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1507.01345","title":"DiffNodesets: An Efficient Structure for Fast Mining Frequent Itemsets","abstract":"Mining frequent itemsets is an essential problem in data mining and plays an\nimportant role in many data mining applications. In recent years, some itemset\nrepresentations based on node sets have been proposed, which have shown to be\nvery efficient for mining frequent itemsets. In this paper, we propose\nDiffNodeset, a novel and more efficient itemset representation, for mining\nfrequent itemsets. Based on the DiffNodeset structure, we present an efficient\nalgorithm, named dFIN, to mining frequent itemsets. To achieve high efficiency,\ndFIN finds frequent itemsets using a set-enumeration tree with a hybrid search\nstrategy and directly enumerates frequent itemsets without candidate generation\nunder some case. For evaluating the performance of dFIN, we have conduct\nextensive experiments to compare it against with existing leading algorithms on\na variety of real and synthetic datasets. The experimental results show that\ndFIN is significantly faster than these leading algorithms.","primary_category":"cs","categories":["cs.DS","cs.DB"],"authors":["Deng Zhi-Hong"],"created":"2015-07-06","updated":" ","doi":"10.1016\/j.asoc.2016.01.010"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1507.02103","title":"Measuring centrality by a generalization of degree","abstract":"Network analysis has emerged as a key technique in communication studies,\neconomics, geography, history and sociology, among others. A fundamental issue\nis how to identify key nodes, for which purpose a number of centrality measures\nhave been developed. This paper proposes a new parametric family of centrality\nmeasures called generalized degree. It is based on the idea that a relationship\nto a more interconnected node contributes to centrality in a greater extent\nthan a connection to a less central one. Generalized degree improves on degree\nby redistributing its sum over the network with the consideration of the global\nstructure. Application of the measure is supported by a set of basic\nproperties. A sufficient condition is given for generalized degree to be rank\nmonotonic, excluding counter-intuitive changes in the centrality ranking after\ncertain modifications of the network. The measure has a graph interpretation\nand can be calculated iteratively. Generalized degree is recommended to apply\nbesides degree since it preserves most favourable attributes of degree, but\nbetter reflects the role of the nodes in the network and has an increased\nability to distinguish among their importance.","primary_category":"cs","categories":["cs.SI","physics.soc-ph"],"authors":["Csat\u00f3 L\u00e1szl\u00f3"],"created":"2015-07-08","updated":"2017-04-12","doi":"10.1007\/s10100-016-0439-6"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1507.03838","title":"Towards Green and Infinite Capacity in Wireless Communication Networks:\n  Beyond The Shannon Theorem","abstract":"New and novel way for resources allocation in wireless communication has been\nproposed in this paper. Under this new method, it has been shown that the\nrequired power budget becomes independent of the number of served terminals in\nthe downlink. However, the required power depends only of the coverage area,\ni.e. the channel losses at the cell boarder. Therefore, huge number\n(theoretically any number) of terminals could be supported concurrently at\nfinite and small downlink power budget. This could be very useful to support\nthe downlink signalling channels in HSPA+, LTE, and 5G. It can be very useful\nalso to support huge D2D communication downlinks. Moreover, and based on the\nsame concept, a new system configuration for a single link point-to-point\ncommunication has been presented. With this new configuration, the achieved\ndata rate becomes independent of the required transmit power. This means that\nany data rate can be achieved at the target BER and with small and finite\ntransmit power. This seems violating with some major results of the Shannon\ntheorem. This issue will be discussed in details in this article.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Elmusrati Mohammed"],"created":"2015-07-14","updated":" ","doi":"10.1049\/iet-com.2016.0963"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1507.05014","title":"Compositional Construction of Approximate Abstractions of Interconnected\n  Control Systems","abstract":"We consider a compositional construction of approximate abstractions of\ninterconnected control systems. In our framework, an abstraction acts as a\nsubstitute in the controller design process and is itself a continuous control\nsystem. The abstraction is related to the concrete control system via a\nso-called simulation function: a Lyapunov-like function, which is used to\nestablish a quantitative bound between the behavior of the approximate\nabstraction and the concrete system. In the first part of the paper, we provide\na small gain type condition that facilitates the compositional construction of\nan abstraction of an interconnected control system together with a simulation\nfunction from the abstractions and simulation functions of the individual\nsubsystems. In the second part of the paper, we restrict our attention to\nlinear control system and characterize simulation functions in terms of\ncontrolled invariant, externally stabilizable subspaces. Based on those\ncharacterizations, we propose a particular scheme to construct abstractions for\nlinear control systems. We illustrate the compositional construction of an\nabstraction on an interconnected system consisting of four linear subsystems.\nWe use the abstraction as a substitute to synthesize a controller to enforce a\ncertain linear temporal logic specification.","primary_category":"cs","categories":["math.OC","cs.SY"],"authors":["Rungger Matthias","Zamani Majid"],"created":"2015-07-17","updated":"2016-06-25","doi":"10.1109\/TCNS.2016.2583063"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1507.05880","title":"A study of the classification of low-dimensional data with supervised\n  manifold learning","abstract":"Supervised manifold learning methods learn data representations by preserving\nthe geometric structure of data while enhancing the separation between data\nsamples from different classes. In this work, we propose a theoretical study of\nsupervised manifold learning for classification. We consider nonlinear\ndimensionality reduction algorithms that yield linearly separable embeddings of\ntraining data and present generalization bounds for this type of algorithms. A\nnecessary condition for satisfactory generalization performance is that the\nembedding allow the construction of a sufficiently regular interpolation\nfunction in relation with the separation margin of the embedding. We show that\nfor supervised embeddings satisfying this condition, the classification error\ndecays at an exponential rate with the number of training samples. Finally, we\nexamine the separability of supervised nonlinear embeddings that aim to\npreserve the low-dimensional geometric structure of data based on graph\nrepresentations. The proposed analysis is supported by experiments on several\nreal data sets.","primary_category":"cs","categories":["cs.LG"],"authors":["Vural Elif","Guillemot Christine"],"created":"2015-07-21","updated":"2018-01-05","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1507.06111","title":"COMs: Complexes of Oriented Matroids","abstract":"In his seminal 1983 paper, Jim Lawrence introduced lopsided sets and featured\nthem as asymmetric counterparts of oriented matroids, both sharing the key\nproperty of strong elimination. Moreover, symmetry of faces holds in both\nstructures as well as in the so-called affine oriented matroids. These two\nfundamental properties (formulated for covectors) together lead to the natural\nnotion of \"conditional oriented matroid\" (abbreviated COM). These novel\nstructures can be characterized in terms of three cocircuits axioms,\ngeneralizing the familiar characterization for oriented matroids. We describe a\nbinary composition scheme by which every COM can successively be erected as a\ncertain complex of oriented matroids, in essentially the same way as a lopsided\nset can be glued together from its maximal hypercube faces. A realizable COM is\nrepresented by a hyperplane arrangement restricted to an open convex set. Among\nthese are the examples formed by linear extensions of ordered sets,\ngeneralizing the oriented matroids corresponding to the permutohedra. Relaxing\nrealizability to local realizability, we capture a wider class of combinatorial\nobjects: we show that non-positively curved Coxeter zonotopal complexes give\nrise to locally realizable COMs.","primary_category":"cs","categories":["math.CO","cs.DM"],"authors":["Bandelt Hans-Juergen","Chepoi Victor","Knauer Kolja"],"created":"2015-07-22","updated":"2018-01-03","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1508.04606","title":"Distributed Event-Triggered Control for Asymptotic Synchronization of\n  Dynamical Networks","abstract":"This paper studies synchronization of dynamical networks with event-based\ncommunication. Firstly, two estimators are introduced into each node, one to\nestimate its own state, and the other to estimate the average state of its\nneighbours. Then, with these two estimators, a distributed event-triggering\nrule (ETR) with a dwell time is designed such that the network achieves\nsynchronization asymptotically with no Zeno behaviours. The designed ETR only\ndepends on the information that each node can obtain, and thus can be\nimplemented in a decentralized way.","primary_category":"cs","categories":["cs.SY","cs.MA","math.DS"],"authors":["Liu Tao","Cao Ming","De Persis Claudio","Hendrickx Julien M."],"created":"2015-08-19","updated":"2018-01-06","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1508.07435","title":"Subdifferential-based implicit return-mapping operators in Mohr-Coulomb\n  plasticity","abstract":"The paper is devoted to a constitutive solution, limit load analysis and\nNewton-like methods in elastoplastic problems containing the Mohr-Coulomb yield\ncriterion. Within the constitutive problem, we introduce a self-contained\nderivation of the implicit return-mapping solution scheme using a recent\nsubdifferential-based treatment. Unlike conventional techniques based on\nKoiter's rules, the presented scheme a priori detects a position of the unknown\nstress tensor on the yield surface even if the constitutive solution cannot be\nfound in closed form. This fact eliminates blind guesswork from the scheme,\nenables to analyze properties of the constitutive operator, and simplifies\nconstruction of the consistent tangent operator which is important for the\nsemismooth Newton method applied on the incremental boundary value\nelastoplastic problem. The incremental problem in Mohr-Coulomb plasticity is\ncombined with the limit load analysis. Beside a conventional direct method of\nthe incremental limit analysis, a recent indirect one is introduced and its\nadvantages are described. The paper contains 2D and 3D numerical experiments on\nslope stability with publicly available Matlab implementations.","primary_category":"cs","categories":["cs.CE"],"authors":["Sysala Stanislav","Cermak Martin"],"created":"2015-08-29","updated":"2016-09-27","doi":"10.1002\/zamm.201600215"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1509.05572","title":"Randomised enumeration of small witnesses using a decision oracle","abstract":"Many combinatorial problems involve determining whether a universe of $n$\nelements contains a witness consisting of $k$ elements which have some\nspecified property. In this paper we investigate the relationship between the\ndecision and enumeration versions of such problems: efficient methods are known\nfor transforming a decision algorithm into a search procedure that finds a\nsingle witness, but even finding a second witness is not so straightforward in\ngeneral. We show that, if the decision version of the problem can be solved in\ntime $f(k) \\cdot poly(n)$, there is a randomised algorithm which enumerates all\nwitnesses in time $e^{k + o(k)} \\cdot f(k) \\cdot poly(n) \\cdot N$, where $N$ is\nthe total number of witnesses. If the decision version of the problem is solved\nby a randomised algorithm which may return false negatives, then the same\nmethod allows us to output a list of witnesses in which any given witness will\nbe included with high probability. The enumeration algorithm also gives rise to\nan efficient algorithm to count the total number of witnesses when this number\nis small.","primary_category":"cs","categories":["cs.DS","cs.CC"],"authors":["Meeks Kitty"],"created":"2015-09-18","updated":"2018-01-04","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1509.08102","title":"Discriminative Learning of the Prototype Set for Nearest Neighbor\n  Classification","abstract":"The nearest neighbor rule is a classic yet essential classification model,\nparticularly in problems where the supervising information is given by pairwise\ndissimilarities and the embedding function are not easily obtained. Prototype\nselection provides means of generalization and improving efficiency of the\nnearest neighbor model, but many existing methods assume and rely on the\nanalyses of the input vector space. In this paper, we explore a\ndissimilarity-based, parametrized model of the nearest neighbor rule. In the\nproposed model, the selection of the nearest prototypes is influenced by the\nparameters of the respective prototypes. It provides a formulation for\nminimizing the violation of the extended nearest neighbor rule over the\ntraining set in a tractable form to exploit numerical techniques. We show that\nthe minimization problem reduces to a large-margin principle learning and\ndemonstrate its advantage by empirical comparisons with other prototype\nselection methods.","primary_category":"cs","categories":["cs.LG"],"authors":["Ando Shin"],"created":"2015-09-27","updated":"2018-01-05","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1509.08764","title":"On the Min-cost Traveling Salesman Problem with Drone","abstract":"Over the past few years, unmanned aerial vehicles (UAV), also known as\ndrones, have been adopted as part of a new logistic method in the commercial\nsector called \"last-mile delivery\". In this novel approach, they are deployed\nalongside trucks to deliver goods to customers to improve the quality of\nservice and reduce the transportation cost. This approach gives rise to a new\nvariant of the traveling salesman problem (TSP), called TSP with drone (TSP-D).\nA variant of this problem that aims to minimize the time at which truck and\ndrone finish the service (or, in other words, to maximize the quality of\nservice) was studied in the work of Murray and Chu (2015). In contrast, this\npaper considers a new variant of TSP-D in which the objective is to minimize\noperational costs including total transportation cost and one created by waste\ntime a vehicle has to wait for the other. The problem is first formulated\nmathematically. Then, two algorithms are proposed for the solution. The first\nalgorithm (TSP-LS) was adapted from the approach proposed by Murray and Chu\n(2015), in which an optimal TSP solution is converted to a feasible TSP-D\nsolution by local searches. The second algorithm, a Greedy Randomized Adaptive\nSearch Procedure (GRASP), is based on a new split procedure that optimally\nsplits any TSP tour into a TSP-D solution. After a TSP-D solution has been\ngenerated, it is then improved through local search operators. Numerical\nresults obtained on various instances of both objective functions with\ndifferent sizes and characteristics are presented. The results show that GRASP\noutperforms TSP-LS in terms of solution quality under an acceptable running\ntime.","primary_category":"cs","categories":["cs.AI"],"authors":["Ha Quang Minh","Deville Yves","Pham Quang Dung","H\u00e0 Minh Ho\u00e0ng"],"created":"2015-09-29","updated":"2017-07-29","doi":"10.1016\/j.trc.2017.11.015"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1510.03895","title":"A faster subquadratic algorithm for finding outlier correlations","abstract":"We study the problem of detecting outlier pairs of strongly correlated\nvariables among a collection of $n$ variables with otherwise weak pairwise\ncorrelations. After normalization, this task amounts to the geometric task\nwhere we are given as input a set of $n$ vectors with unit Euclidean norm and\ndimension $d$, and for some constants $0<\\tau<\\rho<1$, we are asked to find all\nthe outlier pairs of vectors whose inner product is at least $\\rho$ in absolute\nvalue, subject to the promise that all but at most $q$ pairs of vectors have\ninner product at most $\\tau$ in absolute value.\n  Improving on an algorithm of G. Valiant [FOCS 2012; J. ACM 2015], we present\na randomized algorithm that for Boolean inputs ($\\{-1,1\\}$-valued data\nnormalized to unit Euclidean length) runs in time \\[ \\tilde\nO\\bigl(n^{\\max\\,\\{1-\\gamma+M(\\Delta\\gamma,\\gamma),\\,M(1-\\gamma,2\\Delta\\gamma)\\}}+qdn^{2\\gamma}\\bigr)\\,,\n\\] where $0<\\gamma<1$ is a constant tradeoff parameter and $M(\\mu,\\nu)$ is the\nexponent to multiply an $\\lfloor n^\\mu\\rfloor\\times\\lfloor n^\\nu\\rfloor$ matrix\nwith an $\\lfloor n^\\nu\\rfloor\\times \\lfloor n^\\mu\\rfloor$ matrix and\n$\\Delta=1\/(1-\\log_\\tau\\rho)$. As corollaries we obtain randomized algorithms\nthat run in time \\[ \\tilde\nO\\bigl(n^{\\frac{2\\omega}{3-\\log_\\tau\\rho}}+qdn^{\\frac{2(1-\\log_\\tau\\rho)}{3-\\log_\\tau\\rho}}\\bigr)\n\\] and in time \\[ \\tilde\nO\\bigl(n^{\\frac{4}{2+\\alpha(1-\\log_\\tau\\rho)}}+qdn^{\\frac{2\\alpha(1-\\log_\\tau\\rho)}{2+\\alpha(1-\\log_\\tau\\rho)}}\\bigr)\\,,\n\\] where $2\\leq\\omega<2.38$ is the exponent for square matrix multiplication\nand $0.3<\\alpha\\leq 1$ is the exponent for rectangular matrix multiplication.\nThe notation $\\tilde O(\\cdot)$ hides polylogarithmic factors in $n$ and $d$\nwhose degree may depend on $\\rho$ and $\\tau$. We present further corollaries\nfor the light bulb problem and for learning sparse Boolean functions.","primary_category":"cs","categories":["cs.DS"],"authors":["Karppa Matti","Kaski Petteri","Kohonen Jukka"],"created":"2015-10-13","updated":"2018-01-04","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1510.08202","title":"Oblivious Fronthaul-Constrained Relay for a Gaussian Channel","abstract":"We consider systems in which the transmitter conveys messages to the receiver\nthrough a capacity-limited relay station. The channel between the transmitter\nand the relay-station is assumed to be a frequency selective additive Gaussian\nnoise channel. It is assumed that the transmitter can shape the spectrum and\nadapt the coding technique so as to optimize performance. The relay operation\nis oblivious (nomadic transmitters), that is, the specific codebooks used are\nunknown. We find the reliable information rate that can be achieved with\nGaussian signaling in this setting, and to that end, employ Gaussian bottleneck\nresults combined with Shannon's incremental frequency approach. We also prove\nthat, unlike classical water-pouring, the allocated spectrum (power and\nbit-rate) of the optimal solution could frequently be discontinuous. These\nresults can be applied to a MIMO transmission scheme. We also investigate the\ncase of an entropy limited relay. We present lower and upper bounds on the\noptimal performance (in terms of mutual information), and derive an analytical\napproximation.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Homri Adi","Peleg Michael","Shamai Shlomo"],"created":"2015-10-28","updated":"2018-01-05","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1512.01503","title":"On the Min-cost Traveling Salesman Problem with Drone","abstract":"Once known to be used exclusively in military domain, unmanned aerial\nvehicles (drones) have stepped up to become a part of new logistic method in\ncommercial sector called \"last-mile delivery\". In this novel approach, small\nunmanned aerial vehicles (UAV), also known as drones, are deployed alongside\nwith trucks to deliver goods to customers in order to improve the service\nquality or reduce the transportation cost. It gives rise to a new variant of\nthe traveling salesman problem (TSP), of which we call TSP with drone (TSP-D).\nIn this article, we consider a variant of TSP-D where the main objective is to\nminimize the total transportation cost. We also propose two heuristics: \"Drone\nFirst, Truck Second\" (DFTS) and \"Truck First, Drone Second\" (TFDS), to\neffectively solve the problem. The former constructs route for drone first\nwhile the latter constructs route for truck first. We solve a TSP to generate\nroute for truck and propose a mixed integer programming (MIP) formulation with\ndifferent profit functions to build route for drone. Numerical results obtained\non many instances with different sizes and characteristics are presented.\nRecommendations on promising algorithm choices are also provided.","primary_category":"cs","categories":["cs.AI"],"authors":["Ha Quang Minh","Deville Yves","Pham Quang Dung","H\u00e0 Minh Ho\u00e0ng"],"created":"2015-12-04","updated":"2016-05-26","doi":"10.1016\/j.trc.2017.11.015"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1512.03465","title":"Mined Semantic Analysis: A New Concept Space Model for Semantic\n  Representation of Textual Data","abstract":"Mined Semantic Analysis (MSA) is a novel concept space model which employs\nunsupervised learning to generate semantic representations of text. MSA\nrepresents textual structures (terms, phrases, documents) as a Bag of Concepts\n(BoC) where concepts are derived from concept rich encyclopedic corpora.\nTraditional concept space models exploit only target corpus content to\nconstruct the concept space. MSA, alternatively, uncovers implicit relations\nbetween concepts by mining for their associations (e.g., mining Wikipedia's\n\"See also\" link graph). We evaluate MSA's performance on benchmark datasets for\nmeasuring semantic relatedness of words and sentences. Empirical results show\ncompetitive performance of MSA compared to prior state-of-the-art methods.\nAdditionally, we introduce the first analytical study to examine statistical\nsignificance of results reported by different semantic relatedness methods. Our\nstudy shows that, the nuances of results across top performing methods could be\nstatistically insignificant. The study positions MSA as one of state-of-the-art\nmethods for measuring semantic relatedness, besides the inherent\ninterpretability and simplicity of the generated semantic representation.","primary_category":"cs","categories":["cs.CL"],"authors":["Shalaby Walid","Zadrozny Wlodek"],"created":"2015-12-10","updated":"2017-12-31","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1512.05840","title":"Deep Poisson Factorization Machines: factor analysis for mapping\n  behaviors in journalist ecosystem","abstract":"Newsroom in online ecosystem is difficult to untangle. With prevalence of\nsocial media, interactions between journalists and individuals become visible,\nbut lack of understanding to inner processing of information feedback loop in\npublic sphere leave most journalists baffled. Can we provide an organized view\nto characterize journalist behaviors on individual level to know better of the\necosystem? To this end, I propose Poisson Factorization Machine (PFM), a\nBayesian analogue to matrix factorization that assumes Poisson distribution for\ngenerative process. The model generalizes recent studies on Poisson Matrix\nFactorization to account temporal interaction which involves tensor-like\nstructure, and label information. Two inference procedures are designed, one\nbased on batch variational EM and another stochastic variational inference\nscheme that efficiently scales with data size. An important novelty in this\nnote is that I show how to stack layers of PFM to introduce a deep\narchitecture. This work discusses some potential results applying the model and\nexplains how such latent factors may be useful for analyzing latent behaviors\nfor data exploration.","primary_category":"cs","categories":["cs.CY","cs.LG","stat.ML"],"authors":["Kung Pau Perng-Hwa"],"created":"2015-12-17","updated":"2017-12-29","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1512.08050","title":"Large deviation, Basic Information Theory for Wireless Sensor Networks","abstract":"In this article, we prove Shannon-MacMillan-Breiman Theorem for Wireless\nSensor Networks modelled as coloured geometric random graphs. For large $n,$ we\nshow that a Wireless Sensor Network consisting of $n$ sensors in $[0,1]^d$\nconnected by an average number of links of order $n\\log n $ can be coded by\nabout $[n(\\log n )^2\\pi^{d\/2}\/(d\/2)!]\\,\\mathcal{H}$ bits, where $\\mathcal{H}$\nis an explicitly defined entropy. In the process, we derive a joint large\ndeviation principle (LDP) for the \\emph{empirical sensor measure} and \\emph{the\nempirical link measure} of coloured random geometric graph models.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Doku-Amponsah Kwabena"],"created":"2015-12-25","updated":"2015-12-30","doi":"10.3844\/jmssp.2017.325.329"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1601.00416","title":"Computing Robust Controlled Invariant Sets of Linear Systems","abstract":"We consider controllable linear discrete-time systems with bounded\nperturbations and present two methods to compute robust controlled invariant\nsets. The first method tolerates an arbitrarily small constraint violation to\ncompute an arbitrarily precise outer approximation of the maximal robust\ncontrolled invariant set, while the second method provides an inner\napproximation. The outer approximation scheme is $\\delta$-complete, given that\nthe constraint sets are formulated as finite unions of polytopes.","primary_category":"cs","categories":["math.OC","cs.SY","math.DS"],"authors":["Rungger Matthias","Tabuada Paulo"],"created":"2016-01-04","updated":"2017-02-20","doi":"10.1109\/TAC.2017.2672859"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1601.01952","title":"A Scalable Low-Cost-UAV Traffic Network (uNet)","abstract":"This article proposes a new Unmanned Aerial Vehicle (UAV) operation paradigm\nto enable a large number of relatively low-cost UAVs to fly\nbeyond-line-of-sight without costly sensing and communication systems or\nsubstantial human intervention in individual UAV control. Under current\nfree-flight-like paradigm, wherein a UAV can travel along any route as long as\nit avoids restricted airspace and altitudes. However, this requires expensive\non-board sensing and communication as well as substantial human effort in order\nto ensure avoidance of obstacles and collisions. The increased cost serves as\nan impediment to the emergence and development of broader UAV applications. The\nmain contribution of this work is to propose the use of pre-established route\nnetwork for UAV traffic management, which allows: (i) pre- mapping of obstacles\nalong the route network to reduce the onboard sensing requirements and the\nassociated costs for avoiding such obstacles; and (ii) use of well-developed\nrouting algorithms to select UAV schedules that avoid conflicts. Available\nGPS-based navigation can be used to fly the UAV along the selected route and\ntime schedule with relatively low added cost, which therefore, reduces the\nbarrier to entry into new UAV-applications market. Finally, this article\nproposes a new decoupling scheme for conflict-free transitions between edges of\nthe route network at each node of the route network to reduce potential\nconflicts between UAVs and ensuing delays. A simulation example is used to\nillustrate the proposed uNet approach.","primary_category":"cs","categories":["cs.SY"],"authors":["Devasia Santosh","Lee Alexander"],"created":"2016-01-07","updated":"2016-01-11","doi":"10.2514\/1.D0022"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1601.06548","title":"Schematic Cut elimination and the Ordered Pigeonhole Principle [Extended\n  Version]","abstract":"In previous work, an attempt was made to apply the schematic CERES method [8]\nto a formal proof with an arbitrary number of {\\Pi} 2 cuts (a recursive proof\nencapsulating the infinitary pigeonhole principle) [5]. However the derived\nschematic refutation for the characteristic clause set of the proof could not\nbe expressed in the formal language provided in [8]. Without this formalization\na Herbrand system cannot be algorithmically extracted. In this work, we provide\na restriction of the proof found in [5], the ECA-schema (Eventually Constant\nAssertion), or ordered infinitary pigeonhole principle, whose analysis can be\ncompletely carried out in the framework of [8], this is the first time the\nframework is used for proof analysis. From the refutation of the clause set and\na substitution schema we construct a Herbrand system.","primary_category":"cs","categories":["math.LO","cs.LO"],"authors":["Cerna David","Leitsch Alexander"],"created":"2016-01-25","updated":" ","doi":"10.1007\/978-3-319-40229-1_17"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1602.02102","title":"The Spacey Random Walk: a Stochastic Process for Higher-order Data","abstract":"Random walks are a fundamental model in applied mathematics and are a common\nexample of a Markov chain. The limiting stationary distribution of the Markov\nchain represents the fraction of the time spent in each state during the\nstochastic process. A standard way to compute this distribution for a random\nwalk on a finite set of states is to compute the Perron vector of the\nassociated transition matrix. There are algebraic analogues of this Perron\nvector in terms of transition probability tensors of higher-order Markov\nchains. These vectors are nonnegative, have dimension equal to the dimension of\nthe state space, and sum to one and are derived by making an algebraic\nsubstitution in the equation for the joint-stationary distribution of a\nhigher-order Markov chains. Here, we present the spacey random walk, a\nnon-Markovian stochastic process whose stationary distribution is given by the\ntensor eigenvector. The process itself is a vertex-reinforced random walk, and\nits discrete dynamics are related to a continuous dynamical system. We analyze\nthe convergence properties of these dynamics and discuss numerical methods for\ncomputing the stationary distribution. Finally, we provide several applications\nof the spacey random walk model in population genetics, ranking, and clustering\ndata, and we use the process to analyze taxi trajectory data in New York. This\nexample shows definite non-Markovian structure.","primary_category":"cs","categories":["cs.NA","cs.SI","math.DS","math.NA","math.PR"],"authors":["Benson Austin R.","Gleich David F.","Lim Lek-Heng"],"created":"2016-02-05","updated":"2016-12-26","doi":"10.1137\/16M1074023"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1602.04396","title":"Optimal Sample Complexity for Stable Matrix Recovery","abstract":"Tremendous efforts have been made to study the theoretical and algorithmic\naspects of sparse recovery and low-rank matrix recovery. This paper fills a\ntheoretical gap in matrix recovery: the optimal sample complexity for stable\nrecovery without constants or log factors. We treat sparsity, low-rankness, and\npotentially other parsimonious structures within the same framework: constraint\nsets that have small covering numbers or Minkowski dimensions. We consider\nthree types of random measurement matrices (unstructured, rank-1, and symmetric\nrank-1 matrices), following probability distributions that satisfy some mild\nconditions. In all these cases, we prove a fundamental result -- the recovery\nof matrices with parsimonious structures, using an optimal (or near optimal)\nnumber of measurements, is stable with high probability.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Li Yanjun","Lee Kiryung","Bresler Yoram"],"created":"2016-02-13","updated":"2017-12-22","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1602.08149","title":"Exponential capacity of associative memories under quantum annealing\n  recall","abstract":"Associative memory models, in theoretical neuro- and computer sciences, can\ngenerally store a sublinear number of memories. We show that using quantum\nannealing for recall tasks endows associative memory models with exponential\nstorage capacities. Theoretically, we obtain the radius of attractor basins,\n$R(N)$, and the capacity, $C(N)$, of such a scheme and their tradeoffs. Our\ncalculations establish that for randomly chosen memories the capacity of a\nmodel using the Hebbian learning rule with recall via quantum annealing is\nexponential in the size of the problem, $C(N)=\\mathcal{O}(e^{C_1N}),~C_1\\geq0$,\nand succeeds on randomly chosen memory sets with a probability of\n$(1-e^{-C_2N}),~C_2\\geq0$ with $C_1+C_2=(.5-f)^2\/(1-f)$, where,\n$f=R(N)\/N,~0\\leq f\\leq .5$ is the radius of attraction in terms of Hamming\ndistance of an input probe from a stored memory as a fraction of the problem\nsize. We demonstrate the application of this scheme on a programmable quantum\nannealing device - the Dwave processor.","primary_category":"cs","categories":["quant-ph","cs.OH"],"authors":["Santra Siddhartha","Shehab Omar","Balu Radhakrishnan"],"created":"2016-02-25","updated":" ","doi":"10.1103\/PhysRevA.96.062330"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1602.08313","title":"Enhancing Genetic Algorithms using Multi Mutations","abstract":"Mutation is one of the most important stages of the genetic algorithm because\nof its impact on the exploration of global optima, and to overcome premature\nconvergence. There are many types of mutation, and the problem lies in\nselection of the appropriate type, where the decision becomes more difficult\nand needs more trial and error. This paper investigates the use of more than\none mutation operator to enhance the performance of genetic algorithms. Novel\nmutation operators are proposed, in addition to two selection strategies for\nthe mutation operators, one of which is based on selecting the best mutation\noperator and the other randomly selects any operator. Several experiments on\nsome Travelling Salesman Problems (TSP) were conducted to evaluate the proposed\nmethods, and these were compared to the well-known exchange mutation and\nrearrangement mutation. The results show the importance of some of the proposed\nmethods, in addition to the significant enhancement of the genetic algorithm's\nperformance, particularly when using more than one mutation operator.","primary_category":"cs","categories":["cs.AI","cs.NE"],"authors":["Hassanat Ahmad B. A.","Alkafaween Esra'a","Al-Nawaiseh Nedal A.","Abbadi Mohammad A.","Alkasassbeh Mouhammd","Alhasanat Mahmoud B."],"created":"2016-02-26","updated":"2018-01-10","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1602.09107","title":"Estimation of Discretized Motion of Pedestrians by the Decision-Making\n  Model","abstract":"The contribution gives a micro-structural insight into the pedestrian\ndecision process during an egress situation. A method how to extract the\ndecisions of pedestrians from the trajectories recorded during the experiments\nis introduced. The underlying Markov decision process is estimated using the\nfinite mixture approximation. Furthermore, the results of this estimation can\nbe used as an input to the optimization of a Markov decision process for one\n`clever' agent. This agent optimizes his strategy of motion with respect to\ndifferent reward functions, minimizing the time spent in the room or minimizing\nthe amount of inhaled CO.","primary_category":"cs","categories":["cs.MA","cs.IT","math.IT"],"authors":["Hrab\u00e1k Pavel","Tich\u00e1\u010dek Ond\u0159ej","Se\u010dk\u00e1rov\u00e1 Vladim\u00edra"],"created":"2016-02-29","updated":" ","doi":"10.1007\/978-3-319-33482-0_40"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1603.02345","title":"Hand Segmentation for Hand-Object Interaction from Depth map","abstract":"Hand segmentation for hand-object interaction is a necessary preprocessing\nstep in many applications such as augmented reality, medical application, and\nhuman-robot interaction. However, typical methods are based on color\ninformation which is not robust to objects with skin color, skin pigment\ndifference, and light condition variations. Thus, we propose hand segmentation\nmethod for hand-object interaction using only a depth map. It is challenging\nbecause of the small depth difference between a hand and objects during an\ninteraction. To overcome this challenge, we propose the two-stage random\ndecision forest (RDF) method consisting of detecting hands and segmenting\nhands. To validate the proposed method, we demonstrate results on the publicly\navailable dataset of hand segmentation for hand-object interaction. The\nproposed method achieves high accuracy in short processing time comparing to\nthe other state-of-the-art methods.","primary_category":"cs","categories":["cs.CV"],"authors":["Kang Byeongkeun","Tan Kar-Han","Jiang Nan","Tai Hung-Shuo","Tretter Daniel","Nguyen Truong Q."],"created":"2016-03-07","updated":"2018-01-09","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1603.02611","title":"Scheduling meets n-fold Integer Programming","abstract":"Scheduling problems are fundamental in combinatorial optimization. Much work\nhas been done on approximation algorithms for NP-hard cases, but relatively\nlittle is known about exact solutions when some part of the input is a fixed\nparameter. In 2014, Mnich and Wiese initiated a systematic study in this\ndirection.\n  In this paper we continue this study and show that several additional cases\nof fundamental scheduling problems are fixed parameter tractable for some\nnatural parameters. Our main tool is n-fold integer programming, a recent\nvariable dimension technique which we believe to be highly relevant for the\nparameterized complexity community. This paper serves to showcase and highlight\nthis technique.\n  Specifically, we show the following four scheduling problems to be\nfixed-parameter tractable, where p max is the maximum processing time of a job\nand w max is the maximum weight of a job:\n  - Makespan minimization on uniformly related machines $(Q||C_{max} )$\nparameterized by $p_{max}$,\n  - Makespan minimization on unrelated machines $(R||C_{max} )$ parameterized\nby $p_{max}$ and the number of kinds of machines,\n  - Sum of weighted completion times minimization on unrelated machines $(R||\n\\sum w_i C_i )$ parameterized by $p_{max} + w_{max}$ and the number of kinds of\nmachines,\n  - The same problem, $(R|| \\sum w_i C_i),$ parameterized by the number of\ndistinct job times and the number of machines.","primary_category":"cs","categories":["cs.DS"],"authors":["Knop Du\u0161an","Kouteck\u00fd Martin"],"created":"2016-03-08","updated":"2017-02-14","doi":"10.1007\/s10951-017-0550-0"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1603.07285","title":"A guide to convolution arithmetic for deep learning","abstract":"We introduce a guide to help deep learning practitioners understand and\nmanipulate convolutional neural network architectures. The guide clarifies the\nrelationship between various properties (input shape, kernel shape, zero\npadding, strides and output shape) of convolutional, pooling and transposed\nconvolutional layers, as well as the relationship between convolutional and\ntransposed convolutional layers. Relationships are derived for various cases,\nand are illustrated in order to make them intuitive.","primary_category":"cs","categories":["stat.ML","cs.LG","cs.NE"],"authors":["Dumoulin Vincent","Visin Francesco"],"created":"2016-03-23","updated":"2018-01-11","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1603.08648","title":"A Comparison of NOOP to Structural Domain-Theoretic Models of OOP","abstract":"Mainstream object-oriented programming languages such as Java, C#, C++ and\nScala are all almost entirely nominally-typed. NOOP is a recently developed\ndomain-theoretic model of OOP that was designed to include full nominal\ninformation found in nominally-typed OOP. This paper compares NOOP to the most\nwidely known domain-theoretic models of OOP, namely, the models developed by\nCardelli and Cook, which were structurally-typed models. Leveraging the\ndevelopment of NOOP, the comparison presented in this paper provides a clear\nand precise mathematical account for the relation between nominal and\nstructural OO type systems.","primary_category":"cs","categories":["cs.PL"],"authors":["AbdelGawad Moez A."],"created":"2016-03-29","updated":"2017-12-29","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1604.00870","title":"Mixing Time for Some Adjacent Transposition Markov Chains","abstract":"We prove rapid mixing for certain Markov chains on the set $S_n$ of\npermutations on $1,2,\\dots,n$ in which adjacent transpositions are made with\nprobabilities that depend on the items being transposed. Typically, when in\nstate $\\sigma$, a position $i<n$ is chosen uniformly at random, and $\\sigma(i)$\nand $\\sigma(i{+}1)$ are swapped with probability depending on $\\sigma(i)$ and\n$\\sigma(i{+}1)$. The stationary distributions of such chains appear in various\nfields of theoretical computer science, and rapid mixing established in the\nuniform case.\n  Recently, there has been progress in cases with biased stationary\ndistributions, but there are wide classes of such chains whose mixing time is\nunknown. One case of particular interest is what we call the \"gladiator chain,\"\nin which each number $g$ is assigned a \"strength\" $s_g$ and when $g$ and $g'$\nare adjacent and chosen for possible swapping, $g$ comes out on top with\nprobability $s_g\/(s_g + s_{g'})$. We obtain a polynomial-time upper bound on\nmixing time when the gladiators fall into only three strength classes.\n  A preliminary version of this paper appeared as \"Mixing of Permutations by\nBiased Transposition\" in STACS 2017.","primary_category":"cs","categories":["cs.DS"],"authors":["Haddadan Shahrzad","Winkler Peter"],"created":"2016-04-04","updated":"2018-01-11","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1604.01175","title":"On the Combinatorial Complexity of Approximating Polytopes","abstract":"Approximating convex bodies succinctly by convex polytopes is a fundamental\nproblem in discrete geometry. A convex body $K$ of diameter $\\mathrm{diam}(K)$\nis given in Euclidean $d$-dimensional space, where $d$ is a constant. Given an\nerror parameter $\\varepsilon > 0$, the objective is to determine a polytope of\nminimum combinatorial complexity whose Hausdorff distance from $K$ is at most\n$\\varepsilon \\cdot \\mathrm{diam}(K)$. By combinatorial complexity we mean the\ntotal number of faces of all dimensions of the polytope. A well-known result by\nDudley implies that $O(1\/\\varepsilon^{(d-1)\/2})$ facets suffice, and a dual\nresult by Bronshteyn and Ivanov similarly bounds the number of vertices, but\nneither result bounds the total combinatorial complexity. We show that there\nexists an approximating polytope whose total combinatorial complexity is\n$\\tilde{O}(1\/\\varepsilon^{(d-1)\/2})$, where $\\tilde{O}$ conceals a\npolylogarithmic factor in $1\/\\varepsilon$. This is a significant improvement\nupon the best known bound, which is roughly $O(1\/\\varepsilon^{d-2})$.\n  Our result is based on a novel combination of both old and new ideas. First,\nwe employ Macbeath regions, a classical structure from the theory of convexity.\nThe construction of our approximating polytope employs a new stratified\nplacement of these regions. Second, in order to analyze the combinatorial\ncomplexity of the approximating polytope, we present a tight analysis of a\nwidth-based variant of B\\'{a}r\\'{a}ny and Larman's economical cap covering.\nFinally, we use a deterministic adaptation of the witness-collector technique\n(developed recently by Devillers et al.) in the context of our stratified\nconstruction.","primary_category":"cs","categories":["cs.CG","math.MG"],"authors":["Arya Sunil","da Fonseca Guilherme D.","Mount David M."],"created":"2016-04-05","updated":"2016-12-21","doi":"10.1007\/s00454-016-9856-5"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1604.01183","title":"Approximate Polytope Membership Queries","abstract":"In the polytope membership problem, a convex polytope $K$ in $\\mathbb{R}^d$\nis given, and the objective is to preprocess $K$ into a data structure so that,\ngiven any query point $q \\in \\mathbb{R}^d$, it is possible to determine\nefficiently whether $q \\in K$. We consider this problem in an approximate\nsetting. Given an approximation parameter $\\varepsilon$, the query can be\nanswered either way if the distance from $q$ to $K$'s boundary is at most\n$\\varepsilon$ times $K$'s diameter. We assume that the dimension $d$ is fixed,\nand $K$ is presented as the intersection of $n$ halfspaces. Previous solutions\nto approximate polytope membership were based on straightforward applications\nof classic polytope approximation techniques by Dudley (1974) and Bentley et\nal. (1982). The former is optimal in the worst-case with respect to space, and\nthe latter is optimal with respect to query time.\n  We present four main results. First, we show how to combine the two above\ntechniques to obtain a simple space-time trade-off. Second, we present an\nalgorithm that dramatically improves this trade-off. In particular, for any\nconstant $\\alpha \\ge 4$, this data structure achieves query time\n$O(1\/\\varepsilon^{(d-1)\/\\alpha})$ and space roughly $O(1\/\\varepsilon^{(d-1)(1 -\nO(\\log \\alpha)\/\\alpha)})$. We do not know whether this space bound is tight,\nbut our third result shows that there is a convex body such that our algorithm\nachieves a space of at least $\\Omega(\n1\/\\varepsilon^{(d-1)(1-O(\\sqrt{\\alpha})\/\\alpha} )$. Our fourth result shows\nthat it is possible to reduce approximate Euclidean nearest neighbor searching\nto approximate polytope membership queries. Combined with the above results,\nthis provides significant improvements to the best known space-time trade-offs\nfor approximate nearest neighbor searching in $\\mathbb{R}^d$.","primary_category":"cs","categories":["cs.CG"],"authors":["Arya Sunil","da Fonseca Guilherme D.","Mount David M."],"created":"2016-04-05","updated":"2017-06-26","doi":"10.1137\/16M1061096"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1604.02532","title":"T-CNN: Tubelets with Convolutional Neural Networks for Object Detection\n  from Videos","abstract":"The state-of-the-art performance for object detection has been significantly\nimproved over the past two years. Besides the introduction of powerful deep\nneural networks such as GoogleNet and VGG, novel object detection frameworks\nsuch as R-CNN and its successors, Fast R-CNN and Faster R-CNN, play an\nessential role in improving the state-of-the-art. Despite their effectiveness\non still images, those frameworks are not specifically designed for object\ndetection from videos. Temporal and contextual information of videos are not\nfully investigated and utilized. In this work, we propose a deep learning\nframework that incorporates temporal and contextual information from tubelets\nobtained in videos, which dramatically improves the baseline performance of\nexisting still-image detection frameworks when they are applied to videos. It\nis called T-CNN, i.e. tubelets with convolutional neueral networks. The\nproposed framework won the recently introduced object-detection-from-video\n(VID) task with provided data in the ImageNet Large-Scale Visual Recognition\nChallenge 2015 (ILSVRC2015).","primary_category":"cs","categories":["cs.CV"],"authors":["Kang Kai","Li Hongsheng","Yan Junjie","Zeng Xingyu","Yang Bin","Xiao Tong","Zhang Cong","Wang Zhe","Wang Ruohui","Wang Xiaogang","Ouyang Wanli"],"created":"2016-04-09","updated":"2017-08-03","doi":"10.1109\/TCSVT.2017.2736553"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1604.05225","title":"Annotation Order Matters: Recurrent Image Annotator for Arbitrary Length\n  Image Tagging","abstract":"Automatic image annotation has been an important research topic in\nfacilitating large scale image management and retrieval. Existing methods focus\non learning image-tag correlation or correlation between tags to improve\nannotation accuracy. However, most of these methods evaluate their performance\nusing top-k retrieval performance, where k is fixed. Although such setting\ngives convenience for comparing different methods, it is not the natural way\nthat humans annotate images. The number of annotated tags should depend on\nimage contents. Inspired by the recent progress in machine translation and\nimage captioning, we propose a novel Recurrent Image Annotator (RIA) model that\nforms image annotation task as a sequence generation problem so that RIA can\nnatively predict the proper length of tags according to image contents. We\nevaluate the proposed model on various image annotation datasets. In addition\nto comparing our model with existing methods using the conventional top-k\nevaluation measures, we also provide our model as a high quality baseline for\nthe arbitrary length image tagging task. Moreover, the results of our\nexperiments show that the order of tags in training phase has a great impact on\nthe final annotation performance.","primary_category":"cs","categories":["cs.CV","cs.AI"],"authors":["Jin Jiren","Nakayama Hideki"],"created":"2016-04-18","updated":"2016-12-07","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1604.08226","title":"Influence of Agents Heterogeneity in Cellular Model of Evacuation","abstract":"The influence of agents heterogeneity on the microscopic characteristics of\npedestrian flow is studied via an evacuation simulation tool based on the\nFloor-Field model. The heterogeneity is introduced in agents velocity,\naggressiveness, and sensitivity to occupation. The simulation results are\ncompared to data gathered during an original experiment. The comparison shows\nthat the heterogeneity in aggressiveness and sensitivity occupation enables to\nreproduce some microscopic aspects. The heterogeneity in velocity seems to be\nredundant.","primary_category":"cs","categories":["cs.MA"],"authors":["Hrab\u00e1k Pavel","Buk\u00e1\u010dek Marek"],"created":"2016-04-27","updated":" ","doi":"10.1016\/j.jocs.2016.08.002"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1605.01480","title":"Towards Understanding Generics in Mainstream OOP","abstract":"This article reports on steps towards building a simple and accurate\ndomain-theoretic model of generic nominally-typed OOP.","primary_category":"cs","categories":["cs.PL"],"authors":["AbdelGawad Moez A."],"created":"2016-05-04","updated":"2017-12-29","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1605.04000","title":"The nonnegative rank of a matrix: Hard problems, easy solutions","abstract":"Using elementary linear algebra, we develop a technique that leads to\nsolutions of two widely known problems on nonnegative matrices. First, we give\na short proof of the result by Vavasis stating that the nonnegative rank of a\nmatrix is NP-hard to compute. This proof is essentially contained in the paper\nby Jiang and Ravikumar, who discussed this topic in different terms fifteen\nyears before the work of Vavasis. Secondly, we present a solution of the\nproblem of Cohen and Rothblum on rational nonnegative factorizations, which was\nposed in 1993 and remained open.","primary_category":"cs","categories":["math.CO","cs.CC"],"authors":["Shitov Yaroslav"],"created":"2016-05-12","updated":"2017-12-28","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1605.06304","title":"Local communities obstruct global consensus: Naming game on\n  multi-local-world networks","abstract":"Community structure is essential for social communications, where individuals\nbelonging to the same community are much more actively interacting and\ncommunicating with each other than those in different communities within the\nhuman society. Naming game, on the other hand, is a social communication model\nthat simulates the process of learning a name of an object within a community\nof humans, where the individuals can generally reach global consensus\nasymptotically through iterative pair-wise conversations. The underlying\nnetwork indicates the relationships among the individuals. In this paper, three\ntypical topologies, namely random-graph, small-world and scale-free networks,\nare employed, which are embedded with the multi-local-world community\nstructure, to study the naming game. Simulations show that 1) the convergence\nprocess to global consensus is getting slower as the community structure\nbecomes more prominent, and eventually might fail; 2) if the inter-community\nconnections are sufficiently dense, neither the number nor the size of the\ncommunities affects the convergence process; and 3) for different topologies\nwith the same average node-degree, local clustering of individuals obstruct or\nprohibit global consensus to take place. The results reveal the role of local\ncommunities in a global naming game in social network studies.","primary_category":"cs","categories":["cs.SI","cs.CL","physics.soc-ph"],"authors":["Lou Yang","Chen Guanrong","Fan Zhengping","Xiang Luna"],"created":"2016-05-20","updated":"2018-01-03","doi":"10.1016\/j.physa.2017.11.094"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1605.08951","title":"A handle is enough for a hard game of Pull","abstract":"We are going to show that some variants of a puzzle called Pull in which the\nboxes have handles (i.e. we can only pull the boxes in certain directions) are\nNP-hard","primary_category":"cs","categories":["cs.CC"],"authors":["Temprano Oscar"],"created":"2016-05-28","updated":"2017-12-28","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1605.09332","title":"Parametric Exponential Linear Unit for Deep Convolutional Neural\n  Networks","abstract":"Object recognition is an important task for improving the ability of visual\nsystems to perform complex scene understanding. Recently, the Exponential\nLinear Unit (ELU) has been proposed as a key component for managing bias shift\nin Convolutional Neural Networks (CNNs), but defines a parameter that must be\nset by hand. In this paper, we propose learning a parameterization of ELU in\norder to learn the proper activation shape at each layer in the CNNs. Our\nresults on the MNIST, CIFAR-10\/100 and ImageNet datasets using the NiN,\nOverfeat, All-CNN and ResNet networks indicate that our proposed Parametric ELU\n(PELU) has better performances than the non-parametric ELU. We have observed as\nmuch as a 7.28% relative error improvement on ImageNet with the NiN network,\nwith only 0.0003% parameter increase. Our visual examination of the non-linear\nbehaviors adopted by Vgg using PELU shows that the network took advantage of\nthe added flexibility by learning different activations at different layers.","primary_category":"cs","categories":["cs.LG","cs.CV","cs.NE"],"authors":["Trottier Ludovic","Gigu\u00e8re Philippe","Chaib-draa Brahim"],"created":"2016-05-30","updated":"2018-01-10","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1606.02194","title":"The Price of Anarchy in Transportation Networks: Data-Driven Evaluation\n  and Reduction Strategies","abstract":"Among the many functions a Smart City must support, transportation dominates\nin terms of resource consumption, strain on the environment, and frustration of\nits citizens. We study transportation networks under two different routing\npolicies, the commonly assumed selfish user-centric routing policy and a\nsocially-optimal system-centric one. We consider a performance metric of\nefficiency - the Price of Anarchy (PoA) - defined as the ratio of the total\ntravel latency cost under selfish routing over the corresponding quantity under\nsocially-optimal routing. We develop a data-driven approach to estimate the\nPoA, which we subsequently use to conduct a case study using extensive actual\ntraffic data from the Eastern Massachusetts road network. To estimate the PoA,\nour approach learns from data a complete model of the transportation network,\nincluding origin-destination demand and user preferences. We leverage this\nmodel to propose possible strategies to reduce the PoA and increase efficiency.","primary_category":"cs","categories":["math.OC","cs.GT"],"authors":["Zhang Jing","Pourazarm Sepideh","Cassandras Christos G.","Paschalidis Ioannis Ch."],"created":"2016-06-07","updated":"2018-01-03","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1606.02455","title":"The Internet of Things for Aging and Independent Living: A Modeling and\n  Simulation Study","abstract":"Population aging is affecting many countries, Sweden being one of them, and\nit may lead to a shortage of caregivers for elderly people in near future.\nSmart interconnected devices known as the Internet of Things may help elderly\nto live independently at home and avoid unnecessary hospital stay. For\ninstance, a carephone device enables the elderly to establish a communication\nlink with caregivers and ask for help when it is needed. In this paper, we\ndescribe a simulation study of the care giving system in the V\\\"axj\\\"o\nmunicipality in Sweden. The simulation model can be used to address various\nissues, such as, determining the lack or excess of resources or long waiting\ntimes, and study the system behavior when the number of alarms is increased.","primary_category":"cs","categories":["cs.CY"],"authors":["Perez David","Memeti Suejb","Pllana Sabri"],"created":"2016-06-08","updated":"2017-12-31","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1606.03809","title":"Why Nominal-Typing Matters in OOP","abstract":"The statements `inheritance is not subtyping' and `mainstream OO languages\nunnecessarily place restrictions over inheritance' have rippled as mantras\nthrough the PL research community for years. Many mainstream OO developers and\nOO language designers however do not accept these statements. In\n\\emph{nominally-typed} OO languages that these developers and language\ndesigners are dearly familiar with, inheritance simply is subtyping; and they\nbelieve OO type inheritance is an inherently nominal notion not a structural\none.\n  Nominally-typed OO languages are among the most used programming languages\ntoday. However, the value of nominal typing to mainstream OO developers, as a\nmeans for designing robust OO software, seems to be in wait for full\nappreciation among PL researchers--thereby perpetuating an unnecessary schism\nbetween many OO developers and language designers and many OO PL researchers,\nwith each side discounting, if not even disregarding, the views of the other.\n  In this essay we strengthen earlier efforts to demonstrate the semantic value\nof nominal typing by presenting a technical comparison between nominal OO type\nsystems and structural OO type systems. Recently, a domain-theoretic model of\nnominally-typed OOP was compared to well-known models of structurally-typed\nOOP. Combined, these comparisons provide a clear and deep account for the\nrelation between nominal and structural OO type systems that has not been\npresented before, and they help demonstrate the key value of nominal typing and\nnominal subtyping to OO developers and language designers.\n  We believe a clearer understanding of the key semantic advantage of pure\nnominal OO typing over pure structural OO typing can help remedy the existing\nschism. We believe future foundational OO PL research, to further its relevance\nto mainstream OOP, should be based less on structural models of OOP and more on\nnominal ones instead.","primary_category":"cs","categories":["cs.PL"],"authors":["AbdelGawad Moez A."],"created":"2016-06-13","updated":"2017-12-29","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1606.04080","title":"Matching Networks for One Shot Learning","abstract":"Learning from a few examples remains a key challenge in machine learning.\nDespite recent advances in important domains such as vision and language, the\nstandard supervised deep learning paradigm does not offer a satisfactory\nsolution for learning new concepts rapidly from little data. In this work, we\nemploy ideas from metric learning based on deep neural features and from recent\nadvances that augment neural networks with external memories. Our framework\nlearns a network that maps a small labelled support set and an unlabelled\nexample to its label, obviating the need for fine-tuning to adapt to new class\ntypes. We then define one-shot learning problems on vision (using Omniglot,\nImageNet) and language tasks. Our algorithm improves one-shot accuracy on\nImageNet from 87.6% to 93.2% and from 88.0% to 93.8% on Omniglot compared to\ncompeting approaches. We also demonstrate the usefulness of the same model on\nlanguage modeling by introducing a one-shot task on the Penn Treebank.","primary_category":"cs","categories":["cs.LG","stat.ML"],"authors":["Vinyals Oriol","Blundell Charles","Lillicrap Timothy","Kavukcuoglu Koray","Wierstra Daan"],"created":"2016-06-13","updated":"2017-12-29","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1606.05123","title":"Revisiting the Majority Problem: Average-Case Analysis with Arbitrarily\n  Many Colours","abstract":"The majority problem is a special case of the heavy hitters problem. Given a\ncollection of coloured balls, the task is to identify the majority colour or\nstate that no such colour exists. Whilst the special case of two-colours has\nbeen well studied, the average-case performance for arbitrarily many colours\nhas not. In this paper, we present heuristic analysis of the average-case\nperformance of three deterministic algorithms that appear in the literature. We\nempirically validate our analysis with large scale simulations.","primary_category":"cs","categories":["cs.DS"],"authors":["Kleerekoper Anthony"],"created":"2016-06-16","updated":"2018-01-04","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1606.05525","title":"On the Zero Defect Conjecture","abstract":"Brlek et al. conjectured in 2008 that any fixed point of a primitive morphism\nwith finite palindromic defect is either periodic or its palindromic defect is\nzero. Bucci and Vaslet disproved this conjecture in 2012 by a counterexample\nover ternary alphabet. We prove that the conjecture is valid on binary\nalphabet. We also describe a class of morphisms over multiliteral alphabet for\nwhich the conjecture still holds. The proof is based on properties of extension\ngraphs.","primary_category":"cs","categories":["math.CO","cs.FL"],"authors":["Labb\u00e9 S\u00e9bastien","Pelantov\u00e1 Edita","Starosta \u0160t\u011bp\u00e1n"],"created":"2016-06-17","updated":"2016-11-07","doi":"10.1016\/j.ejc.2016.12.006"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1606.05556","title":"A critical analysis of some popular methods for the discretisation of\n  the gradient operator in finite volume methods","abstract":"Finite volume methods (FVMs) constitute a popular class of methods for the\nnumerical simulation of fluid flows. Among the various components of these\nmethods, the discretisation of the gradient operator has received less\nattention despite its fundamental importance with regards to the accuracy of\nthe FVM. The most popular gradient schemes are the divergence theorem (DT) (or\nGreen-Gauss) scheme, and the least-squares (LS) scheme. Both are widely\nbelieved to be second-order accurate, but the present study shows that in fact\nthe common variant of the DT gradient is second-order accurate only on\nstructured meshes whereas it is zeroth-order accurate on general unstructured\nmeshes, and the LS gradient is second-order and first-order accurate,\nrespectively. This is explained through a theoretical analysis and is confirmed\nby numerical tests. The schemes are then used within a FVM to solve a simple\ndiffusion equation on unstructured grids generated by several methods; the\nresults reveal that the zeroth-order accuracy of the DT gradient is inherited\nby the FVM as a whole, and the discretisation error does not decrease with grid\nrefinement. On the other hand, use of the LS gradient leads to second-order\naccurate results, as does the use of alternative, consistent, DT gradient\nschemes, including a new iterative scheme that makes the common DT gradient\nconsistent at almost no extra cost. The numerical tests are performed using\nboth an in-house code and the popular public domain PDE solver OpenFOAM.","primary_category":"cs","categories":["cs.NA","cs.CE"],"authors":["Syrakos Alexandros","Varchanis Stylianos","Dimakopoulos Yannis","Goulas Apostolos","Tsamopoulos John"],"created":"2016-06-17","updated":"2017-12-29","doi":"10.1063\/1.4997682"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1606.07457","title":"Device and Circuit Interaction Analysis of Stochastic Behaviors in\n  Cross-Point RRAM Arrays","abstract":"Stochastic behaviors of resistive random access memory (RRAM) play an\nimportant role in the design of cross-point memory arrays. A Monte Carlo\ncompact model of oxide RRAM is developed and calibrated with experiments on\nvarious device stack configurations. With Monte Carlo SPICE simulations, we\nshow that an increase in array size and interconnect wire resistance will\nstatistically deteriorate write functionality. Write failure probability (WFP)\nhas an exponential dependency on device uniformity and supply voltage (VDD),\nand the array bias scheme is a key knob. Lowering array VDD leads to higher\neffective energy consumption (EEC) due to the increase in WFP when the\nvariation statistics are included in the analysis. Random-access simulations\nindicate that data sparsity statistically benefits write functionality and\nenergy consumption. Finally, we show that a pseudo-sub-array topology with\nuniformly distributed pre-forming cells in the pristine high resistance state\nis able to reduce both WFP and EEC, enabling higher net capacity for memory\ncircuits due to improved variation tolerance.","primary_category":"cs","categories":["cs.ET"],"authors":["Li Haitong","Huang Peng","Gao Bin","Liu Xiaoyan","Kang Jinfeng","Wong H. -S. Philip"],"created":"2016-06-23","updated":"2018-01-01","doi":"10.1109\/TED.2017.2766046"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1606.07659","title":"Hybrid Recommender System based on Autoencoders","abstract":"A standard model for Recommender Systems is the Matrix Completion setting:\ngiven partially known matrix of ratings given by users (rows) to items\n(columns), infer the unknown ratings. In the last decades, few attempts where\ndone to handle that objective with Neural Networks, but recently an\narchitecture based on Autoencoders proved to be a promising approach. In\ncurrent paper, we enhanced that architecture (i) by using a loss function\nadapted to input data with missing values, and (ii) by incorporating side\ninformation. The experiments demonstrate that while side information only\nslightly improve the test error averaged on all users\/items, it has more impact\non cold users\/items.","primary_category":"cs","categories":["cs.LG","cs.IR"],"authors":["Strub Florian","Gaudel Romaric","Mary J\u00e9r\u00e9mie"],"created":"2016-06-24","updated":"2017-12-29","doi":"10.1145\/2988450.2988456"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1606.08036","title":"The bounded and precise word problems for presentations of groups","abstract":"We introduce and study the bounded word problem and the precise word problem\nfor groups given by means of generators and defining relations. For example,\nfor every finitely presented group, the bounded word problem is in NP, i.e., it\ncan be solved in nondeterministic polynomial time, and the precise word problem\nis in PSPACE. The main technical result of the paper states that, for certain\nfinite presentations of groups, which include the Baumslag-Solitar one-relator\ngroups and free products of cyclic groups, the bounded word problem and the\nprecise word problem can be solved in polylogarithmic space. As consequences of\ndeveloped techniques that can be described as calculus of brackets, we obtain\npolylogarithmic space bounds for the computational complexity of the diagram\nproblem for free groups, for the width problem for elements of free groups, and\nfor computation of the area defined by polygonal singular closed curves in the\nplane. We also obtain polynomial time bounds for these problems.","primary_category":"cs","categories":["math.GR","cs.CG"],"authors":["Ivanov Sergei V."],"created":"2016-06-26","updated":"2017-12-29","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1606.08920","title":"Exact Lower Bounds for the Agnostic Probably-Approximately-Correct (PAC)\n  Machine Learning Model","abstract":"We provide an exact non-asymptotic lower bound on the minimax expected excess\nrisk (EER) in the agnostic probably-ap\\-proximately-correct (PAC) machine\nlearning classification model and identify minimax learning algorithms as\ncertain maximally symmetric and minimally randomized \"voting\" procedures. Based\non this result, an exact asymptotic lower bound on the minimax EER is provided.\nThis bound is of the simple form $c_\\infty\/\\sqrt{\\nu}$ as $\\nu\\to\\infty$, where\n$c_\\infty=0.16997\\dots$ is a universal constant, $\\nu=m\/d$, $m$ is the size of\nthe training sample, and $d$ is the Vapnik--Chervonenkis dimension of the\nhypothesis class. It is shown that the differences between these asymptotic and\nnon-asymptotic bounds, as well as the differences between these two bounds and\nthe maximum EER of any learning algorithms that minimize the empirical risk,\nare asymptotically negligible, and all these differences are due to ties in the\nmentioned \"voting\" procedures. A few easy to compute non-asymptotic lower\nbounds on the minimax EER are also obtained, which are shown to be close to the\nexact asymptotic lower bound $c_\\infty\/\\sqrt{\\nu}$ even for rather small values\nof the ratio $\\nu=m\/d$. As an application of these results, we substantially\nimprove existing lower bounds on the tail probability of the excess risk. Among\nthe tools used are Bayes estimation and apparently new identities and\ninequalities for binomial distributions.","primary_category":"cs","categories":["cs.LG","math.PR","math.ST","stat.TH"],"authors":["Kontorovich Aryeh","Pinelis Iosif"],"created":"2016-06-28","updated":"2017-12-30","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1606.09233","title":"Unequal Error Protection Querying Policies for the Noisy 20 Questions\n  Problem","abstract":"In this paper, we propose an open-loop unequal-error-protection querying\npolicy based on superposition coding for the noisy 20 questions problem. In\nthis problem, a player wishes to successively refine an estimate of the value\nof a continuous random variable by posing binary queries and receiving noisy\nresponses. When the queries are designed non-adaptively as a single block and\nthe noisy responses are modeled as the output of a binary symmetric channel the\n20 questions problem can be mapped to an equivalent problem of channel coding\nwith unequal error protection (UEP). A new non-adaptive querying strategy based\non UEP superposition coding is introduced whose estimation error decreases with\nan exponential rate of convergence that is significantly better than that of\nthe UEP repetition coding introduced by Variani et al. (2015). With the\nproposed querying strategy, the rate of exponential decrease in the number of\nqueries matches the rate of a closed-loop adaptive scheme where queries are\nsequentially designed with the benefit of feedback. Furthermore, the achievable\nerror exponent is significantly better than that of random block codes\nemploying equal error protection.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Chung Hye Won","Sadler Brian M.","Zheng Lizhong","Hero Alfred O."],"created":"2016-06-29","updated":"2017-09-28","doi":"10.1109\/TIT.2017.2760634"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1607.00470","title":"Keyframe-based monocular SLAM: design, survey, and future directions","abstract":"Extensive research in the field of monocular SLAM for the past fifteen years\nhas yielded workable systems that found their way into various applications in\nrobotics and augmented reality. Although filter-based monocular SLAM systems\nwere common at some time, the more efficient keyframe-based solutions are\nbecoming the de facto methodology for building a monocular SLAM system. The\nobjective of this paper is threefold: first, the paper serves as a guideline\nfor people seeking to design their own monocular SLAM according to specific\nenvironmental constraints. Second, it presents a survey that covers the various\nkeyframe-based monocular SLAM systems in the literature, detailing the\ncomponents of their implementation, and critically assessing the specific\nstrategies made in each proposed solution. Third, the paper provides insight\ninto the direction of future research in this field, to address the major\nlimitations still facing monocular SLAM; namely, in the issues of illumination\nchanges, initialization, highly dynamic motion, poorly textured scenes,\nrepetitive textures, map maintenance, and failure recovery.","primary_category":"cs","categories":["cs.CV","cs.RO"],"authors":["Younes Georges","Asmar Daniel","Shammas Elie","Zelek John"],"created":"2016-07-02","updated":"2018-01-07","doi":"10.1016\/j.robot.2017.09.010"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1607.01167","title":"Deterministic polynomial-time approximation algorithms for partition\n  functions and graph polynomials","abstract":"In this paper we show a new way of constructing deterministic polynomial-time\napproximation algorithms for computing complex-valued evaluations of a large\nclass of graph polynomials on bounded degree graphs. In particular, our\napproach works for the Tutte polynomial and independence polynomial, as well as\npartition functions of complex-valued spin and edge-coloring models.\n  More specifically, we define a large class of graph polynomials $\\mathcal C$\nand show that if $p\\in \\cal C$ and there is a disk $D$ centered at zero in the\ncomplex plane such that $p(G)$ does not vanish on $D$ for all bounded degree\ngraphs $G$, then for each $z$ in the interior of $D$ there exists a\ndeterministic polynomial-time approximation algorithm for evaluating $p(G)$ at\n$z$. This gives an explicit connection between absence of zeros of graph\npolynomials and the existence of efficient approximation algorithms, allowing\nus to show new relationships between well-known conjectures.\n  Our work builds on a recent line of work initiated by. Barvinok, which\nprovides a new algorithmic approach besides the existing Markov chain Monte\nCarlo method and the correlation decay method for these types of problems.","primary_category":"cs","categories":["math.CO","cs.CC","cs.DM","cs.DS"],"authors":["Patel Viresh","Regts Guus"],"created":"2016-07-05","updated":"2017-07-18","doi":"10.1137\/16M1101003"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1607.01217","title":"Identification of block-oriented nonlinear systems starting from linear\n  approximations: A survey","abstract":"Block-oriented nonlinear models are popular in nonlinear system\nidentification because of their advantages of being simple to understand and\neasy to use. Many different identification approaches were developed over the\nyears to estimate the parameters of a wide range of block-oriented nonlinear\nmodels. One class of these approaches uses linear approximations to initialize\nthe identification algorithm. The best linear approximation framework and the\n$\\epsilon$-approximation framework, or equivalent frameworks, allow the user to\nextract important information about the system, guide the user in selecting\ngood candidate model structures and orders, and prove to be a good starting\npoint for nonlinear system identification algorithms. This paper gives an\noverview of the different block-oriented nonlinear models that can be\nidentified using linear approximations, and of the identification algorithms\nthat have been developed in the past. A non-exhaustive overview of the most\nimportant other block-oriented nonlinear system identification approaches is\nalso provided throughout this paper.","primary_category":"cs","categories":["cs.SY"],"authors":["Schoukens Maarten","Tiels Koen"],"created":"2016-07-05","updated":"2018-01-09","doi":"10.1016\/j.automatica.2017.06.044"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1607.03766","title":"AudioPairBank: Towards A Large-Scale Tag-Pair-Based Audio Content\n  Analysis","abstract":"Recently, sound recognition has been used to identify sounds, such as car and\nriver. However, sounds have nuances that may be better described by\nadjective-noun pairs such as slow car, and verb-noun pairs such as flying\ninsects, which are under explored. Therefore, in this work we investigate the\nrelation between audio content and both adjective-noun pairs and verb-noun\npairs. Due to the lack of datasets with these kinds of annotations, we\ncollected and processed the AudioPairBank corpus consisting of a combined total\nof 1,123 pairs and over 33,000 audio files. One contribution is the previously\nunavailable documentation of the challenges and implications of collecting\naudio recordings with these type of labels. A second contribution is to show\nthe degree of correlation between the audio content and the labels through\nsound recognition experiments, which yielded results of 70% accuracy, hence\nalso providing a performance benchmark. The results and study in this paper\nencourage further exploration of the nuances in audio and are meant to\ncomplement similar research performed on images and text in multimedia\nanalysis.","primary_category":"cs","categories":["cs.SD","cs.CL"],"authors":["Sager Sebastian","Elizalde Benjamin","Borth Damian","Schulze Christian","Raj Bhiksha","Lane Ian"],"created":"2016-07-13","updated":"2018-01-08","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1607.07676","title":"Complexity of Token Swapping and its Variants","abstract":"In the Token Swapping problem we are given a graph with a token placed on\neach vertex. Each token has exactly one destination vertex, and we try to move\nall the tokens to their destinations, using the minimum number of swaps, i.e.,\noperations of exchanging the tokens on two adjacent vertices. As the main\nresult of this paper, we show that Token Swapping is $W[1]$-hard parameterized\nby the length $k$ of a shortest sequence of swaps. In fact, we prove that, for\nany computable function $f$, it cannot be solved in time $f(k)n^{o(k \/ \\log\nk)}$ where $n$ is the number of vertices of the input graph, unless the ETH\nfails. This lower bound almost matches the trivial $n^{O(k)}$-time algorithm.\n  We also consider two generalizations of the Token Swapping, namely Colored\nToken Swapping (where the tokens have different colors and tokens of the same\ncolor are indistinguishable), and Subset Token Swapping (where each token has a\nset of possible destinations). To complement the hardness result, we prove that\neven the most general variant, Subset Token Swapping, is FPT in nowhere-dense\ngraph classes.\n  Finally, we consider the complexities of all three problems in very\nrestricted classes of graphs: graphs of bounded treewidth and diameter, stars,\ncliques, and paths, trying to identify the borderlines between polynomial and\nNP-hard cases.","primary_category":"cs","categories":["cs.CC","cs.DM","cs.DS"],"authors":["Bonnet \u00c9douard","Miltzow Tillmann","Rz\u0105\u017cewski Pawe\u0142"],"created":"2016-07-26","updated":"2018-01-05","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1607.08303","title":"The intersection of subgroups in free groups and linear programming","abstract":"We study the intersection of finitely generated subgroups of free groups by\nutilizing the method of linear programming. We prove that if $H_1$ is a\nfinitely generated subgroup of a free group $F$, then the WN-coefficient\n$\\sigma(H_1)$ of $H_1$ is rational and can be computed in deterministic\nexponential time in the size of $H_1$. This coefficient $\\sigma(H_1)$ is the\nminimal nonnegative real number such that, for every finitely generated\nsubgroup $H_2$ of $F$, it is true that $\\bar {\\rm r}(H_1, H_2) \\le \\sigma(H_1)\n\\bar {\\rm r}(H_1) \\bar {\\rm r}(H_2)$, where $\\bar{ {\\rm r}} (H) := \\max ( {\\rm\nr} (H)-1,0)$ is the reduced rank of $H$, ${\\rm r} (H)$ is the rank of $H$, and\n$\\bar {\\rm r}(H_1, H_2)$ is the reduced rank of the generalized intersection of\n$H_1$ and $H_2$. We also show the existence of a subgroup $H_2^* = H_2^*(H_1)$\nof $F$ such that $\\bar {\\rm r}(H_1, H_2^*) = \\sigma(H_1) \\bar {\\rm r}(H_1) \\bar\n{\\rm r}(H_2^*)$, the Stallings graph $\\Gamma(H_2^*)$ of $H_2^*$ has at most\ndoubly exponential size in the size of $H_1$ and $\\Gamma(H_2^*)$ can be\nconstructed in exponential time in the size of $H_1$.","primary_category":"cs","categories":["math.GR","cs.DM","math.OC"],"authors":["Ivanov Sergei V."],"created":"2016-07-27","updated":"2017-12-31","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1608.01611","title":"Deploying learning materials to game content for serious education game\n  development: A case study","abstract":"The ultimate goals of serious education games (SEG) are to facilitate\nlearning and maximizing enjoyment during playing SEGs. In SEG development,\nthere are normally two spaces to be taken into account: knowledge space\nregarding learning materials and content space regarding games to be used to\nconvey learning materials. How to deploy the learning materials seamlessly and\neffectively into game content becomes one of the most challenging problems in\nSEG development. Unlike previous work where experts in education have to be\nused heavily, we proposed a novel approach that works toward minimizing the\nefforts of education experts in mapping learning materials to content space.\nFor a proof-of-concept, we apply the proposed approach in developing an SEG\ngame, named \\emph{Chem Dungeon}, as a case study in order to demonstrate the\neffectiveness of our proposed approach. This SEG game has been tested with a\nnumber of users, and the user survey suggests our method works reasonably well.","primary_category":"cs","categories":["cs.AI","cs.CY","cs.HC"],"authors":["Rosyid Harits Ar","Palmerlee Matt","Chen Ke"],"created":"2016-08-04","updated":" ","doi":"10.1016\/j.entcom.2018.01.001"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1608.02374","title":"Exact quantum query complexity of $\\rm{EXACT}_{k,l}^n$","abstract":"In the exact quantum query model a successful algorithm must always output\nthe correct function value. We investigate the function that is true if exactly\n$k$ or $l$ of the $n$ input bits given by an oracle are 1. We find an optimal\nalgorithm (for some cases), and a nontrivial general lower and upper bound on\nthe minimum number of queries to the black box.","primary_category":"cs","categories":["quant-ph","cs.CC"],"authors":["Ambainis Andris","Iraids J\u0101nis","Nagaj Daniel"],"created":"2016-08-08","updated":"2017-01-25","doi":"10.1007\/978-3-319-51963-0_19"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1608.03351","title":"Uplink-Downlink Duality for Integer-Forcing","abstract":"Consider a Gaussian multiple-input multiple-output (MIMO) multiple-access\nchannel (MAC) with channel matrix $\\mathbf{H}$ and a Gaussian MIMO broadcast\nchannel (BC) with channel matrix $\\mathbf{H}^{\\mathsf{T}}$. For the MIMO MAC,\nthe integer-forcing architecture consists of first decoding integer-linear\ncombinations of the transmitted codewords, which are then solved for the\noriginal messages. For the MIMO BC, the integer-forcing architecture consists\nof pre-inverting the integer-linear combinations at the transmitter so that\neach receiver can obtain its desired codeword by decoding an integer-linear\ncombination. In both cases, integer-forcing offers higher achievable rates than\nzero-forcing while maintaining a similar implementation complexity. This paper\nestablishes an uplink-downlink duality relationship for integer-forcing, i.e.,\nany sum rate that is achievable via integer-forcing on the MIMO MAC can be\nachieved via integer-forcing on the MIMO BC with the same sum power and vice\nversa. Using this duality relationship, it is shown that integer-forcing can\noperate within a constant gap of the MIMO BC sum capacity. Finally, the paper\nproposes a duality-based iterative algorithm for the non-convex problem of\nselecting optimal beamforming and equalization vectors, and establishes that it\nconverges to a local optimum.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["He Wenbo","Nazer Bobak","Shamai Shlomo"],"created":"2016-08-10","updated":"2018-01-06","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1608.05188","title":"Quantum Entanglement Distribution in Next-Generation Wireless\n  Communication Systems","abstract":"In this work we analyze the distribution of quantum entanglement over\ncommunication channels in the millimeter-wave regime. The motivation for such a\nstudy is the possibility for next-generation wireless networks (beyond 5G) to\naccommodate such a distribution directly - without the need to integrate\nadditional optical communication hardware into the transceivers. Future\nwireless communication systems are bound to require some level of quantum\ncommunications capability. We find that direct quantum-entanglement\ndistribution in the millimeter-wave regime is indeed possible, but that its\nimplementation will be very demanding from both a system-design perspective and\na channel-requirement perspective.","primary_category":"cs","categories":["quant-ph","cs.CR","cs.IT","math.IT"],"authors":["Hosseinidehaj Nedasadat","Malaney Robert"],"created":"2016-08-18","updated":" ","doi":"10.1109\/VTCSpring.2017.8108494"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1608.05288","title":"Accelerating Exact and Approximate Inference for (Distributed) Discrete\n  Optimization with GPUs","abstract":"Discrete optimization is a central problem in artificial intelligence. The\noptimization of the aggregated cost of a network of cost functions arises in a\nvariety of problems including (W)CSP, DCOP, as well as optimization in\nstochastic variants such as the tasks of finding the most probable explanation\n(MPE) in belief networks. Inference-based algorithms are powerful techniques\nfor solving discrete optimization problems, which can be used independently or\nin combination with other techniques. However, their applicability is often\nlimited by their compute intensive nature and their space requirements. This\npaper proposes the design and implementation of a novel inference-based\ntechnique, which exploits modern massively parallel architectures, such as\nthose found in Graphical Processing Units (GPUs), to speed up the resolution of\nexact and approximated inference-based algorithms for discrete optimization.\nThe paper studies the proposed algorithm in both centralized and distributed\noptimization contexts. The paper demonstrates that the use of GPUs provides\nsignificant advantages in terms of runtime and scalability, achieving up to two\norders of magnitude in speedups and showing a considerable reduction in\nexecution time (up to 345 times faster) with respect to a sequential version.","primary_category":"cs","categories":["cs.AI","cs.DC"],"authors":["Fioretto Ferdinando","Pontelli Enrico","Yeoh William","Dechter Rina"],"created":"2016-08-18","updated":"2017-06-15","doi":"10.1007\/s10601-017-9274-1"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1608.06949","title":"Urban Pulse: Capturing the Rhythm of Cities","abstract":"Cities are inherently dynamic. Interesting patterns of behavior typically\nmanifest at several key areas of a city over multiple temporal resolutions.\nStudying these patterns can greatly help a variety of experts ranging from city\nplanners and architects to human behavioral experts. Recent technological\ninnovations have enabled the collection of enormous amounts of data that can\nhelp in these studies. However, techniques using these data sets typically\nfocus on understanding the data in the context of the city, thus failing to\ncapture the dynamic aspects of the city. The goal of this work is to instead\nunderstand the city in the context of multiple urban data sets. To do so, we\ndefine the concept of an \"urban pulse\" which captures the spatio-temporal\nactivity in a city across multiple temporal resolutions. The prominent pulses\nin a city are obtained using the topology of the data sets, and are\ncharacterized as a set of beats. The beats are then used to analyze and compare\ndifferent pulses. We also design a visual exploration framework that allows\nusers to explore the pulses within and across multiple cities under different\nconditions. Finally, we present three case studies carried out by experts from\ntwo different domains that demonstrate the utility of our framework.","primary_category":"cs","categories":["cs.CY","cs.GR","cs.SI","physics.data-an","physics.soc-ph"],"authors":["Miranda Fabio","Doraiswamy Harish","Lage Marcos","Zhao Kai","Gon\u00e7alves Bruno","Wilson Luc","Hsieh Mondrian","Silva Cl\u00e1udio T."],"created":"2016-08-24","updated":"2017-12-29","doi":"10.1109\/TVCG.2016.2598585"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1608.07163","title":"Total Recursion over Lexicographical Orderings: Elementary Recursive\n  Operators Beyond PR","abstract":"In this work we generalize primitive recursion in order to construct a\nhierarchy of terminating total recursive operators which we refer to as {\\em\nleveled primitive recursion of order $i$}($\\mathbf{PR}_{i}$). Primitive\nrecursion is equivalent to leveled primitive recursion of order $1$\n($\\mathbf{PR}_{1}$). The functions constructable from the basic functions make\nup $\\mathbf{PR}_{0}$. Interestingly, we show that $\\mathbf{PR}_{2}$ is a\nconservative extension of $\\mathbf{PR}_{1}$. However, members of the hierarchy\nbeyond $\\mathbf{PR}_{2}$, that is $\\mathbf{PR}_{i}$ where $i\\geq 3$, can\nformalize the Ackermann function, and thus are more expressive than primitive\nrecursion. It remains an open question which members of the hierarchy are more\nexpressive than the previous members and which are conservative extensions. We\nconjecture that for all $i\\geq 1$ $\\mathbf{PR}_{2i} \\subset\n\\mathbf{PR}_{2i+1}$. Investigation of further extensions is left for future\nwork.","primary_category":"cs","categories":["cs.LO","math.LO"],"authors":["Cerna David"],"created":"2016-08-24","updated":"2018-01-03","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1608.07617","title":"\"Sampling\"' as a Baseline Optimizer for Search-based Software\n  Engineering","abstract":"Increasingly, Software Engineering (SE) researchers use search-based\noptimization techniques to solve SE problems with multiple conflicting\nobjectives. These techniques often apply CPU-intensive evolutionary algorithms\nto explore generations of mutations to a population of candidate solutions. An\nalternative approach, proposed in this paper, is to start with a very large\npopulation and sample down to just the better solutions. We call this method\n\"SWAY\", short for \"the sampling way\". Sway is very simple to implement and, in\nstudies with various software engineering models, this sampling approach was\nfound to be competitive with corresponding state-of-the-art evolutionary\nalgorithms while requiring far less computation cost. Considering the\nsimplicity and effectiveness of Sway, we, therefore, propose this approach as a\nbaseline method for search-based software engineering models, especially for\nmodels that are very slow to execute.","primary_category":"cs","categories":["cs.SE"],"authors":["Chen Jianfeng","Nair Vivek","Krishna Rahul","Menzies Tim"],"created":"2016-08-26","updated":"2018-01-05","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1609.00048","title":"Practical sketching algorithms for low-rank matrix approximation","abstract":"This paper describes a suite of algorithms for constructing low-rank\napproximations of an input matrix from a random linear image of the matrix,\ncalled a sketch. These methods can preserve structural properties of the input\nmatrix, such as positive-semidefiniteness, and they can produce approximations\nwith a user-specified rank. The algorithms are simple, accurate, numerically\nstable, and provably correct. Moreover, each method is accompanied by an\ninformative error bound that allows users to select parameters a priori to\nachieve a given approximation quality. These claims are supported by numerical\nexperiments with real and synthetic data.","primary_category":"cs","categories":["cs.NA","cs.DS","math.NA","stat.CO","stat.ML"],"authors":["Tropp Joel A.","Yurtsever Alp","Udell Madeleine","Cevher Volkan"],"created":"2016-08-31","updated":"2018-01-02","doi":"10.1137\/17M1111590"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1609.00594","title":"On Gaussian MACs with Variable-Length Feedback and Non-Vanishing\n  Error~Probabilities","abstract":"We characterize the fundamental limits of transmission of information over a\nGaussian multiple access channel (MAC) with the use of variable-length feedback\ncodes and under a non-vanishing error probability formalism. We develop new\nachievability and converse techniques to handle the continuous nature of the\nchannel and the presence of expected power constraints. We establish the\n$\\varepsilon$-capacity regions and bounds on the second-order asymptotics of\nthe Gaussian MAC with variable-length feedback with termination (VLFT) codes\nand stop-feedback codes. We show that the former outperforms the latter\nsignificantly. Due to the multi-terminal nature of the channel model, we\nleverage tools from renewal theory developed by Lai and Siegmund to bound the\nasymptotic behavior of the maximum of a finite number of stopping times.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Truong Lan V.","Tan Vincent Y. F."],"created":"2016-09-02","updated":"2018-01-08","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1609.01789","title":"Bounded degree and planar spectra","abstract":"The finite spectrum of a first-order sentence is the set of positive integers\nthat are the sizes of its models. The class of finite spectra is known to be\nthe same as the complexity class NE. We consider the spectra obtained by\nlimiting models to be either planar (in the graph-theoretic sense) or by\nbounding the degree of elements. We show that the class of such spectra is\nstill surprisingly rich by establishing that significant fragments of NE are\nincluded among them. At the same time, we establish non-trivial upper bounds\nshowing that not all sets in NE are obtained as planar or bounded-degree\nspectra.","primary_category":"cs","categories":["cs.LO","math.LO"],"authors":["Dawar Anuj","Kopczy\u0144ski Eryk"],"created":"2016-09-06","updated":"2017-11-03","doi":"10.23638\/LMCS-13(4:6)2017"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1609.04585","title":"On Memory Footprints of Partitioned Sparse Matrices","abstract":"Runtime characteristics of sparse matrix computations and related processes\nmay be often improved by reducing memory footprints of involved matrices. Such\na reduction can be usually achieved when matrices are processed in a block-wise\nmanner. The presented study analysed memory footprints of 563 representative\nbenchmark sparse matrices with respect to their partitioning into\nuniformly-sized blocks. Different block sizes and different ways of storing\nblocks in memory were considered and statistically evaluated. Memory footprints\nof partitioned matrices were additionally compared with lower bounds and with\nthe CSR storage format. The average measured memory savings against CSR in case\nof single and double precision were 42.3 and 28.7 percents, the corresponding\nworst-case savings 25.5 and 17.1 percents. Moreover, memory footprints of\npartitioned matrices were in average 5 times closer to their lower bounds than\nCSR. Based on the obtained results, generic suggestions for efficient\npartitioning and storage of sparse matrices in a computer memory are provided.","primary_category":"cs","categories":["cs.NA"],"authors":["Langr Daniel"],"created":"2016-09-15","updated":"2017-01-10","doi":"10.15439\/2017F70"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1609.07254","title":"Taking a Detour to Zero: An Alternative Formalization of Functions\n  Beyond PR","abstract":"There are two well known systems formalizing total recursion beyond primitive\nrecursion (\\textbf{PR}), system \\textbf{T} by G\\\"odel and system \\textbf{F} by\nGirard and Reynolds. system \\textbf{T} defines recursion on typed objects and\ncan construct every function of Heyting arithmetic (\\textbf{HA}). System\n\\textbf{F} introduces type variables which can define the recursion of system\n\\textbf{T}. The result is a system as expressive as second-order Heyting\narithmetic (\\textbf{HA}$_{2}$). Though, both are able to express unimaginably\nfast growing functions, in some applications a more flexible formalism is\nneeded. One such application is CERES cut-elimination for schematic\n\\textbf{LK}-proofs ($CERES_{s}$) where the shape of the recursion is important.\nIn this paper we introduce a formalism for fast growing functions without a\ntype theory foundation. The recursion is indexed by ordered sets of natural\nnumbers. We highlight the relationship between our recursion and the Wainer\nhierarchy to provide an comparison to existing systems. We can show that our\nformalism expresses the functions expressible using system \\textbf{T}. We leave\ncomparison to system \\textbf{F} and beyond to future work.","primary_category":"cs","categories":["cs.LO"],"authors":["Cerna David M."],"created":"2016-09-23","updated":"2018-01-03","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1609.07574","title":"Dynamic Pricing in High-dimensions","abstract":"We study the pricing problem faced by a firm that sells a large number of\nproducts, described via a wide range of features, to customers that arrive over\ntime. Customers independently make purchasing decisions according to a general\nchoice model that includes products features and customers' characteristics,\nencoded as $d$-dimensional numerical vectors, as well as the price offered. The\nparameters of the choice model are a priori unknown to the firm, but can be\nlearned as the (binary-valued) sales data accrues over time. The firm's\nobjective is to minimize the regret, i.e., the expected revenue loss against a\nclairvoyant policy that knows the parameters of the choice model in advance,\nand always offers the revenue-maximizing price. This setting is motivated in\npart by the prevalence of online marketplaces that allow for real-time pricing.\nWe assume a structured choice model, parameters of which depend on $s_0$ out of\nthe $d$ product features. We propose a dynamic policy, called Regularized\nMaximum Likelihood Pricing (RMLP) that leverages the (sparsity) structure of\nthe high-dimensional model and obtains a logarithmic regret in $T$. More\nspecifically, the regret of our algorithm is of $O(s_0 \\log d \\cdot \\log T)$.\nFurthermore, we show that no policy can obtain regret better than $O(s_0 (\\log\nd + \\log T))$.","primary_category":"cs","categories":["stat.ML","cs.LG"],"authors":["Javanmard Adel","Nazerzadeh Hamid"],"created":"2016-09-24","updated":"2017-12-31","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1610.02608","title":"Research and Education in Computational Science and Engineering","abstract":"Over the past two decades the field of computational science and engineering\n(CSE) has penetrated both basic and applied research in academia, industry, and\nlaboratories to advance discovery, optimize systems, support decision-makers,\nand educate the scientific and engineering workforce. Informed by centuries of\ntheory and experiment, CSE performs computational experiments to answer\nquestions that neither theory nor experiment alone is equipped to answer. CSE\nprovides scientists and engineers of all persuasions with algorithmic\ninventions and software systems that transcend disciplines and scales. Carried\non a wave of digital technology, CSE brings the power of parallelism to bear on\ntroves of data. Mathematics-based advanced computing has become a prevalent\nmeans of discovery and innovation in essentially all areas of science,\nengineering, technology, and society; and the CSE community is at the core of\nthis transformation. However, a combination of disruptive\ndevelopments---including the architectural complexity of extreme-scale\ncomputing, the data revolution that engulfs the planet, and the specialization\nrequired to follow the applications to new frontiers---is redefining the scope\nand reach of the CSE endeavor. This report describes the rapid expansion of CSE\nand the challenges to sustaining its bold advances. The report also presents\nstrategies and directions for CSE research and education for the next decade.","primary_category":"cs","categories":["cs.CE","math.HO","stat.OT"],"authors":["R\u00fcde Ulrich","Willcox Karen","McInnes Lois Curfman","De Sterck Hans","Biros George","Bungartz Hans","Corones James","Cramer Evin","Crowley James","Ghattas Omar","Gunzburger Max","Hanke Michael","Harrison Robert","Heroux Michael","Hesthaven Jan","Jimack Peter","Johnson Chris","Jordan Kirk E.","Keyes David E.","Krause Rolf","Kumar Vipin","Mayer Stefan","Meza Juan","M\u00f8rken Knut Martin","Oden J. Tinsley","Petzold Linda","Raghavan Padma","Shontz Suzanne M.","Trefethen Anne","Turner Peter","Voevodin Vladimir","Wohlmuth Barbara","Woodward Carol S."],"created":"2016-10-08","updated":"2017-12-31","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1610.02627","title":"Learning Deep Generative Spatial Models for Mobile Robots","abstract":"We propose a new probabilistic framework that allows mobile robots to\nautonomously learn deep, generative models of their environments that span\nmultiple levels of abstraction. Unlike traditional approaches that combine\nengineered models for low-level features, geometry, and semantics, our approach\nleverages recent advances in Sum-Product Networks (SPNs) and deep learning to\nlearn a single, universal model of the robot's spatial environment. Our model\nis fully probabilistic and generative, and represents a joint distribution over\nspatial information ranging from low-level geometry to semantic\ninterpretations. Once learned, it is capable of solving a wide range of tasks:\nfrom semantic classification of places, uncertainty estimation, and novelty\ndetection, to generation of place appearances based on semantic information and\nprediction of missing data in partial observations. Experiments on laser-range\ndata from a mobile robot show that the proposed universal model obtains\nperformance superior to state-of-the-art models fine-tuned to one specific\ntask, such as Generative Adversarial Networks (GANs) or SVMs.","primary_category":"cs","categories":["cs.RO"],"authors":["Pronobis Andrzej","Rao Rajesh P. N."],"created":"2016-10-09","updated":"2017-12-28","doi":"10.1109\/IROS.2017.8202235"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1610.02704","title":"Approximating Rectangles by Juntas and Weakly-Exponential Lower Bounds\n  for LP Relaxations of CSPs","abstract":"We show that for constraint satisfaction problems (CSPs), sub-exponential\nsize linear programming relaxations are as powerful as $n^{\\Omega(1)}$-rounds\nof the Sherali-Adams linear programming hierarchy. As a corollary, we obtain\nsub-exponential size lower bounds for linear programming relaxations that beat\nrandom guessing for many CSPs such as MAX-CUT and MAX-3SAT. This is a\nnearly-exponential improvement over previous results, previously, it was only\nknown that linear programs of size $n^{o(\\log n)}$ cannot beat random guessing\nfor any CSP (Chan-Lee-Raghavendra-Steurer 2013).\n  Our bounds are obtained by exploiting and extending the recent progress in\ncommunication complexity for \"lifting\" query lower bounds to communication\nproblems. The main ingredient in our results is a new structural result on\n\"high-entropy rectangles\" that may of independent interest in communication\ncomplexity.","primary_category":"cs","categories":["cs.CC","cs.DM","cs.DS","math.CO"],"authors":["Kothari Pravesh K.","Meka Raghu","Raghavendra Prasad"],"created":"2016-10-09","updated":"2017-12-30","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1610.04592","title":"The Recursion Theorem from a Different Angle","abstract":"This paper is about computability. I claim the likely existence of a program\nDoesHalt(Program, Input) such that DoesHalt( HaltsOnItself, AntiSelf ) halts\nwith resounding 'NO'. HaltsOnItself( Program ) is simply DoesHalt( Program,\nProgram ). AntiSelf() is a self-referential self-contradictory program that\nloops when HaltsOnItself() returns 'YES' and halts when HaltsOnItself() returns\n'NO'.","primary_category":"cs","categories":["cs.LO"],"authors":["Newberry X. Y."],"created":"2016-05-23","updated":"2018-01-10","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1610.09183","title":"Multiactive objects and their applications","abstract":"In order to tackle the development of concurrent and distributed systems, the\nactive object programming model provides a high-level abstraction to program\nconcurrent behaviours. There exists already a variety of active object\nframeworks targeted at a large range of application domains: modelling,\nverification, efficient execution. However, among these frameworks, very few\nconsider a multi-threaded execution of active objects. Introducing controlled\nparallelism within active objects enables overcoming some of their limitations.\nIn this paper, we present a complete framework around the multi-active object\nprogramming model. We present it through ProActive, the Java library that\noffers multi-active objects, and through MultiASP, the programming language\nthat allows the formalisation of our developments. We then show how to compile\nan active object language with cooperative multi-threading into multi-active\nobjects. This paper also presents different use cases and the development\nsupport to illustrate the practical usability of our language. Formalisation of\nour work provides the programmer with guarantees on the behaviour of the\nmulti-active object programming model and of the compiler.","primary_category":"cs","categories":["cs.PL"],"authors":["Henrio Ludovic","Rochas Justine"],"created":"2016-10-28","updated":"2017-11-20","doi":"10.23638\/LMCS-13(4:12)2017"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1611.02010","title":"Convergence Analysis of Distributed Inference with Vector-Valued\n  Gaussian Belief Propagation","abstract":"This paper considers inference over distributed linear Gaussian models using\nfactor graphs and Gaussian belief propagation (BP). The distributed inference\nalgorithm involves only local computation of the information matrix and of the\nmean vector, and message passing between neighbors. Under broad conditions, it\nis shown that the message information matrix converges to a unique positive\ndefinite limit matrix for arbitrary positive semidefinite initialization, and\nit approaches an arbitrarily small neighborhood of this limit matrix at a\ndoubly exponential rate. A necessary and sufficient convergence condition for\nthe belief mean vector to converge to the optimal centralized estimator is\nprovided under the assumption that the message information matrix is\ninitialized as a positive semidefinite matrix. Further, it is shown that\nGaussian BP always converges when the underlying factor graph is given by the\nunion of a forest and a single loop. The proposed convergence condition in the\nsetup of distributed linear Gaussian models is shown to be strictly weaker than\nother existing convergence conditions and requirements, including the Gaussian\nMarkov random field based walk-summability condition, and applicable to a large\nclass of scenarios.","primary_category":"cs","categories":["stat.ML","cs.IT","math.IT"],"authors":["Du Jian","Ma Shaodan","Wu Yik-Chung","Kar Soummya","Moura Jos\u00e9 M. F."],"created":"2016-11-07","updated":"2017-12-28","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1611.02453","title":"The Data Complexity of Description Logic Ontologies","abstract":"We analyze the data complexity of ontology-mediated querying where the\nontologies are formulated in a description logic (DL) of the ALC family and\nqueries are conjunctive queries, positive existential queries, or acyclic\nconjunctive queries. Our approach is non-uniform in the sense that we aim to\nunderstand the complexity of each single ontology instead of for all ontologies\nformulated in a certain language. While doing so, we quantify over the queries\nand are interested, for example, in the question whether all queries can be\nevaluated in polynomial time w.r.t. a given ontology. Our results include a\nPTime\/coNP-dichotomy for ontologies of depth one in the description logic\nALCFI, the same dichotomy for ALC- and ALCI-ontologies of unrestricted depth,\nand the non-existence of such a dichotomy for ALCF-ontologies. For the latter\nDL, we additionally show that it is undecidable whether a given ontology admits\nPTime query evaluation. We also consider the connection between PTime query\nevaluation and rewritability into (monadic) Datalog.","primary_category":"cs","categories":["cs.AI"],"authors":["Lutz Carsten","Wolter Frank"],"created":"2016-11-08","updated":"2017-11-10","doi":"10.23638\/LMCS-13(4:7)2017"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1611.03267","title":"Finite Satisfiability of the Two-Variable Guarded Fragment with\n  Transitive Guards and Related Variants","abstract":"We consider extensions of the two-variable guarded fragment, GF2, where\ndistinguished binary predicates that occur only in guards are required to be\ninterpreted in a special way (as transitive relations, equivalence relations,\npre-orders or partial orders). We prove that the only fragment that retains the\nfinite (exponential) model property is GF2 with equivalence guards without\nequality. For remaining fragments we show that the size of a minimal finite\nmodel is at most doubly exponential. To obtain the result we invent a strategy\nof building finite models that are formed from a number of multidimensional\ngrids placed over a cylindrical surface. The construction yields a\n2NExpTime-upper bound on the complexity of the finite satisfiability problem\nfor these fragments. We improve the bounds and obtain optimal ones for all the\nfragments considered, in particular NExpTime for GF2 with equivalence guards,\nand 2ExpTime for GF2 with transitive guards. To obtain our results we\nessentially use some results from integer programming.","primary_category":"cs","categories":["cs.LO"],"authors":["Kieronski Emanuel","Tendera Lidia"],"created":"2016-11-10","updated":"2018-01-02","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1611.04706","title":"High-Dimensional Stochastic Optimal Control using Continuous Tensor\n  Decompositions","abstract":"Motion planning and control problems are embedded and essential in almost all\nrobotics applications. These problems are often formulated as stochastic\noptimal control problems and solved using dynamic programming algorithms.\nUnfortunately, most existing algorithms that guarantee convergence to optimal\nsolutions suffer from the curse of dimensionality: the run time of the\nalgorithm grows exponentially with the dimension of the state space of the\nsystem. We propose novel dynamic programming algorithms that alleviate the\ncurse of dimensionality in problems that exhibit certain low-rank structure.\nThe proposed algorithms are based on continuous tensor decompositions recently\ndeveloped by the authors. Essentially, the algorithms represent\nhigh-dimensional functions (e.g., the value function) in a compressed format,\nand directly perform dynamic programming computations (e.g., value iteration,\npolicy iteration) in this format. Under certain technical assumptions, the new\nalgorithms guarantee convergence towards optimal solutions with arbitrary\nprecision. Furthermore, the run times of the new algorithms scale polynomially\nwith the state dimension and polynomially with the ranks of the value function.\nThis approach realizes substantial computational savings in \"compressible\"\nproblem instances, where value functions admit low-rank approximations. We\ndemonstrate the new algorithms in a wide range of problems, including a\nsimulated six-dimensional agile quadcopter maneuvering example and a\nseven-dimensional aircraft perching example. In some of these examples, we\nestimate computational savings of up to ten orders of magnitude over standard\nvalue iteration algorithms. We further demonstrate the algorithms running in\nreal time on board a quadcopter during a flight experiment under motion\ncapture.","primary_category":"cs","categories":["cs.RO","cs.SY"],"authors":["Gorodetsky Alex A.","Karaman Sertac","Marzouk Youssef M."],"created":"2016-11-15","updated":"2018-01-11","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1611.06164","title":"Improving the Coverage and Spectral Efficiency of Millimeter-Wave\n  Cellular Networks using Device-to-Device Relays","abstract":"The susceptibility of millimeter waveform propagation to blockages limits the\ncoverage of millimeter-wave (mmWave) signals. To overcome blockages, we propose\nto leverage two-hop device-to-device (D2D) relaying. Using stochastic geometry,\nwe derive expressions for the downlink coverage probability of relay-assisted\nmmWave cellular networks when the D2D links are implemented in either uplink\nmmWave or uplink microwave bands. We further investigate the spectral\nefficiency (SE) improvement in the cellular downlink, and the effect of D2D\ntransmissions on the cellular uplink. For mmWave links, we derive the coverage\nprobability using dominant interferer analysis while accounting for both\nblockages and beamforming gains. For microwave D2D links, we derive the\ncoverage probability considering both line-of-sight (LOS) and non-line-of-sight\n(NLOS) propagation. Numerical results show that downlink coverage and SE can be\nimproved using two-hop D2D relaying. Specifically, microwave D2D relays achieve\nbetter coverage because D2D connections can be established under NLOS\nconditions. However, mmWave D2D relays achieve better coverage when the density\nof interferers is large because blockages eliminate interference from NLOS\ninterferers. The SE on the downlink depends on the relay mode selection\nstrategy, and mmWave D2D relays use a significantly smaller fraction of uplink\nresources than microwave D2D relays.","primary_category":"cs","categories":["cs.ET"],"authors":["Wu Shuanshuan","Atat Rachad","Mastronarde Nicholas","Liu Lingjia"],"created":"2016-11-18","updated":"2018-01-02","doi":"10.1109\/TCOMM.2017.2787990"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1611.07400","title":"A Deep Learning Based DDoS Detection System in Software-Defined\n  Networking (SDN)","abstract":"Distributed Denial of Service (DDoS) is one of the most prevalent attacks\nthat an organizational network infrastructure comes across nowadays. We propose\na deep learning based multi-vector DDoS detection system in a software-defined\nnetwork (SDN) environment. SDN provides flexibility to program network devices\nfor different objectives and eliminates the need for third-party\nvendor-specific hardware. We implement our system as a network application on\ntop of an SDN controller. We use deep learning for feature reduction of a large\nset of features derived from network traffic headers. We evaluate our system\nbased on different performance metrics by applying it on traffic traces\ncollected from different scenarios. We observe high accuracy with a low\nfalse-positive for attack detection in our proposed system.","primary_category":"cs","categories":["cs.NI"],"authors":["Niyaz Quamar","Sun Weiqing","Javaid Ahmad Y"],"created":"2016-11-22","updated":" ","doi":"10.4108\/eai.28-12-2017.153515"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1611.07630","title":"Degrees of Freedom of the Bursty MIMO X Channel without Feedback","abstract":"We study the sum degrees of freedom (DoF) of the bursty MIMO X channel\nwithout feedback, where the four transmitter-receiver links are intermittently\non-and-off, controlled by four Bernoulli random sequences which may be\narbitrarily correlated, subject to a symmetry assumption: The two direct-links\nhave the same level of burstiness, modeled by $\\mathrm{Ber}(p_d)$, and so do\nthe cross-links, modeled by $\\mathrm{Ber}(p_c)$. The sum DoF is fully\ncharacterized in the regime where $\\frac{p_c}{p_d}$ is small, i.e. below a\ncertain threshold, and is partially characterized in the other regime where\n$\\frac{p_c}{p_d}$ is above the threshold. The achievability is proved with a\ncombination of Han-Kobayashi strategy and interference alignment, which can\nachieve strictly higher DoF than interference alignment alone. The converse\nproof employs a channel-state-sequence pairing technique. We highlight that\nburstiness of the channel disrupts the network topology, turning the MIMO X\nchannel into a network with time-varying topology. This fundamental difference\nhas striking ramifications. In particular, various interference alignment\nschemes that achieve the DoF of non-bursty X channels are found to be\nsuboptimal when the channels become bursty. The reciprocity between the forward\nand the reverse links is lost, and the sum DoF does not saturate when the ratio\nof the transmitter and the receiver antennas exceeds $\\frac{2}{3}$.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Yeh Shih-Yi","Wang I-Hsiang"],"created":"2016-11-22","updated":"2018-01-01","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1611.08738","title":"Adding Path-Functional Dependencies to the Guarded Two-Variable Fragment\n  with Counting","abstract":"The satisfiability and finite satisfiability problems for the two-variable\nguarded fragment of first-order logic with counting quantifiers, a database,\nand path-functional dependencies are both ExpTime-complete.","primary_category":"cs","categories":["cs.LO"],"authors":["Kourtis Georgios","Pratt-Hartmann Ian"],"created":"2016-11-26","updated":"2017-10-27","doi":"10.23638\/LMCS-13(4:4)2017"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1612.01696","title":"Optimal Approximate Polytope Membership","abstract":"In the polytope membership problem, a convex polytope $K$ in $R^d$ is given,\nand the objective is to preprocess $K$ into a data structure so that, given a\nquery point $q \\in R^d$, it is possible to determine efficiently whether $q \\in\nK$. We consider this problem in an approximate setting and assume that $d$ is a\nconstant. Given an approximation parameter $\\varepsilon > 0$, the query can be\nanswered either way if the distance from $q$ to $K$'s boundary is at most\n$\\varepsilon$ times $K$'s diameter. Previous solutions to the problem were on\nthe form of a space-time trade-off, where logarithmic query time demands\n$O(1\/\\varepsilon^{d-1})$ storage, whereas storage $O(1\/\\varepsilon^{(d-1)\/2})$\nadmits roughly $O(1\/\\varepsilon^{(d-1)\/8})$ query time. In this paper, we\npresent a data structure that achieves logarithmic query time with storage of\nonly $O(1\/\\varepsilon^{(d-1)\/2})$, which matches the worst-case lower bound on\nthe complexity of any $\\varepsilon$-approximating polytope. Our data structure\nis based on a new technique, a hierarchy of ellipsoids defined as\napproximations to Macbeath regions.\n  As an application, we obtain major improvements to approximate Euclidean\nnearest neighbor searching. Notably, the storage needed to answer\n$\\varepsilon$-approximate nearest neighbor queries for a set of $n$ points in\n$O(\\log \\frac{n}{\\varepsilon})$ time is reduced to $O(n\/\\varepsilon^{d\/2})$.\nThis halves the exponent in the $\\varepsilon$-dependency of the existing space\nbound of roughly $O(n\/\\varepsilon^d)$, which has stood for 15 years (Har-Peled,\n2001).","primary_category":"cs","categories":["cs.CG"],"authors":["Arya Sunil","da Fonseca Guilherme D.","Mount David M."],"created":"2016-12-06","updated":" ","doi":"10.1137\/1.9781611974782.18"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1612.03412","title":"Non-Redundant Spectral Dimensionality Reduction","abstract":"Spectral dimensionality reduction algorithms are widely used in numerous\ndomains, including for recognition, segmentation, tracking and visualization.\nHowever, despite their popularity, these algorithms suffer from a major\nlimitation known as the \"repeated Eigen-directions\" phenomenon. That is, many\nof the embedding coordinates they produce typically capture the same direction\nalong the data manifold. This leads to redundant and inefficient\nrepresentations that do not reveal the true intrinsic dimensionality of the\ndata. In this paper, we propose a general method for avoiding redundancy in\nspectral algorithms. Our approach relies on replacing the orthogonality\nconstraints underlying those methods by unpredictability constraints.\nSpecifically, we require that each embedding coordinate be unpredictable (in\nthe statistical sense) from all previous ones. We prove that these constraints\nnecessarily prevent redundancy, and provide a simple technique to incorporate\nthem into existing methods. As we illustrate on challenging high-dimensional\nscenarios, our approach produces significantly more informative and compact\nrepresentations, which improve visualization and classification tasks.","primary_category":"cs","categories":["cs.LG","stat.ML"],"authors":["Blau Yochai","Michaeli Tomer"],"created":"2016-12-11","updated":"2017-04-20","doi":"10.1007\/978-3-319-71249-9_16"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1612.07540","title":"Planar posets have dimension at most linear in their height","abstract":"We prove that every planar poset $P$ of height $h$ has dimension at most\n$192h + 96$. This improves on previous exponential bounds and is best possible\nup to a constant factor. We complement this result with a construction of\nplanar posets of height $h$ and dimension at least $(4\/3)h-2$.","primary_category":"cs","categories":["math.CO","cs.DM"],"authors":["Joret Gwena\u00ebl","Micek Piotr","Wiechert Veit"],"created":"2016-12-22","updated":"2017-09-23","doi":"10.1137\/17M111300X"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1612.08447","title":"Higher-order organization of complex networks","abstract":"Networks are a fundamental tool for understanding and modeling complex\nsystems in physics, biology, neuroscience, engineering, and social science.\nMany networks are known to exhibit rich, lower-order connectivity patterns that\ncan be captured at the level of individual nodes and edges. However,\nhigher-order organization of complex networks---at the level of small network\nsubgraphs---remains largely unknown. Here we develop a generalized framework\nfor clustering networks based on higher-order connectivity patterns. This\nframework provides mathematical guarantees on the optimality of obtained\nclusters and scales to networks with billions of edges. The framework reveals\nhigher-order organization in a number of networks including information\npropagation units in neuronal networks and hub structure in transportation\nnetworks. Results show that networks exhibit rich higher-order organizational\nstructures that are exposed by clustering based on higher-order connectivity\npatterns.","primary_category":"cs","categories":["cs.SI","cs.DM","physics.soc-ph"],"authors":["Benson Austin R.","Gleich David F.","Leskovec Jure"],"created":"2016-12-26","updated":" ","doi":"10.1126\/science.aad9029"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1612.08709","title":"Randomized algorithms for distributed computation of principal component\n  analysis and singular value decomposition","abstract":"Randomized algorithms provide solutions to two ubiquitous problems: (1) the\ndistributed calculation of a principal component analysis or singular value\ndecomposition of a highly rectangular matrix, and (2) the distributed\ncalculation of a low-rank approximation (in the form of a singular value\ndecomposition) to an arbitrary matrix. Carefully honed algorithms yield results\nthat are uniformly superior to those of the stock, deterministic\nimplementations in Spark (the popular platform for distributed computation); in\nparticular, whereas the stock software will without warning return left\nsingular vectors that are far from numerically orthonormal, a significantly\nburnished randomized implementation generates left singular vectors that are\nnumerically orthonormal to nearly the machine precision.","primary_category":"cs","categories":["cs.DC","cs.NA","math.NA","stat.CO"],"authors":["Li Huamin","Kluger Yuval","Tygert Mark"],"created":"2016-12-27","updated":"2018-01-01","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1612.08965","title":"A new shell formulation for graphene structures based on existing\n  ab-initio data","abstract":"An existing hyperelastic membrane model for graphene calibrated from\nab-initio data (Kumar and Parks, 2014) is adapted to curvilinear coordinates\nand extended to a rotation-free shell formulation based on isogeometric finite\nelements. Therefore, the membrane model is extended by a hyperelastic bending\nmodel that reflects the ab-inito data of Kudin et al. (2001). The proposed\nformulation can be implemented straight-forwardly into an existing finite\nelement package, since it does not require the description of molecular\ninteractions. It thus circumvents the use of interatomic potentials that tend\nto be less accurate than ab-initio data. The proposed shell formulation is\nverified and analyzed by a set of simple test cases. The results are in\nagreement to analytical solutions and satisfy the FE patch test. The\nperformance of the shell formulation for graphene structures is illustrated by\nseveral numerical examples. The considered examples are indentation and peeling\nof graphene and torsion, bending and axial stretch of carbon nanotubes.\nAdhesive substrates are modeled by the Lennard-Jones potential and a coarse\ngrained contact model. In principle, the proposed formulation can be extended\nto other 2D materials.","primary_category":"cs","categories":["physics.comp-ph","cond-mat.mes-hall","cs.CE"],"authors":["Ghaffari Reza","Duong Thang X.","Sauer Roger A."],"created":"2016-12-28","updated":"2017-12-01","doi":"10.1016\/j.ijsolstr.2017.11.008"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1612.09259","title":"Motifs in Temporal Networks","abstract":"Networks are a fundamental tool for modeling complex systems in a variety of\ndomains including social and communication networks as well as biology and\nneuroscience. Small subgraph patterns in networks, called network motifs, are\ncrucial to understanding the structure and function of these systems. However,\nthe role of network motifs in temporal networks, which contain many timestamped\nlinks between the nodes, is not yet well understood.\n  Here we develop a notion of a temporal network motif as an elementary unit of\ntemporal networks and provide a general methodology for counting such motifs.\nWe define temporal network motifs as induced subgraphs on sequences of temporal\nedges, design fast algorithms for counting temporal motifs, and prove their\nruntime complexity. Our fast algorithms achieve up to 56.5x speedup compared to\na baseline method. Furthermore, we use our algorithms to count temporal motifs\nin a variety of networks. Results show that networks from different domains\nhave significantly different motif counts, whereas networks from the same\ndomain tend to have similar motif counts. We also find that different motifs\noccur at different time scales, which provides further insights into structure\nand function of temporal networks.","primary_category":"cs","categories":["cs.SI","physics.soc-ph","stat.ML"],"authors":["Paranjape Ashwin","Benson Austin R.","Leskovec Jure"],"created":"2016-12-29","updated":" ","doi":"10.1145\/3018661.3018731"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1701.00352","title":"Weakly Supervised Semantic Segmentation using Web-Crawled Videos","abstract":"We propose a novel algorithm for weakly supervised semantic segmentation\nbased on image-level class labels only. In weakly supervised setting, it is\ncommonly observed that trained model overly focuses on discriminative parts\nrather than the entire object area. Our goal is to overcome this limitation\nwith no additional human intervention by retrieving videos relevant to target\nclass labels from web repository, and generating segmentation labels from the\nretrieved videos to simulate strong supervision for semantic segmentation.\nDuring this process, we take advantage of image classification with\ndiscriminative localization technique to reject false alarms in retrieved\nvideos and identify relevant spatio-temporal volumes within retrieved videos.\nAlthough the entire procedure does not require any additional supervision, the\nsegmentation annotations obtained from videos are sufficiently strong to learn\na model for semantic segmentation. The proposed algorithm substantially\noutperforms existing methods based on the same level of supervision and is even\nas competitive as the approaches relying on extra annotations.","primary_category":"cs","categories":["cs.CV"],"authors":["Hong Seunghoon","Yeo Donghun","Kwak Suha","Lee Honglak","Han Bohyung"],"created":"2017-01-02","updated":"2018-01-07","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1701.02227","title":"Interpolating Between Choices for the Approximate Intermediate Value\n  Theorem","abstract":"This paper proves the approximate intermediate value theorem, constructively\nand from notably weak hypotheses: from pointwise rather than uniform\ncontinuity, without assuming that reals are presented with rational\napproximants, and without using countable choice. The theorem is that if a\npointwise continuous function has both a negative and a positive value, then it\nhas values arbitrarily close to 0. The proof builds on the usual classical\nproof by bisection, which repeatedly selects the left or right half of an\ninterval; the algorithm here selects an interval of half the size in a\ncontinuous way, interpolating between those two possibilities.","primary_category":"cs","categories":["math.LO","cs.LO"],"authors":["Frank Matthew"],"created":"2017-01-04","updated":"2018-01-01","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1701.03186","title":"Feedback Capacity over Networks","abstract":"In this paper, we investigate the fundamental limitations of feedback\nmechanism in dealing with uncertainties for network systems. The study of\nmaximum capability of feedback control was pioneered in Xie and Guo (2000) for\nscalar systems with nonparametric nonlinear uncertainty. In a network setting,\nnodes with unknown and nonlinear dynamics are interconnected through a directed\ninteraction graph. Nodes can design feedback controls based on all available\ninformation, where the objective is to stabilize the network state. Using\ninformation structure and decision pattern as criteria, we specify three\ncategories of network feedback laws, namely the\nglobal-knowledge\/global-decision, network-flow\/local-decision, and\nlocal-flow\/local-decision feedback. We establish a series of network capacity\ncharacterizations for these three fundamental types of network control laws.\nFirst of all, we prove that for global-knowledge\/global-decision and\nnetwork-flow\/local-decision control where nodes know the information flow\nacross the entire network, there exists a critical number\n$\\big(3\/2+\\sqrt{2}\\big)\/\\|A_{\\mathrm{G}}\\|_\\infty$, where $3\/2+\\sqrt{2}$ is as\nknown as the Xie-Guo constant and $A_{\\mathrm{G}}$ is the network adjacency\nmatrix, defining exactly how much uncertainty in the node dynamics can be\novercome by feedback. Interestingly enough, the same feedback capacity can be\nachieved under max-consensus enhanced local flows where nodes only observe\ninformation flows from neighbors as well as extreme (max and min) states in the\nnetwork. Next, for local-flow\/local-decision control, we prove that there\nexists a structure-determined value being a lower bound of the network feedback\ncapacity. These results reveal the important connection between network\nstructure and fundamental capabilities of in-network feedback control.","primary_category":"cs","categories":["cs.SY"],"authors":["Li Bo","Shi Guodong"],"created":"2017-01-11","updated":"2018-01-10","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1701.04010","title":"Density-Wise Two Stage Mammogram Classification using Texture Exploiting\n  Descriptors","abstract":"Breast cancer is becoming pervasive with each passing day. Hence, its early\ndetection is a big step in saving the life of any patient. Mammography is a\ncommon tool in breast cancer diagnosis. The most important step here is\nclassification of mammogram patches as normal-abnormal and benign-malignant.\n  Texture of a breast in a mammogram patch plays a significant role in these\nclassifications. We propose a variation of Histogram of Gradients (HOG) and\nGabor filter combination called Histogram of Oriented Texture (HOT) that\nexploits this fact. We also revisit the Pass Band - Discrete Cosine Transform\n(PB-DCT) descriptor that captures texture information well. All features of a\nmammogram patch may not be useful. Hence, we apply a feature selection\ntechnique called Discrimination Potentiality (DP). Our resulting descriptors,\nDP-HOT and DP-PB-DCT, are compared with the standard descriptors.\n  Density of a mammogram patch is important for classification, and has not\nbeen studied exhaustively. The Image Retrieval in Medical Application (IRMA)\ndatabase from RWTH Aachen, Germany is a standard database that provides\nmammogram patches, and most researchers have tested their frameworks only on a\nsubset of patches from this database. We apply our two new descriptors on all\nimages of the IRMA database for density wise classification, and compare with\nthe standard descriptors. We achieve higher accuracy than all of the existing\nstandard descriptors (more than 92%).","primary_category":"cs","categories":["cs.CV"],"authors":["Shastri Aditya A.","Tamrakar Deepti","Ahuja Kapil"],"created":"2017-01-15","updated":"2018-01-02","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1701.04420","title":"On the Characteristic and Permanent Polynomials of a Matrix","abstract":"There is a digraph corresponding to every square matrix over $\\mathbb{C}$. We\ngenerate a recurrence relation using the Laplace expansion to calculate the\ncharacteristic, and permanent polynomials of a square matrix. Solving this\nrecurrence relation, we found that the characteristic, and permanent\npolynomials can be calculated in terms of characteristic, and permanent\npolynomials of some specific induced subdigraphs of blocks in the digraph,\nrespectively. Interestingly, these induced subdigraphs are vertex-disjoint and\nthey partition the digraph. Similar to the characteristic, and permanent\npolynomials; the determinant, and permanent can also be calculated. Therefore,\nthis article provides a combinatorial meaning of these useful quantities of the\nmatrix theory. We conclude this article with a number of open problems which\nmay be attempted for further research in this direction.","primary_category":"cs","categories":["cs.DM"],"authors":["Singh Ranveer","Bapat R. B."],"created":"2017-01-16","updated":"2017-04-06","doi":"10.1515\/spma-2017-0010"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1701.04723","title":"A Resistive CAM Processing-in-Storage Architecture for DNA Sequence\n  Alignment","abstract":"A novel processing-in-storage (PRinS) architecture based on Resistive CAM\n(ReCAM) is described and proposed for Smith-Waterman (S-W) sequence alignment.\nThe ReCAM massively-parallel compare operation finds matching base-pairs in a\nfixed number of cycles, regardless of sequence length. The ReCAM PRinS S-W\nalgorithm is simulated and compared to FPGA, Xeon Phi and GPU-based\nimplementations, showing at least 4.7x higher throughput and at least 15x lower\npower dissipation.","primary_category":"cs","categories":["cs.ET"],"authors":["Kaplan Roman","Yavits Leonid","Ginosar Ran","Weiser Uri"],"created":"2017-01-17","updated":"2017-06-11","doi":"10.1109\/MM.2017.3211121"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1701.06174","title":"Feedback capacity and coding for the BIBO channel with a\n  no-repeated-ones input constraint","abstract":"In this paper, a general binary-input binary-output (BIBO) channel is\ninvestigated in the presence of feedback and input constraints. The feedback\ncapacity and the optimal input distribution of this setting are calculated for\nthe case of an $(1,\\infty)$-RLL input constraint, that is, the input sequence\ncontains no consecutive ones. These results are obtained via explicit solution\nof a corresponding dynamic programming optimization problem. A simple coding\nscheme is designed based on the principle of posterior matching, which was\nintroduced by Shayevitz and Feder for memoryless channels. The posterior\nmatching scheme for our input-constrained setting is shown to achieve capacity\nusing two new ideas: \\textit{message history}, which captures the memory\nembedded in the setting, and \\textit{message splitting}, which eases the\nanalysis of the scheme. Additionally, in the special case of an S-channel, we\ngive a very simple zero-error coding scheme that is shown to achieve capacity.\nFor the input-constrained BSC, we show using our capacity formula that feedback\nincreases capacity when the cross-over probability is small.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Sabag Oron","Permuter Haim H.","Kashyap Navin"],"created":"2017-01-22","updated":"2018-01-08","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1701.06805","title":"A Projected Gradient Descent Method for CRF Inference allowing\n  End-To-End Training of Arbitrary Pairwise Potentials","abstract":"Are we using the right potential functions in the Conditional Random Field\nmodels that are popular in the Vision community? Semantic segmentation and\nother pixel-level labelling tasks have made significant progress recently due\nto the deep learning paradigm. However, most state-of-the-art structured\nprediction methods also include a random field model with a hand-crafted\nGaussian potential to model spatial priors, label consistencies and\nfeature-based image conditioning.\n  In this paper, we challenge this view by developing a new inference and\nlearning framework which can learn pairwise CRF potentials restricted only by\ntheir dependence on the image pixel values and the size of the support. Both\nstandard spatial and high-dimensional bilateral kernels are considered. Our\nframework is based on the observation that CRF inference can be achieved via\nprojected gradient descent and consequently, can easily be integrated in deep\nneural networks to allow for end-to-end training. It is empirically\ndemonstrated that such learned potentials can improve segmentation accuracy and\nthat certain label class interactions are indeed better modelled by a\nnon-Gaussian potential. In addition, we compare our inference method to the\ncommonly used mean-field algorithm. Our framework is evaluated on several\npublic benchmarks for semantic segmentation with improved performance compared\nto previous state-of-the-art CNN+CRF models.","primary_category":"cs","categories":["cs.CV"],"authors":["Larsson M\u00e5ns","Arnab Anurag","Kahl Fredrik","Zheng Shuai","Torr Philip"],"created":"2017-01-24","updated":"2018-01-02","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1701.07044","title":"Experimentally feasible protocol for semiquantum key distribution","abstract":"Quantum key distribution (QKD) protocols make it possible for two quantum\nparties to generate a secret shared key. Semiquantum key distribution (SQKD)\nprotocols, such as \"QKD with classical Bob\" and \"QKD with classical Alice\"\n(that have both been proven robust), achieve this goal even if one of the\nparties is classical. However, existing SQKD protocols are not experimentally\nfeasible with current technology. Here we suggest a new protocol, \"Classical\nAlice with a controllable mirror\", that can be experimentally implemented with\ncurrent technology (using 4-level systems instead of qubits), and we prove it\nto be robust.","primary_category":"cs","categories":["quant-ph","cs.CR"],"authors":["Boyer Michel","Katz Matty","Liss Rotem","Mor Tal"],"created":"2017-01-24","updated":"2017-12-29","doi":"10.1103\/PhysRevA.96.062335"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1701.07253","title":"Characterizations of idempotent discrete uninorms","abstract":"In this paper we provide an axiomatic characterization of the idempotent\ndiscrete uninorms by means of three conditions only: conservativeness,\nsymmetry, and nondecreasing monotonicity. We also provide an alternative\ncharacterization involving the bisymmetry property. Finally, we provide a\ngraphical characterization of these operations in terms of their contour plots,\nand we mention a few open questions for further research.","primary_category":"cs","categories":["math.RA","cs.DM"],"authors":["Couceiro Miguel","Devillet Jimmy","Marichal Jean-Luc"],"created":"2017-01-25","updated":"2017-06-29","doi":"10.1016\/j.fss.2017.06.013"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1701.07479","title":"Epidemiological modeling of the 2005 French riots: a spreading wave and\n  the role of contagion","abstract":"As a large-scale instance of dramatic collective behaviour, the 2005 French\nriots started in a poor suburb of Paris, then spread in all of France, lasting\nabout three weeks. Remarkably, although there were no displacements of rioters,\nthe riot activity did travel. Access to daily national police data has allowed\nus to explore the dynamics of riot propagation. Here we show that an\nepidemic-like model, with just a few parameters and a single sociological\nvariable characterizing neighbourhood deprivation, accounts quantitatively for\nthe full spatio-temporal dynamics of the riots. This is the first time that\nsuch data-driven modelling involving contagion both within and between cities\n(through geographic proximity or media) at the scale of a country, and on a\ndaily basis, is performed. Moreover, we give a precise mathematical\ncharacterization to the expression \"wave of riots\", and provide a visualization\nof the propagation around Paris, exhibiting the wave in a way not described\nbefore. The remarkable agreement between model and data demonstrates that\ngeographic proximity played a major role in the propagation, even though\ninformation was readily available everywhere through media. Finally, we argue\nthat our approach gives a general framework for the modelling of the dynamics\nof spontaneous collective uprisings.","primary_category":"cs","categories":["physics.soc-ph","cs.SI"],"authors":["Bonnasse-Gahot Laurent","Berestycki Henri","Depuiset Marie-Aude","Gordon Mirta B.","Roch\u00e9 Sebastian","Rodriguez Nancy","Nadal Jean-Pierre"],"created":"2017-01-25","updated":"2018-01-08","doi":"10.1038\/s41598-017-18093-4"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1701.07774","title":"Adaptively Detecting Malicious Queries in Web Attacks","abstract":"Web request query strings (queries), which pass parameters to the referenced\nresource, are always manipulated by attackers to retrieve sensitive data and\neven take full control of victim web servers and web applications. However,\nexisting malicious query detection approaches in the current literature cannot\ncope with changing web attacks with constant detection models. In this paper,\nwe propose AMODS, an adaptive system that periodically updates the detection\nmodel to detect the latest unknown attacks. We also propose an adaptive\nlearning strategy, called SVM HYBRID, leveraged by our system to minimize\nmanual work. In the evaluation, an up-to-date detection model is trained on a\nten-day query dataset collected from an academic institute's web server logs.\nOur system outperforms existing web attack detection methods, with an F-value\nof 94.79% and FP rate of 0.09%. The total number of malicious queries obtained\nby SVM HYBRID is 2.78 times that by the popular Support Vector Machine Adaptive\nLearning (SVM AL) method. The malicious queries obtained can be used to update\nthe Web Application Firewall (WAF) signature library.","primary_category":"cs","categories":["cs.CR","cs.NI"],"authors":["Dong Ying","Zhang Yuqing"],"created":"2017-01-26","updated":"2017-11-28","doi":"10.1007\/s11432-017-9288-4"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1701.08180","title":"Camera-trap images segmentation using multi-layer robust principal\n  component analysis","abstract":"The segmentation of animals from camera-trap images is a difficult task. To\nillustrate, there are various challenges due to environmental conditions and\nhardware limitation in these images. We proposed a multi-layer robust principal\ncomponent analysis (multi-layer RPCA) approach for background subtraction. Our\nmethod computes sparse and low-rank images from a weighted sum of descriptors,\nusing color and texture features as case of study for camera-trap images\nsegmentation. The segmentation algorithm is composed of histogram equalization\nor Gaussian filtering as pre-processing, and morphological filters with active\ncontour as post-processing. The parameters of our multi-layer RPCA were\noptimized with an exhaustive search. The database consists of camera-trap\nimages from the Colombian forest taken by the Instituto de Investigaci\\'on de\nRecursos Biol\\'ogicos Alexander von Humboldt. We analyzed the performance of\nour method in inherent and therefore challenging situations of camera-trap\nimages. Furthermore, we compared our method with some state-of-the-art\nalgorithms of background subtraction, where our multi-layer RPCA outperformed\nthese other methods. Our multi-layer RPCA reached 76.17 and 69.97% of average\nfine-grained F-measure for color and infrared sequences, respectively. To our\nbest knowledge, this paper is the first work proposing multi-layer RPCA and\nusing it for camera-trap images segmentation.","primary_category":"cs","categories":["cs.CV"],"authors":["Giraldo-Zuluaga Jhony-Heriberto","Gomez Alexander","Salazar Augusto","Diaz-Pulido Ang\u00e9lica"],"created":"2017-01-27","updated":"2017-12-30","doi":"10.1007\/s00371-017-1463-9"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1701.08361","title":"Accelerated Computing in Magnetic Resonance Imaging -- Real-Time Imaging\n  Using Non-Linear Inverse Reconstruction","abstract":"Purpose: To develop generic optimization strategies for image reconstruction\nusing graphical processing units (GPUs) in magnetic resonance imaging (MRI) and\nto exemplarily report about our experience with a highly accelerated\nimplementation of the non-linear inversion algorithm (NLINV) for dynamic MRI\nwith high frame rates. Methods: The NLINV algorithm is optimized and ported to\nrun on an a multi-GPU single-node server. The algorithm is mapped to multiple\nGPUs by decomposing the data domain along the channel dimension. Furthermore,\nthe algorithm is decomposed along the temporal domain by relaxing a temporal\nregularization constraint, allowing the algorithm to work on multiple frames in\nparallel. Finally, an autotuning method is presented that is capable of\ncombining different decomposition variants to achieve optimal algorithm\nperformance in different imaging scenarios. Results: The algorithm is\nsuccessfully ported to a multi-GPU system and allows online image\nreconstruction with high frame rates. Real-time reconstruction with low latency\nand frame rates up to 30 frames per second is demonstrated. Conclusion: Novel\nparallel decomposition methods are presented which are applicable to many\niterative algorithms for dynamic MRI. Using these methods to parallelize the\nNLINV algorithm on multiple GPUs it is possible to achieve online image\nreconstruction with high frame rates.","primary_category":"cs","categories":["cs.DC","physics.med-ph"],"authors":["Schaetz Sebastian","Voit Dirk","Frahm Jens","Uecker Martin"],"created":"2017-01-29","updated":"2017-11-08","doi":"10.1155\/2017\/3527269"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1702.01393","title":"Time Series Cube Data Model","abstract":"The purpose of this document is to create a data model and its serialization\nfor expressing generic time series data. Already existing IVOA data models are\nreused as much as possible. The model is also made as generic as possible to be\nopen to new extensions but at the same time closed for modifications. This\nenables maintaining interoperability throughout different versions of the data\nmodel. We define the necessary building blocks for metadata discovery,\nserialization of time series data and understanding it by clients. We present\nseveral categories of time series science cases with examples of\nimplementation. We also take into account the most pressing topics for time\nseries providers like tracking original images for every individual point of a\nlight curve or time-derived axes like frequency for gravitational wave\nanalysis. The main motivation for the creation of a new model is to provide a\nunified time series data publishing standard - not only for light curves but\nalso more generic time series data, e.g., radial velocity curves, power\nspectra, hardness ratio, provenance linkage, etc. The flexibility is the most\ncrucial part of our model - we are not dependent on any physical domain or\nframe models. While images or spectra are already stable and standardized\nproducts, the time series related domains are still not completely evolved and\nnew ones will likely emerge in near future. That is why we need to keep models\nlike Time Series Cube DM independent of any underlying physical models. In our\nopinion, this is the only correct and sustainable way for future development of\nIVOA standards.","primary_category":"cs","categories":["cs.DB","astro-ph.IM"],"authors":["Nadvornik Jiri","Skoda Petr","Morris Dave","Tvrdik Pavel"],"created":"2017-02-05","updated":"2018-01-11","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1702.03059","title":"Feedback Capacity of Stationary Gaussian Channels Further Examined","abstract":"It is well known that the problem of computing the feedback capacity of a\nstationary Gaussian channel can be recast as an infinite-dimensional\noptimization problem; moreover, necessary and sufficient conditions for the\noptimality of a solution to this optimization problem have been characterized,\nand based on this characterization, an explicit formula for the feedback\ncapacity has been given for the case that the noise is a first-order\nautoregressive moving-average Gaussian process. In this paper, we further\nexamine the above-mentioned infinite-dimensional optimization problem. We prove\nthat unless the Gaussian noise is white, its optimal solution is unique, and we\npropose an algorithm to recursively compute the unique optimal solution, which\nis guaranteed to converge in theory and features an efficient implementation\nfor a suboptimal solution in practice. Furthermore, for the case that the noise\nis a k-th order autoregressive moving-average Gaussian process, we give a\nrelatively more explicit formula for the feedback capacity; more specifically,\nthe feedback capacity is expressed as a simple function evaluated at a solution\nto a system of polynomial equations, which is amenable to numerical computation\nfor the cases k=1, 2 and possibly beyond.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Liu Tao","Han Guangyue"],"created":"2017-02-09","updated":"2018-01-08","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1702.04322","title":"Parameterized Algorithms for Recognizing Monopolar and 2-Subcolorable\n  Graphs","abstract":"A graph $G$ is a $(\\Pi_A,\\Pi_B)$-graph if $V(G)$ can be bipartitioned into\n$A$ and $B$ such that $G[A]$ satisfies property $\\Pi_A$ and $G[B]$ satisfies\nproperty $\\Pi_B$. The $(\\Pi_{A},\\Pi_{B})$-Recognition problem is to recognize\nwhether a given graph is a $(\\Pi_A,\\Pi_B)$-graph. There are many\n$(\\Pi_{A},\\Pi_{B})$-Recognition problems, including the recognition problems\nfor bipartite, split, and unipolar graphs. We present efficient algorithms for\nmany cases of $(\\Pi_A,\\Pi_B)$-Recognition based on a technique which we dub\ninductive recognition. In particular, we give fixed-parameter algorithms for\ntwo NP-hard $(\\Pi_{A},\\Pi_{B})$-Recognition problems, Monopolar Recognition and\n2-Subcoloring. We complement our algorithmic results with several hardness\nresults for $(\\Pi_{A},\\Pi_{B})$-Recognition.","primary_category":"cs","categories":["cs.CC","cs.DS"],"authors":["Kanj Iyad","Komusiewicz Christian","Sorge Manuel","van Leeuwen Erik Jan"],"created":"2017-02-14","updated":"2018-01-04","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1702.04376","title":"Automata theory on sliding windows","abstract":"In a recent paper we analyzed the space complexity of streaming algorithms\nwhose goal is to decide membership of a sliding window to a fixed language. For\nthe class of regular languages we proved a space trichotomy theorem: for every\nregular language the optimal space bound is either constant, logarithmic or\nlinear. In this paper we continue this line of research: We present natural\ncharacterizations for the constant and logarithmic space classes and establish\ntight relationships to the concept of language growth. We also analyze the\nspace complexity with respect to automata size and prove almost matching lower\nand upper bounds. Finally, we consider the decision problem whether a language\ngiven by a DFA\/NFA admits a sliding window algorithm using logarithmic\/constant\nspace.","primary_category":"cs","categories":["cs.FL","cs.DS"],"authors":["Ganardi Moses","Hucke Danny","K\u00f6nig Daniel","Lohrey Markus","Mamouras Konstantinos"],"created":"2017-02-14","updated":"2018-01-05","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1702.05536","title":"Beyond the Hazard Rate: More Perturbation Algorithms for Adversarial\n  Multi-armed Bandits","abstract":"Recent work on follow the perturbed leader (FTPL) algorithms for the\nadversarial multi-armed bandit problem has highlighted the role of the hazard\nrate of the distribution generating the perturbations. Assuming that the hazard\nrate is bounded, it is possible to provide regret analyses for a variety of\nFTPL algorithms for the multi-armed bandit problem. This paper pushes the\ninquiry into regret bounds for FTPL algorithms beyond the bounded hazard rate\ncondition. There are good reasons to do so: natural distributions such as the\nuniform and Gaussian violate the condition. We give regret bounds for both\nbounded support and unbounded support distributions without assuming the hazard\nrate condition. We also disprove a conjecture that the Gaussian distribution\ncannot lead to a low-regret algorithm. In fact, it turns out that it leads to\nnear optimal regret, up to logarithmic factors. A key ingredient in our\napproach is the introduction of a new notion called the generalized hazard\nrate.","primary_category":"cs","categories":["cs.LG","cs.GT","stat.ML"],"authors":["Li Zifan","Tewari Ambuj"],"created":"2017-02-17","updated":"2018-01-05","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1702.05770","title":"Achieving the Desired Dynamic Behavior in Multi-Robot Systems\n  Interacting with the Environment","abstract":"In this paper we consider the problem of controlling the dynamic behavior of\na multi-robot system while interacting with the environment. In particular, we\npropose a general methodology that, by means of locally scaling inter-robot\ncoupling relationships, leads to achieving a desired interactive behavior. The\nproposed method is shown to guarantee passivity preservation, which ensures a\nsafe interaction. The performance of the proposed methodology is evaluated in\nsimulation, over large-scale multi-robot systems.","primary_category":"cs","categories":["cs.RO"],"authors":["Sabattini Lorenzo","Secchi Cristian","Fantuzzi Cesare"],"created":"2017-02-19","updated":" ","doi":"10.1109\/ICRA.2017.7989241"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1702.06265","title":"Task-Space Consensus of Networked Robotic Systems: Separation and\n  Manipulability","abstract":"In this paper, we investigate the task-space consensus problem for multiple\nrobotic systems with both the uncertain kinematics and dynamics and address two\nmain issues, i.e., the separation of the kinematic and dynamic loops in the\ncase of no task-space velocity measurement and the quantification of the\nmanipulability of the system. We propose an observer-based adaptive controller\nto achieve the manipulable consensus without relying on the measurement of\ntask-space velocities, and also formalize the concept of manipulability to\nquantify the degree of adjustability of the consensus value. The proposed\nadaptive controller employs a new distributed observer that does not rely on\nthe joint velocity and a new kinematic parameter adaptation law with a\ndistributed adaptive kinematic regressor matrix that is driven by both the\nobservation and consensus errors. In addition, it is shown that the proposed\ncontroller has the separation property, which yields an adaptive kinematic\ncontroller that is applicable to most industrial\/commercial robots. The\nperformance of the proposed observer-based adaptive schemes is shown by\nnumerical simulations.","primary_category":"cs","categories":["cs.SY"],"authors":["Wang Hanlei","Xie Yongchun"],"created":"2017-02-21","updated":"2018-01-10","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1702.06355","title":"Object Detection in Videos with Tubelet Proposal Networks","abstract":"Object detection in videos has drawn increasing attention recently with the\nintroduction of the large-scale ImageNet VID dataset. Different from object\ndetection in static images, temporal information in videos is vital for object\ndetection. To fully utilize temporal information, state-of-the-art methods are\nbased on spatiotemporal tubelets, which are essentially sequences of associated\nbounding boxes across time. However, the existing methods have major\nlimitations in generating tubelets in terms of quality and efficiency.\nMotion-based methods are able to obtain dense tubelets efficiently, but the\nlengths are generally only several frames, which is not optimal for\nincorporating long-term temporal information. Appearance-based methods, usually\ninvolving generic object tracking, could generate long tubelets, but are\nusually computationally expensive. In this work, we propose a framework for\nobject detection in videos, which consists of a novel tubelet proposal network\nto efficiently generate spatiotemporal proposals, and a Long Short-term Memory\n(LSTM) network that incorporates temporal information from tubelet proposals\nfor achieving high object detection accuracy in videos. Experiments on the\nlarge-scale ImageNet VID dataset demonstrate the effectiveness of the proposed\nframework for object detection in videos.","primary_category":"cs","categories":["cs.CV"],"authors":["Kang Kai","Li Hongsheng","Xiao Tong","Ouyang Wanli","Yan Junjie","Liu Xihui","Wang Xiaogang"],"created":"2017-02-21","updated":"2017-04-10","doi":"10.1109\/CVPR.2017.101"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1702.06698","title":"Computing the longest common prefix of a context-free language in\n  polynomial time","abstract":"We present two structural results concerning longest common prefixes of\nnon-empty languages. First, we show that the longest common prefix of the\nlanguage generated by a context-free grammar of size $N$ equals the longest\ncommon prefix of the same grammar where the heights of the derivation trees are\nbounded by $4N$. Second, we show that each nonempty language $L$ has a\nrepresentative subset of at most three elements which behaves like $L$ w.r.t.\nthe longest common prefix as well as w.r.t. longest common prefixes of $L$\nafter unions or concatenations with arbitrary other languages. From that, we\nconclude that the longest common prefix, and thus the longest common suffix, of\na context-free language can be computed in polynomial time.","primary_category":"cs","categories":["cs.FL"],"authors":["Luttenberger Michael","Palenta Raphaela","Seidl Helmut"],"created":"2017-02-22","updated":"2018-01-06","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1702.07429","title":"On the Optimality of Secret Key Agreement via Omniscience","abstract":"For the multiterminal secret key agreement problem under a private source\nmodel, it is known that the maximum key rate, i.e., the secrecy capacity, can\nbe achieved through communication for omniscience, but the omniscience strategy\ncan be strictly suboptimal in terms of minimizing the public discussion rate.\nWhile a single-letter characterization is not known for the minimum discussion\nrate needed for achieving the secrecy capacity, we derive single-letter lower\nand upper bounds that yield some simple conditions for omniscience to be\ndiscussion-rate optimal. These conditions turn out to be enough to deduce the\noptimality of omniscience for a large class of sources including the\nhypergraphical sources. Through conjectures and examples, we explore other\nsource models to which our methods do not easily extend.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Chan Chung","Mukherjee Manuj","Kashyap Navin","Zhou Qiaoqiao"],"created":"2017-02-23","updated":"2018-01-04","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1702.08376","title":"Admittance Control Parameter Adaptation for Physical Human-Robot\n  Interaction","abstract":"In physical human-robot interaction, the coexistence of robots and humans in\nthe same workspace requires the guarantee of a stable interaction, trying to\nminimize the effort for the operator. To this aim, the admittance control is\nwidely used and the appropriate selection of the its parameters is crucial,\nsince they affect both the stability and the ability of the robot to interact\nwith the user. In this paper, we present a strategy for detecting deviations\nfrom the nominal behavior of an admittance-controlled robot and for adapting\nthe parameters of the controller while guaranteeing the passivity. The proposed\nmethodology is validated on a KUKA LWR 4+.","primary_category":"cs","categories":["cs.RO"],"authors":["Landi Chiara Talignani","Ferraguti Federica","Sabattini Lorenzo","Secchi Cristian","Fantuzzi Cesare"],"created":"2017-02-27","updated":" ","doi":"10.1109\/ICRA.2017.7989338"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1702.08593","title":"Mind the Gap: A Study in Global Development through Persistent Homology","abstract":"The Gapminder project set out to use statistics to dispel simplistic notions\nabout global development. In the same spirit, we use persistent homology, a\ntechnique from computational algebraic topology, to explore the relationship\nbetween country development and geography. For each country, four indicators,\ngross domestic product per capita; average life expectancy; infant mortality;\nand gross national income per capita, were used to quantify the development.\nTwo analyses were performed. The first considers clusters of the countries\nbased on these indicators, and the second uncovers cycles in the data when\ncombined with geographic border structure. Our analysis is a multi-scale\napproach that reveals similarities and connections among countries at a variety\nof levels. We discover localized development patterns that are invisible in\nstandard statistical methods.","primary_category":"cs","categories":["math.AT","cs.CG"],"authors":["Banman Andrew","Ziegelmeier Lori"],"created":"2017-02-27","updated":"2018-01-10","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1703.00099","title":"Learning Conversational Systems that Interleave Task and Non-Task\n  Content","abstract":"Task-oriented dialog systems have been applied in various tasks, such as\nautomated personal assistants, customer service providers and tutors. These\nsystems work well when users have clear and explicit intentions that are\nwell-aligned to the systems' capabilities. However, they fail if users\nintentions are not explicit. To address this shortcoming, we propose a\nframework to interleave non-task content (i.e. everyday social conversation)\ninto task conversations. When the task content fails, the system can still keep\nthe user engaged with the non-task content. We trained a policy using\nreinforcement learning algorithms to promote long-turn conversation coherence\nand consistency, so that the system can have smooth transitions between task\nand non-task content. To test the effectiveness of the proposed framework, we\ndeveloped a movie promotion dialog system. Experiments with human users\nindicate that a system that interleaves social and task content achieves a\nbetter task success rate and is also rated as more engaging compared to a pure\ntask-oriented system.","primary_category":"cs","categories":["cs.CL","cs.AI","cs.HC"],"authors":["Yu Zhou","Black Alan W","Rudnicky Alexander I."],"created":"2017-02-28","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1703.01135","title":"Deep Learning with Domain Adaptation for Accelerated\n  Projection-Reconstruction MR","abstract":"Purpose: The radial k-space trajectory is a well-established sampling\ntrajectory used in conjunction with magnetic resonance imaging. However, the\nradial k-space trajectory requires a large number of radial lines for\nhigh-resolution reconstruction. Increasing the number of radial lines causes\nlonger acquisition time, making it more difficult for routine clinical use. On\nthe other hand, if we reduce the number of radial lines, streaking artifact\npatterns are unavoidable. To solve this problem, we propose a novel deep\nlearning approach with domain adaptation to restore high-resolution MR images\nfrom under-sampled k-space data.\n  Methods: The proposed deep network removes the streaking artifacts from the\nartifact corrupted images. To address the situation given the limited available\ndata, we propose a domain adaptation scheme that employs a pre-trained network\nusing a large number of x-ray computed tomography (CT) or synthesized radial MR\ndatasets, which is then fine-tuned with only a few radial MR datasets.\n  Results: The proposed method outperforms existing compressed sensing\nalgorithms, such as the total variation and PR-FOCUSS methods. In addition, the\ncalculation time is several orders of magnitude faster than the total variation\nand PR-FOCUSS methods.Moreover, we found that pre-training using CT or MR data\nfrom similar organ data is more important than pre-training using data from the\nsame modality for different organ.\n  Conclusion: We demonstrate the possibility of a domain-adaptation when only a\nlimited amount of MR data is available. The proposed method surpasses the\nexisting compressed sensing algorithms in terms of the image quality and\ncomputation time.","primary_category":"cs","categories":["cs.CV"],"authors":["Han Yo Seob","Yoo Jaejun","Ye Jong Chul"],"created":"2017-03-03","updated":"2018-01-08","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1703.01220","title":"Denoising Adversarial Autoencoders","abstract":"Unsupervised learning is of growing interest because it unlocks the potential\nheld in vast amounts of unlabelled data to learn useful representations for\ninference. Autoencoders, a form of generative model, may be trained by learning\nto reconstruct unlabelled input data from a latent representation space. More\nrobust representations may be produced by an autoencoder if it learns to\nrecover clean input samples from corrupted ones. Representations may be further\nimproved by introducing regularisation during training to shape the\ndistribution of the encoded data in latent space. We suggest denoising\nadversarial autoencoders, which combine denoising and regularisation, shaping\nthe distribution of latent space using adversarial training. We introduce a\nnovel analysis that shows how denoising may be incorporated into the training\nand sampling of adversarial autoencoders. Experiments are performed to assess\nthe contributions that denoising makes to the learning of representations for\nclassification and sample synthesis. Our results suggest that autoencoders\ntrained using a denoising criterion achieve higher classification performance,\nand can synthesise samples that are more consistent with the input data than\nthose trained without a corruption process.","primary_category":"cs","categories":["cs.CV","cs.LG","stat.ML"],"authors":["Creswell Antonia","Bharath Anil Anthony"],"created":"2017-03-03","updated":"2018-01-04","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1703.01256","title":"The Global Optimization Geometry of Low-Rank Matrix Optimization","abstract":"This paper considers general rank-constrained optimization problems that\nminimize a general objective function $f(X)$ over the set of rectangular\n$n\\times m$ matrices that have rank at most $r$. To tackle the rank constraint\nand also to reduce the computational burden, we factorize $X$ into $UV^T$ where\n$U$ and $V$ are $n\\times r$ and $m\\times r$ matrices, respectively, and then\noptimize over the small matrices $U$ and $V$. We characterize the global\noptimization geometry of the nonconvex factored problem and show that the\ncorresponding objective function satisfies the robust strict saddle property as\nlong as the original objective function $f$ satisfies restricted strong\nconvexity and smoothness properties, ensuring global convergence of many local\nsearch algorithms (such as noisy gradient descent) in polynomial time for\nsolving the factored problem. We also provide a comprehensive analysis for the\noptimization geometry of a matrix factorization problem where we aim to find\n$n\\times r$ and $m\\times r$ matrices $U$ and $V$ such that $UV^T$ approximates\na given matrix $X^\\star$. Aside from the robust strict saddle property, we show\nthat the objective function of the matrix factorization problem has no spurious\nlocal minima and obeys the strict saddle property not only for the\nexact-parameterization case where $rank(X^\\star) = r$, but also for the\nover-parameterization case where $rank(X^\\star) < r$ and the\nunder-parameterization case where $rank(X^\\star) > r$. These geometric\nproperties imply that a number of iterative optimization algorithms (such as\ngradient descent) converge to a global solution with random initialization.","primary_category":"cs","categories":["cs.IT","math.IT","math.OC"],"authors":["Zhu Zhihui","Li Qiuwei","Tang Gongguo","Wakin Michael B."],"created":"2017-03-03","updated":"2018-01-04","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1703.01671","title":"Controlling for Unobserved Confounds in Classification Using\n  Correlational Constraints","abstract":"As statistical classifiers become integrated into real-world applications, it\nis important to consider not only their accuracy but also their robustness to\nchanges in the data distribution. In this paper, we consider the case where\nthere is an unobserved confounding variable $z$ that influences both the\nfeatures $\\mathbf{x}$ and the class variable $y$. When the influence of $z$\nchanges from training to testing data, we find that the classifier accuracy can\ndegrade rapidly. In our approach, we assume that we can predict the value of\n$z$ at training time with some error. The prediction for $z$ is then fed to\nPearl's back-door adjustment to build our model. Because of the attenuation\nbias caused by measurement error in $z$, standard approaches to controlling for\n$z$ are ineffective. In response, we propose a method to properly control for\nthe influence of $z$ by first estimating its relationship with the class\nvariable $y$, then updating predictions for $z$ to match that estimated\nrelationship. By adjusting the influence of $z$, we show that we can build a\nmodel that exceeds competing baselines on accuracy as well as on robustness\nover a range of confounding relationships.","primary_category":"cs","categories":["cs.AI","cs.CL"],"authors":["Landeiro Virgile","Culotta Aron"],"created":"2017-03-05","updated":"2018-01-11","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1703.01905","title":"A randomized, efficient algorithm for 3SAT","abstract":"In this paper I present a 3SAT algorithm based on the randomized algorithm of\nPapadimitriou from 1991, and Schoning from 1991. We also present strong\narguments that this algorithm finds a solution (if it exists) for a 3SAT\nproblem with high probability in polynomial time.","primary_category":"cs","categories":["cs.DS"],"authors":["Dumitrescu Cristian"],"created":"2017-03-06","updated":"2018-01-02","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1703.03150","title":"A Normalization Model for Analyzing Multi-Tier Millimeter Wave Cellular\n  Networks","abstract":"Based on the distinguishing features of multi-tier millimeter wave (mmWave)\nnetworks such as different transmit powers, different directivity gains from\ndirectional beamforming alignment and path loss laws for line-of-sight (LOS)\nand non-line-of-sight (NLOS) links, we introduce a normalization model to\nsimplify the analysis of multi-tier mmWave cellular networks. The highlight of\nthe model is that we convert a multi-tier mmWave cellular network into a\nsingle-tier mmWave network, where all the base stations (BSs) have the same\nnormalized transmit power 1 and the densities of BSs scaled by LOS or NLOS\nscaling factors respectively follow piecewise constant function which has\nmultiple demarcation points. On this basis, expressions for computing the\ncoverage probability are obtained in general case with beamforming alignment\nerrors and the special case with perfect beamforming alignment in the\ncommunication. According to corresponding numerical exploration, we conclude\nthat the normalization model for multi-tier mmWave cellular networks fully\nmeets requirements of network performance analysis, and it is simpler and\nclearer than the untransformed model. Besides, an unexpected but sensible\nfinding is that there is an optimal beam width that maximizes coverage\nprobability in the case with beamforming alignment errors.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Xiong Siqing","Wang Lijun","Kwak Kyung Sup","Bai Zhiquan","Wang Jiang","Li Qiang","Han Tao"],"created":"2017-03-09","updated":"2018-01-07","doi":"10.1109\/IWCMC.2017.7986389"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1703.03214","title":"Optimal Network-Assisted Multi-user DASH Video Streaming","abstract":"Streaming video is becoming the predominant type of traffic over the Internet\nwith reports forecasting the video content to account for 80% of all traffic by\n2019. With significant investment on Internet backbone, the main bottleneck\nremains at the edge servers (e.g., WiFi access points, small cells, etc.). In\nthis work, we propose and prove the optimality of a multiuser resource\nallocation mechanism operating at the edge server that minimizes the\nprobability of stalling of video streams due to buffer under-flows. Our\nproposed policy utilizes Media Presentation Description (MPD) files of clients\nthat are sent in compliant to Dynamic Adaptive Streaming over HTTP (DASH)\nprotocol to be cognizant of the deadlines of each of the media file to be\ndisplayed by the clients. Then, the policy schedules the users in the order of\ntheir deadlines. After establishing the optimality of this policy to minimize\nthe stalling probability for a network with links associated with fixed loss\nrates, the utility of the algorithm is verified under realistic network\nconditions with detailed NS-3 simulations.","primary_category":"cs","categories":["cs.NI","cs.MM"],"authors":["Ozfatura Emre","Ercetin Ozgur","Inaltekin Hazer"],"created":"2017-03-09","updated":"2017-12-29","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1703.03912","title":"Mitigating the Curse of Correlation in Security Games by Entropy\n  Maximization","abstract":"In Stackelberg security games, a defender seeks to randomly allocate limited\nsecurity resources to protect critical targets from an attack. In this paper,\nwe study a fundamental, yet underexplored, phenomenon in security games, which\nwe term the \\emph{Curse of Correlation} (CoC). Specifically, we observe that\nthere are inevitable correlations among the protection status of different\ntargets. Such correlation is a crucial concern, especially in\n\\emph{spatio-temporal} domains like conservation area patrolling, where\nattackers can surveil patrollers at certain areas and then infer their\npatrolling routes using such correlations. To mitigate this issue, we propose\nto design entropy-maximizing defending strategies for spatio-temporal security\ngames, which frequently suffer from CoC. We prove that the problem is \\#P-hard\nin general. However, it admits efficient algorithms in well-motivated special\nsettings. Our experiments show significant advantages of max-entropy algorithms\nover previous algorithms. A scalable implementation of our algorithm is\ncurrently under pre-deployment testing for integration into FAMS software to\nimprove the scheduling of US federal air marshals.","primary_category":"cs","categories":["cs.GT","cs.AI","cs.CR"],"authors":["Xu Haifeng","Tambe Milind","Dughmi Shaddin","Noronha Venil Loyd"],"created":"2017-03-11","updated":"2018-01-03","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1703.05769","title":"A 588 Gbps LDPC Decoder Based on Finite-Alphabet Message Passing","abstract":"An ultra-high throughput low-density parity check (LDPC) decoder with an\nunrolled full-parallel architecture is proposed, which achieves the highest\ndecoding throughput compared to previously reported LDPC decoders in the\nliterature. The decoder benefits from a serial message-transfer approach\nbetween the decoding stages to alleviate the well-known routing congestion\nproblem in parallel LDPC decoders. Furthermore, a finite-alphabet message\npassing algorithm is employed to replace the variable node update rule of the\nstandard min-sum decoder with look-up tables, which are designed in a way that\nmaximizes the mutual information between decoding messages. The proposed\nalgorithm results in an architecture with reduced bit-width messages, leading\nto a significantly higher decoding throughput and to a lower area as compared\nto a min-sum decoder when serial message-transfer is used. The architecture is\nplaced and routed for the standard min-sum reference decoder and for the\nproposed finite-alphabet decoder using a custom pseudo-hierarchical backend\ndesign strategy to further alleviate routing congestions and to handle the\nlarge design. Post-layout results show that the finite-alphabet decoder with\nthe serial message-transfer architecture achieves a throughput as large as 588\nGbps with an area of 16.2 mm$^2$ and dissipates an average power of 22.7 pJ per\ndecoded bit in a 28 nm FD-SOI library. Compared to the reference min-sum\ndecoder, this corresponds to 3.1 times smaller area and 2 times better energy\nefficiency.","primary_category":"cs","categories":["cs.AR","cs.IT","math.IT"],"authors":["Ghanaatian Reza","Balatsoukas-Stimming Alexios","Muller Christoph","Meidlinger Michael","Matz Gerald","Teman Adam","Burg Andreas"],"created":"2017-03-16","updated":"2017-12-30","doi":"10.1109\/TVLSI.2017.2766925"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1703.06359","title":"Fully symmetric kernel quadrature","abstract":"Kernel quadratures and other kernel-based approximation methods typically\nsuffer from prohibitive cubic time and quadratic space complexity in the number\nof function evaluations. The problem arises because a system of linear\nequations needs to be solved. In this article we show that the weights of a\nkernel quadrature rule can be computed efficiently and exactly for up to tens\nof millions of nodes if the kernel, integration domain, and measure are fully\nsymmetric and the node set is a union of fully symmetric sets. This is based on\nthe observations that in such a setting there are only as many distinct weights\nas there are fully symmetric sets and that these weights can be solved from a\nlinear system of equations constructed out of row sums of certain submatrices\nof the full kernel matrix. We present several numerical examples that show\nfeasibility, both for a large number of nodes and in high dimensions, of the\ndeveloped fully symmetric kernel quadrature rules. Most prominent of the fully\nsymmetric kernel quadrature rules we propose are those that use sparse grids.","primary_category":"cs","categories":["math.NA","cs.NA","stat.CO"],"authors":["Karvonen Toni","S\u00e4rkk\u00e4 Simo"],"created":"2017-03-18","updated":"2018-01-06","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1703.07710","title":"Unifying PAC and Regret: Uniform PAC Bounds for Episodic Reinforcement\n  Learning","abstract":"Statistical performance bounds for reinforcement learning (RL) algorithms can\nbe critical for high-stakes applications like healthcare. This paper introduces\na new framework for theoretically measuring the performance of such algorithms\ncalled Uniform-PAC, which is a strengthening of the classical Probably\nApproximately Correct (PAC) framework. In contrast to the PAC framework, the\nuniform version may be used to derive high probability regret guarantees and so\nforms a bridge between the two setups that has been missing in the literature.\nWe demonstrate the benefits of the new framework for finite-state episodic MDPs\nwith a new algorithm that is Uniform-PAC and simultaneously achieves optimal\nregret and PAC guarantees except for a factor of the horizon.","primary_category":"cs","categories":["cs.LG","cs.AI","stat.ML"],"authors":["Dann Christoph","Lattimore Tor","Brunskill Emma"],"created":"2017-03-22","updated":"2018-01-02","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1703.07943","title":"Role of zero synapses in unsupervised feature learning","abstract":"Synapses in real neural circuits can take discrete values, including zero\n(silent or potential) synapses. The computational role of zero synapses in\nunsupervised feature learning of unlabeled noisy data is still unclear, thus it\nis important to understand how the sparseness of synaptic activity is shaped\nduring learning and its relationship with receptive field formation. Here, we\nformulate this kind of sparse feature learning by a statistical mechanics\napproach. We find that learning decreases the fraction of zero synapses, and\nwhen the fraction decreases rapidly around a critical data size, an\nintrinsically structured receptive field starts to develop. Further increasing\nthe data size refines the receptive field, while a very small fraction of zero\nsynapses remain to act as contour detectors. This phenomenon is discovered not\nonly in learning a handwritten digits dataset, but also in learning retinal\nneural activity measured in a natural-movie-stimuli experiment.","primary_category":"cs","categories":["q-bio.NC","cond-mat.dis-nn","cond-mat.stat-mech","cs.LG","cs.NE"],"authors":["Huang Haiping"],"created":"2017-03-23","updated":"2018-01-10","doi":"10.1088\/1751-8121\/aaa631"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1703.08774","title":"Who Said What: Modeling Individual Labelers Improves Classification","abstract":"Data are often labeled by many different experts with each expert only\nlabeling a small fraction of the data and each data point being labeled by\nseveral experts. This reduces the workload on individual experts and also gives\na better estimate of the unobserved ground truth. When experts disagree, the\nstandard approaches are to treat the majority opinion as the correct label or\nto model the correct label as a distribution. These approaches, however, do not\nmake any use of potentially valuable information about which expert produced\nwhich label. To make use of this extra information, we propose modeling the\nexperts individually and then learning averaging weights for combining them,\npossibly in sample-specific ways. This allows us to give more weight to more\nreliable experts and take advantage of the unique strengths of individual\nexperts at classifying certain types of data. Here we show that our approach\nleads to improvements in computer-aided diagnosis of diabetic retinopathy. We\nalso show that our method performs better than competing algorithms by Welinder\nand Perona (2010), and by Mnih and Hinton (2012). Our work offers an innovative\napproach for dealing with the myriad real-world settings that use expert\nopinions to define labels for training.","primary_category":"cs","categories":["cs.LG","cs.CV"],"authors":["Guan Melody Y.","Gulshan Varun","Dai Andrew M.","Hinton Geoffrey E."],"created":"2017-03-26","updated":"2018-01-04","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1703.09518","title":"Existence and Continuity of Differential Entropy for a Class of\n  Distributions","abstract":"In this paper, we identify a class of absolutely continuous probability\ndistributions, and show that the differential entropy is uniformly convergent\nover this space under the metric of total variation distance. One of the\nadvantages of this class is that the requirements could be readily verified for\na given distribution.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Ghourchian Hamid","Gohari Amin","Amini Arash"],"created":"2017-03-28","updated":" ","doi":"10.1109\/LCOMM.2017.2689770"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1703.10316","title":"Efficient Parallel Translating Embedding For Knowledge Graphs","abstract":"Knowledge graph embedding aims to embed entities and relations of knowledge\ngraphs into low-dimensional vector spaces. Translating embedding methods regard\nrelations as the translation from head entities to tail entities, which achieve\nthe state-of-the-art results among knowledge graph embedding methods. However,\na major limitation of these methods is the time consuming training process,\nwhich may take several days or even weeks for large knowledge graphs, and\nresult in great difficulty in practical applications. In this paper, we propose\nan efficient parallel framework for translating embedding methods, called\nParTrans-X, which enables the methods to be paralleled without locks by\nutilizing the distinguished structures of knowledge graphs. Experiments on two\ndatasets with three typical translating embedding methods, i.e., TransE [3],\nTransH [17], and a more efficient variant TransE- AdaGrad [10] validate that\nParTrans-X can speed up the training process by more than an order of\nmagnitude.","primary_category":"cs","categories":["cs.AI"],"authors":["Zhang Denghui","Li Manling","Jia Yantao","Wang Yuanzhuo","Cheng Xueqi"],"created":"2017-03-30","updated":"2018-01-08","doi":"10.1145\/3106426.3106447"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1704.00905","title":"Interacting With a Mobile Robot with a Natural Infrastructure-Less\n  Interface","abstract":"In this paper we introduce a novel approach that enables users to interact\nwith a mobile robot in a natural manner. The proposed interaction system does\nnot require any specific infrastructure or device, but relies on commonly\nutilized objects while leaving the user's hands free. Specifically, we propose\nto utilize a smartwatch (or a sensorized wristband) for recognizing the motion\nof the user's forearm. Measurements of accelerations and angular velocities are\nexploited to recognize user's gestures and define velocity commands for the\nrobot. The proposed interaction system is evaluated experimentally with\ndifferent users controlling a mobile robot and compared to the use of a remote\ncontrol device for the teleoperation of robots. Results show that the usability\nand effectiveness of the proposed natural interaction system based on the use\nof a smartwatch provide significant improvement in the human-robot interaction\nexperience.","primary_category":"cs","categories":["cs.RO"],"authors":["Villani Valeria","Sabattini Lorenzo","Riggio Giuseppe","Levratti Alessio","Secchi Cristian","Fantuzzi Cesare"],"created":"2017-04-04","updated":" ","doi":"10.1016\/j.ifacol.2017.08.1829"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1704.01306","title":"Using Convolutional Codes for Key Extraction in SRAM Physical Unclonable\n  Functions","abstract":"Physical Unclonable Functions (PUFs) exploit variations in the manufacturing\nprocess to derive bit sequences from integrated circuits, which can be used as\nsecure cryptographic keys. Instead of storing the keys in an insecure,\nnon-volatile memory, they can be reproduced when needed. Since the reproduced\nsequences are not stable due to physical reasons, error correction must be\napplied. Recently, convolutional codes were shown to be suitable for key\nreproduction in PUFs based on SRAM. This work shows how to further decrease the\nreconstruction failure probability and PUF implementation size using codes with\nlarger memory length and decoding concepts such as soft-information and list\ndecoding.","primary_category":"cs","categories":["cs.IT","cs.CR","math.IT"],"authors":["M\u00fcelich Sven","Puchinger Sven","Bossert Martin"],"created":"2017-04-05","updated":"2018-01-10","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1704.01472","title":"Automatic Breast Ultrasound Image Segmentation: A Survey","abstract":"Breast cancer is one of the leading causes of cancer death among women\nworldwide. In clinical routine, automatic breast ultrasound (BUS) image\nsegmentation is very challenging and essential for cancer diagnosis and\ntreatment planning. Many BUS segmentation approaches have been studied in the\nlast two decades, and have been proved to be effective on private datasets.\nCurrently, the advancement of BUS image segmentation seems to meet its\nbottleneck. The improvement of the performance is increasingly challenging, and\nonly few new approaches were published in the last several years. It is the\ntime to look at the field by reviewing previous approaches comprehensively and\nto investigate the future directions. In this paper, we study the basic ideas,\ntheories, pros and cons of the approaches, group them into categories, and\nextensively review each category in depth by discussing the principles,\napplication issues, and advantages\/disadvantages.","primary_category":"cs","categories":["cs.CV","cs.LG"],"authors":["Xian Min","Zhang Yingtao","Cheng H. D.","Xu Fei","Zhang Boyu","Ding Jianrui"],"created":"2017-04-04","updated":"2018-01-09","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1704.02275","title":"Mitigating Interference in Content Delivery Networks by Spatial Signal\n  Alignment: The Approach of Shot-Noise Ratio","abstract":"Multimedia content especially videos is expected to dominate data traffic in\nnext-generation mobile networks. Caching popular content at the network edge\nhas emerged to be a solution for low-latency content delivery. Compared with\nthe traditional wireless communication, content delivery has a key\ncharacteristic that many signals coexisting in the air carry identical popular\ncontent. They, however, can interfere with each other at a receiver if their\nmodulation-and-coding (MAC) schemes are adapted to individual channels\nfollowing the classic approach. To address this issue, we present a novel idea\nof content adaptive MAC (CAMAC) where adapting MAC schemes to content ensures\nthat all signals carry identical content are encoded using an identical MAC\nscheme, achieving spatial MAC alignment. Consequently, interference can be\nharnessed as signals, to improve the reliability of wireless delivery. In the\nremaining part of the paper, we focus on quantifying the gain CAMAC can bring\nto a content-delivery network using a stochastic-geometry model. Specifically,\ncontent helpers are distributed as a Poisson point process, each of which\ntransmits a file from a content database based on a given popularity\ndistribution. It is discovered that the successful content-delivery probability\nis closely related to the distribution of the ratio of two independent shot\nnoise processes, named a shot-noise ratio. The distribution itself is an open\nmathematical problem that we tackle in this work. Using stable-distribution\ntheory and tools from stochastic geometry, the distribution function is derived\nin closed form. Extending the result in the context of content-delivery\nnetworks with CAMAC yields the content-delivery probability in different closed\nforms. In addition, the gain in the probability due to CAMAC is shown to grow\nwith the level of skewness in the content popularity distribution.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Liu Dongzhu","Huang Kaibin"],"created":"2017-04-07","updated":"2018-01-05","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1704.02431","title":"Learning Cross-Modal Deep Representations for Robust Pedestrian\n  Detection","abstract":"This paper presents a novel method for detecting pedestrians under adverse\nillumination conditions. Our approach relies on a novel cross-modality learning\nframework and it is based on two main phases. First, given a multimodal\ndataset, a deep convolutional network is employed to learn a non-linear\nmapping, modeling the relations between RGB and thermal data. Then, the learned\nfeature representations are transferred to a second deep network, which\nreceives as input an RGB image and outputs the detection results. In this way,\nfeatures which are both discriminative and robust to bad illumination\nconditions are learned. Importantly, at test time, only the second pipeline is\nconsidered and no thermal data are required. Our extensive evaluation\ndemonstrates that the proposed approach outperforms the state-of- the-art on\nthe challenging KAIST multispectral pedestrian dataset and it is competitive\nwith previous methods on the popular Caltech dataset.","primary_category":"cs","categories":["cs.CV"],"authors":["Xu Dan","Ouyang Wanli","Ricci Elisa","Wang Xiaogang","Sebe Nicu"],"created":"2017-04-07","updated":"2018-01-01","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1704.02457","title":"BLASFEO: basic linear algebra subroutines for embedded optimization","abstract":"BLASFEO is a dense linear algebra library providing high-performance\nimplementations of BLAS- and LAPACK-like routines for use in embedded\noptimization. A key difference with respect to existing high-performance\nimplementations of BLAS is that the computational performance is optimized for\nsmall to medium scale matrices, i.e., for sizes up to a few hundred. BLASFEO\ncomes with three different implementations: a high-performance implementation\naiming at providing the highest performance for matrices fitting in cache, a\nreference implementation providing portability and embeddability and optimized\nfor very small matrices, and a wrapper to standard BLAS and LAPACK providing\nhigh-performance on large matrices. The three implementations of BLASFEO\ntogether provide high-performance dense linear algebra routines for matrices\nranging from very small to large. Compared to both open-source and proprietary\nhighly-tuned BLAS libraries, for matrices of size up to about one hundred the\nhigh-performance implementation of BLASFEO is about 20-30% faster than the\ncorresponding level 3 BLAS routines and 2-3 times faster than the corresponding\nLAPACK routines.","primary_category":"cs","categories":["cs.MS"],"authors":["Frison Gianluca","Kouzoupis Dimitris","Sartor Tommaso","Zanelli Andrea","Diehl Moritz"],"created":"2017-04-08","updated":"2018-01-07","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1704.02708","title":"Evolving a Vector Space with any Generating Set","abstract":"In Valiant's model of evolution, a class of representations is evolvable iff\na polynomial-time process of random mutations guided by selection converges\nwith high probability to a representation as $\\epsilon$-close as desired from\nthe optimal one, for any required $\\epsilon>0$. Several previous positive\nresults exist that can be related to evolving a vector space, but each former\nresult imposes disproportionate representations or restrictions on\n(re)initialisations, distributions, performance functions and\/or the mutator.\nIn this paper, we show that all it takes to evolve a normed vector space is\nmerely a set that generates the space. Furthermore, it takes only\n$\\tilde{O}(1\/\\epsilon^2)$ steps and it is essentially stable, agnostic and\nhandles target drifts that rival some proven in fairly restricted settings. Our\nalgorithm can be viewed as a close relative to a popular fifty-years old\ngradient-free optimization method for which little is still known from the\nconvergence standpoint: Nelder-Mead simplex method.","primary_category":"cs","categories":["cs.LG"],"authors":["Nock Richard","Nielsen Frank"],"created":"2017-04-10","updated":"2017-12-31","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1704.03069","title":"A semidiscrete version of the Citti-Petitot-Sarti model as a plausible\n  model for anthropomorphic image reconstruction and pattern recognition","abstract":"In his beautiful book [66], Jean Petitot proposes a sub-Riemannian model for\nthe primary visual cortex of mammals. This model is neurophysiologically\njustified. Further developments of this theory lead to efficient algorithms for\nimage reconstruction, based upon the consideration of an associated\nhypoelliptic diffusion. The sub-Riemannian model of Petitot and Citti-Sarti (or\ncertain of its improvements) is a left-invariant structure over the group\n$SE(2)$ of rototranslations of the plane. Here, we propose a semi-discrete\nversion of this theory, leading to a left-invariant structure over the group\n$SE(2,N)$, restricting to a finite number of rotations. This apparently very\nsimple group is in fact quite atypical: it is maximally almost periodic, which\nleads to much simpler harmonic analysis compared to $SE(2).$ Based upon this\nsemi-discrete model, we improve on previous image-reconstruction algorithms and\nwe develop a pattern-recognition theory that leads also to very efficient\nalgorithms in practice.","primary_category":"cs","categories":["cs.CV","math.AP","math.RT"],"authors":["Prandi Dario","Gauthier Jean-Paul"],"created":"2017-04-10","updated":"2018-01-11","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1704.03296","title":"Interpretable Explanations of Black Boxes by Meaningful Perturbation","abstract":"As machine learning algorithms are increasingly applied to high impact yet\nhigh risk tasks, such as medical diagnosis or autonomous driving, it is\ncritical that researchers can explain how such algorithms arrived at their\npredictions. In recent years, a number of image saliency methods have been\ndeveloped to summarize where highly complex neural networks \"look\" in an image\nfor evidence for their predictions. However, these techniques are limited by\ntheir heuristic nature and architectural constraints. In this paper, we make\ntwo main contributions: First, we propose a general framework for learning\ndifferent kinds of explanations for any black box algorithm. Second, we\nspecialise the framework to find the part of an image most responsible for a\nclassifier decision. Unlike previous works, our method is model-agnostic and\ntestable because it is grounded in explicit and interpretable image\nperturbations.","primary_category":"cs","categories":["cs.CV","cs.AI","cs.LG","stat.ML"],"authors":["Fong Ruth","Vedaldi Andrea"],"created":"2017-04-11","updated":"2018-01-10","doi":"10.1109\/ICCV.2017.371"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1704.04238","title":"A dynamic connectome supports the emergence of stable computational\n  function of neural circuits through reward-based learning","abstract":"Synaptic connections between neurons in the brain are dynamic because of\ncontinuously ongoing spine dynamics, axonal sprouting, and other processes. In\nfact, it was recently shown that the spontaneous synapse-autonomous component\nof spine dynamics is at least as large as the component that depends on the\nhistory of pre- and postsynaptic neural activity. These data are inconsistent\nwith common models for network plasticity, and raise the questions how neural\ncircuits can maintain a stable computational function in spite of these\ncontinuously ongoing processes, and what functional uses these ongoing\nprocesses might have. Here, we present a rigorous theoretical framework for\nthese seemingly stochastic spine dynamics and rewiring processes in the context\nof reward-based learning tasks. We show that spontaneous synapse-autonomous\nprocesses, in combination with reward signals such as dopamine, can explain the\ncapability of networks of neurons in the brain to configure themselves for\nspecific computational tasks, and to compensate automatically for later changes\nin the network or task. Furthermore we show theoretically and through computer\nsimulations that stable computational performance is compatible with\ncontinuously ongoing synapse-autonomous changes. After reaching good\ncomputational performance it causes primarily a slow drift of network\narchitecture and dynamics in task-irrelevant dimensions, as observed for neural\nactivity in motor cortex and other areas. On the more abstract level of\nreinforcement learning the resulting model gives rise to an understanding of\nreward-driven network plasticity as continuous sampling of network\nconfigurations.","primary_category":"cs","categories":["q-bio.NC","cs.LG","cs.NE"],"authors":["Kappel David","Legenstein Robert","Habenschuss Stefan","Hsieh Michael","Maass Wolfgang"],"created":"2017-04-13","updated":"2018-01-05","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1704.05831","title":"Learning to Generate Long-term Future via Hierarchical Prediction","abstract":"We propose a hierarchical approach for making long-term predictions of future\nframes. To avoid inherent compounding errors in recursive pixel-level\nprediction, we propose to first estimate high-level structure in the input\nframes, then predict how that structure evolves in the future, and finally by\nobserving a single frame from the past and the predicted high-level structure,\nwe construct the future frames without having to observe any of the pixel-level\npredictions. Long-term video prediction is difficult to perform by recurrently\nobserving the predicted frames because the small errors in pixel space\nexponentially amplify as predictions are made deeper into the future. Our\napproach prevents pixel-level error propagation from happening by removing the\nneed to observe the predicted frames. Our model is built with a combination of\nLSTM and analogy based encoder-decoder convolutional neural networks, which\nindependently predict the video structure and generate the future frames,\nrespectively. In experiments, our model is evaluated on the Human3.6M and Penn\nAction datasets on the task of long-term pixel-level video prediction of humans\nperforming actions and demonstrate significantly better results than the\nstate-of-the-art.","primary_category":"cs","categories":["cs.CV"],"authors":["Villegas Ruben","Yang Jimei","Zou Yuliang","Sohn Sungryull","Lin Xunyu","Lee Honglak"],"created":"2017-04-19","updated":"2018-01-07","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1704.05936","title":"Global Stabilization of Triangular Systems with Time-Delayed Dynamic\n  Input Perturbations","abstract":"A control design approach is developed for a general class of uncertain\nstrict-feedback-like nonlinear systems with dynamic uncertain input\nnonlinearities with time delays. The system structure considered in this paper\nincludes a nominal uncertain strict-feedback-like subsystem, the input signal\nto which is generated by an uncertain nonlinear input unmodeled dynamics that\nis driven by the entire system state (including unmeasured state variables) and\nis also allowed to depend on time delayed versions of the system state variable\nand control input signals. The system also includes additive uncertain\nnonlinear functions, coupled nonlinear appended dynamics, and uncertain dynamic\ninput nonlinearities with time-varying uncertain time delays. The proposed\ncontrol design approach provides a globally stabilizing delay-independent\nrobust adaptive output-feedback dynamic controller based on a dual dynamic\nhigh-gain scaling based structure.","primary_category":"cs","categories":["math.OC","cs.SY"],"authors":["Krishnamurthy Prashanth","Khorrami Farshad"],"created":"2017-04-19","updated":"2018-01-05","doi":"10.1109\/CarpathianCC.2017.7970466"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1704.06256","title":"Robust Wirtinger Flow for Phase Retrieval with Arbitrary Corruption","abstract":"We consider the robust phase retrieval problem of recovering the unknown\nsignal from the magnitude-only measurements, where the measurements can be\ncontaminated by both sparse arbitrary corruption and bounded random noise. We\npropose a new nonconvex algorithm for robust phase retrieval, namely Robust\nWirtinger Flow to jointly estimate the unknown signal and the sparse\ncorruption. We show that our proposed algorithm is guaranteed to converge\nlinearly to the unknown true signal up to a minimax optimal statistical\nprecision in such a challenging setting. Compared with existing robust phase\nretrieval methods, we achieve an optimal sample complexity of $O(n)$ in both\nnoisy and noise-free settings. Thorough experiments on both synthetic and real\ndatasets corroborate our theory.","primary_category":"cs","categories":["stat.ML","cs.LG"],"authors":["Chen Jinghui","Wang Lingxiao","Zhang Xiao","Gu Quanquan"],"created":"2017-04-20","updated":"2018-01-03","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1704.07433","title":"Active Bias: Training More Accurate Neural Networks by Emphasizing High\n  Variance Samples","abstract":"Self-paced learning and hard example mining re-weight training instances to\nimprove learning accuracy. This paper presents two improved alternatives based\non lightweight estimates of sample uncertainty in stochastic gradient descent\n(SGD): the variance in predicted probability of the correct class across\niterations of mini-batch SGD, and the proximity of the correct class\nprobability to the decision threshold. Extensive experimental results on six\ndatasets show that our methods reliably improve accuracy in various network\narchitectures, including additional gains on top of other popular training\ntechniques, such as residual learning, momentum, ADAM, batch normalization,\ndropout, and distillation.","primary_category":"cs","categories":["stat.ML","cs.LG"],"authors":["Chang Haw-Shiuan","Learned-Miller Erik","McCallum Andrew"],"created":"2017-04-24","updated":"2018-01-06","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1704.07816","title":"Introspective Classification with Convolutional Nets","abstract":"We propose introspective convolutional networks (ICN) that emphasize the\nimportance of having convolutional neural networks empowered with generative\ncapabilities. We employ a reclassification-by-synthesis algorithm to perform\ntraining using a formulation stemmed from the Bayes theory. Our ICN tries to\niteratively: (1) synthesize pseudo-negative samples; and (2) enhance itself by\nimproving the classification. The single CNN classifier learned is at the same\ntime generative --- being able to directly synthesize new samples within its\nown discriminative model. We conduct experiments on benchmark datasets\nincluding MNIST, CIFAR-10, and SVHN using state-of-the-art CNN architectures,\nand observe improved classification results.","primary_category":"cs","categories":["cs.CV","cs.LG","cs.NE"],"authors":["Jin Long","Lazarow Justin","Tu Zhuowen"],"created":"2017-04-25","updated":"2018-01-05","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1704.08049","title":"Epsilon-shapes: characterizing, detecting and thickening thin features\n  in geometric models","abstract":"We focus on the analysis of planar shapes and solid objects having thin\nfeatures and propose a new mathematical model to characterize them. Based on\nour model, that we call an epsilon-shape, we show how thin parts can be\neffectively and efficiently detected by an algorithm, and propose a novel\napproach to thicken these features while leaving all the other parts of the\nshape unchanged. When compared with state-of-the-art solutions, our proposal\nproves to be particularly flexible, efficient and stable, and does not require\nany unintuitive parameter to fine-tune the process. Furthermore, our method is\nable to detect thin features both in the object and in its complement, thus\nproviding a useful tool to detect thin cavities and narrow channels. We discuss\nthe importance of this kind of analysis in the design of robust structures and\nin the creation of geometry to be fabricated with modern additive manufacturing\ntechnology.","primary_category":"cs","categories":["cs.CG","cs.GR"],"authors":["Cabiddu Daniela","Attene Marco"],"created":"2017-04-26","updated":"2018-01-08","doi":"10.1016\/j.cag.2017.05.014"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1705.00321","title":"Tree-Structured Neural Machine for Linguistics-Aware Sentence Generation","abstract":"Different from other sequential data, sentences in natural language are\nstructured by linguistic grammars. Previous generative conversational models\nwith chain-structured decoder ignore this structure in human language and might\ngenerate plausible responses with less satisfactory relevance and fluency. In\nthis study, we aim to incorporate the results from linguistic analysis into the\nprocess of sentence generation for high-quality conversation generation.\nSpecifically, we use a dependency parser to transform each response sentence\ninto a dependency tree and construct a training corpus of sentence-tree pairs.\nA tree-structured decoder is developed to learn the mapping from a sentence to\nits tree, where different types of hidden states are used to depict the local\ndependencies from an internal tree node to its children. For training\nacceleration, we propose a tree canonicalization method, which transforms trees\ninto equivalent ternary trees. Then, with a proposed tree-structured search\nmethod, the model is able to generate the most probable responses in the form\nof dependency trees, which are finally flattened into sequences as the system\noutput. Experimental results demonstrate that the proposed X2Tree framework\noutperforms baseline methods over 11.15% increase of acceptance ratio.","primary_category":"cs","categories":["cs.AI","cs.CL","cs.LG"],"authors":["Zhou Ganbin","Luo Ping","Cao Rongyu","Xiao Yijun","Lin Fen","Chen Bo","He Qing"],"created":"2017-04-30","updated":"2018-01-03","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1705.00454","title":"Autocorrelation Function for Dispersion-Free Fiber Channels with\n  Distributed Amplification","abstract":"Optical fiber signals with high power exhibit spectral broadening that seems\nto limit capacity. To study spectral broadening, the autocorrelation function\nof the output signal given the input signal is derived for a simplified fiber\nmodel that has zero dispersion, distributed optical amplification (OA), and\nidealized spatial noise processes. The autocorrelation function is used to\nupper bound the output power of bandlimited or time-resolution limited\nreceivers, and thereby to bound spectral broadening and the capacity of\nreceivers with thermal noise. The output power scales at most as the\nsquare-root of the launch power, and thus capacity scales at most as one-half\nthe logarithm of the launch power. The propagating signal bandwidth scales at\nleast as the square-root of the launch power. However, in practice the OA\nbandwidth should exceed the signal bandwidth to compensate attenuation. Hence,\nthere is a launch power threshold beyond which the fiber model loses practical\nrelevance. Nevertheless, for the mathematical model an upper bound on capacity\nis developed when the OA bandwidth scales as the square-root of the launch\npower, in which case capacity scales at most as the inverse fourth root of the\nlaunch power.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Kramer Gerhard"],"created":"2017-05-01","updated":"2018-01-01","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1705.02451","title":"Identifying combinations of tetrahedra into hexahedra: a vertex based\n  strategy","abstract":"Indirect hex-dominant meshing methods rely on the detection of adjacent\ntetrahedra an algorithm that performs this identification and builds the set of\nall possible combinations of tetrahedral elements of an input mesh T into\nhexahedra, prisms, or pyramids. All identified cells are valid for engineering\nanalysis. First, all combinations of eight\/six\/five vertices whose connectivity\nin T matches the connectivity of a hexahedron\/prism\/pyramid are computed. The\nsubset of tetrahedra of T triangulating each potential cell is then determined.\nQuality checks allow to early discard poor quality cells and to dramatically\nimprove the efficiency of the method. Each potential hexahedron\/prism\/pyramid\nis computed only once. Around 3 millions potential hexahedra are computed in 10\nseconds on a laptop. We finally demonstrate that the set of potential hexes\nbuilt by our algorithm is significantly larger than those built using\npredefined patterns of subdivision of a hexahedron in tetrahedral elements.","primary_category":"cs","categories":["cs.CG"],"authors":["Pellerin Jeanne","Johnen Amaury","Verhetsel Kilian","Remacle Jean-Francois"],"created":"2017-05-06","updated":"2018-01-04","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1705.02723","title":"Joint Trajectory and Communication Design for Multi-UAV Enabled Wireless\n  Networks","abstract":"Unmanned aerial vehicles (UAVs) have attracted significant interest recently\nin assisting wireless communication due to their high maneuverability, flexible\ndeployment, and low cost. This paper considers a multi-UAV enabled wireless\ncommunication system, where multiple UAV-mounted aerial base stations (BSs) are\nemployed to serve a group of users on the ground. To achieve fair performance\namong users, we maximize the minimum throughput over all ground users in the\ndownlink communication by optimizing the multiuser communication scheduling and\nassociation jointly with the UAVs' trajectory and power control. The formulated\nproblem is a mixed integer non-convex optimization problem that is challenging\nto solve. As such, we propose an efficient iterative algorithm for solving it\nby applying the block coordinate descent and successive convex optimization\ntechniques. Specifically, the user scheduling and association, UAV trajectory,\nand transmit power are alternately optimized in each iteration. In particular,\nfor the non-convex UAV trajectory and transmit power optimization problems, two\napproximate convex optimization problems are solved, respectively. We further\nshow that the proposed algorithm is guaranteed to converge to at least a\nlocally optimal solution. To speed up the algorithm convergence and achieve\ngood throughput, a low-complexity and systematic initialization scheme is also\nproposed for the UAV trajectory design based on the simple circular trajectory\nand the circle packing scheme. Extensive simulation results are provided to\ndemonstrate the significant throughput gains of the proposed design as compared\nto other benchmark schemes.","primary_category":"cs","categories":["cs.IT","math.DS","math.IT","math.OC"],"authors":["Wu Qingqing","Zeng Yong","Zhang Rui"],"created":"2017-05-07","updated":"2018-01-06","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1705.02877","title":"Ultra Reliable UAV Communication Using Altitude and Cooperation\n  Diversity","abstract":"The use of unmanned aerial vehicles (UAVs) that serve as aerial base stations\nis expected to become predominant in the next decade. However, in order for\nthis technology to unfold its full potential it is necessary to develop a\nfundamental understanding of the distinctive features of air-to-ground (A2G)\nlinks. As a contribution in this direction, this paper proposes a generic\nframework for the analysis and optimization of the A2G systems. In contrast to\nthe existing literature, this framework incorporates both height-dependent path\nloss exponent and small-scale fading, and unifies a widely used\nground-to-ground channel model with that of A2G for analysis of large-scale\nwireless networks. We derive analytical expressions for the optimal UAV height\nthat minimizes the outage probability of a given A2G link. Moreover, our\nframework allows us to derive a height-dependent closed-form expression and a\ntight lower bound for the outage probability of an \\textit{A2G cooperative\ncommunication} network. Our results suggest that the optimal location of the\nUAVs with respect to the ground nodes does not change by the inclusion of\nground relays. This enables interesting insights in the deployment of future\nA2G networks, as the system reliability could be adjusted dynamically by adding\nrelaying nodes without requiring changes in the position of the corresponding\nUAVs.","primary_category":"cs","categories":["cs.IT","math.IT","math.PR"],"authors":["Azari Mohammad Mahdi","Rosas Fernando","Chen Kwang-Cheng","Pollin Sofie"],"created":"2017-04-28","updated":" ","doi":"10.1109\/TCOMM.2017.2746105"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1705.02982","title":"How to Balance Privacy and Money through Pricing Mechanism in Personal\n  Data Market","abstract":"A personal data market is a platform including three participants: data\nowners (individuals), data buyers and market maker. Data owners who provide\npersonal data are compensated according to their privacy loss. Data buyers can\nsubmit a query and pay for the result according to their desired accuracy.\nMarket maker coordinates between data owner and buyer. This framework has been\npreviously studied based on differential privacy. However, the previous study\nassumes data owners can accept any level of privacy loss and data buyers can\nconduct the transaction without regard to the financial budget. In this paper,\nwe propose a practical personal data trading framework that is able to strike a\nbalance between money and privacy. In order to gain insights on user\npreferences, we first conducted an online survey on human attitude to- ward\nprivacy and interest in personal data trading. Second, we identify the 5 key\nprinciples of personal data market, which is important for designing a\nreasonable trading frame- work and pricing mechanism. Third, we propose a\nreason- able trading framework for personal data which provides an overview of\nhow the data is traded. Fourth, we propose a balanced pricing mechanism which\ncomputes the query price for data buyers and compensation for data owners\n(whose data are utilized) as a function of their privacy loss. The main goal is\nto ensure a fair trading for both parties. Finally, we will conduct an\nexperiment to evaluate the output of our proposed pricing mechanism in\ncomparison with other previously proposed mechanism.","primary_category":"cs","categories":["cs.CY","cs.DB","cs.GT"],"authors":["Nget Rachana","Cao Yang","Yoshikawa Masatoshi"],"created":"2017-05-08","updated":"2018-01-02","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1705.03162","title":"Accelerating solutions of one-dimensional unsteady PDEs with GPU-based\n  swept time-space decomposition","abstract":"The expedient design of precision components in aerospace and other high-tech\nindustries requires simulations of physical phenomena often described by\npartial differential equations (PDEs) without exact solutions. Modern design\nproblems require simulations with a level of resolution difficult to achieve in\nreasonable amounts of time---even in effectively parallelized solvers. Though\nthe scale of the problem relative to available computing power is the greatest\nimpediment to accelerating these applications, significant performance gains\ncan be achieved through careful attention to the details of memory\ncommunication and access. The swept time-space decomposition rule reduces\ncommunication between sub-domains by exhausting the domain of influence before\ncommunicating boundary values. Here we present a GPU implementation of the\nswept rule, which modifies the algorithm for improved performance on this\nprocessing architecture by prioritizing use of private (shared) memory,\navoiding interblock communication, and overwriting unnecessary values. It shows\nsignificant improvement in the execution time of finite-difference solvers for\none-dimensional unsteady PDEs, producing speedups of 2--9$\\times$ for a range\nof problem sizes, respectively, compared with simple GPU versions and\n7--300$\\times$ compared with parallel CPU versions. However, for a more\nsophisticated one-dimensional system of equations discretized with a\nsecond-order finite-volume scheme, the swept rule performs 1.2--1.9$\\times$\nworse than a standard implementation for all problem sizes.","primary_category":"cs","categories":["physics.comp-ph","cs.DC","cs.MS"],"authors":["Magee Daniel J","Niemeyer Kyle E"],"created":"2017-05-08","updated":"2017-11-10","doi":"10.1016\/j.jcp.2017.12.028"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1705.04839","title":"Annotating and Modeling Empathy in Spoken Conversations","abstract":"Empathy, as defined in behavioral sciences, expresses the ability of human\nbeings to recognize, understand and react to emotions, attitudes and beliefs of\nothers. The lack of an operational definition of empathy makes it difficult to\nmeasure it. In this paper, we address two related problems in automatic\naffective behavior analysis: the design of the annotation protocol and the\nautomatic recognition of empathy from spoken conversations. We propose and\nevaluate an annotation scheme for empathy inspired by the modal model of\nemotions. The annotation scheme was evaluated on a corpus of real-life, dyadic\nspoken conversations. In the context of behavioral analysis, we designed an\nautomatic segmentation and classification system for empathy. Given the\ndifferent speech and language levels of representation where empathy may be\ncommunicated, we investigated features derived from the lexical and acoustic\nspaces. The feature development process was designed to support both the fusion\nand automatic selection of relevant features from high dimensional space. The\nautomatic classification system was evaluated on call center conversations\nwhere it showed significantly better performance than the baseline.","primary_category":"cs","categories":["cs.CL"],"authors":["Alam Firoj","Danieli Morena","Riccardi Giuseppe"],"created":"2017-05-13","updated":"2017-12-29","doi":"10.1016\/j.csl.2017.12.003"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1705.04970","title":"Relaxation heuristics for the set multicover problem with generalized\n  upper bound constraints","abstract":"We consider an extension of the set covering problem (SCP) introducing\n(i)~multicover and (ii)~generalized upper bound (GUB)~constraints. For the\nconventional SCP, the pricing method has been introduced to reduce the size of\ninstances, and several efficient heuristic algorithms based on such reduction\ntechniques have been developed to solve large-scale instances. However, GUB\nconstraints often make the pricing method less effective, because they often\nprevent solutions from containing highly evaluated variables together. To\novercome this problem, we develop heuristic algorithms to reduce the size of\ninstances, in which new evaluation schemes of variables are introduced taking\naccount of GUB constraints. We also develop an efficient implementation of a\n2-flip neighborhood local search algorithm that reduces the number of\ncandidates in the neighborhood without sacrificing the solution quality. In\norder to guide the search to visit a wide variety of good solutions, we also\nintroduce a path relinking method that generates new solutions by combining two\nor more solutions obtained so far. According to computational comparison on\nbenchmark instances, the proposed method succeeds in selecting a small number\nof promising variables properly and performs quite effectively even for\nlarge-scale instances having hard GUB constraints.","primary_category":"cs","categories":["cs.DS","cs.AI","math.OC"],"authors":["Umetani Shunji","Arakawa Masanao","Yagiura Mutsunori"],"created":"2017-05-14","updated":"2018-01-05","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1705.06575","title":"Sympiler: Transforming Sparse Matrix Codes by Decoupling Symbolic\n  Analysis","abstract":"Sympiler is a domain-specific code generator that optimizes sparse matrix\ncomputations by decoupling the symbolic analysis phase from the numerical\nmanipulation stage in sparse codes. The computation patterns in sparse\nnumerical methods are guided by the input sparsity structure and the sparse\nalgorithm itself. In many real-world simulations, the sparsity pattern changes\nlittle or not at all. Sympiler takes advantage of these properties to\nsymbolically analyze sparse codes at compile-time and to apply inspector-guided\ntransformations that enable applying low-level transformations to sparse codes.\nAs a result, the Sympiler-generated code outperforms highly-optimized matrix\nfactorization codes from commonly-used specialized libraries, obtaining average\nspeedups over Eigen and CHOLMOD of 3.8X and 1.5X respectively.","primary_category":"cs","categories":["cs.PL"],"authors":["Cheshmi Kazem","Kamil Shoaib","Strout Michelle Mills","Dehnavi Maryam Mehri"],"created":"2017-05-18","updated":" ","doi":"10.1145\/3126908.3126936"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1705.06616","title":"Sensor Array Design Through Submodular Optimization","abstract":"We consider the problem of far-field sensing by means of a sensor array.\nTraditional array geometry design techniques are agnostic to prior information\nabout the far-field scene. However, in many applications such priors are\navailable and may be utilized to design more efficient array topologies. We\nformulate the problem of array geometry design with scene prior as one of\nfinding a sampling configuration that enables efficient inference, which turns\nout to be a combinatorial optimization problem. While generic combinatorial\noptimization problems are NP-hard and resist efficient solvers, we show how for\narray design problems the theory of submodular optimization may be utilized to\nobtain efficient algorithms that are guaranteed to achieve solutions within a\nconstant approximation factor from the optimum. We leverage the connection\nbetween array design problems and submodular optimization and port several\nresults of interest. We demonstrate efficient methods for designing arrays with\nconstraints on the sensing aperture, as well as arrays respecting combinatorial\nplacement constraints. This novel connection between array design and\nsubmodularity suggests the possibility for utilizing other insights and\ntechniques from the growing body of literature on submodular optimization in\nthe field of array design.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Shulkind Gal","Jegelka Stefanie","Wornell Gregory W."],"created":"2017-05-18","updated":"2017-12-28","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1705.06989","title":"Cooperative Spectrum Sensing over Generalized Fading Channels Based on\n  Energy Detection","abstract":"This paper analyzes the unified performance of energy detection (ED) of\nspectrum sensing (SS) over generalized fading channels in cognitive radio (CR)\nnetworks. The detective performance of SS schemes will be obviously affected by\nfading channel between communication nodes, and ED has the advantages of fast\nimplementation, no requirement of priori received information and low\ncomplexity, so it is meaningful to investigate ED that is performed over fading\nchannels such as Nakagami-m channel and Rice channel, or generalized fading\nchannels such as \\k{appa}-{\\mu} fading distribution and {\\eta}-{\\mu} fading\ndistribution. The {\\alpha}-\\k{appa}-{\\mu} fading distribution is a generalized\nfading model that represents the nonlinear and small-scale variation of fading\nchannels. The probability density function (p.d.f.) of instantaneous\nsignal-to-ratio (SNR) of {\\alpha}-\\k{appa}-{\\mu} distribution is derived from\nthe envelope p.d.f. to evaluate energy efficiency for sensing systems. Next,\nthe probability of detection model with Marcum-Q function has been derived and\nthe close-form detective expressions with moment generating function (MGF)\nmethod are deduced to achieve sensing communications over generalized fading\nchannels. Furthermore, novel and exact closed-form analytic expressions for\naverage area under the receiver operating characteristics curve also have been\ndeduced to analyze the performance characteristics of ED over\n{\\alpha}-\\k{appa}-{\\mu} fading channels. Besides, cooperative spectrum sensing\n(CSS) with diversity reception has been applied to improve the detection\naccuracy and mitigate the shadowed fading features with OR-rule. At last, the\nresults show that the detection capacity can be evidently affected by\n{\\alpha}-\\k{appa}-{\\mu} fading conditions, but appropriate channel parameters\nwill improve sensing performance.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Huang He","Yuan Chaowei"],"created":"2017-05-19","updated":"2017-12-29","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1705.06992","title":"Cooperative spectrum sensing with enhanced energy detection under\n  GAUSSIAN noise uncertainty in cognitive radios","abstract":"This paper presents optimization issues of energy detection (ED) thresholds\nin cooperative spectrum sensing (CSS) with regard to general Gaussian noise.\nEnhanced ED thresholds are proposed to overcome sensitivity of multiple noise\nuncertainty. Two-steps decision pattern and convex samples thresholds have been\nput forward under Gaussian noise uncertainty. Through deriving the probability\nof detection (Pd) and the probability of false alarm (Pf ) for independent and\nidentical distribution (i.i.d.) SUs, we obtain lower total error rate (Qe) with\nproposed ED thresholds at low signal-to-noise-ratio (SNR) condition.\nFurthermore, simulation results show that proposed schemes outperform most\nother noise uncertainty plans.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Huang He","al et."],"created":"2017-05-19","updated":"2017-12-29","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1705.07142","title":"Simultaneous Multiple Surface Segmentation Using Deep Learning","abstract":"The task of automatically segmenting 3-D surfaces representing boundaries of\nobjects is important for quantitative analysis of volumetric images, and plays\na vital role in biomedical image analysis. Recently, graph-based methods with a\nglobal optimization property have been developed and optimized for various\nmedical imaging applications. Despite their widespread use, these require human\nexperts to design transformations, image features, surface smoothness priors,\nand re-design for a different tissue, organ or imaging modality. Here, we\npropose a Deep Learning based approach for segmentation of the surfaces in\nvolumetric medical images, by learning the essential features and\ntransformations from training data, without any human expert intervention. We\nemploy a regional approach to learn the local surface profiles. The proposed\napproach was evaluated on simultaneous intraretinal layer segmentation of\noptical coherence tomography (OCT) images of normal retinas and retinas\naffected by age related macular degeneration (AMD). The proposed approach was\nvalidated on 40 retina OCT volumes including 20 normal and 20 AMD subjects. The\nexperiments showed statistically significant improvement in accuracy for our\napproach compared to state-of-the-art graph based optimal surface segmentation\nwith convex priors (G-OSC). A single Convolution Neural Network (CNN) was used\nto learn the surfaces for both normal and diseased images. The mean unsigned\nsurface positioning errors obtained by G-OSC method 2.31 voxels (95% CI\n2.02-2.60 voxels) was improved to $1.27$ voxels (95% CI 1.14-1.40 voxels) using\nour new approach. On average, our approach takes 94.34 s, requiring 95.35 MB\nmemory, which is much faster than the 2837.46 s and 6.87 GB memory required by\nthe G-OSC method on the same computer system.","primary_category":"cs","categories":["cs.CV"],"authors":["Shah Abhay","Abramoff Michael","Wu Xiaodong"],"created":"2017-05-19","updated":" ","doi":"10.1007\/978-3-319-67558-9_1"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1705.07285","title":"Optimality of orders one to three and beyond: characterization and\n  evaluation complexity in constrained nonconvex optimization","abstract":"Necessary conditions for high-order optimality in smooth nonlinear\nconstrained optimization are explored and their inherent intricacy discussed. A\ntwo-phase minimization algorithm is proposed which can achieve approximate\nfirst-, second- and third-order criticality and its evaluation complexity is\nanalyzed as a function of the choice (among existing methods) of an inner\nalgorithm for solving subproblems in each of the two phases. The relation\nbetween high-order criticality and penalization techniques is finally\nconsidered, showing that standard algorithmic approaches will fail if\napproximate constrained high-order critical points are sought.","primary_category":"cs","categories":["math.OC","cs.CC","cs.NA"],"authors":["Cartis C.","Gould N. I. M.","Toint Ph. L."],"created":"2017-05-20","updated":"2018-01-07","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1705.07826","title":"Iterative Machine Learning for Output Tracking","abstract":"This article develops iterative machine learning (IML) for output tracking.\nThe input-output data generated during iterations to develop the model used in\nthe iterative update. The main contribution of this article to propose the use\nof kernel-based machine learning to iteratively update both the model and the\nmodel-inversion-based input simultaneously. Additionally, augmented inputs with\npersistency of excitation are proposed to promote learning of the model during\nthe iteration process. The proposed approach is illustrated with a simulation\nexample.","primary_category":"cs","categories":["cs.SY"],"authors":["Devasia Santosh"],"created":"2017-05-22","updated":"2017-06-08","doi":"10.1109\/TCST.2017.2772807"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1705.07878","title":"TernGrad: Ternary Gradients to Reduce Communication in Distributed Deep\n  Learning","abstract":"High network communication cost for synchronizing gradients and parameters is\nthe well-known bottleneck of distributed training. In this work, we propose\nTernGrad that uses ternary gradients to accelerate distributed deep learning in\ndata parallelism. Our approach requires only three numerical levels {-1,0,1},\nwhich can aggressively reduce the communication time. We mathematically prove\nthe convergence of TernGrad under the assumption of a bound on gradients.\nGuided by the bound, we propose layer-wise ternarizing and gradient clipping to\nimprove its convergence. Our experiments show that applying TernGrad on AlexNet\ndoes not incur any accuracy loss and can even improve accuracy. The accuracy\nloss of GoogLeNet induced by TernGrad is less than 2% on average. Finally, a\nperformance model is proposed to study the scalability of TernGrad. Experiments\nshow significant speed gains for various deep neural networks. Our source code\nis available.","primary_category":"cs","categories":["cs.LG","cs.DC","cs.NE"],"authors":["Wen Wei","Xu Cong","Yan Feng","Wu Chunpeng","Wang Yandan","Chen Yiran","Li Hai"],"created":"2017-05-22","updated":"2017-12-28","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1705.08586","title":"Self-organized Segregation on the Grid","abstract":"We consider an agent-based model in which two types of agents interact\nlocally over a graph and have a common intolerance threshold $\\tau$ for\nchanging their types with exponentially distributed waiting times. The model is\nequivalent to an unperturbed Schelling model of self-organized segregation, an\nAsynchronous Cellular Automata (ACA) with extended Moore neighborhoods, or a\nzero-temperature Ising model with Glauber dynamics, and has applications in the\nanalysis of social and biological networks, and spin glasses systems. Some\nrigorous results were recently obtained in the theoretical computer science\nliterature, and this work provides several extensions. We enlarge the\nintolerance interval leading to the formation of large segregated regions of\nagents of a single type from the known size $\\epsilon>0$ to size $\\approx\n0.134$. Namely, we show that for $0.433 < \\tau < 1\/2$ (and by symmetry\n$1\/2<\\tau<0.567$), the expected size of the largest segregated region\ncontaining an arbitrary agent is exponential in the size of the neighborhood.\nWe further extend the interval leading to large segregated regions to size\n$\\approx 0.312$ considering \"almost segregated\" regions, namely regions where\nthe ratio of the number of agents of one type and the number of agents of the\nother type vanishes quickly as the size of the neighborhood grows. In this\ncase, we show that for $0.344 < \\tau \\leq 0.433$ (and by symmetry for $0.567\n\\leq \\tau<0.656$) the expected size of the largest almost segregated region\ncontaining an arbitrary agent is exponential in the size of the neighborhood.\nThe exponential bounds that we provide also imply that complete segregation,\nwhere agents of a single type cover the whole grid, does not occur with high\nprobability for $p=1\/2$ and the range of tolerance considered.","primary_category":"cs","categories":["cs.SI"],"authors":["Omidvar Hamed","Franceschetti Massimo"],"created":"2017-05-23","updated":"2018-01-03","doi":"10.1007\/s10955-017-1942-4"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1705.08741","title":"Train longer, generalize better: closing the generalization gap in large\n  batch training of neural networks","abstract":"Background: Deep learning models are typically trained using stochastic\ngradient descent or one of its variants. These methods update the weights using\ntheir gradient, estimated from a small fraction of the training data. It has\nbeen observed that when using large batch sizes there is a persistent\ndegradation in generalization performance - known as the \"generalization gap\"\nphenomena. Identifying the origin of this gap and closing it had remained an\nopen problem.\n  Contributions: We examine the initial high learning rate training phase. We\nfind that the weight distance from its initialization grows logarithmically\nwith the number of weight updates. We therefore propose a \"random walk on\nrandom landscape\" statistical model which is known to exhibit similar\n\"ultra-slow\" diffusion behavior. Following this hypothesis we conducted\nexperiments to show empirically that the \"generalization gap\" stems from the\nrelatively small number of updates rather than the batch size, and can be\ncompletely eliminated by adapting the training regime used. We further\ninvestigate different techniques to train models in the large-batch regime and\npresent a novel algorithm named \"Ghost Batch Normalization\" which enables\nsignificant decrease in the generalization gap without increasing the number of\nupdates. To validate our findings we conduct several additional experiments on\nMNIST, CIFAR-10, CIFAR-100 and ImageNet. Finally, we reassess common practices\nand beliefs concerning training of deep models and suggest they may not be\noptimal to achieve good generalization.","primary_category":"cs","categories":["stat.ML","cs.LG"],"authors":["Hoffer Elad","Hubara Itay","Soudry Daniel"],"created":"2017-05-24","updated":"2018-01-01","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1705.08868","title":"Flow-GAN: Combining Maximum Likelihood and Adversarial Learning in\n  Generative Models","abstract":"Adversarial learning of probabilistic models has recently emerged as a\npromising alternative to maximum likelihood. Implicit models such as generative\nadversarial networks (GAN) often generate better samples compared to explicit\nmodels trained by maximum likelihood. Yet, GANs sidestep the characterization\nof an explicit density which makes quantitative evaluations challenging. To\nbridge this gap, we propose Flow-GANs, a generative adversarial network for\nwhich we can perform exact likelihood evaluation, thus supporting both\nadversarial and maximum likelihood training. When trained adversarially,\nFlow-GANs generate high-quality samples but attain extremely poor\nlog-likelihood scores, inferior even to a mixture model memorizing the training\ndata; the opposite is true when trained by maximum likelihood. Results on MNIST\nand CIFAR-10 demonstrate that hybrid training can attain high held-out\nlikelihoods while retaining visual fidelity in the generated samples.","primary_category":"cs","categories":["cs.LG","cs.AI","cs.NE","stat.ML"],"authors":["Grover Aditya","Dhar Manik","Ermon Stefano"],"created":"2017-05-24","updated":"2018-01-03","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1705.09600","title":"Approximating Constrained Minimum Cost Input-Output Selection for\n  Generic Arbitrary Pole Placement in Structured Systems","abstract":"This paper is about minimum cost constrained selection of inputs and outputs\nfor generic arbitrary pole placement. The input-output set is constrained in\nthe sense that the set of states that each input can influence and the set of\nstates that each output can sense is pre-specified. Our goal is to optimally\nselect an input-output set that the system has no structurally fixed modes.\nPolynomial algorithms do not exist for solving this problem unless P=NP. To\nthis end, we propose an approximation algorithm by splitting the problem in to\nthree sub-problems: a) minimum cost accessibility problem, b) minimum cost\nsensability problem and c) minimum cost disjoint cycle problem. We prove that\nproblems a) and b) are equivalent to a suitably defined weighted set cover\nproblems. We also show that problem c) is equivalent to a minimum cost perfect\nmatching problem. Using these we give an approximation algorithm which solves\nthe minimum cost generic arbitrary pole placement problem. The proposed\nalgorithm incorporates an approximation algorithm to solve the weighted set\ncover problem for solving a) and b) and a minimum cost perfect matching\nalgorithm to solve c). Further, we show that the algorithm is polynomial time\nan gives an order optimal solution to the minimum cost input-output selection\nfor generic arbitrary pole placement problem.","primary_category":"cs","categories":["math.OC","cs.DS"],"authors":["Moothedath Shana","Chaporkar Prasanna","Belur Madhu N."],"created":"2017-05-26","updated":"2018-01-09","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1705.10142","title":"Kronecker Recurrent Units","abstract":"Our work addresses two important issues with recurrent neural networks: (1)\nthey are over-parameterized, and (2) the recurrence matrix is ill-conditioned.\nThe former increases the sample complexity of learning and the training time.\nThe latter causes the vanishing and exploding gradient problem. We present a\nflexible recurrent neural network model called Kronecker Recurrent Units (KRU).\nKRU achieves parameter efficiency in RNNs through a Kronecker factored\nrecurrent matrix. It overcomes the ill-conditioning of the recurrent matrix by\nenforcing soft unitary constraints on the factors. Thanks to the small\ndimensionality of the factors, maintaining these constraints is computationally\nefficient. Our experimental results on seven standard data-sets reveal that KRU\ncan reduce the number of parameters by three orders of magnitude in the\nrecurrent weight matrix compared to the existing recurrent models, without\ntrading the statistical performance. These results in particular show that\nwhile there are advantages in having a high dimensional recurrent space, the\ncapacity of the recurrent part of the model can be dramatically reduced.","primary_category":"cs","categories":["cs.LG"],"authors":["Jose Cijo","Cisse Moustpaha","Fleuret Francois"],"created":"2017-05-29","updated":"2017-12-31","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1705.10202","title":"Mining Process Model Descriptions of Daily Life through Event\n  Abstraction","abstract":"Process mining techniques focus on extracting insight in processes from event\nlogs. Process mining has the potential to provide valuable insights in\n(un)healthy habits and to contribute to ambient assisted living solutions when\napplied on data from smart home environments. However, events recorded in smart\nhome environments are on the level of sensor triggers, at which process\ndiscovery algorithms produce overgeneralizing process models that allow for too\nmuch behavior and that are difficult to interpret for human experts. We show\nthat abstracting the events to a higher-level interpretation can enable\ndiscovery of more precise and more comprehensible models. We present a\nframework for the extraction of features that can be used for abstraction with\nsupervised learning methods that is based on the XES IEEE standard for event\nlogs. This framework can automatically abstract sensor-level events to their\ninterpretation at the human activity level, after training it on training data\nfor which both the sensor and human activity events are known. We demonstrate\nour abstraction framework on three real-life smart home event logs and show\nthat the process models that can be discovered after abstraction are more\nprecise indeed.","primary_category":"cs","categories":["cs.LG","cs.AI","cs.DB"],"authors":["Tax Niek","Sidorova Natalia","Haakma Reinder","van der Aalst Wil M. P."],"created":"2017-05-25","updated":" ","doi":"10.1007\/978-3-319-69266-1_5"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1705.10387","title":"Tiny Groups Tackle Byzantine Adversaries","abstract":"A popular technique for tolerating malicious faults in open distributed\nsystems is to establish small groups of participants, each of which has a\nnon-faulty majority. These groups are used as building blocks to design\nattack-resistant algorithms.\n  Despite over a decade of active research, current constructions require group\nsizes of $O(\\log n)$, where $n$ is the number of participants in the system.\nThis group size is important since communication and state costs scale\npolynomially with this parameter. Given the stubbornness of this logarithmic\nbarrier, a natural question is whether better bounds are possible.\n  Here, we consider an attacker that controls a constant fraction of the total\ncomputational resources in the system. By leveraging proof-of-work (PoW), we\ndemonstrate how to reduce the group size exponentially to $O(\\log\\log n)$ while\nmaintaining strong security guarantees. This reduction in group size yields a\nsignificant improvement in communication and state costs.","primary_category":"cs","categories":["cs.DS","cs.DC"],"authors":["Jaiyeola Mercy O.","Patron Kyle","Saia Jared","Young Maxwell","Zhou Qian M."],"created":"2017-05-29","updated":"2018-01-08","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1706.00274","title":"Towards a Java Subtyping Operad","abstract":"The subtyping relation in Java exhibits self-similarity. The self-similarity\nin Java subtyping is interesting and intricate due to the existence of wildcard\ntypes and, accordingly, the existence of three subtyping rules for generic\ntypes: covariant subtyping, contravariant subtyping and invariant subtyping.\nSupporting bounded type variables also adds to the complexity of the subtyping\nrelation in Java and in other generic nominally-typed OO languages such as C#\nand Scala. In this paper we explore defining an operad to model the\nconstruction of the subtyping relation in Java and in similar generic\nnominally-typed OO programming languages. Operads, from category theory, are\nfrequently used to model self-similar phenomena. The Java subtyping operad, we\nhope, will shed more light on understanding the type systems of generic\nnominally-typed OO languages.","primary_category":"cs","categories":["cs.PL"],"authors":["AbdelGawad Moez A."],"created":"2017-06-01","updated":"2017-12-29","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1706.00536","title":"Modeling Latent Attention Within Neural Networks","abstract":"Deep neural networks are able to solve tasks across a variety of domains and\nmodalities of data. Despite many empirical successes, we lack the ability to\nclearly understand and interpret the learned internal mechanisms that\ncontribute to such effective behaviors or, more critically, failure modes. In\nthis work, we present a general method for visualizing an arbitrary neural\nnetwork's inner mechanisms and their power and limitations. Our dataset-centric\nmethod produces visualizations of how a trained network attends to components\nof its inputs. The computed \"attention masks\" support improved interpretability\nby highlighting which input attributes are critical in determining output. We\ndemonstrate the effectiveness of our framework on a variety of deep neural\nnetwork architectures in domains from computer vision, natural language\nprocessing, and reinforcement learning. The primary contribution of our\napproach is an interpretable visualization of attention that provides unique\ninsights into the network's underlying decision-making process irrespective of\nthe data modality.","primary_category":"cs","categories":["cs.AI"],"authors":["Grimm Christopher","Arumugam Dilip","Karamcheti Siddharth","Abel David","Wong Lawson L. S.","Littman Michael L."],"created":"2017-06-01","updated":"2017-12-30","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1706.01498","title":"Stochastic Gradient Monomial Gamma Sampler","abstract":"Recent advances in stochastic gradient techniques have made it possible to\nestimate posterior distributions from large datasets via Markov Chain Monte\nCarlo (MCMC). However, when the target posterior is multimodal, mixing\nperformance is often poor. This results in inadequate exploration of the\nposterior distribution. A framework is proposed to improve the sampling\nefficiency of stochastic gradient MCMC, based on Hamiltonian Monte Carlo. A\ngeneralized kinetic function is leveraged, delivering superior stationary\nmixing, especially for multimodal distributions. Techniques are also discussed\nto overcome the practical issues introduced by this generalization. It is shown\nthat the proposed approach is better at exploring complex multimodal posterior\ndistributions, as demonstrated on multiple applications and in comparison with\nother stochastic gradient MCMC methods.","primary_category":"cs","categories":["stat.ML","cs.LG","stat.AP"],"authors":["Zhang Yizhe","Chen Changyou","Gan Zhe","Henao Ricardo","Carin Lawrence"],"created":"2017-06-05","updated":"2018-01-10","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1706.03436","title":"Repair of Multiple Descriptions on Distributed Storage","abstract":"In multiple descriptions on distributed storage, a source is stored in a\nshared fashion on multiple servers. When a subset of servers are contacted, the\nsource should be estimated with a certain maximum distortion depending on the\nnumber of servers. The problem considered in this paper is how to restore the\nsystem operation when one of the servers fail and a new server replaces it,\nthat is, repair. The requirement is that the distortions in the restored system\nshould be no more than in the original system. The question is how many extra\nbits are needed for repair. We find the optimum solution for a two server\nproblem in the Gaussian case, and an achievable rate for general $n$ nodes. One\nconclusion is that it is necessary to design the multiple description codes\nwith repair in mind; just using an existing multiple description code results\nin unnecessary high repair rates.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Host-Madsen Anders","Yang Heechoel","Kim Minchul","Lee Jungwoo"],"created":"2017-06-11","updated":"2018-01-09","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1706.04009","title":"Secure uniform random number extraction via incoherent strategies","abstract":"To guarantee the security of uniform random numbers generated by a quantum\nrandom number generator, we study secure extraction of uniform random numbers\nwhen the environment of a given quantum state is controlled by the third party,\nthe eavesdropper. Here we restrict our operations to incoherent strategies that\nare composed of the measurement on the computational basis and incoherent\noperations (or incoherence-preserving operations). We show that the maximum\nsecure extraction rate is equal to the relative entropy of coherence. By\ncontrast, the coherence of formation gives the extraction rate when a certain\nconstraint is imposed on eavesdropper's operations. The condition under which\nthe two extraction rates coincide is then determined. Furthermore, we find that\nthe exponential decreasing rate of the leaked information is characterized by\nR\\'{e}nyi relative entropies of coherence. These results clarify the power of\nincoherent strategies in random number generation, and can be applied to\nguarantee the quality of random numbers generated by a quantum random number\ngenerator.","primary_category":"cs","categories":["quant-ph","cs.CR"],"authors":["Hayashi Masahito","Zhu Huangjun"],"created":"2017-06-13","updated":" ","doi":"10.1103\/PhysRevA.97.012302"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1706.04264","title":"von Mises-Fisher Mixture Model-based Deep learning: Application to Face\n  Verification","abstract":"A number of pattern recognition tasks, \\textit{e.g.}, face verification, can\nbe boiled down to classification or clustering of unit length directional\nfeature vectors whose distance can be simply computed by their angle. In this\npaper, we propose the von Mises-Fisher (vMF) mixture model as the theoretical\nfoundation for an effective deep-learning of such directional features and\nderive a novel vMF Mixture Loss and its corresponding vMF deep features. The\nproposed vMF feature learning achieves the characteristics of discriminative\nlearning, \\textit{i.e.}, compacting the instances of the same class while\nincreasing the distance of instances from different classes. Moreover, it\nsubsumes a number of popular loss functions as well as an effective method in\ndeep learning, namely normalization. We conduct extensive experiments on face\nverification using 4 different challenging face datasets, \\textit{i.e.}, LFW,\nYouTube faces, CACD and IJB-A. Results show the effectiveness and excellent\ngeneralization ability of the proposed approach as it achieves state-of-the-art\nresults on the LFW, YouTube faces and CACD datasets and competitive results on\nthe IJB-A dataset.","primary_category":"cs","categories":["cs.CV"],"authors":["Hasnat Md. Abul","Bohn\u00e9 Julien","Milgram Jonathan","Gentric St\u00e9phane","Chen Liming"],"created":"2017-06-13","updated":"2017-12-31","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1706.04815","title":"S-Net: From Answer Extraction to Answer Generation for Machine Reading\n  Comprehension","abstract":"In this paper, we present a novel approach to machine reading comprehension\nfor the MS-MARCO dataset. Unlike the SQuAD dataset that aims to answer a\nquestion with exact text spans in a passage, the MS-MARCO dataset defines the\ntask as answering a question from multiple passages and the words in the answer\nare not necessary in the passages. We therefore develop an\nextraction-then-synthesis framework to synthesize answers from extraction\nresults. Specifically, the answer extraction model is first employed to predict\nthe most important sub-spans from the passage as evidence, and the answer\nsynthesis model takes the evidence as additional features along with the\nquestion and passage to further elaborate the final answers. We build the\nanswer extraction model with state-of-the-art neural networks for single\npassage reading comprehension, and propose an additional task of passage\nranking to help answer extraction in multiple passages. The answer synthesis\nmodel is based on the sequence-to-sequence neural networks with extracted\nevidences as features. Experiments show that our extraction-then-synthesis\nmethod outperforms state-of-the-art methods.","primary_category":"cs","categories":["cs.CL"],"authors":["Tan Chuanqi","Wei Furu","Yang Nan","Du Bowen","Lv Weifeng","Zhou Ming"],"created":"2017-06-15","updated":"2018-01-02","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1706.05170","title":"Interactive 3D Modeling with a Generative Adversarial Network","abstract":"This paper proposes the idea of using a generative adversarial network (GAN)\nto assist a novice user in designing real-world shapes with a simple interface.\nThe user edits a voxel grid with a painting interface (like Minecraft). Yet, at\nany time, he\/she can execute a SNAP command, which projects the current voxel\ngrid onto a latent shape manifold with a learned projection operator and then\ngenerates a similar, but more realistic, shape using a learned generator\nnetwork. Then the user can edit the resulting shape and snap again until he\/she\nis satisfied with the result. The main advantage of this approach is that the\nprojection and generation operators assist novice users to create 3D models\ncharacteristic of a background distribution of object shapes, but without\nhaving to specify all the details. The core new research idea is to use a GAN\nto support this application. 3D GANs have previously been used for shape\ngeneration, interpolation, and completion, but never for interactive modeling.\nThe new challenge for this application is to learn a projection operator that\ntakes an arbitrary 3D voxel model and produces a latent vector on the shape\nmanifold from which a similar and realistic shape can be generated. We develop\nalgorithms for this and other steps of the SNAP processing pipeline and\nintegrate them into a simple modeling tool. Experiments with these algorithms\nand tool suggest that GANs provide a promising approach to computer-assisted\ninteractive modeling.","primary_category":"cs","categories":["cs.CV","cs.GR"],"authors":["Liu Jerry","Yu Fisher","Funkhouser Thomas"],"created":"2017-06-16","updated":"2018-01-07","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1706.05259","title":"Learning with Feature Evolvable Streams","abstract":"Learning with streaming data has attracted much attention during the past few\nyears. Though most studies consider data stream with fixed features, in real\npractice the features may be evolvable. For example, features of data gathered\nby limited-lifespan sensors will change when these sensors are substituted by\nnew ones. In this paper, we propose a novel learning paradigm: \\emph{Feature\nEvolvable Streaming Learning} where old features would vanish and new features\nwould occur. Rather than relying on only the current features, we attempt to\nrecover the vanished features and exploit it to improve performance.\nSpecifically, we learn two models from the recovered features and the current\nfeatures, respectively. To benefit from the recovered features, we develop two\nensemble methods. In the first method, we combine the predictions from two\nmodels and theoretically show that with the assistance of old features, the\nperformance on new features can be improved. In the second approach, we\ndynamically select the best single prediction and establish a better\nperformance guarantee when the best model switches. Experiments on both\nsynthetic and real data validate the effectiveness of our proposal.","primary_category":"cs","categories":["cs.LG","stat.ML"],"authors":["Hou Bo-Jian","Zhang Lijun","Zhou Zhi-Hua"],"created":"2017-06-16","updated":"2018-01-08","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1706.05429","title":"Modeling Biological Problems in Computer Science: A Case Study in Genome\n  Assembly","abstract":"As computer scientists working in bioinformatics\/computational biology, we\noften face the challenge of coming up with an algorithm to answer a biological\nquestion. This occurs in many areas, such as variant calling, alignment, and\nassembly. In this tutorial, we use the example of the genome assembly problem\nto demonstrate how to go from a question in the biological realm to a solution\nin the computer science realm. We show the modeling process step-by-step,\nincluding all the intermediate failed attempts.","primary_category":"cs","categories":["cs.DS","cs.DM","q-bio.GN"],"authors":["Medvedev Paul"],"created":"2017-06-16","updated":"2018-01-02","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1706.05699","title":"Gradient Diversity: a Key Ingredient for Scalable Distributed Learning","abstract":"It has been experimentally observed that distributed implementations of\nmini-batch stochastic gradient descent (SGD) algorithms exhibit speedup\nsaturation and decaying generalization ability beyond a particular batch-size.\nIn this work, we present an analysis hinting that high similarity between\nconcurrently processed gradients may be a cause of this performance\ndegradation. We introduce the notion of gradient diversity that measures the\ndissimilarity between concurrent gradient updates, and show its key role in the\nperformance of mini-batch SGD. We prove that on problems with high gradient\ndiversity, mini-batch SGD is amenable to better speedups, while maintaining the\ngeneralization performance of serial (one sample) SGD. We further establish\nlower bounds on convergence where mini-batch SGD slows down beyond a particular\nbatch-size, solely due to the lack of gradient diversity. We provide\nexperimental evidence indicating the key role of gradient diversity in\ndistributed learning, and discuss how heuristics like dropout, Langevin\ndynamics, and quantization can improve it.","primary_category":"cs","categories":["cs.LG","cs.DC"],"authors":["Yin Dong","Pananjady Ashwin","Lam Max","Papailiopoulos Dimitris","Ramchandran Kannan","Bartlett Peter"],"created":"2017-06-18","updated":"2018-01-06","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1706.06086","title":"An exponential lower bound for cut sparsifiers in planar graphs","abstract":"Given an edge-weighted graph $G$ with a set $Q$ of $k$ terminals, a mimicking\nnetwork is a graph with the same set of terminals that exactly preserves the\nsizes of minimum cuts between any partition of the terminals. A natural\nquestion in the area of graph compression is to provide as small mimicking\nnetworks as possible for input graph $G$ being either an arbitrary graph or\ncoming from a specific graph class.\n  In this note we show an exponential lower bound for cut mimicking networks in\nplanar graphs: there are edge-weighted planar graphs with $k$ terminals that\nrequire $2^{k-2}$ edges in any mimicking network. This nearly matches an upper\nbound of $O(k 2^{2k})$ of Krauthgamer and Rika [SODA 2013, arXiv:1702.05951]\nand is in sharp contrast with the $O(k^2)$ upper bound under the assumption\nthat all terminals lie on a single face [Goranci, Henzinger, Peng,\narXiv:1702.01136]. As a side result we show a hard instance for the\ndouble-exponential upper bounds given by Hagerup, Katajainen, Nishimura, and\nRagde~[JCSS 1998], Khan and Raghavendra~[IPL 2014], and Chambers and\nEppstein~[JGAA 2013].","primary_category":"cs","categories":["cs.DS"],"authors":["Karpov Nikolai","Pilipczuk Marcin","Zych-Pawlewicz Anna"],"created":"2017-06-19","updated":"2017-12-30","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1706.06964","title":"Lumping of Degree-Based Mean Field and Pair Approximation Equations for\n  Multi-State Contact Processes","abstract":"Contact processes form a large and highly interesting class of dynamic\nprocesses on networks, including epidemic and information spreading. While\ndevising stochastic models of such processes is relatively easy, analyzing them\nis very challenging from a computational point of view, particularly for large\nnetworks appearing in real applications. One strategy to reduce the complexity\nof their analysis is to rely on approximations, often in terms of a set of\ndifferential equations capturing the evolution of a random node, distinguishing\nnodes with different topological contexts (i.e., different degrees of different\nneighborhoods), like degree-based mean field (DBMF), approximate master\nequation (AME), or pair approximation (PA). The number of differential\nequations so obtained is typically proportional to the maximum degree kmax of\nthe network, which is much smaller than the size of the master equation of the\nunderlying stochastic model, yet numerically solving these equations can still\nbe problematic for large kmax. In this paper, we extend AME and PA, which has\nbeen proposed only for the binary state case, to a multi-state setting and\nprovide an aggregation procedure that clusters together nodes having similar\ndegrees, treating those in the same cluster as indistinguishable, thus reducing\nthe number of equations while preserving an accurate description of global\nobservables of interest. We also provide an automatic way to build such\nequations and to identify a small number of degree clusters that give accurate\nresults. The method is tested on several case studies, where it shows a high\nlevel of compression and a reduction of computational time of several orders of\nmagnitude for large networks, with minimal loss in accuracy.","primary_category":"cs","categories":["cs.SI","physics.soc-ph"],"authors":["Kyriakopoulos Charalampos","Grossmann Gerrit","Wolf Verena","Bortolussi Luca"],"created":"2017-06-21","updated":"2017-12-13","doi":"10.1103\/PhysRevE.97.012301"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1706.07230","title":"Gated-Attention Architectures for Task-Oriented Language Grounding","abstract":"To perform tasks specified by natural language instructions, autonomous\nagents need to extract semantically meaningful representations of language and\nmap it to visual elements and actions in the environment. This problem is\ncalled task-oriented language grounding. We propose an end-to-end trainable\nneural architecture for task-oriented language grounding in 3D environments\nwhich assumes no prior linguistic or perceptual knowledge and requires only raw\npixels from the environment and the natural language instruction as input. The\nproposed model combines the image and text representations using a\nGated-Attention mechanism and learns a policy to execute the natural language\ninstruction using standard reinforcement and imitation learning methods. We\nshow the effectiveness of the proposed model on unseen instructions as well as\nunseen maps, both quantitatively and qualitatively. We also introduce a novel\nenvironment based on a 3D game engine to simulate the challenges of\ntask-oriented language grounding over a rich set of instructions and\nenvironment states.","primary_category":"cs","categories":["cs.LG","cs.AI","cs.CL","cs.RO"],"authors":["Chaplot Devendra Singh","Sathyendra Kanthashree Mysore","Pasumarthi Rama Kumar","Rajagopal Dheeraj","Salakhutdinov Ruslan"],"created":"2017-06-22","updated":"2018-01-08","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1706.07513","title":"ParVecMF: A Paragraph Vector-based Matrix Factorization Recommender\n  System","abstract":"Review-based recommender systems have gained noticeable ground in recent\nyears. In addition to the rating scores, those systems are enriched with\ntextual evaluations of items by the users. Neural language processing models,\non the other hand, have already found application in recommender systems,\nmainly as a means of encoding user preference data, with the actual textual\ndescription of items serving only as side information. In this paper, a novel\napproach to incorporating the aforementioned models into the recommendation\nprocess is presented. Initially, a neural language processing model and more\nspecifically the paragraph vector model is used to encode textual user reviews\nof variable length into feature vectors of fixed length. Subsequently this\ninformation is fused along with the rating scores in a probabilistic matrix\nfactorization algorithm, based on maximum a-posteriori estimation. The\nresulting system, ParVecMF, is compared to a ratings' matrix factorization\napproach on a reference dataset. The obtained preliminary results on a set of\ntwo metrics are encouraging and may stimulate further research in this area.","primary_category":"cs","categories":["cs.IR"],"authors":["Alexandridis Georgios","Siolas Georgios","Stafylopatis Andreas"],"created":"2017-06-22","updated":"2018-01-10","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1706.08033","title":"Decomposing Motion and Content for Natural Video Sequence Prediction","abstract":"We propose a deep neural network for the prediction of future frames in\nnatural video sequences. To effectively handle complex evolution of pixels in\nvideos, we propose to decompose the motion and content, two key components\ngenerating dynamics in videos. Our model is built upon the Encoder-Decoder\nConvolutional Neural Network and Convolutional LSTM for pixel-level prediction,\nwhich independently capture the spatial layout of an image and the\ncorresponding temporal dynamics. By independently modeling motion and content,\npredicting the next frame reduces to converting the extracted content features\ninto the next frame content by the identified motion features, which simplifies\nthe task of prediction. Our model is end-to-end trainable over multiple time\nsteps, and naturally learns to decompose motion and content without separate\ntraining. We evaluate the proposed network architecture on human activity\nvideos using KTH, Weizmann action, and UCF-101 datasets. We show\nstate-of-the-art performance in comparison to recent approaches. To the best of\nour knowledge, this is the first end-to-end trainable network architecture with\nmotion and content separation to model the spatiotemporal dynamics for\npixel-level future prediction in natural videos.","primary_category":"cs","categories":["cs.CV"],"authors":["Villegas Ruben","Yang Jimei","Hong Seunghoon","Lin Xunyu","Lee Honglak"],"created":"2017-06-25","updated":"2018-01-07","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1706.08271","title":"Verifying Stochastic Behaviors of Decentralized Self-Adaptive Systems: A\n  Formal Modeling and Simulation Based Approach","abstract":"Self-adaptive software is considered as the most advanced approach and its\ndevelopment attracts a lot of attention. Decentralization is an effective way\nto design and manage the complexity of modern self-adaptive software systems.\nHowever, there are still tremendous challenges. One major challenge is to unify\ndecentrality with traditional self-adaptive implementation framework during\ndesign and implementation activity. One is to guarantee the required global\ngoals and performance of decentralized self-adaptive systems operating in\nhighly dynamic and uncertain environments. Another challenge is to predict the\ninfluence of system's internal change on its self-adaptability to the\nenvironment. To solve these problems, we combine the mechanisms of separation\nof concerns with modeling method using timed automata to allow the system to be\nanalyzed and verified. Timed computation tree logic is used to specify system\ngoals and stochastic simulations in dynamic environment are experimented to\nverify decentralized self-adaptive system's adaptation properties. In this\npaper, we extracted a motivation example from practical applications in UAV\nemergency mission scenarios. The whole approach is evaluated and illustrated\nwith this motivation example and the statistical results can be used as\nreference for arrangement planning of UAVs in cyber physical spaces.","primary_category":"cs","categories":["cs.SE","cs.FL"],"authors":["Li Nianyu","Bai Di","Yang Zhuoqun","Jiao Wenpin"],"created":"2017-06-26","updated":"2017-12-28","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1706.08324","title":"Hierarchy and assortativity as new tools for affinity investigation: the\n  case of the TBA aptamer-ligand complex","abstract":"Aptamers are single stranded DNA, RNA or peptide sequences having the ability\nto bind a variety of specific targets (proteins, molecules as well as ions).\nTherefore, aptamer production and selection for therapeutic and diagnostic\napplications is very challenging. Usually they are in vitro generated, but,\nrecently, computational approaches have been developed for the in silico\nselection, with a higher affinity for the specific target. Anyway, the\nmechanism of aptamer-ligand formation is not completely clear, and not obvious\nto predict. This paper aims to develop a computational model able to describe\naptamer-ligand affinity performance by using the topological structure of the\ncorresponding graphs, assessed by means of numerical tools such as the\nconventional degree distribution, but also the rank-degree distribution\n(hierarchy) and the node assortativity. Calculations are applied to the\nthrombin binding aptamer (TBA), and the TBA-thrombin complex, produced in the\npresence of Na+ or K+. The topological analysis reveals different affinity\nperformances between the macromolecules in the presence of the two cations, as\nexpected by previous investigations in literature. These results nominate the\ngraph topological analysis as a novel theoretical tool for testing affinity.\nOtherwise, starting from the graphs, an electrical network can be obtained by\nusing the specific electrical properties of amino acids and nucleobases.\nTherefore, a further analysis concerns with the electrical response, which\nreveals that the resistance sensitively depends on the presence of sodium or\npotassium thus posing resistance as a crucial physical parameter for testing\naffinity.","primary_category":"cs","categories":["q-bio.BM","cond-mat.soft","cs.CE","physics.bio-ph"],"authors":["Cataldo R.","Alfinito E.","Reggiani L."],"created":"2017-06-26","updated":" ","doi":"10.1109\/TNB.2017.2783440"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1706.08493","title":"Towards the Evolution of Multi-Layered Neural Networks: A Dynamic\n  Structured Grammatical Evolution Approach","abstract":"Current grammar-based NeuroEvolution approaches have several shortcomings. On\nthe one hand, they do not allow the generation of Artificial Neural Networks\n(ANNs composed of more than one hidden-layer. On the other, there is no way to\nevolve networks with more than one output neuron. To properly evolve ANNs with\nmore than one hidden-layer and multiple output nodes there is the need to know\nthe number of neurons available in previous layers. In this paper we introduce\nDynamic Structured Grammatical Evolution (DSGE): a new genotypic representation\nthat overcomes the aforementioned limitations. By enabling the creation of\ndynamic rules that specify the connection possibilities of each neuron, the\nmethodology enables the evolution of multi-layered ANNs with more than one\noutput neuron. Results in different classification problems show that DSGE\nevolves effective single and multi-layered ANNs, with a varying number of\noutput neurons.","primary_category":"cs","categories":["cs.NE","cs.AI"],"authors":["Assun\u00e7\u00e3o Filipe","Louren\u00e7o Nuno","Machado Penousal","Ribeiro Bernardete"],"created":"2017-06-26","updated":" ","doi":"10.1145\/3071178.3071286"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1706.09393","title":"Default Logic and Bounded Treewidth","abstract":"In this paper, we study Reiter's propositional default logic when the\ntreewidth of a certain graph representation (semi-primal graph) of the input\ntheory is bounded. We establish a dynamic programming algorithm on tree\ndecompositions that decides whether a theory has a consistent stable extension\n(Ext). Our algorithm can even be used to enumerate all generating defaults\n(ExtEnum) that lead to stable extensions.\n  We show that our algorithm decides Ext in linear time in the input theory and\ntriple exponential time in the treewidth (so-called fixed-parameter linear\nalgorithm).\n  Further, our algorithm solves ExtEnum with a pre-computation step that is\nlinear in the input theory and triple exponential in the treewidth followed by\na linear delay to output solutions.","primary_category":"cs","categories":["cs.AI","cs.CC","cs.LO"],"authors":["Fichte Johannes K.","Hecher Markus","Schindler Irina"],"created":"2017-06-28","updated":"2017-12-30","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1706.09814","title":"Data-dependent Generalization Bounds for Multi-class Classification","abstract":"In this paper, we study data-dependent generalization error bounds exhibiting\na mild dependency on the number of classes, making them suitable for\nmulti-class learning with a large number of label classes. The bounds generally\nhold for empirical multi-class risk minimization algorithms using an arbitrary\nnorm as regularizer. Key to our analysis are new structural results for\nmulti-class Gaussian complexities and empirical $\\ell_\\infty$-norm covering\nnumbers, which exploit the Lipschitz continuity of the loss function with\nrespect to the $\\ell_2$- and $\\ell_\\infty$-norm, respectively. We establish\ndata-dependent error bounds in terms of complexities of a linear function class\ndefined on a finite set induced by training examples, for which we show tight\nlower and upper bounds. We apply the results to several prominent multi-class\nlearning machines, exhibiting a tighter dependency on the number of classes\nthan the state of the art. For instance, for the multi-class SVM by Crammer and\nSinger (2002), we obtain a data-dependent bound with a logarithmic dependency\nwhich significantly improves the previous square-root dependency. Experimental\nresults are reported to verify the effectiveness of our theoretical findings.","primary_category":"cs","categories":["cs.LG"],"authors":["Lei Yunwen","Dogan Urun","Zhou Ding-Xuan","Kloft Marius"],"created":"2017-06-29","updated":"2017-12-29","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1706.10094","title":"Time-Space Trade-Offs for Lempel-Ziv Compressed Indexing","abstract":"Given a string $S$, the \\emph{compressed indexing problem} is to preprocess\n$S$ into a compressed representation that supports fast \\emph{substring\nqueries}. The goal is to use little space relative to the compressed size of\n$S$ while supporting fast queries. We present a compressed index based on the\nLempel--Ziv 1977 compression scheme. We obtain the following time-space\ntrade-offs: For constant-sized alphabets; (i) $O(m + occ \\lg\\lg n)$ time using\n$O(z\\lg(n\/z)\\lg\\lg z)$ space, or (ii) $O(m(1 + \\frac{\\lg^\\epsilon z}{\\lg(n\/z)})\n+ occ(\\lg\\lg n + \\lg^\\epsilon z))$ time using $O(z\\lg(n\/z))$ space. For integer\nalphabets polynomially bounded by $n$; (iii) $O(m(1 + \\frac{\\lg^\\epsilon\nz}{\\lg(n\/z)}) + occ(\\lg\\lg n + \\lg^\\epsilon z))$ time using $O(z(\\lg(n\/z) +\n\\lg\\lg z))$ space, or (iv) $O(m + occ(\\lg\\lg n + \\lg^{\\epsilon} z))$ time using\n$O(z(\\lg(n\/z) + \\lg^{\\epsilon} z))$ space, where $n$ and $m$ are the length of\nthe input string and query string respectively, $z$ is the number of phrases in\nthe LZ77 parse of the input string, $occ$ is the number of occurrences of the\nquery in the input and $\\epsilon > 0$ is an arbitrarily small constant. In\nparticular, (i) improves the leading term in the query time of the previous\nbest solution from $O(m\\lg m)$ to $O(m)$ at the cost of increasing the space by\na factor $\\lg \\lg z$. Alternatively, (ii) matches the previous best space\nbound, but has a leading term in the query time of $O(m(1+\\frac{\\lg^{\\epsilon}\nz}{\\lg (n\/z)}))$. However, for any polynomial compression ratio, i.e., $z =\nO(n^{1-\\delta})$, for constant $\\delta > 0$, this becomes $O(m)$. Our index\nalso supports extraction of any substring of length $\\ell$ in $O(\\ell +\n\\lg(n\/z))$ time. Technically, our results are obtained by novel extensions and\ncombinations of existing data structures of independent interest, including a\nnew batched variant of weak prefix search.","primary_category":"cs","categories":["cs.DS"],"authors":["Bille Philip","Ettienne Mikko Berggren","G\u00f8rtz Inge Li","Vildh\u00f8j Hjalte Wedel"],"created":"2017-06-30","updated":"2018-01-09","doi":"10.1016\/j.tcs.2017.12.021"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1707.00827","title":"Document Spanners for Extracting Incomplete Information: Expressiveness\n  and Complexity","abstract":"Rule-based information extraction has lately received a fair amount of\nattention from the database community, with several languages appearing in the\nlast few years. Although information extraction systems are intended to deal\nwith semistructured data, all language proposals introduced so far are designed\nto output relations, thus making them incapable of handling incomplete\ninformation. To remedy the situation, we propose to extend information\nextraction languages with the ability to use mappings, thus allowing us to work\nwith documents which have missing or optional parts. Using this approach, we\nsimplify the semantics of regex formulas and extraction rules, two previously\ndefined methods for extracting information, extend them with the ability to\nhandle incomplete data, and study how they compare in terms of expressive\npower. We also study computational properties of these languages, focusing on\nthe query enumeration problem, as well as satisfiability and containment.","primary_category":"cs","categories":["cs.DB"],"authors":["Maturana Francisco","Riveros Cristian","Vrgo\u010d Domagoj"],"created":"2017-07-04","updated":"2017-12-29","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1707.01978","title":"Local Large deviation: A McMillian Theorem for Coloured Random Graph\n  Processes","abstract":"For a finite typed graph on $n$ nodes and with type law $\\mu,$ we define the\nso-called spectral potential $\\rho_{\\lambda}(\\,\\cdot,\\,\\mu),$ of the graph.From\nthe $\\rho_{\\lambda}(\\,\\cdot,\\,\\mu)$ we obtain Kullback action or the deviation\nfunction, $\\mathcal{H}_{\\lambda}(\\pi\\,\\|\\,\\nu),$ with respect to an empirical\npair measure, $\\pi,$ as the Legendre dual.\n  For the finite typed random graph conditioned to have an empirical link\nmeasure $\\pi$ and empirical type measure $\\mu$, we prove a Local large\ndeviation principle (LLDP), with rate function\n$\\mathcal{H}_{\\lambda}(\\pi\\,\\|\\,\\nu)$ and speed $n.$ We deduce from this LLDP,\na full conditional large deviation principle and a weak variant of the\nclassical McMillian Theorem for the typed random graphs. Given the typical\nempirical link measure, $\\lambda\\mu\\otimes\\mu,$ the number of typed random\ngraphs is approximately equal\n$e^{n\\|\\lambda\\mu\\otimes\\mu\\|H\\big(\\lambda\\mu\\otimes\\mu\/\\|\\lambda\\mu\\otimes\\mu\\|\\big)}.$\nNote that we do not require any topological restrictions on the space of finite\ngraphs for these LLDPs.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Doku-Amponsah Kwabena"],"created":"2017-07-06","updated":" ","doi":"10.3844\/jmssp.2017.347.352"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1707.03186","title":"Community Discovery in Dynamic Networks: a Survey","abstract":"Networks built to model real world phenomena are characeterised by some\nproperties that have attracted the attention of the scientific community: (i)\nthey are organised according to community structure and (ii) their structure\nevolves with time. Many researchers have worked on methods that can efficiently\nunveil substructures in complex networks, giving birth to the field of\ncommunity discovery. A novel and challenging problem started capturing\nresearcher interest recently: the identification of evolving communities. To\nmodel the evolution of a system, dynamic networks can be used: nodes and edges\nare mutable and their presence, or absence, deeply impacts the community\nstructure that composes them. The aim of this survey is to present the\ndistinctive features and challenges of dynamic community discovery, and propose\na classification of published approaches. As a \"user manual\", this work\norganizes state of art methodologies into a taxonomy, based on their rationale,\nand their specific instanciation. Given a desired definition of network\ndynamics, community characteristics and analytical needs, this survey will\nsupport researchers to identify the set of approaches that best fit their\nneeds. The proposed classification could also help researchers to choose in\nwhich direction should future research be oriented.","primary_category":"cs","categories":["cs.SI","physics.soc-ph"],"authors":["Rossetti Giulio","Cazabet R\u00e9my"],"created":"2017-07-11","updated":"2017-12-06","doi":"10.1145\/3172867"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1707.04061","title":"Automatic Recognition of Facial Displays of Unfelt Emotions","abstract":"Humans modify their facial expressions in order to communicate their internal\nstates and sometimes to mislead observers regarding their true emotional\nstates. Evidence in experimental psychology shows that discriminative facial\nresponses are short and subtle. This suggests that such behavior would be\neasier to distinguish when captured in high resolution at an increased frame\nrate. We are proposing SASE-FE, the first dataset of facial expressions that\nare either congruent or incongruent with underlying emotion states. We show\nthat overall the problem of recognizing whether facial movements are\nexpressions of authentic emotions or not can be successfully addressed by\nlearning spatio-temporal representations of the data. For this purpose, we\npropose a method that aggregates features along fiducial trajectories in a\ndeeply learnt space. Performance of the proposed model shows that on average it\nis easier to distinguish among genuine facial expressions of emotion than among\nunfelt facial expressions of emotion and that certain emotion pairs such as\ncontempt and disgust are more difficult to distinguish than the rest.\nFurthermore, the proposed methodology improves state of the art results on CK+\nand OULU-CASIA datasets for video emotion recognition, and achieves competitive\nresults when classifying facial action units on BP4D datase.","primary_category":"cs","categories":["cs.CV"],"authors":["Kulkarni Kaustubh","Corneanu Ciprian Adrian","Ofodile Ikechukwu","Escalera Sergio","Baro Xavier","Hyniewska Sylwia","Allik Juri","Anbarjafari Gholamreza"],"created":"2017-07-13","updated":"2018-01-09","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1707.04497","title":"A Comparative Study of Unipolar OFDM Schemes in Gaussian Optical\n  Intensity Channel","abstract":"We study the information rates of unipolar orthogonal frequency division\nmultiplexing (OFDM) in discrete-time optical intensity channels (OIC) with\nGaussian noise under average optical power constraint. Several single-,\ndouble-, and multicomponent unipolar OFDM schemes are considered under the\nassumption that independent and identically distributed (i.i.d.) Gaussian or\ncomplex Gaussian codebook ensemble and nearest neighbor decoding (minimum\nEuclidean distance decoding) are used. We obtain an array of information rate\nresult. These results validate existing signal-to-noise-and-distortion-ratio\n(SNDR) based rate analysis, establish the equivalence of information rates of\ncertain schemes, and demonstrate the evident benefits of using\ncomponent-multiplexing at high signal-to-noise-ratio (SNR). For double- and\nmulti-component schemes, the component power allocation strategies that\nmaximize the information rates are investigated. In particular, by utilizing a\npower allocation strategy, we prove that several multi-component schemes\napproach the high SNR capacity of the discrete-time Gaussian OIC under average\npower constraint to within 0.07 bits.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Zhou Jing","Zhang Wenyi"],"created":"2017-07-14","updated":"2018-01-04","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1707.05031","title":"Residual Features and Unified Prediction Network for Single Stage\n  Detection","abstract":"Recently, a lot of single stage detectors using multi-scale features have\nbeen actively proposed. They are much faster than two stage detectors that use\nregion proposal networks (RPN) without much degradation in the detection\nperformances. However, the feature maps in the lower layers close to the input\nwhich are responsible for detecting small objects in a single stage detector\nhave a problem of insufficient representation power because they are too\nshallow. There is also a structural contradiction that the feature maps have to\ndeliver low-level information to next layers as well as contain high-level\nabstraction for prediction. In this paper, we propose a method to enrich the\nrepresentation power of feature maps using Resblock and deconvolution layers.\nIn addition, a unified prediction module is applied to generalize output\nresults and boost earlier layers' representation power for prediction. The\nproposed method enables more precise prediction, which achieved higher score\nthan SSD on PASCAL VOC and MS COCO. In addition, it maintains the advantage of\nfast computation of a single stage detector, which requires much less\ncomputation than other detectors with similar performance. Code is available at\nhttps:\/\/github.com\/kmlee-snu\/run","primary_category":"cs","categories":["cs.CV"],"authors":["Lee Kyoungmin","Choi Jaeseok","Jeong Jisoo","Kwak Nojun"],"created":"2017-07-17","updated":"2018-01-04","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1707.06183","title":"Domain-adversarial neural networks to address the appearance variability\n  of histopathology images","abstract":"Preparing and scanning histopathology slides consists of several steps, each\nwith a multitude of parameters. The parameters can vary between pathology labs\nand within the same lab over time, resulting in significant variability of the\ntissue appearance that hampers the generalization of automatic image analysis\nmethods. Typically, this is addressed with ad-hoc approaches such as staining\nnormalization that aim to reduce the appearance variability. In this paper, we\npropose a systematic solution based on domain-adversarial neural networks. We\nhypothesize that removing the domain information from the model representation\nleads to better generalization. We tested our hypothesis for the problem of\nmitosis detection in breast cancer histopathology images and made a comparative\nanalysis with two other approaches. We show that combining color augmentation\nwith domain-adversarial training is a better alternative than standard\napproaches to improve the generalization of deep learning methods.","primary_category":"cs","categories":["cs.CV"],"authors":["Lafarge Maxime W.","Pluim Josien P. W.","Eppenhof Koen A. J.","Moeskops Pim","Veta Mitko"],"created":"2017-07-19","updated":" ","doi":"10.1007\/978-3-319-67558-9"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1707.06907","title":"What Looks Good with my Sofa: Multimodal Search Engine for Interior\n  Design","abstract":"In this paper, we propose a multi-modal search engine for interior design\nthat combines visual and textual queries. The goal of our engine is to retrieve\ninterior objects, e.g. furniture or wall clocks, that share visual and\naesthetic similarities with the query. Our search engine allows the user to\ntake a photo of a room and retrieve with a high recall a list of items\nidentical or visually similar to those present in the photo. Additionally, it\nallows to return other items that aesthetically and stylistically fit well\ntogether. To achieve this goal, our system blends the results obtained using\ntextual and visual modalities. Thanks to this blending strategy, we increase\nthe average style similarity score of the retrieved items by 11%. Our work is\nimplemented as a Web-based application and it is planned to be opened to the\npublic.","primary_category":"cs","categories":["cs.CV"],"authors":["Tautkute Ivona","Mo\u017cejko Aleksandra","Stokowiec Wojciech","Trzci\u0144ski Tomasz","Brocki \u0141ukasz","Marasek Krzysztof"],"created":"2017-07-21","updated":"2018-01-08","doi":"10.15439\/2017F56"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1707.07849","title":"Performance evaluation of energy detector over generalized non-linear\n  and shadowed composite fading channels using a Mixture Gamma Distribution","abstract":"The performance of energy detection (ED) for independent and identically\ndistribution (i.i.d.) signal models is analyzed over generalized composite\nnon-linear line-of-sight (LOS) and non-line-of-sight (NLOS) shadowed fading\nscenarios. The novel expressions for {\\alpha}-\\k{appa}-{\\mu}\/Gamma and\n{\\alpha}-{\\eta}-{\\mu}\/Gamma fading channels have been derived to approximate by\nusing the mixture gamma (MG) distribution under low instantaneous\nsignal-to-noise (SNR) condition. On the basis of the deduced fading\ndistributions, novel, exact and close-form detective models are derived to\nevaluate the sensing performance with different key fading parameters over\ngeneralized non-linear and shadowed composite fading channels.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Huang He"],"created":"2017-07-25","updated":"2017-12-30","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1707.08409","title":"Caching Policy for Cache-enabled D2D Communications by Learning User\n  Preference","abstract":"Prior works in designing caching policy do not distinguish content popularity\nwith user preference. In this paper, we illustrate the caching gain by\nexploiting individual user behavior in sending requests. After showing the\nconnection between the two concepts, we provide a model for synthesizing user\npreference from content popularity. We then optimize the caching policy with\nthe knowledge of user preference and active level to maximize the offloading\nprobability for cache-enabled device-to-device communications, and develop a\nlow-complexity algorithm to find the solution. In order to learn user\npreference, we model the user request behavior resorting to probabilistic\nlatent semantic analysis, and learn the model parameters by expectation\nmaximization algorithm. By analyzing a Movielens dataset, we find that the user\npreferences are less similar, and the active level and topic preference of each\nuser change slowly over time. Based on this observation, we introduce a prior\nknowledge based learning algorithm for user preference, which can shorten the\nlearning time. Simulation results show remarkable performance gain of the\ncaching policy with user preference over existing policy with content\npopularity, both with realistic dataset and synthetic data validated by the\nreal dataset.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Chen Binqiang","Yang Chenyang"],"created":"2017-07-26","updated":"2018-01-03","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1707.08535","title":"Inference from Randomized Transmissions by Many Backscatter Sensors","abstract":"Attaining the vision of Smart Cities requires the deployment of an enormous\nnumber of sensors for monitoring various conditions of the environment.\nBackscatter-sensors have emerged to be a promising solution due to the\nuninterruptible energy supply and relative simple hardwares. On the other hand,\nbackscatter-sensors with limited signal-processing capabilities are unable to\nsupport conventional algorithms for multiple-access and channel-training. Thus,\nthe key challenge in designing backscatter-sensor networks is to enable readers\nto accurately detect sensing-values given simple ALOHA random access, primitive\ntransmission schemes, and no knowledge of channel-states. We tackle this\nchallenge by proposing the novel framework of backscatter sensing featuring\nrandom-encoding at sensors and statistical-inference at readers. Specifically,\nassuming the on\/off keying for backscatter transmissions, the practical\nrandom-encoding scheme causes the on\/off transmission of a sensor to follow a\ndistribution parameterized by the sensing values. Facilitated by the scheme,\nstatistical-inference algorithms are designed to enable a reader to infer\nsensing-values from randomized transmissions by multiple sensors. The specific\ndesign procedure involves the construction of Bayesian networks, namely\nderiving conditional distributions for relating unknown parameters and\nvariables to signals observed by the reader. Then based on the Bayesian\nnetworks and the well-known expectation-maximization principle, inference\nalgorithms are derived to recover sensing-values.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Zhu Guangxu","Ko Seung-Woo","Huang Kaibin"],"created":"2017-07-26","updated":"2018-01-09","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1707.09789","title":"Relations Between Greedy and Bit-Optimal LZ77 Encodings","abstract":"This paper investigates the size in bits of the LZ77 encoding, which is the\nmost popular and efficient variant of the Lempel-Ziv encodings used in data\ncompression. We prove that, for a wide natural class of variable-length\nencoders for LZ77 phrases, the size of the greedily constructed LZ77 encoding\non constant alphabets is within a factor $O(\\frac{\\log n}{\\log\\log\\log n})$ of\nthe optimal LZ77 encoding, where $n$ is the length of the processed string. We\ndescribe a series of examples showing that, surprisingly, this bound is tight,\nthus improving both the previously known upper and lower bounds. Further, we\nobtain a more detailed bound $O(\\min\\{z, \\frac{\\log n}{\\log\\log z}\\})$, which\nuses the number $z$ of phrases in the greedy LZ77 encoding as a parameter, and\nconstruct a series of examples showing that this bound is tight even for binary\nalphabet. We then investigate the problem on non-constant alphabets: we show\nthat the known $O(\\log n)$ bound is tight even for alphabets of logarithmic\nsize, and provide tight bounds for some other important cases.","primary_category":"cs","categories":["cs.DM"],"authors":["Kosolobov Dmitry"],"created":"2017-07-31","updated":"2018-01-09","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1707.09933","title":"Learning Neural Network Classifiers with Low Model Complexity","abstract":"Modern neural network architectures for large-scale learning tasks have\nsubstantially higher model complexities, which makes understanding, visualizing\nand training these architectures difficult. Recent contributions to deep\nlearning techniques have focused on architectural modifications to improve\nparameter efficiency and performance. In this paper, we derive a continuous and\ndifferentiable error functional for a neural network that minimizes its\nempirical error as well as a measure of the model complexity. The latter\nmeasure is obtained by deriving a differentiable upper bound on the\nVapnik-Chervonenkis (VC) dimension of the classifier layer of a class of deep\nnetworks. Using standard backpropagation, we realize a training rule that tries\nto minimize the error on training samples, while improving generalization by\nkeeping the model complexity low. We demonstrate the effectiveness of our\nformulation (the Low Complexity Neural Network - LCNN) across several deep\nlearning algorithms, and a variety of large benchmark datasets. We show that\nhidden layer neurons in the resultant networks learn features that are crisp,\nand in the case of image datasets, quantitatively sharper. Our proposed\napproach yields benefits across a wide range of architectures, in comparison to\nand in conjunction with methods such as Dropout and Batch Normalization, and\nour results strongly suggest that deep learning techniques can benefit from\nmodel complexity control methods such as the LCNN learning rule.","primary_category":"cs","categories":["cs.LG"],"authors":["Pant Himanshu","Sharma Mayank","Dubey Abhimanyu","Soman Sumit","Tripathi Suraj","Guruju Sai","Goalla Nihal"],"created":"2017-07-31","updated":"2018-01-02","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1708.00681","title":"Maximum-Area Quadrilateral in a Convex Polygon, Revisited","abstract":"In this note we show by example that the algorithm presented in 1979 by\nDobkin and Snyder for finding the largest-area k-gon that is inscribed in a\nconvex polygon fails to find the optimal solution for k=4. This question, posed\nby Keikha et al. where they showed that the Dobkin Snyder algorithm fails for\nk=3.","primary_category":"cs","categories":["cs.CG"],"authors":["Keikha Vahideh","L\u00f6ffler Maarten","Mohades Ali","Urhausen J\u00e9r\u00f4me","van der Hoog Ivor"],"created":"2017-08-02","updated":"2017-12-24","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1708.00842","title":"Latent Parameter Estimation in Fusion Networks Using Separable\n  Likelihoods","abstract":"Multi-sensor state space models underpin fusion applications in networks of\nsensors. Estimation of latent parameters in these models has the potential to\nprovide highly desirable capabilities such as network self-calibration.\nConventional solutions to the problem pose difficulties in scaling with the\nnumber of sensors due to the joint multi-sensor filtering involved when\nevaluating the parameter likelihood. In this article, we propose a separable\npseudo-likelihood which is a more accurate approximation compared to a\npreviously proposed alternative under typical operating conditions. In\naddition, we consider using separable likelihoods in the presence of many\nobjects and ambiguity in associating measurements with objects that originated\nthem. To this end, we use a state space model with a hypothesis based\nparameterisation, and, develop an empirical Bayesian perspective in order to\nevaluate separable likelihoods on this model using local filtering. Bayesian\ninference with this likelihood is carried out using belief propagation on the\nassociated pairwise Markov random field. We specify a particle algorithm for\nlatent parameter estimation in a linear Gaussian state space model and\ndemonstrate its efficacy for network self-calibration using measurements from\nnon-cooperative targets in comparison with alternatives.","primary_category":"cs","categories":["cs.SY","cs.IT","cs.MA","math.IT","stat.AP","stat.CO"],"authors":["Uney Murat","Mulgrew Bernard","Clark Daniel E"],"created":"2017-08-02","updated":"2018-01-02","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1708.01462","title":"How Amdahl's low restricts supercomputer applications and building ever\n  bigger supercomputers","abstract":"This paper reinterprets Amdahl's law in terms of execution time and applies\nthis simple model to supercomputing. The systematic discussion results in\npractical formulas enabling to calculate expected running time using large\nnumber of processors from experimental runs using low number of processors,\ndelivers a quantitative measure of computational efficiency of supercomputing\napplications. Through separating non-parallelizable contribution to fractions\naccording to their origin, Amdahl's law enables to derive a timeline for\nsupercomputers (quite similar to Moore's law) and describes why Amdahl's law\nlimits the size of supercomputers. The paper validates that Amdahl's 50-years\nold model (with slight extension) correctly describes the performance\nlimitations of the present supercomputers. Using some simple and reasonable\nassumptions, the absolute performance bound of supercomputers is concluded,\nfurthermore that serious enhancements are still necessary to achieve the\nexaFLOPS dream value.","primary_category":"cs","categories":["cs.DC"],"authors":["V\u00e9gh J\u00e1nos"],"created":"2017-08-04","updated":"2017-12-29","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1708.01732","title":"Private Web Browser Forensics: A Case Study of the Epic Privacy Browser","abstract":"Organised crime, as well as individual criminals, is benefiting from the\nprotection of private browsers provide to those who would carry out illegal\nactivity, such as money laundering, drug trafficking, the online exchange of\nchild-abuse material, etc. The protection afforded to users of the Epic Privacy\nBrowser illustrates these benefits. This browser is currently in use in\napproximately 180 countries worldwide. This paper outlines the location and\ntype of evidence available through live and post-mortem state analyses of the\nEpic Privacy Browser. This study identifies the manner in which the browser\nfunctions during use, where evidence can be recovered after use, as well as the\ntools and effective presentation of the recovered material.","primary_category":"cs","categories":["cs.CR"],"authors":["Reed Alan","Scanlon Mark","Le-Khac Nhien-An"],"created":"2017-08-05","updated":"2018-01-04","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1708.01844","title":"Automated Assessment of Facial Wrinkling: a case study on the effect of\n  smoking","abstract":"Facial wrinkle is one of the most prominent biological changes that\naccompanying the natural aging process. However, there are some external\nfactors contributing to premature wrinkles development, such as sun exposure\nand smoking. Clinical studies have shown that heavy smoking causes premature\nwrinkles development. However, there is no computerised system that can\nautomatically assess the facial wrinkles on the whole face. This study\ninvestigates the effect of smoking on facial wrinkling using a social habit\nface dataset and an automated computerised computer vision algorithm. The\nwrinkles pattern represented in the intensity of 0-255 was first extracted\nusing a modified Hybrid Hessian Filter. The face was divided into ten\npredefined regions, where the wrinkles in each region was extracted. Then the\nstatistical analysis was performed to analyse which region is effected mainly\nby smoking. The result showed that the density of wrinkles for smokers in two\nregions around the mouth was significantly higher than the non-smokers, at\np-value of 0.05. Other regions are inconclusive due to lack of large scale\ndataset. Finally, the wrinkle was visually compared between smoker and\nnon-smoker faces by generating a generic 3D face model.","primary_category":"cs","categories":["cs.CV"],"authors":["Osman Omaima FathElrahman","Elbashir Remah Mutasim Ibrahim","Abbass Imad Eldain","Kendrick Connah","Goyal Manu","Yap Moi Hoon"],"created":"2017-08-06","updated":"2017-12-31","doi":"10.1109\/SMC.2017.8122755"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1708.01977","title":"Why Adaptively Collected Data Have Negative Bias and How to Correct for\n  It","abstract":"From scientific experiments to online A\/B testing, the previously observed\ndata often affects how future experiments are performed, which in turn affects\nwhich data will be collected. Such adaptivity introduces complex correlations\nbetween the data and the collection procedure. In this paper, we prove that\nwhen the data collection procedure satisfies natural conditions, then sample\nmeans of the data have systematic \\emph{negative} biases. As an example,\nconsider an adaptive clinical trial where additional data points are more\nlikely to be tested for treatments that show initial promise. Our surprising\nresult implies that the average observed treatment effects would underestimate\nthe true effects of each treatment. We quantitatively analyze the magnitude and\nbehavior of this negative bias in a variety of settings. We also propose a\nnovel debiasing algorithm based on selective inference techniques. In\nexperiments, our method can effectively reduce bias and estimation error.","primary_category":"cs","categories":["stat.ML","cs.LG"],"authors":["Nie Xinkun","Tian Xiaoying","Taylor Jonathan","Zou James"],"created":"2017-08-06","updated":"2017-12-30","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1708.02392","title":"Learning Human-Robot Collaboration Insights through the Integration of\n  Muscle Activity in Interaction Motion Models","abstract":"Recent progress in human-robot collaboration makes fast and fluid\ninteractions possible, even when human observations are partial and occluded.\nMethods like Interaction Probabilistic Movement Primitives (ProMP) model human\ntrajectories through motion capture systems. However, such representation does\nnot properly model tasks where similar motions handle different objects. Under\ncurrent approaches, a robot would not adapt its pose and dynamics for proper\nhandling. We integrate the use of Electromyography (EMG) into the Interaction\nProMP framework and utilize muscular signals to augment the human observation\nrepresentation. The contribution of our paper is increased task discernment\nwhen trajectories are similar but tools are different and require the robot to\nadjust its pose for proper handling. Interaction ProMPs are used with an\naugmented vector that integrates muscle activity. Augmented time-normalized\ntrajectories are used in training to learn correlation parameters and robot\nmotions are predicted by finding the best weight combination and temporal\nscaling for a task. Collaborative single task scenarios with similar motions\nbut different objects were used and compared. For one experiment only joint\nangles were recorded, for the other EMG signals were additionally integrated.\nTask recognition was computed for both tasks. Observation state vectors with\naugmented EMG signals were able to completely identify differences across\ntasks, while the baseline method failed every time. Integrating EMG signals\ninto collaborative tasks significantly increases the ability of the system to\nrecognize nuances in the tasks that are otherwise imperceptible, up to 74.6% in\nour studies. Furthermore, the integration of EMG signals for collaboration also\nopens the door to a wide class of human-robot physical interactions based on\nhaptic communication that has been largely unexploited in the field.","primary_category":"cs","categories":["cs.RO"],"authors":["Chen Longxin","Rojas Juan","Duan Shuangda","Guan Yisheng"],"created":"2017-08-08","updated":" ","doi":"10.1109\/HUMANOIDS.2017.8246917"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1708.02553","title":"Robust Computer Algebra, Theorem Proving, and Oracle AI","abstract":"In the context of superintelligent AI systems, the term \"oracle\" has two\nmeanings. One refers to modular systems queried for domain-specific tasks.\nAnother usage, referring to a class of systems which may be useful for\naddressing the value alignment and AI control problems, is a superintelligent\nAI system that only answers questions. The aim of this manuscript is to survey\ncontemporary research problems related to oracles which align with long-term\nresearch goals of AI safety. We examine existing question answering systems and\nargue that their high degree of architectural heterogeneity makes them poor\ncandidates for rigorous analysis as oracles. On the other hand, we identify\ncomputer algebra systems (CASs) as being primitive examples of domain-specific\noracles for mathematics and argue that efforts to integrate computer algebra\nsystems with theorem provers, systems which have largely been developed\nindependent of one another, provide a concrete set of problems related to the\nnotion of provable safety that has emerged in the AI safety community. We\nreview approaches to interfacing CASs with theorem provers, describe\nwell-defined architectural deficiencies that have been identified with CASs,\nand suggest possible lines of research and practical software projects for\nscientists interested in AI safety.","primary_category":"cs","categories":["cs.AI","cs.SC"],"authors":["Sarma Gopal P.","Hay Nick J."],"created":"2017-08-08","updated":"2017-12-31","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1708.02763","title":"Has the Online Discussion Been Manipulated? Quantifying Online\n  Discussion Authenticity within Online Social Media","abstract":"Online social media (OSM) has a enormous influence in today's world. Some\nindividuals view OSM as fertile ground for abuse and use it to disseminate\nmisinformation and political propaganda, slander competitors, and spread spam.\nThe crowdturfing industry employs large numbers of bots and human workers to\nmanipulate OSM and misrepresent public opinion. The detection of online\ndiscussion topics manipulated by OSM \\emph{abusers} is an emerging issue\nattracting significant attention. In this paper, we propose an approach for\nquantifying the authenticity of online discussions based on the similarity of\nOSM accounts participating in the discussion to known abusers and legitimate\naccounts. Our method uses several similarity functions for the analysis and\nclassification of OSM accounts. The proposed methods are demonstrated using\nTwitter data collected for this study and previously published \\emph{Arabic\nhoneypot dataset}. The former includes manually labeled accounts and abusers\nwho participated in crowdturfing platforms. Evaluation of the topic's\nauthenticity, derived from account similarity functions, shows that the\nsuggested approach is effective for discriminating between topics that were\nstrongly promoted by abusers and topics that attracted authentic public\ninterest.","primary_category":"cs","categories":["cs.SI"],"authors":["Elyashar Aviad","Bendahan Jorge","Puzis Rami"],"created":"2017-08-09","updated":"2018-01-04","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1708.03402","title":"Product Matrix MSR Codes with Bandwidth Adaptive Exact Repair","abstract":"In a distributed storage systems (DSS) with $k$ systematic nodes, robustness\nagainst node failure is commonly provided by storing redundancy in a number of\nother nodes and performing repair mechanism to reproduce the content of the\nfailed nodes. Efficiency is then achieved by minimizing the storage overhead\nand the amount of data transmission required for data reconstruction and\nrepair, provided by coding solutions such as regenerating codes [1]. Common\nexplicit regenerating code constructions enable efficient repair through\naccessing a predefined number, $d$, of arbitrary chosen available nodes, namely\nhelpers. In practice, however, the state of the system dynamically changes\nbased on the request load, the link traffic, etc., and the parameters which\noptimize system's performance vary accordingly. It is then desirable to have\ncoding schemes which are able to operate optimally under a range of different\nparameters simultaneously. Specifically, adaptivity in the number of helper\nnodes for repair is of interest. While robustness requires capability of\nperforming repair with small number of helpers, it is desirable to use as many\nhelpers as available to reduce the transmission delay and total repair traffic.\n  In this work we focus on the minimum storage regenerating (MSR) codes, where\neach node is supposed to store $\\alpha$ information units, and the source data\nof size $k\\alpha$ could be recovered from any arbitrary set of $k$ nodes. We\nintroduce a class MSR codes that realize optimal repair bandwidth\nsimultaneously with a set of different choices for the number of helpers,\nnamely $D=\\{d_{1}, \\cdots, d_{\\delta}\\}$. Our coding scheme follows the Product\nMatrix (PM) framework introduced in [2], and could be considered as a\ngeneralization of the PM MSR code presented in [2], such that any $d_{i} =\n(i+1)(k-1)$ helpers can perform an optimal repair. ...","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Mahdaviani Kaveh","Mohajer Soheil","Khisti Ashish"],"created":"2017-08-10","updated":"2017-12-28","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1708.03549","title":"Dynamic controllers for column synchronization of rotation matrices: a\n  QR-factorization approach","abstract":"In the multi-agent systems setting, this paper addresses continuous-time\ndistributed synchronization of columns of rotation matrices. More precisely, k\nspecific columns shall be synchronized and only the corresponding k columns of\nthe relative rotations between the agents are assumed to be available for the\ncontrol design. When one specific column is considered, the problem is\nequivalent to synchronization on the (d-1)-dimensional unit sphere and when all\nthe columns are considered, the problem is equivalent to synchronization on\nSO(d). We design dynamic control laws for these synchronization problems. The\ncontrol laws are based on the introduction of auxiliary variables in\ncombination with a QR-factorization approach. The benefit of this\nQR-factorization approach is that we can decouple the dynamics for the k\ncolumns from the remaining d-k ones. Under the control scheme, the closed loop\nsystem achieves almost global convergence to synchronization for quasi-strong\ninteraction graph topologies.","primary_category":"cs","categories":["math.OC","cs.DC","cs.MA","cs.SY"],"authors":["Thunberg Johan","Markdahl Johan","Goncalves Jorge"],"created":"2017-08-11","updated":"2018-01-08","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1708.04728","title":"DeepRebirth: Accelerating Deep Neural Network Execution on Mobile\n  Devices","abstract":"Deploying deep neural networks on mobile devices is a challenging task.\nCurrent model compression methods such as matrix decomposition effectively\nreduce the deployed model size, but still cannot satisfy real-time processing\nrequirement. This paper first discovers that the major obstacle is the\nexcessive execution time of non-tensor layers such as pooling and normalization\nwithout tensor-like trainable parameters. This motivates us to design a novel\nacceleration framework: DeepRebirth through \"slimming\" existing consecutive and\nparallel non-tensor and tensor layers. The layer slimming is executed at\ndifferent substructures: (a) streamline slimming by merging the consecutive\nnon-tensor and tensor layer vertically; (b) branch slimming by merging\nnon-tensor and tensor branches horizontally. The proposed optimization\noperations significantly accelerate the model execution and also greatly reduce\nthe run-time memory cost since the slimmed model architecture contains less\nhidden layers. To maximally avoid accuracy loss, the parameters in new\ngenerated layers are learned with layer-wise fine-tuning based on both\ntheoretical analysis and empirical verification. As observed in the experiment,\nDeepRebirth achieves more than 3x speed-up and 2.5x run-time memory saving on\nGoogLeNet with only 0.4% drop of top-5 accuracy on ImageNet. Furthermore, by\ncombining with other model compression techniques, DeepRebirth offers an\naverage of 65ms inference time on the CPU of Samsung Galaxy S6 with 86.5% top-5\naccuracy, 14% faster than SqueezeNet which only has a top-5 accuracy of 80.5%.","primary_category":"cs","categories":["cs.CV"],"authors":["Li Dawei","Wang Xiaolong","Kong Deguang"],"created":"2017-08-15","updated":"2018-01-10","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1708.04866","title":"Economic Factors of Vulnerability Trade and Exploitation","abstract":"Cybercrime markets support the development and diffusion of new attack\ntechnologies, vulnerability exploits, and malware. Whereas the revenue streams\nof cyber attackers have been studied multiple times in the literature, no\nquantitative account currently exists on the economics of attack acquisition\nand deployment. Yet, this understanding is critical to characterize the\nproduction of (traded) exploits, the economy that drives it, and its effects on\nthe overall attack scenario. In this paper we provide an empirical\ninvestigation of the economics of vulnerability exploitation, and the effects\nof market factors on likelihood of exploit. Our data is collected\nfirst-handedly from a prominent Russian cybercrime market where the trading of\nthe most active attack tools reported by the security industry happens. Our\nfindings reveal that exploits in the underground are priced similarly or above\nvulnerabilities in legitimate bug-hunting programs, and that the refresh cycle\nof exploits is slower than currently often assumed. On the other hand,\ncybercriminals are becoming faster at introducing selected vulnerabilities, and\nthe market is in clear expansion both in terms of players, traded exploits, and\nexploit pricing. We then evaluate the effects of these market variables on\nlikelihood of attack realization, and find strong evidence of the correlation\nbetween market activity and exploit deployment. We discuss implications on\nvulnerability metrics, economics, and exploit measurement.","primary_category":"cs","categories":["cs.CR"],"authors":["Allodi Luca"],"created":"2017-08-16","updated":"2018-01-03","doi":"10.1145\/3133956.3133960"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1708.04974","title":"A fast coset-translation algorithm for computing the cycle structure of\n  Comer relation algebras over $\\mathbb{Z}\/p\\mathbb{Z}$","abstract":"Proper relation algebras can be constructed using $\\mathbb{Z}\/p\\mathbb{Z}$ as\na base set using a method due to Comer. The cycle structure of such an algebra\nmust, in general, be determined \\emph{a posteriori}, normally with the aid of a\ncomputer. In this paper, we give an improved algorithm for checking the cycle\nstructure that reduces the time complexity from $\\mathcal{O}(p^2)$ to\n$\\mathcal{O}(p)$.","primary_category":"cs","categories":["math.CO","cs.DS"],"authors":["Alm Jeremy F.","Ylvisaker Andrew"],"created":"2017-08-14","updated":"2018-01-05","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1708.04987","title":"ANI-1: A data set of 20M off-equilibrium DFT calculations for organic\n  molecules","abstract":"One of the grand challenges in modern theoretical chemistry is designing and\nimplementing approximations that expedite ab initio methods without loss of\naccuracy. Machine learning (ML), in particular neural networks, are emerging as\na powerful approach to constructing various forms of transferable atomistic\npotentials. They have been successfully applied in a variety of applications in\nchemistry, biology, catalysis, and solid-state physics. However, these models\nare heavily dependent on the quality and quantity of data used in their\nfitting. Fitting highly flexible ML potentials comes at a cost: a vast amount\nof reference data is required to properly train these models. We address this\nneed by providing access to a large computational DFT database, which consists\nof 20M conformations for 57,454 small organic molecules. We believe it will\nbecome a new standard benchmark for comparison of current and future methods in\nthe ML potential community.","primary_category":"cs","categories":["physics.chem-ph","cs.LG","physics.data-an"],"authors":["Smith Justin S.","Isayev Olexandr","Roitberg Adrian E."],"created":"2017-08-16","updated":"2017-12-12","doi":"10.1038\/sdata.2017.193"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1708.05070","title":"Data-driven Advice for Applying Machine Learning to Bioinformatics\n  Problems","abstract":"As the bioinformatics field grows, it must keep pace not only with new data\nbut with new algorithms. Here we contribute a thorough analysis of 13\nstate-of-the-art, commonly used machine learning algorithms on a set of 165\npublicly available classification problems in order to provide data-driven\nalgorithm recommendations to current researchers. We present a number of\nstatistical and visual comparisons of algorithm performance and quantify the\neffect of model selection and algorithm tuning for each algorithm and dataset.\nThe analysis culminates in the recommendation of five algorithms with\nhyperparameters that maximize classifier performance across the tested\nproblems, as well as general guidelines for applying machine learning to\nsupervised classification problems.","primary_category":"cs","categories":["q-bio.QM","cs.LG","stat.ML"],"authors":["Olson Randal S.","La Cava William","Mustahsan Zairah","Varik Akshay","Moore Jason H."],"created":"2017-08-08","updated":"2018-01-07","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1708.05207","title":"Learning Universal Adversarial Perturbations with Generative Models","abstract":"Neural networks are known to be vulnerable to adversarial examples, inputs\nthat have been intentionally perturbed to remain visually similar to the source\ninput, but cause a misclassification. It was recently shown that given a\ndataset and classifier, there exists so called universal adversarial\nperturbations, a single perturbation that causes a misclassification when\napplied to any input. In this work, we introduce universal adversarial\nnetworks, a generative network that is capable of fooling a target classifier\nwhen it's generated output is added to a clean sample from a dataset. We show\nthat this technique improves on known universal adversarial attacks.","primary_category":"cs","categories":["cs.CR","cs.LG","stat.ML"],"authors":["Hayes Jamie","Danezis George"],"created":"2017-08-17","updated":"2018-01-05","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1708.05221","title":"Deep Neural Network with l2-norm Unit for Brain Lesions Detection","abstract":"Automated brain lesions detection is an important and very challenging\nclinical diagnostic task because the lesions have different sizes, shapes,\ncontrasts, and locations. Deep Learning recently has shown promising progress\nin many application fields, which motivates us to apply this technology for\nsuch important problem. In this paper, we propose a novel and end-to-end\ntrainable approach for brain lesions classification and detection by using deep\nConvolutional Neural Network (CNN). In order to investigate the applicability,\nwe applied our approach on several brain diseases including high and low-grade\nglioma tumor, ischemic stroke, Alzheimer diseases, by which the brain Magnetic\nResonance Images (MRI) have been applied as an input for the analysis. We\nproposed a new operating unit which receives features from several projections\nof a subset units of the bottom layer and computes a normalized l2-norm for\nnext layer. We evaluated the proposed approach on two different CNN\narchitectures and number of popular benchmark datasets. The experimental\nresults demonstrate the superior ability of the proposed approach.","primary_category":"cs","categories":["cs.CV"],"authors":["Rezaei Mina","Yang Haojin","Meinel Christoph"],"created":"2017-08-17","updated":" ","doi":"10.1007\/978-3-319-70093-9_85"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1708.05480","title":"The Linear Complexity of a Class of Binary Sequences With Optimal\n  Autocorrelation","abstract":"Binary sequences with optimal autocorrelation and large linear complexity\nhave important applications in cryptography and communications. Very recently,\na class of binary sequences of period $4p$ with optimal autocorrelation was\nproposed via interleaving four suitable Ding-Helleseth-Lam sequences (Des.\nCodes Cryptogr., DOI 10.1007\/s10623-017-0398-5), where $p$ is an odd prime with\n$p\\equiv 1(\\bmod~4)$. The objective of this paper is to determine the minimal\npolynomial and the linear complexity of this class of binary optimal sequences\nvia sequence polynomial approach. It turns out that this class of sequences has\nquite good linear complexity.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Fan Cuiling"],"created":"2017-08-17","updated":"2018-01-01","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1708.06012","title":"Product Matrix Minimum Storage Regenerating Codes with Flexible Number\n  of Helpers","abstract":"In coding for distributed storage systems, efficient data reconstruction and\nrepair through accessing a predefined number of arbitrarily chosen storage\nnodes is guaranteed by regenerating codes. Traditionally, code parameters,\nspecially the number of helper nodes participating in a repair process, are\npredetermined. However, depending on the state of the system and network\ntraffic, it is desirable to adapt such parameters accordingly in order to\nminimize the cost of repair. In this work a class of regenerating codes with\nminimum storage is introduced that can simultaneously operate at the optimal\nrepair bandwidth, for a wide range of exact repair mechanisms, based on\ndifferent number of helper nodes.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Mahdaviani Kaveh","Mohajer Soheil","Khisti Ashish"],"created":"2017-08-20","updated":"2017-12-28","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1708.06046","title":"nuts-flow\/ml: data pre-processing for deep learning","abstract":"Data preprocessing is a fundamental part of any machine learning application\nand frequently the most time-consuming aspect when developing a machine\nlearning solution. Preprocessing for deep learning is characterized by\npipelines that lazily load data and perform data transformation, augmentation,\nbatching and logging. Many of these functions are common across applications\nbut require different arrangements for training, testing or inference. Here we\nintroduce a novel software framework named nuts-flow\/ml that encapsulates\ncommon preprocessing operations as components, which can be flexibly arranged\nto rapidly construct efficient preprocessing pipelines for deep learning.","primary_category":"cs","categories":["cs.LG","cs.SE"],"authors":["Maetschke S.","Tennakoon R.","Vecchiola C.","Garnavi R."],"created":"2017-08-20","updated":"2018-01-09","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1708.06219","title":"On the approximation by single hidden layer feedforward neural networks\n  with fixed weights","abstract":"Feedforward neural networks have wide applicability in various disciplines of\nscience due to their universal approximation property. Some authors have shown\nthat single hidden layer feedforward neural networks (SLFNs) with fixed weights\nstill possess the universal approximation property provided that approximated\nfunctions are univariate. But this phenomenon does not lay any restrictions on\nthe number of neurons in the hidden layer. The more this number, the more the\nprobability of the considered network to give precise results. In this note, we\nconstructively prove that SLFNs with the fixed weight $1$ and two neurons in\nthe hidden layer can approximate any continuous function on a compact subset of\nthe real line. The applicability of this result is demonstrated in various\nnumerical examples. Finally, we show that SLFNs with fixed weights cannot\napproximate all continuous multivariate functions.","primary_category":"cs","categories":["cs.NE","cs.IT","math.IT","math.NA"],"authors":["Guliyev Namig J.","Ismailov Vugar E."],"created":"2017-08-21","updated":" ","doi":"10.1016\/j.neunet.2017.12.007"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1708.07476","title":"M2D: Monolog to Dialog Generation for Conversational Story Telling","abstract":"Storytelling serves many different social functions, e.g. stories are used to\npersuade, share troubles, establish shared values, learn social behaviors, and\nentertain. Moreover, stories are often told conversationally through dialog,\nand previous work suggests that information provided dialogically is more\nengaging than when provided in monolog. In this paper, we present algorithms\nfor converting a deep representation of a story into a dialogic storytelling,\nthat can vary aspects of the telling, including the personality of the\nstorytellers. We conduct several experiments to test whether dialogic\nstorytellings are more engaging, and whether automatically generated variants\nin linguistic form that correspond to personality differences can be recognized\nin an extended storytelling dialog.","primary_category":"cs","categories":["cs.CL"],"authors":["Bowden Kevin K.","Lin Grace I.","Reed Lena I.","Walker Marilyn A."],"created":"2017-08-24","updated":" ","doi":"10.1007\/978-3-319-48279-8_2"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1708.07739","title":"Relaxation dynamics of maximally clustered networks","abstract":"We study the relaxation dynamics of fully clustered networks (maximal number\nof triangles) to an unclustered state under two different edge dynamics---the\ndouble-edge swap, corresponding to degree-preserving randomization of the\nconfiguration model, and single edge replacement, corresponding to full\nrandomization of the Erd\\H{o}s--R\\'enyi random graph. We derive expressions for\nthe time evolution of the degree distribution, edge multiplicity distribution\nand clustering coefficient. We show that under both dynamics networks undergo a\ncontinuous phase transition in which a giant connected component is formed. We\ncalculate the position of the phase transition analytically using the\nErd\\H{o}s--R\\'enyi phenomenology.","primary_category":"cs","categories":["physics.soc-ph","cs.SI"],"authors":["Klaise Janis","Johnson Samuel"],"created":"2017-08-25","updated":" ","doi":"10.1103\/PhysRevE.97.012302"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1708.08000","title":"Mining the Demographics of Political Sentiment from Twitter Using\n  Learning from Label Proportions","abstract":"Opinion mining and demographic attribute inference have many applications in\nsocial science. In this paper, we propose models to infer daily joint\nprobabilities of multiple latent attributes from Twitter data, such as\npolitical sentiment and demographic attributes. Since it is costly and\ntime-consuming to annotate data for traditional supervised classification, we\ninstead propose scalable Learning from Label Proportions (LLP) models for\ndemographic and opinion inference using U.S. Census, national and state\npolitical polls, and Cook partisan voting index as population level data. In\nLLP classification settings, the training data is divided into a set of\nunlabeled bags, where only the label distribution in of each bag is known,\nremoving the requirement of instance-level annotations. Our proposed LLP model,\nWeighted Label Regularization (WLR), provides a scalable generalization of\nprior work on label regularization to support weights for samples inside bags,\nwhich is applicable in this setting where bags are arranged hierarchically\n(e.g., county-level bags are nested inside of state-level bags). We apply our\nmodel to Twitter data collected in the year leading up to the 2016 U.S.\npresidential election, producing estimates of the relationships among political\nsentiment and demographics over time and place. We find that our approach\nclosely tracks traditional polling data stratified by demographic category,\nresulting in error reductions of 28-44% over baseline approaches. We also\nprovide descriptive evaluations showing how the model may be used to estimate\ninteractions among many variables and to identify linguistic temporal\nvariation, capabilities which are typically not feasible using traditional\npolling methods.","primary_category":"cs","categories":["cs.SI"],"authors":["Ardehaly Ehsan Mohammady","Culotta Aron"],"created":"2017-08-26","updated":" ","doi":"10.1109\/ICDM.2017.84"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1708.08305","title":"Community detection using preference networks","abstract":"Community detection is the task of identifying clusters or groups of nodes in\na network where nodes within the same group are more connected with each other\nthan with nodes in different groups. It has practical uses in identifying\nsimilar functions or roles of nodes in many biological, social and computer\nnetworks. With the availability of very large networks in recent years,\nperformance and scalability of community detection algorithms become crucial,\ni.e. if time complexity of an algorithm is high, it can not run on large\nnetworks. In this paper, we propose a new community detection algorithm, which\nhas a local approach and is able to run on large networks. It has a simple and\neffective method; given a network, algorithm constructs a preference network of\nnodes where each node has a single outgoing edge showing its preferred node to\nbe in the same community with. In such a preference network, each connected\ncomponent is a community. Selection of the preferred node is performed using\nsimilarity based metrics of nodes. We use two alternatives for this purpose\nwhich can be calculated in 1-neighborhood of nodes, i.e. number of common\nneighbors of selector node and its neighbors and, the spread capability of\nneighbors around the selector node which is calculated by the gossip algorithm\nof Lind et.al. Our algorithm is tested on both computer generated LFR networks\nand real-life networks with ground-truth community structure. It can identify\ncommunities accurately in a fast way. It is local, scalable and suitable for\ndistributed execution on large networks.","primary_category":"cs","categories":["physics.soc-ph","cs.SI"],"authors":["Tasgin Mursel","Bingol Haluk O."],"created":"2017-08-28","updated":"2017-11-12","doi":"10.1016\/j.physa.2017.12.060"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1708.09740","title":"Sparse-then-Dense Alignment based 3D Map Reconstruction Method for\n  Endoscopic Capsule Robots","abstract":"Since the development of capsule endoscopcy technology, substantial progress\nwere made in converting passive capsule endoscopes to robotic active capsule\nendoscopes which can be controlled by the doctor. However, robotic capsule\nendoscopy still has some challenges. In particular, the use of such devices to\ngenerate a precise and globally consistent three-dimensional (3D) map of the\nentire inner organ remains an unsolved problem. Such global 3D maps of inner\norgans would help doctors to detect the location and size of diseased areas\nmore accurately, precisely, and intuitively, thus permitting more accurate and\nintuitive diagnoses. The proposed 3D reconstruction system is built in a\nmodular fashion including preprocessing, frame stitching, and shading-based 3D\nreconstruction modules. We propose an efficient scheme to automatically select\nthe key frames out of the huge quantity of raw endoscopic images. Together with\na bundle fusion approach that aligns all the selected key frames jointly in a\nglobally consistent way, a significant improvement of the mosaic and 3D map\naccuracy was reached. To the best of our knowledge, this framework is the first\ncomplete pipeline for an endoscopic capsule robot based 3D map reconstruction\ncontaining all of the necessary steps for a reliable and accurate endoscopic 3D\nmap. For the qualitative evaluations, a real pig stomach is employed. Moreover,\nfor the first time in literature, a detailed and comprehensive quantitative\nanalysis of each proposed pipeline modules is performed using a non-rigid\nesophagus gastro duodenoscopy simulator, four different endoscopic cameras, a\nmagnetically activated soft capsule robot (MASCE), a sub-millimeter precise\noptical motion tracker and a fine-scale 3D optical scanner.","primary_category":"cs","categories":["cs.CV"],"authors":["Turan Mehmet","Pilavci Yusuf Yigit","Ganiyusufoglu Ipek","Araujo Helder","Konukoglu Ender","Sitti Metin"],"created":"2017-08-29","updated":" ","doi":"10.1007\/s00138-017-0905-8"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1708.09746","title":"Faster Multiplication for Long Binary Polynomials","abstract":"We set new speed records for multiplying long polynomials over finite fields\nof characteristic two. Our multiplication algorithm is based on an additive FFT\n(Fast Fourier Transform) by Lin, Chung, and Huang in 2014 comparing to\npreviously best results based on multiplicative FFTs. Both methods have similar\ncomplexity for arithmetic operations on underlying finite field; however, our\nimplementation shows that the additive FFT has less overhead. For further\noptimization, we employ a tower field construction because the multipliers in\nthe additive FFT naturally fall into small subfields, which leads to speed-ups\nusing table-lookup instructions in modern CPUs. Benchmarks show that our method\nsaves about $40 \\%$ computing time when multiplying polynomials of $2^{28}$ and\n$2^{29}$ bits comparing to previous multiplicative FFT implementations.","primary_category":"cs","categories":["cs.SC","math.NT"],"authors":["Chen Ming-Shing","Cheng Chen-Mou","Kuo Po-Chun","Li Wen-Ding","Yang Bo-Yin"],"created":"2017-08-31","updated":"2018-01-05","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1708.09765","title":"Boundedness in languages of infinite words","abstract":"We define a new class of languages of $\\omega$-words, strictly extending\n$\\omega$-regular languages.\n  One way to present this new class is by a type of regular expressions. The\nnew expressions are an extension of $\\omega$-regular expressions where two new\nvariants of the Kleene star $L^*$ are added: $L^B$ and $L^S$. These new\nexponents are used to say that parts of the input word have bounded size, and\nthat parts of the input can have arbitrarily large sizes, respectively. For\ninstance, the expression $(a^Bb)^\\omega$ represents the language of infinite\nwords over the letters $a,b$ where there is a common bound on the number of\nconsecutive letters $a$. The expression $(a^Sb)^\\omega$ represents a similar\nlanguage, but this time the distance between consecutive $b$'s is required to\ntend toward the infinite.\n  We develop a theory for these languages, with a focus on decidability and\nclosure. We define an equivalent automaton model, extending B\\\"uchi automata.\nThe main technical result is a complementation lemma that works for languages\nwhere only one type of exponent---either $L^B$ or $L^S$---is used.\n  We use the closure and decidability results to obtain partial decidability\nresults for the logic MSOLB, a logic obtained by extending monadic second-order\nlogic with new quantifiers that speak about the size of sets.","primary_category":"cs","categories":["cs.LO","cs.FL"],"authors":["Boja\u0144czyk Miko\u0142aj","Colcombet Thomas"],"created":"2017-08-31","updated":"2017-10-25","doi":"10.23638\/LMCS-13(4:3)2017"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1709.01126","title":"From MPI to MPI+OpenACC: Conversion of a legacy FORTRAN PCG solver for\n  the spherical Laplace equation","abstract":"A real-world example of adding OpenACC to a legacy MPI FORTRAN Preconditioned\nConjugate Gradient code is described, and timing results for multi-node\nmulti-GPU runs are shown. The code is used to obtain three-dimensional\nspherical solutions to the Laplace equation. Its application is finding\npotential field solutions of the solar corona, a useful tool in space weather\nmodeling. We highlight key tips, strategies, and challenges faced when adding\nOpenACC. Performance results are shown for running the code with MPI-only on\nmultiple CPUs, and with MPI+OpenACC on multiple GPUs and CPUs.","primary_category":"cs","categories":["cs.MS"],"authors":["Caplan Ronald M.","Mikic Zoran","Linker Jon A."],"created":"2017-09-04","updated":"2017-12-29","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1709.01305","title":"Cross-Media Similarity Evaluation for Web Image Retrieval in the Wild","abstract":"In order to retrieve unlabeled images by textual queries, cross-media\nsimilarity computation is a key ingredient. Although novel methods are\ncontinuously introduced, little has been done to evaluate these methods\ntogether with large-scale query log analysis. Consequently, how far have these\nmethods brought us in answering real-user queries is unclear. Given baseline\nmethods that compute cross-media similarity using relatively simple text\/image\nmatching, how much progress have advanced models made is also unclear. This\npaper takes a pragmatic approach to answering the two questions. Queries are\nautomatically categorized according to the proposed query visualness measure,\nand later connected to the evaluation of multiple cross-media similarity models\non three test sets. Such a connection reveals that the success of the\nstate-of-the-art is mainly attributed to their good performance on\nvisual-oriented queries, while these queries account for only a small part of\nreal-user queries. To quantify the current progress, we propose a simple\ntext2image method, representing a novel test query by a set of images selected\nfrom large-scale query log. Consequently, computing cross-media similarity\nbetween the test query and a given image boils down to comparing the visual\nsimilarity between the given image and the selected images. Image retrieval\nexperiments on the challenging Clickture dataset show that the proposed\ntext2image compares favorably to recent deep learning based alternatives.","primary_category":"cs","categories":["cs.CV"],"authors":["Dong Jianfeng","Li Xirong","Xu Duanqing"],"created":"2017-09-05","updated":"2018-01-06","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1709.01424","title":"Towards social pattern characterization in egocentric photo-streams","abstract":"Following the increasingly popular trend of social interaction analysis in\negocentric vision, this manuscript presents a comprehensive study for automatic\nsocial pattern characterization of a wearable photo-camera user, by relying on\nthe visual analysis of egocentric photo-streams. The proposed framework\nconsists of three major steps. The first step is to detect social interactions\nof the user where the impact of several social signals on the task is explored.\nThe detected social events are inspected in the second step for categorization\ninto different social meetings. These two steps act at event-level where each\npotential social event is modeled as a multi-dimensional time-series, whose\ndimensions correspond to a set of relevant features for each task, and LSTM is\nemployed to classify the time-series. The last step of the framework is to\ncharacterize social patterns, which is essentially to infer the diversity and\nfrequency of the social relations of the user through discovery of recurrences\nof the same people across the whole set of social events of the user.\nExperimental evaluation over a dataset acquired by 9 users demonstrates\npromising results on the task of social pattern characterization from\negocentric photo-streams.","primary_category":"cs","categories":["cs.CV"],"authors":["Aghaei Maedeh","Dimiccoli Mariella","Ferrer Cristian Canton","Radeva Petia"],"created":"2017-09-05","updated":"2018-01-09","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1709.01491","title":"Balancing Information Exposure in Social Networks","abstract":"Social media has brought a revolution on how people are consuming news.\nBeyond the undoubtedly large number of advantages brought by social-media\nplatforms, a point of criticism has been the creation of echo chambers and\nfilter bubbles, caused by social homophily and algorithmic personalization.\n  In this paper we address the problem of balancing the information exposure in\na social network. We assume that two opposing campaigns (or viewpoints) are\npresent in the network, and that network nodes have different preferences\ntowards these campaigns. Our goal is to find two sets of nodes to employ in the\nrespective campaigns, so that the overall information exposure for the two\ncampaigns is balanced. We formally define the problem, characterize its\nhardness, develop approximation algorithms, and present experimental evaluation\nresults.\n  Our model is inspired by the literature on influence maximization, but we\noffer significant novelties. First, balance of information exposure is modeled\nby a symmetric difference function, which is neither monotone nor submodular,\nand thus, not amenable to existing approaches. Second, while previous papers\nconsider a setting with selfish agents and provide bounds on best response\nstrategies (i.e., move of the last player), we consider a setting with a\ncentralized agent and provide bounds for a global objective function.","primary_category":"cs","categories":["cs.SI","physics.soc-ph"],"authors":["Garimella Kiran","Gionis Aristides","Parotsidis Nikos","Tatti Nikolaj"],"created":"2017-09-05","updated":"2018-01-04","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1709.01586","title":"Robust Semi-Cooperative Multi-Agent Coordination in the Presence of\n  Stochastic Disturbances","abstract":"This paper presents a robust distributed coordination protocol that achieves\ngeneration of collision-free trajectories for multiple unicycle agents in the\npresence of stochastic uncertainties. We build upon our earlier work on\nsemi-cooperative coordination and we redesign the coordination controllers so\nthat the agents counteract a class of state (wind) disturbances and measurement\nnoise. Safety and convergence is proved analytically, while simulation results\ndemonstrate the efficacy of the proposed solution.","primary_category":"cs","categories":["cs.SY","cs.MA"],"authors":["Garg Kunal","Han Dongkun","Panagou Dimitra"],"created":"2017-09-05","updated":"2018-01-05","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1709.01600","title":"Covers of Query Results","abstract":"We introduce succinct lossless representations of query results called\ncovers. They are subsets of the query results that correspond to minimal edge\ncovers in the hypergraphs of these results.\n  We first study covers whose structures are given by fractional hypertree\ndecompositions of join queries. For any decomposition of a query, we give\nasymptotically tight size bounds for the covers of the query result over that\ndecomposition and show that such covers can be computed in worst-case optimal\ntime up to a logarithmic factor in the database size. For acyclic join queries,\nwe can compute covers compositionally using query plans with a new operator\ncalled cover-join. The tuples in the query result can be enumerated from any of\nits covers with linearithmic pre-computation time and constant delay.\n  We then generalize covers from joins to functional aggregate queries that\nexpress a host of computational problems such as aggregate-join queries,\nin-database optimization, matrix chain multiplication, and inference in\nprobabilistic graphical models.","primary_category":"cs","categories":["cs.DB"],"authors":["Kara Ahmet","Olteanu Dan"],"created":"2017-09-05","updated":"2018-01-10","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1709.01872","title":"Synthetic Medical Images from Dual Generative Adversarial Networks","abstract":"Currently there is strong interest in data-driven approaches to medical image\nclassification. However, medical imaging data is scarce, expensive, and fraught\nwith legal concerns regarding patient privacy. Typical consent forms only allow\nfor patient data to be used in medical journals or education, meaning the\nmajority of medical data is inaccessible for general public research. We\npropose a novel, two-stage pipeline for generating synthetic medical images\nfrom a pair of generative adversarial networks, tested in practice on retinal\nfundi images. We develop a hierarchical generation process to divide the\ncomplex image generation task into two parts: geometry and photorealism. We\nhope researchers will use our pipeline to bring private medical data into the\npublic domain, sparking growth in imaging tasks that have previously relied on\nthe hand-tuning of models. We have begun this initiative through the\ndevelopment of SynthMed, an online repository for synthetic medical images.","primary_category":"cs","categories":["cs.CV"],"authors":["Guibas John T.","Virdi Tejpal S.","Li Peter S."],"created":"2017-09-06","updated":"2018-01-08","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1709.02116","title":"Unreported links between trial registrations and published articles were\n  identified using document similarity measures in a cross-sectional analysis\n  of ClinicalTrials.gov","abstract":"Objectives: Trial registries can be used to measure reporting biases and\nsupport systematic reviews but 45% of registrations do not provide a link to\nthe article reporting on the trial. We evaluated the use of document similarity\nmethods to identify unreported links between ClinicalTrials.gov and PubMed.\nStudy Design and Setting: We extracted terms and concepts from a dataset of\n72,469 ClinicalTrials.gov registrations and 276,307 PubMed articles, and tested\nmethods for ranking articles across 16,005 reported links and 90\nmanually-identified unreported links. Performance was measured by the median\nrank of matching articles, and the proportion of unreported links that could be\nfound by screening ranked candidate articles in order. Results: The best\nperforming concept-based representation produced a median rank of 3 (IQR 1-21)\nfor reported links and 3 (IQR 1-19) for the manually-identified unreported\nlinks, and term-based representations produced a median rank of 2 (1-20) for\nreported links and 2 (IQR 1-12) in unreported links. The matching article was\nranked first for 40% of registrations, and screening 50 candidate articles per\nregistration identified 86% of the unreported links. Conclusions: Leveraging\nthe growth in the corpus of reported links between ClinicalTrials.gov and\nPubMed, we found that document similarity methods can assist in the\nidentification of unreported links between trial registrations and\ncorresponding articles.","primary_category":"cs","categories":["cs.IR"],"authors":["Dunn Adam G.","Coiera Enrico","Bourgeois Florence"],"created":"2017-09-07","updated":"2018-01-07","doi":"10.1016\/j.jclinepi.2017.12.007"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1709.03222","title":"Fully Optical Spacecraft Communications: Implementing an Omnidirectional\n  PV-Cell Receiver and 8Mb\/s LED Visible Light Downlink with Deep Learning\n  Error Correction","abstract":"Free space optical communication techniques have been the subject of numerous\ninvestigations in recent years, with multiple missions expected to fly in the\nnear future. Existing methods require high pointing accuracies, drastically\ndriving up overall system cost. Recent developments in LED-based visible light\ncommunication (VLC) and past in-orbit experiments have convinced us that the\ntechnology has reached a critical level of maturity. On these premises, we\npropose a new optical communication system utilizing a VLC downlink and a high\nthroughput, omnidirectional photovoltaic cell receiver system. By performing\nerror-correction via deep learning methods and by utilizing phase-delay\ninterference, the system is able to deliver data rates that match those of\ntraditional laser-based solutions. A prototype of the proposed system has been\nconstructed, demonstrating the scheme to be a feasible alternative to\nlaser-based methods. This creates an opportunity for the full scale development\nof optical communication techniques on small spacecraft as a backup telemetry\nbeacon or as a high throughput link.","primary_category":"cs","categories":["cs.NI"],"authors":["Huang Sihao","Lin Haowen"],"created":"2017-09-10","updated":"2018-01-02","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1709.04108","title":"Co-training for Demographic Classification Using Deep Learning from\n  Label Proportions","abstract":"Deep learning algorithms have recently produced state-of-the-art accuracy in\nmany classification tasks, but this success is typically dependent on access to\nmany annotated training examples. For domains without such data, an attractive\nalternative is to train models with light, or distant supervision. In this\npaper, we introduce a deep neural network for the Learning from Label\nProportion (LLP) setting, in which the training data consist of bags of\nunlabeled instances with associated label distributions for each bag. We\nintroduce a new regularization layer, Batch Averager, that can be appended to\nthe last layer of any deep neural network to convert it from supervised\nlearning to LLP. This layer can be implemented readily with existing deep\nlearning packages. To further support domains in which the data consist of two\nconditionally independent feature views (e.g. image and text), we propose a\nco-training algorithm that iteratively generates pseudo bags and refits the\ndeep LLP model to improve classification accuracy. We demonstrate our models on\ndemographic attribute classification (gender and race\/ethnicity), which has\nmany applications in social media analysis, public health, and marketing. We\nconduct experiments to predict demographics of Twitter users based on their\ntweets and profile image, without requiring any user-level annotations for\ntraining. We find that the deep LLP approach outperforms baselines for both\ntext and image features separately. Additionally, we find that co-training\nalgorithm improves image and text classification by 4% and 8% absolute F1,\nrespectively. Finally, an ensemble of text and image classifiers further\nimproves the absolute F1 measure by 4% on average.","primary_category":"cs","categories":["cs.CV","cs.LG","stat.ML"],"authors":["Ardehaly Ehsan Mohammady","Culotta Aron"],"created":"2017-09-12","updated":" ","doi":"10.1109\/ICDMW.2017.144"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1709.04555","title":"Predicting Organic Reaction Outcomes with Weisfeiler-Lehman Network","abstract":"The prediction of organic reaction outcomes is a fundamental problem in\ncomputational chemistry. Since a reaction may involve hundreds of atoms, fully\nexploring the space of possible transformations is intractable. The current\nsolution utilizes reaction templates to limit the space, but it suffers from\ncoverage and efficiency issues. In this paper, we propose a template-free\napproach to efficiently explore the space of product molecules by first\npinpointing the reaction center -- the set of nodes and edges where graph edits\noccur. Since only a small number of atoms contribute to reaction center, we can\ndirectly enumerate candidate products. The generated candidates are scored by a\nWeisfeiler-Lehman Difference Network that models high-order interactions\nbetween changes occurring at nodes across the molecule. Our framework\noutperforms the top-performing template-based approach with a 10\\% margin,\nwhile running orders of magnitude faster. Finally, we demonstrate that the\nmodel accuracy rivals the performance of domain experts.","primary_category":"cs","categories":["cs.LG","cs.AI","stat.ML"],"authors":["Jin Wengong","Coley Connor W.","Barzilay Regina","Jaakkola Tommi"],"created":"2017-09-13","updated":"2017-12-29","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1709.05675","title":"Organizing Multimedia Data in Video Surveillance Systems Based on Face\n  Verification with Convolutional Neural Networks","abstract":"In this paper we propose the two-stage approach of organizing information in\nvideo surveillance systems. At first, the faces are detected in each frame and\na video stream is split into sequences of frames with face region of one\nperson. Secondly, these sequences (tracks) that contain identical faces are\ngrouped using face verification algorithms and hierarchical agglomerative\nclustering. Gender and age are estimated for each cluster (person) in order to\nfacilitate the usage of the organized video collection. The particular\nattention is focused on the aggregation of features extracted from each frame\nwith the deep convolutional neural networks. The experimental results of the\nproposed approach using YTF and IJB-A datasets demonstrated that the most\naccurate and fast solution is achieved for matching of normalized average of\nfeature vectors of all frames in a track.","primary_category":"cs","categories":["cs.CV"],"authors":["Sokolova Anastasiia D.","Kharchevnikova Angelina S.","Savchenko Andrey V."],"created":"2017-09-17","updated":" ","doi":"10.1007\/978-3-319-73013-4_20"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1709.07212","title":"A First Derivative Potts Model for Segmentation and Denoising Using ILP","abstract":"Unsupervised image segmentation and denoising are two fundamental tasks in\nimage processing. Usually, graph based models such as multicut are used for\nsegmentation and variational models are employed for denoising. Our approach\naddresses both problems at the same time. We propose a novel ILP formulation of\nthe first derivative Potts model with the $\\ell_1$ data term, where binary\nvariables are introduced to deal with the $\\ell_0$ norm of the regularization\nterm. The ILP is then solved by a standard off-the-shelf MIP solver. Numerical\nexperiments are compared with the multicut problem.","primary_category":"cs","categories":["cs.CV"],"authors":["Shen Ruobing","Reinelt Gerhard","Canu St\u00e9phane"],"created":"2017-09-21","updated":"2018-01-10","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1709.07433","title":"Perturbative Black Box Variational Inference","abstract":"Black box variational inference (BBVI) with reparameterization gradients\ntriggered the exploration of divergence measures other than the\nKullback-Leibler (KL) divergence, such as alpha divergences. In this paper, we\nview BBVI with generalized divergences as a form of estimating the marginal\nlikelihood via biased importance sampling. The choice of divergence determines\na bias-variance trade-off between the tightness of a bound on the marginal\nlikelihood (low bias) and the variance of its gradient estimators. Drawing on\nvariational perturbation theory of statistical physics, we use these insights\nto construct a family of new variational bounds. Enumerated by an odd integer\norder $K$, this family captures the standard KL bound for $K=1$, and converges\nto the exact marginal likelihood as $K\\to\\infty$. Compared to\nalpha-divergences, our reparameterization gradients have a lower variance. We\nshow in experiments on Gaussian Processes and Variational Autoencoders that the\nnew bounds are more mass covering, and that the resulting posterior covariances\nare closer to the true posterior and lead to higher likelihoods on held-out\ndata.","primary_category":"cs","categories":["stat.ML","cs.LG"],"authors":["Bamler Robert","Zhang Cheng","Opper Manfred","Mandt Stephan"],"created":"2017-09-21","updated":"2018-01-06","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1709.07739","title":"Single-pixel imaging with Morlet wavelet correlated random patterns","abstract":"Single-pixel imaging is an indirect imaging technique which utilizes\nsimplified optical hardware and advanced computational methods. It offers novel\nsolutions for hyper-spectral imaging, polarimetric imaging, three-dimensional\nimaging, holographic imaging, optical encryption and imaging through scattering\nmedia. The main limitations for its use come from relatively high measurement\nand reconstruction times. In this paper we propose to reduce the required\nsignal acquisition time by using a novel sampling scheme based on a random\nselection of Morlet wavelets convolved with white noise. While such functions\nexhibit random properties, they are locally determined by Morlet wavelet\nparameters. The proposed method is equivalent to random sampling of the\nproperly selected part of the feature space, which maps the measured images\naccurately both in the spatial and spatial frequency domains. We compare both\nnumerically and experimentally the image quality obtained with our sampling\nprotocol against widely-used sampling with Walsh-Hadamard or noiselet\nfunctions. The results show considerable improvement over the former methods,\nenabling single-pixel imaging at low compression rates on the order of a few\npercent.","primary_category":"cs","categories":["eess.IV","cs.CV"],"authors":["Czajkowski Krzysztof M.","Pastuszczak Anna","Koty\u0144ski Rafa\u0142"],"created":"2017-09-22","updated":"2017-10-05","doi":"10.1038\/s41598-017-18968-6"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1709.07771","title":"On the Existence and Structure of Mixed Nash Equilibria for In-Band\n  Full-Duplex Wireless Networks","abstract":"This article offers the first characterisation of mixed Nash equilibria (MNE)\nfor a wireless system with full-duplex capable terminals that share a common\nchannel via Aloha-based contention. Focussing on a simple grid topology, we\nprove that mixed MNE exist only if proportionality, driven by the accuracy of\nself-interference cancellation, is granted between the cost undergone for full-\nand half-duplex operations. The analysis shows how a proper selection of such\ncosts allows MNE that are also optimal from a network viewpoint in terms of\naggregate throughput. The sensitivity of system performance to costs is tackled\nand discussed considering the price of anarchy.","primary_category":"cs","categories":["cs.NI","cs.GT"],"authors":["Munari Andrea","Douros Vaggelis G.","Mahonen Petri"],"created":"2017-09-22","updated":"2017-12-30","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1709.08056","title":"Novel Uses of Category Theory in Modeling OOP","abstract":"An outline and summary of four new potential applications of category theory\nto OOP research are presented. These include (1) the use of operads to model\nJava subtyping, (2) the use of Yoneda's lemma and representable functors in the\nmodeling of generic types in generic nominally-typed OOP, (3) using a\ncombination of category presentations and cartesian closed categories to model\nstructurally-typed OOP, and (4) the use of adjoint functors to model Java\nerasure.","primary_category":"cs","categories":["cs.PL","math.CT"],"authors":["AbdelGawad Moez A."],"created":"2017-09-23","updated":"2017-12-29","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1709.08441","title":"Uncertainty in Multi-Commodity Routing Networks: When does it help?","abstract":"We study the equilibrium behavior in a multi-commodity selfish routing game\nwith many types of uncertain users where each user over- or under-estimates\ntheir congestion costs by a multiplicative factor. Surprisingly, we find that\nuncertainties in different directions have qualitatively distinct impacts on\nequilibria. Namely, contrary to the usual notion that uncertainty increases\ninefficiencies, network congestion actually decreases when users over-estimate\ntheir costs. On the other hand, under-estimation of costs leads to increased\ncongestion. We apply these results to urban transportation networks, where\ndrivers have different estimates about the cost of congestion. In light of the\ndynamic pricing policies aimed at tackling congestion, our results indicate\nthat users' perception of these prices can significantly impact the policy's\nefficacy, and \"caution in the face of uncertainty\" leads to favorable network\nconditions.","primary_category":"cs","categories":["cs.GT"],"authors":["Sekar Shreyas","Zheng Liyuan","Ratliff Lillian J.","Zhang Baosen"],"created":"2017-09-25","updated":"2018-01-10","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1710.00888","title":"Sentiment Perception of Readers and Writers in Emoji use","abstract":"Previous research has traditionally analyzed emoji sentiment from the point\nof view of the reader of the content not the author. Here, we analyze emoji\nsentiment from the point of view of the author and present a emoji sentiment\nbenchmark that was built from an employee happiness dataset where emoji happen\nto be annotated with daily happiness of the author of the comment. The data\nspans over 3 years, and 4k employees of 56 companies based in Barcelona. We\ncompare sentiment of writers to readers. Results indicate that, there is an 82%\nagreement in how emoji sentiment is perceived by readers and writers. Finally,\nwe report that when authors use emoji they report higher levels of happiness.\nEmoji use was not found to be correlated with differences in author moodiness.","primary_category":"cs","categories":["cs.IR","cs.CL","cs.HC"],"authors":["Berengueres Jose","Castro Dani"],"created":"2017-10-02","updated":"2018-01-09","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1710.01701","title":"Robust Localization of an Arbitrary Distribution of Radioactive Sources\n  for Aerial Inspection","abstract":"Radiation source detection has seen various applications in the past decade,\nranging from the detection of dirty bombs in public places to scanning critical\nnuclear facilities for leakage or flaws, and in the autonomous inspection of\nnuclear sites. Despite the success in detecting single point sources or a small\nnumber of spatially separated point sources, most of the existing algorithms\nfail to localize sources in complex scenarios with a large number of point\nsources or non-trivial distributions & bulk sources. Even in simpler\nenvironments, most existing algorithms are not scalable to larger regions\nand\/or higher dimensional spaces. For effective autonomous inspection, we not\nonly need to estimate the positions of the sources, but also the number,\ndistribution, and intensities of each of them. In this paper, we present a\nnovel algorithm for the robust localization of an arbitrary distribution of\nradiation sources using multi-layer sequential Monte Carlo methods coupled with\nsuitable clustering algorithms. We achieve near-perfect accuracy, in terms of\nF1-scores (> 0.95), while allowing the algorithm to scale, both to large\nregions in space and to higher dimensional spaces (5 tested).","primary_category":"cs","categories":["cs.RO","stat.AP"],"authors":["Shah Dhruv","Scherer Sebastian"],"created":"2017-10-04","updated":"2018-01-08","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1710.01782","title":"On the Tree Conjecture for the Network Creation Game","abstract":"Selfish Network Creation focuses on modeling real world networks from a\ngame-theoretic point of view. One of the classic models by Fabrikant et al.\n[PODC'03] is the network creation game, where agents correspond to nodes in a\nnetwork which buy incident edges for the price of $\\alpha$ per edge to minimize\ntheir total distance to all other nodes. The model is well-studied but still\nhas intriguing open problems. The most famous conjectures state that the price\nof anarchy is constant for all $\\alpha$ and that for $\\alpha \\geq n$ all\nequilibrium networks are trees.\n  We introduce a novel technique for analyzing stable networks for high\nedge-price $\\alpha$ and employ it to improve on the best known bounds for both\nconjectures. In particular we show that for $\\alpha > 4n-13$ all equilibrium\nnetworks must be trees, which implies a constant price of anarchy for this\nrange of $\\alpha$. Moreover, we also improve the constant upper bound on the\nprice of anarchy for equilibrium trees.","primary_category":"cs","categories":["cs.GT","cs.DM","cs.SI"],"authors":["Bil\u00f2 Davide","Lenzner Pascal"],"created":"2017-10-04","updated":"2018-01-05","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1710.01895","title":"Eugene Garfield's Scholarly Impact: A Scientometric Review","abstract":"The concept of citation indexing has become deeply involved in many parts of\nresearch itself and the broad environment in which research plays an integral\nrole, ranging from research evaluation, numerous indicators, to an increasingly\nwider range of scientific disciplines. In this article, we pay tribute to\nEugene Garfield and present a scientometric review of the intellectual assets\nthat he brought to us. In addition, we explore the intellectual landscape that\nhas subsequently evolved in connection to many of his ideas. We illustrate what\nsystematic reviews of the scientific literature may reveal and what we may\nlearn from the rich information conveyed through citation-induced patterns. The\nstudy is conducted with CiteSpace, one of many science mapping tools based on\ndata from the Web of Science and Scopus. Without Garfield's inventions, none of\nthese would be possible.","primary_category":"cs","categories":["cs.DL","cs.SI"],"authors":["Chen Chaomei"],"created":"2017-10-05","updated":" ","doi":"10.1007\/s11192-017-2594-5"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1710.02369","title":"End-to-end DNN Based Speaker Recognition Inspired by i-vector and PLDA","abstract":"Recently several end-to-end speaker verification systems based on deep neural\nnetworks (DNNs) have been proposed. These systems have been proven to be\ncompetitive for text-dependent tasks as well as for text-independent tasks with\nshort utterances. However, for text-independent tasks with longer utterances,\nend-to-end systems are still outperformed by standard i-vector + PLDA systems.\nIn this work, we develop an end-to-end speaker verification system that is\ninitialized to mimic an i-vector + PLDA baseline. The system is then further\ntrained in an end-to-end manner but regularized so that it does not deviate too\nfar from the initial system. In this way we mitigate overfitting which normally\nlimits the performance of end-to-end systems. The proposed system outperforms\nthe i-vector + PLDA baseline on both long and short duration utterances.","primary_category":"cs","categories":["eess.AS","cs.SD"],"authors":["Rohdin Johan","Silnova Anna","Diez Mireia","Plchot Oldrich","Matejka Pavel","Burget Lukas"],"created":"2017-10-06","updated":"2018-01-08","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1710.03358","title":"Balanced power diagrams for redistricting","abstract":"We propose a method for redistricting, decomposing a geographical area into\nsubareas, called districts, so that the populations of the districts are as\nclose as possible and the districts are compact and contiguous. Each district\nis the intersection of a polygon with the geographical area. The polygons are\nconvex and the average number of sides per polygon is less than six. The\npolygons tend to be quite compact. With each polygon is associated a center.\nThe center is the centroid of the locations of the residents associated with\nthe polygon. The algorithm can be viewed as a heuristic for finding centers and\na balanced assignment of residents to centers so as to minimize the sum of\nsquared distances of residents to centers; hence the solution can be said to\nhave low dispersion.","primary_category":"cs","categories":["cs.DS"],"authors":["Cohen-Addad Vincent","Klein Philip N.","Young Neal E."],"created":"2017-10-09","updated":"2018-01-07","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1710.03959","title":"Deep learning in remote sensing: a review","abstract":"Standing at the paradigm shift towards data-intensive science, machine\nlearning techniques are becoming increasingly important. In particular, as a\nmajor breakthrough in the field, deep learning has proven as an extremely\npowerful tool in many fields. Shall we embrace deep learning as the key to all?\nOr, should we resist a 'black-box' solution? There are controversial opinions\nin the remote sensing community. In this article, we analyze the challenges of\nusing deep learning for remote sensing data analysis, review the recent\nadvances, and provide resources to make deep learning in remote sensing\nridiculously simple to start with. More importantly, we advocate remote sensing\nscientists to bring their expertise into deep learning, and use it as an\nimplicit general model to tackle unprecedented large-scale influential\nchallenges, such as climate change and urbanization.","primary_category":"cs","categories":["cs.CV","eess.IV"],"authors":["Zhu Xiao Xiang","Tuia Devis","Mou Lichao","Xia Gui-Song","Zhang Liangpei","Xu Feng","Fraundorfer Friedrich"],"created":"2017-10-11","updated":" ","doi":"10.1109\/MGRS.2017.2762307"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1710.04934","title":"RADNET: Radiologist Level Accuracy using Deep Learning for HEMORRHAGE\n  detection in CT Scans","abstract":"We describe a deep learning approach for automated brain hemorrhage detection\nfrom computed tomography (CT) scans. Our model emulates the procedure followed\nby radiologists to analyse a 3D CT scan in real-world. Similar to radiologists,\nthe model sifts through 2D cross-sectional slices while paying close attention\nto potential hemorrhagic regions. Further, the model utilizes 3D context from\nneighboring slices to improve predictions at each slice and subsequently,\naggregates the slice-level predictions to provide diagnosis at CT level. We\nrefer to our proposed approach as Recurrent Attention DenseNet (RADnet) as it\nemploys original DenseNet architecture along with adding the components of\nattention for slice level predictions and recurrent neural network layer for\nincorporating 3D context. The real-world performance of RADnet has been\nbenchmarked against independent analysis performed by three senior radiologists\nfor 77 brain CTs. RADnet demonstrates 81.82% hemorrhage prediction accuracy at\nCT level that is comparable to radiologists. Further, RADnet achieves higher\nrecall than two of the three radiologists, which is remarkable.","primary_category":"cs","categories":["cs.CV","stat.ML"],"authors":["Grewal Monika","Srivastava Muktabh Mayank","Kumar Pulkit","Varadarajan Srikrishna"],"created":"2017-10-13","updated":"2018-01-03","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1710.05006","title":"Skin Lesion Analysis Toward Melanoma Detection: A Challenge at the 2017\n  International Symposium on Biomedical Imaging (ISBI), Hosted by the\n  International Skin Imaging Collaboration (ISIC)","abstract":"This article describes the design, implementation, and results of the latest\ninstallment of the dermoscopic image analysis benchmark challenge. The goal is\nto support research and development of algorithms for automated diagnosis of\nmelanoma, the most lethal skin cancer. The challenge was divided into 3 tasks:\nlesion segmentation, feature detection, and disease classification.\nParticipation involved 593 registrations, 81 pre-submissions, 46 finalized\nsubmissions (including a 4-page manuscript), and approximately 50 attendees,\nmaking this the largest standardized and comparative study in this field to\ndate. While the official challenge duration and ranking of participants has\nconcluded, the dataset snapshots remain available for further research and\ndevelopment.","primary_category":"cs","categories":["cs.CV"],"authors":["Codella Noel C. F.","Gutman David","Celebi M. Emre","Helba Brian","Marchetti Michael A.","Dusza Stephen W.","Kalloo Aadi","Liopyris Konstantinos","Mishra Nabin","Kittler Harald","Halpern Allan"],"created":"2017-10-13","updated":"2018-01-08","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1710.05207","title":"Network Model Selection Using Task-Focused Minimum Description Length","abstract":"Networks are fundamental models for data used in practically every\napplication domain. In most instances, several implicit or explicit choices\nabout the network definition impact the translation of underlying data to a\nnetwork representation, and the subsequent question(s) about the underlying\nsystem being represented. Users of downstream network data may not even be\naware of these choices or their impacts. We propose a task-focused network\nmodel selection methodology which addresses several key challenges. Our\napproach constructs network models from underlying data and uses minimum\ndescription length (MDL) criteria for selection. Our methodology measures\nefficiency, a general and comparable measure of the network's performance of a\nlocal (i.e. node-level) predictive task of interest. Selection on efficiency\nfavors parsimonious (e.g. sparse) models to avoid overfitting and can be\napplied across arbitrary tasks and representations. We show stability,\nsensitivity, and significance testing in our methodology.","primary_category":"cs","categories":["cs.AI"],"authors":["Brugere Ivan","Berger-Wolf Tanya Y."],"created":"2017-10-14","updated":"2018-01-10","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1710.06285","title":"Preliminary steps toward a universal economic dynamics for monetary and\n  fiscal policy","abstract":"We consider the relationship between economic activity and intervention,\nincluding monetary and fiscal policy, using a universal dynamic framework.\nCentral bank policies are designed for growth without excess inflation.\nHowever, unemployment, investment, consumption, and inflation are interlinked.\nUnderstanding dynamics is crucial to assessing the effects of policy,\nespecially in the aftermath of the financial crisis. Here we lay out a program\nof research into monetary and economic dynamics and preliminary steps toward\nits execution. We use principles of response theory to derive implications for\npolicy. We find that the current approach, which considers the overall money\nsupply, is insufficient to regulate economic growth. While it can achieve some\ndegree of control, optimizing growth also requires a fiscal policy balancing\nmonetary injection between two dominant loop flows, the consumption and wages\nloop, and investment and returns loop. The balance arises from a composite of\ngovernment tax, entitlement, subsidy policies, corporate policies, as well as\nmonetary policy. We show empirically that a transition occurred in 1980 between\ntwo regimes--an oversupply to the consumption and wages loop, to an oversupply\nof the investment and returns loop. The imbalance is manifest in savings and\nborrowing by consumers and investors, and in inflation. The latter increased\nuntil 1980, and decreased subsequently, resulting in a zero rate largely\nunrelated to the financial crisis. Three recessions and the financial crisis\nare part of this dynamic. Optimizing growth now requires shifting the balance.\nOur analysis supports advocates of greater income and \/ or government support\nfor the poor who use a larger fraction of income for consumption. This promotes\ninvestment due to growth in demand. Otherwise, investment opportunities are\nlimited, capital remains uninvested, and does not contribute to growth.","primary_category":"cs","categories":["physics.soc-ph","cs.CY","nlin.AO","q-fin.EC","q-fin.GN"],"authors":["Bar-Yam Yaneer","Langlois-Meurinne Jean","Kawakatsu Mari","Garcia Rodolfo"],"created":"2017-10-17","updated":"2017-12-29","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1710.06513","title":"Learning Pose Grammar to Encode Human Body Configuration for 3D Pose\n  Estimation","abstract":"In this paper, we propose a pose grammar to tackle the problem of 3D human\npose estimation. Our model directly takes 2D pose as input and learns a\ngeneralized 2D-3D mapping function. The proposed model consists of a base\nnetwork which efficiently captures pose-aligned features and a hierarchy of\nBi-directional RNNs (BRNN) on the top to explicitly incorporate a set of\nknowledge regarding human body configuration (i.e., kinematics, symmetry, motor\ncoordination). The proposed model thus enforces high-level constraints over\nhuman poses. In learning, we develop a pose sample simulator to augment\ntraining samples in virtual camera views, which further improves our model\ngeneralizability. We validate our method on public 3D human pose benchmarks and\npropose a new evaluation protocol working on cross-view setting to verify the\ngeneralization capability of different methods. We empirically observe that\nmost state-of-the-art methods encounter difficulty under such setting while our\nmethod can well handle such challenges.","primary_category":"cs","categories":["cs.CV","cs.AI"],"authors":["Fang Haoshu","Xu Yuanlu","Wang Wenguan","Liu Xiaobai","Zhu Song-Chun"],"created":"2017-10-17","updated":"2018-01-04","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1710.06744","title":"An intensionally fully-abstract sheaf model for $\\pi$ (expanded version)","abstract":"Following previous work on CCS, we propose a compositional model for the\n$\\pi$-calculus in which processes are interpreted as sheaves on certain simple\nsites. Such sheaves are a concurrent form of innocent strategies, in the sense\nof Hyland-Ong\/Nickau game semantics. We define an analogue of fair testing\nequivalence in the model and show that our interpretation is intensionally\nfully abstract for it. That is, the interpretation preserves and reflects fair\ntesting equivalence; and furthermore, any innocent strategy is fair testing\nequivalent to the interpretation of some process. The central part of our work\nis the construction of our sites, relying on a combinatorial presentation of\n$\\pi$-calculus traces in the spirit of string diagrams.","primary_category":"cs","categories":["cs.LO","cs.PL"],"authors":["Eberhart Clovis","Hirschowitz Tom","Seiller Thomas"],"created":"2017-10-18","updated":"2017-11-14","doi":"10.23638\/LMCS-13(4:9)2017"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1710.07148","title":"A unified polynomial-time algorithm for Feedback Vertex Set on graphs of\n  bounded mim-width","abstract":"We give a first polynomial-time algorithm for (Weighted) Feedback Vertex Set\non graphs of bounded maximum induced matching width (mim-width). Explicitly,\ngiven a branch decomposition of mim-width $w$, we give an\n$n^{\\mathcal{O}(w)}$-time algorithm that solves Feedback Vertex Set. This\nprovides a unified algorithm for many well-known classes, such as Interval\ngraphs and Permutation graphs, and furthermore, it gives the first\npolynomial-time algorithms for other classes of bounded mim-width, such as\nCircular Permutation and Circular $k$-Trapezoid graphs for fixed $k$. In all\nthese classes the decomposition is computable in polynomial time, as shown by\nBelmonte and Vatshelle [Theor. Comput. Sci. 2013]. We show that powers of\ngraphs of tree-width $w - 1$ or path-width $w$ and powers of graphs of\nclique-width $w$ have mim-width at most $w$. These results extensively provide\nnew classes of bounded mim-width. We prove a slight strengthening of the first\nstatement which implies that, surprisingly, Leaf Power graphs which are of\nimportance in the field of phylogenetic studies have mim-width at most $1$.\nGiven a tree decomposition of width $w-1$, a path decomposition of width $w$,\nor a clique-width $w$-expression of a graph, one can for any value of $k$ find\na mim-width decomposition of its $k$-power in polynomial time, and apply our\nalgorithm to solve Feedback Vertex Set on the $k$-power in time\n$n^{\\mathcal{O}(w)}$. In contrast to Feedback Vertex Set, we show that\nHamiltonian Cycle is NP-complete even on graphs of linear mim-width $1$, which\nfurther hints at the expressive power of the mim-width parameter.","primary_category":"cs","categories":["cs.DS"],"authors":["Jaffke Lars","Kwon O-joung","Telle Jan Arne"],"created":"2017-10-19","updated":"2018-01-11","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1710.07782","title":"Image Disguise based on Generative Model","abstract":"To protect image contents, most existing encryption algorithms are designed\nto transform an original image into a texture-like or noise-like image, which\nis, however, an obvious visual sign indicating the presence of an encrypted\nimage, results in a significantly large number of attacks. To solve this\nproblem, in this paper, we propose a new image encryption method to generate a\nvisually same image as the original one by sending a meaning-normal and\nindependent image to a corresponding well-trained generative model to achieve\nthe effect of disguising the original image. This image disguise method not\nonly solves the problem of obvious visual implication, but also guarantees the\nsecurity of the information.","primary_category":"cs","categories":["cs.CV"],"authors":["Duan Xintao","Song Haoxian","Zhang En","Liu Jingjing"],"created":"2017-10-21","updated":"2018-01-02","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1710.07785","title":"Skew cyclic and skew $(\\alpha_1 + u\\alpha_2 + v\\alpha_3 +\n  uv\\alpha_4)$-constacyclic codes over $F_q + uF_q + vF_q + uvF_q$","abstract":"In this note, we study skew cyclic and skew constacyclic codes over the ring\n$\\mathcal{R}=F_{q}+uF_{q}+vF_{q}+uvF_{q}$ where $q=p^{m},$ $p$ is an odd prime,\n$u^{2}=u,~v^{2}=v,~uv=vu$. We show that Gray images of a skew cyclic and skew\n$\\alpha$-constacyclic code of length $n$ are skew quasi-cyclic code of length\n$4n$ over $F_{q}$ of index 4. Also, it is shown that skew $\\alpha$-constacyclic\ncodes are either equivalent to $\\alpha$-constacyclic codes or\n$\\alpha$-quasi-twisted codes over $\\mathcal{R}$. Further, structural\nproperties, specially, generating polynomials and idempotent generators for\nskew cyclic and skew constacyclic codes are determined by decomposition method.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Islam Habibul","Prakash Om"],"created":"2017-10-21","updated":"2018-01-08","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1710.08327","title":"A Scalable and Adaptive Method for Finding Semantically Equivalent Cue\n  Words of Uncertainty","abstract":"Scientific knowledge is constantly subject to a variety of changes due to new\ndiscoveries, alternative interpretations, and fresh perspectives. Understanding\nuncertainties associated with various stages of scientific inquiries is an\nintegral part of scientists' domain expertise and it serves as the core of\ntheir meta-knowledge of science. Despite the growing interest in areas such as\ncomputational linguistics, systematically characterizing and tracking the\nepistemic status of scientific claims and their evolution in scientific\ndisciplines remains a challenge. We present a unifying framework for the study\nof uncertainties explicitly and implicitly conveyed in scientific publications.\nThe framework aims to accommodate a wide range of uncertain types, from\nspeculations to inconsistencies and controversies. We introduce a scalable and\nadaptive method to recognize semantically equivalent cues of uncertainty across\ndifferent fields of research and accommodate individual analysts' unique\nperspectives. We demonstrate how the new method can be used to expand a small\nseed list of uncertainty cue words and how the validity of the expanded\ncandidate cue words are verified. We visualize the mixture of the original and\nexpanded uncertainty cue words to reveal the diversity of expressions of\nuncertainty. These cue words offer a novel resource for the study of\nuncertainty in scientific assertions.","primary_category":"cs","categories":["cs.DL"],"authors":["Chen Chaomei","Song Ming","Heo Go Eun"],"created":"2017-10-23","updated":" ","doi":"10.1016\/j.joi.2017.12.004"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1710.08331","title":"Combined Stochastic Optimization of Frequency Control and\n  Self-Consumption with a Battery","abstract":"Optimally combining frequency control with self-consumption can increase\nrevenues from battery storage systems installed behind-the-meter. This work\npresents an optimized control strategy that allows a battery to be used\nsimultaneously for self-consumption and primary frequency control. Therein, it\naddresses two stochastic problems: the delivery of primary frequency control\nwith a battery and the use of the battery for self-consumption. We propose a\nlinear recharging policy to regulate the state of charge of the battery while\nproviding primary frequency control. Formulating this as a chance-constrained\nproblem, we can ensure that the risk of battery constraint violations stays\nbelow a predefined probability. We use robust optimization as a safe\napproximation to the chance-constraints, which allows to make the risk of\nconstraint violation arbitrarily low, while keeping the problem tractable and\noffering maximum reserve capacity. Simulations with real frequency measurements\nprove the effectiveness of the designed recharging strategy. We adopt a\nrule-based policy for self-consumption, which is optimized using stochastic\nprogramming. This policy allows to reserve more energy and power of the battery\non moments when expected consumption or production is higher, while using other\nmoments for recharging from primary frequency control. We show that optimally\ncombining the two services increases value from batteries significantly.","primary_category":"cs","categories":["math.OC","cs.SY"],"authors":["Engels Jonas","Claessens Bert","Deconinck Geert"],"created":"2017-10-23","updated":" ","doi":"10.1109\/TSG.2017.2785040"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1710.08748","title":"Bottom-up automata on data trees and vertical XPath","abstract":"A data tree is a finite tree whose every node carries a label from a finite\nalphabet and a datum from some infinite domain. We introduce a new model of\nautomata over unranked data trees with a decidable emptiness problem. It is\nessentially a bottom-up alternating automaton with one register that can store\none data value and can be used to perform equality tests with the data values\noccurring within the subtree of the current node. We show that it captures the\nexpressive power of the vertical fragment of XPath - containing the child,\ndescendant, parent and ancestor axes - obtaining thus a decision procedure for\nits satisfiability problem.","primary_category":"cs","categories":["cs.DB"],"authors":["Figueira Diego","Segoufin Luc"],"created":"2017-10-24","updated":"2017-11-03","doi":"10.23638\/LMCS-13(4:5)2017"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1710.09052","title":"Deep Convolutional Neural Networks for Anomaly Event Classification on\n  Distributed Systems","abstract":"The increasing popularity of server usage has brought a plenty of anomaly log\nevents, which have threatened a vast collection of machines. Recognizing and\ncategorizing the anomalous events thereby is a much salient work for our\nsystems, especially the ones generate the massive amount of data and harness it\nfor technology value creation and business development. To assist in focusing\non the classification and the prediction of anomaly events, and gaining\ncritical insights from system event records, we propose a novel log\npreprocessing method which is very effective to filter abundant information and\nretain critical characteristics. Additionally, a competitive approach for\nautomated classification of anomalous events detected from the distributed\nsystem logs with the state-of-the-art deep (Convolutional Neural Network)\narchitectures is proposed in this paper. We measure a series of deep CNN\nalgorithms with varied hyper-parameter combinations by using standard\nevaluation metrics, the results of our study reveals the advantages and\npotential capabilities of the proposed deep CNN models for anomaly event\nclassification tasks on real-world systems. The optimal classification\nprecision of our approach is 98.14%, which surpasses the popular traditional\nmachine learning methods.","primary_category":"cs","categories":["cs.DC","cs.LG"],"authors":["Cheng Jiechao","Ren Rui","Wang Lei","Zhan Jianfeng"],"created":"2017-10-24","updated":"2017-12-29","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1710.09139","title":"Deep Transfer Learning for Error Decoding from Non-Invasive EEG","abstract":"We recorded high-density EEG in a flanker task experiment (31 subjects) and\nan online BCI control paradigm (4 subjects). On these datasets, we evaluated\nthe use of transfer learning for error decoding with deep convolutional neural\nnetworks (deep ConvNets). In comparison with a regularized linear discriminant\nanalysis (rLDA) classifier, ConvNets were significantly better in both intra-\nand inter-subject decoding, achieving an average accuracy of 84.1 % within\nsubject and 81.7 % on unknown subjects (flanker task). Neither method was,\nhowever, able to generalize reliably between paradigms. Visualization of\nfeatures the ConvNets learned from the data showed plausible patterns of brain\nactivity, revealing both similarities and differences between the different\nkinds of errors. Our findings indicate that deep learning techniques are useful\nto infer information about the correctness of action in BCI applications,\nparticularly for the transfer of pre-trained classifiers to new recording\nsessions or subjects.","primary_category":"cs","categories":["cs.LG","cs.HC","q-bio.NC"],"authors":["V\u00f6lker Martin","Schirrmeister Robin T.","Fiederer Lukas D. J.","Burgard Wolfram","Ball Tonio"],"created":"2017-10-25","updated":"2018-01-10","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1710.09363","title":"GeoSeq2Seq: Information Geometric Sequence-to-Sequence Networks","abstract":"The Fisher information metric is an important foundation of information\ngeometry, wherein it allows us to approximate the local geometry of a\nprobability distribution. Recurrent neural networks such as the\nSequence-to-Sequence (Seq2Seq) networks that have lately been used to yield\nstate-of-the-art performance on speech translation or image captioning have so\nfar ignored the geometry of the latent embedding, that they iteratively learn.\nWe propose the information geometric Seq2Seq (GeoSeq2Seq) network which\nabridges the gap between deep recurrent neural networks and information\ngeometry. Specifically, the latent embedding offered by a recurrent network is\nencoded as a Fisher kernel of a parametric Gaussian Mixture Model, a formalism\ncommon in computer vision. We utilise such a network to predict the shortest\nroutes between two nodes of a graph by learning the adjacency matrix using the\nGeoSeq2Seq formalism; our results show that for such a problem the\nprobabilistic representation of the latent embedding supersedes the\nnon-probabilistic embedding by 10-15\\%.","primary_category":"cs","categories":["stat.ML","cs.LG"],"authors":["Bay Alessandro","Sengupta Biswa"],"created":"2017-10-25","updated":"2018-01-05","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1710.09668","title":"PDE-Net: Learning PDEs from Data","abstract":"In this paper, we present an initial attempt to learn evolution PDEs from\ndata. Inspired by the latest development of neural network designs in deep\nlearning, we propose a new feed-forward deep network, called PDE-Net, to\nfulfill two objectives at the same time: to accurately predict dynamics of\ncomplex systems and to uncover the underlying hidden PDE models. The basic idea\nof the proposed PDE-Net is to learn differential operators by learning\nconvolution kernels (filters), and apply neural networks or other machine\nlearning methods to approximate the unknown nonlinear responses. Comparing with\nexisting approaches, which either assume the form of the nonlinear response is\nknown or fix certain finite difference approximations of differential\noperators, our approach has the most flexibility by learning both differential\noperators and the nonlinear responses. A special feature of the proposed\nPDE-Net is that all filters are properly constrained, which enables us to\neasily identify the governing PDE models while still maintaining the expressive\nand predictive power of the network. These constrains are carefully designed by\nfully exploiting the relation between the orders of differential operators and\nthe orders of sum rules of filters (an important concept originated from\nwavelet theory). We also discuss relations of the PDE-Net with some existing\nnetworks in computer vision such as Network-In-Network (NIN) and Residual\nNeural Network (ResNet). Numerical experiments show that the PDE-Net has the\npotential to uncover the hidden PDE of the observed dynamics, and predict the\ndynamical behavior for a relatively long time, even in a noisy environment.","primary_category":"cs","categories":["math.NA","cs.LG","cs.NE","stat.ML"],"authors":["Long Zichao","Lu Yiping","Ma Xianzhong","Dong Bin"],"created":"2017-10-26","updated":"2018-01-01","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1710.10036","title":"Generalization Tower Network: A Novel Deep Neural Network Architecture\n  for Multi-Task Learning","abstract":"Deep learning (DL) advances state-of-the-art reinforcement learning (RL), by\nincorporating deep neural networks in learning representations from the input\nto RL. However, the conventional deep neural network architecture is limited in\nlearning representations for multi-task RL (MT-RL), as multiple tasks can refer\nto different kinds of representations. In this paper, we thus propose a novel\ndeep neural network architecture, namely generalization tower network (GTN),\nwhich can achieve MT-RL within a single learned model. Specifically, the\narchitecture of GTN is composed of both horizontal and vertical streams. In our\nGTN architecture, horizontal streams are used to learn representation shared in\nsimilar tasks. In contrast, the vertical streams are introduced to be more\nsuitable for handling diverse tasks, which encodes hierarchical shared\nknowledge of these tasks. The effectiveness of the introduced vertical stream\nis validated by experimental results. Experimental results further verify that\nour GTN architecture is able to advance the state-of-the-art MT-RL, via being\ntested on 51 Atari games.","primary_category":"cs","categories":["cs.LG","stat.ML"],"authors":["Song Yuhang","Xu Main","Zhang Songyang","Huo Liangyu"],"created":"2017-10-27","updated":"2018-01-01","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1710.10280","title":"One-shot and few-shot learning of word embeddings","abstract":"Standard deep learning systems require thousands or millions of examples to\nlearn a concept, and cannot integrate new concepts easily. By contrast, humans\nhave an incredible ability to do one-shot or few-shot learning. For instance,\nfrom just hearing a word used in a sentence, humans can infer a great deal\nabout it, by leveraging what the syntax and semantics of the surrounding words\ntells us. Here, we draw inspiration from this to highlight a simple technique\nby which deep recurrent networks can similarly exploit their prior knowledge to\nlearn a useful representation for a new word from little data. This could make\nnatural language processing systems much more flexible, by allowing them to\nlearn continually from the new words they encounter.","primary_category":"cs","categories":["cs.CL","cs.LG","stat.ML"],"authors":["Lampinen Andrew K.","McClelland James L."],"created":"2017-10-27","updated":"2018-01-02","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1710.10460","title":"Toward predictive machine learning for active vision","abstract":"We develop a comprehensive description of the active inference framework, as\nproposed by Friston (2010), under a machine-learning compliant perspective.\nStemming from a biological inspiration and the auto-encoding principles, the\nsketch of a cognitive architecture is proposed that should provide ways to\nimplement estimation-oriented control policies. Computer simulations illustrate\nthe effectiveness of the approach through a foveated inspection of the input\ndata. The pros and cons of the control policy are analyzed in detail, showing\ninteresting promises in terms of processing compression. Though optimizing\nfuture posterior entropy over the actions set is shown enough to attain locally\noptimal action selection, offline calculation using class-specific saliency\nmaps is shown better for it saves processing costs through saccades pathways\npre-processing, with a negligible effect on the recognition\/compression rates.","primary_category":"cs","categories":["cs.NE","cs.CV"],"authors":["Dauc\u00e9 Emmanuel"],"created":"2017-10-28","updated":"2018-01-08","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1710.10585","title":"Path-Based Attention Neural Model for Fine-Grained Entity Typing","abstract":"Fine-grained entity typing aims to assign entity mentions in the free text\nwith types arranged in a hierarchical structure. Traditional distant\nsupervision based methods employ a structured data source as a weak supervision\nand do not need hand-labeled data, but they neglect the label noise in the\nautomatically labeled training corpus. Although recent studies use many\nfeatures to prune wrong data ahead of training, they suffer from error\npropagation and bring much complexity. In this paper, we propose an end-to-end\ntyping model, called the path-based attention neural model (PAN), to learn a\nnoise- robust performance by leveraging the hierarchical structure of types.\nExperiments demonstrate its effectiveness.","primary_category":"cs","categories":["cs.CL"],"authors":["Zhang Denghui","Cai Pengshan","Jia Yantao","Li Manling","Wang Yuanzhuo","Cheng Xueqi"],"created":"2017-10-29","updated":"2018-01-08","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1710.11176","title":"CrescendoNet: A Simple Deep Convolutional Neural Network with Ensemble\n  Behavior","abstract":"We introduce a new deep convolutional neural network, CrescendoNet, by\nstacking simple building blocks without residual connections. Each Crescendo\nblock contains independent convolution paths with increased depths. The numbers\nof convolution layers and parameters are only increased linearly in Crescendo\nblocks. In experiments, CrescendoNet with only 15 layers outperforms almost all\nnetworks without residual connections on benchmark datasets, CIFAR10, CIFAR100,\nand SVHN. Given sufficient amount of data as in SVHN dataset, CrescendoNet with\n15 layers and 4.1M parameters can match the performance of DenseNet-BC with 250\nlayers and 15.3M parameters. CrescendoNet provides a new way to construct high\nperformance deep convolutional neural networks without residual connections.\nMoreover, through investigating the behavior and performance of subnetworks in\nCrescendoNet, we note that the high performance of CrescendoNet may come from\nits implicit ensemble behavior, which differs from the FractalNet that is also\na deep convolutional neural network without residual connections. Furthermore,\nthe independence between paths in CrescendoNet allows us to introduce a new\npath-wise training procedure, which can reduce the memory needed for training.","primary_category":"cs","categories":["cs.LG","cs.CV","stat.ML"],"authors":["Zhang Xiang","Vishwamitra Nishant","Hu Hongxin","Luo Feng"],"created":"2017-10-30","updated":"2018-01-04","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1710.11383","title":"Flexible Prior Distributions for Deep Generative Models","abstract":"We consider the problem of training generative models with deep neural\nnetworks as generators, i.e. to map latent codes to data points. Whereas the\ndominant paradigm combines simple priors over codes with complex deterministic\nmodels, we argue that it might be advantageous to use more flexible code\ndistributions. We demonstrate how these distributions can be induced directly\nfrom the data. The benefits include: more powerful generative models, better\nmodeling of latent structure and explicit control of the degree of\ngeneralization.","primary_category":"cs","categories":["cs.LG","stat.ML"],"authors":["Kilcher Yannic","Lucchi Aurelien","Hofmann Thomas"],"created":"2017-10-31","updated":"2018-01-07","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1710.11550","title":"Proceedings of the Data For Good Exchange 2017","abstract":"These are the proceedings of the Data For Good Exchange 2017, which was held\nin New York, NY, on September 24th 2017.","primary_category":"cs","categories":["cs.CY"],"authors":["Meerkamp Philipp"],"created":"2017-10-31","updated":"2018-01-10","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1711.00103","title":"Scheduling Monotone Moldable Jobs in Linear Time","abstract":"A moldable job is a job that can be executed on an arbitrary number of\nprocessors, and whose processing time depends on the number of processors\nallotted to it. A moldable job is monotone if its work doesn't decrease for an\nincreasing number of allotted processors. We consider the problem of scheduling\nmonotone moldable jobs to minimize the makespan.\n  We argue that for certain compact input encodings a polynomial algorithm has\na running time polynomial in n and log(m), where n is the number of jobs and m\nis the number of machines. We describe how monotony of jobs can be used to\ncounteract the increased problem complexity that arises from compact encodings,\nand give tight bounds on the approximability of the problem with compact\nencoding: it is NP-hard to solve optimally, but admits a PTAS.\n  The main focus of this work are efficient approximation algorithms. We\ndescribe different techniques to exploit the monotony of the jobs for better\nrunning times, and present a (3\/2+{\\epsilon})-approximate algorithm whose\nrunning time is polynomial in log(m) and 1\/{\\epsilon}, and only linear in the\nnumber n of jobs.","primary_category":"cs","categories":["cs.DS"],"authors":["Jansen Klaus","Land Felix"],"created":"2017-10-31","updated":"2018-01-07","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1711.00355","title":"Detection for 5G-NOMA: An Online Adaptive Machine Learning Approach","abstract":"Non-orthogonal multiple access (NOMA) has emerged as a promising radio access\ntechnique for enabling the performance enhancements promised by the\nfifth-generation (5G) networks in terms of connectivity, low latency, and high\nspectrum efficiency. In the NOMA uplink, successive interference cancellation\n(SIC) based detection with device clustering has been suggested. In the case of\nmultiple receive antennas, SIC can be combined with the minimum mean-squared\nerror (MMSE) beamforming. However, there exists a tradeoff between the NOMA\ncluster size and the incurred SIC error. Larger clusters lead to larger errors\nbut they are desirable from the spectrum efficiency and connectivity point of\nview. We propose a novel online learning based detection for the NOMA uplink.\nIn particular, we design an online adaptive filter in the sum space of linear\nand Gaussian reproducing kernel Hilbert spaces (RKHSs). Such a sum space design\nis robust against variations of a dynamic wireless network that can deteriorate\nthe performance of a purely nonlinear adaptive filter. We demonstrate by\nsimulations that the proposed method outperforms the MMSE-SIC based detection\nfor large cluster sizes.","primary_category":"cs","categories":["cs.LG","cs.IT","math.IT"],"authors":["Awan Daniyal Amir","Cavalcante Renato L. G.","Yukawa Masahiro","Stanczak Slawomir"],"created":"2017-11-01","updated":"2018-01-11","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1711.00537","title":"Materials that make robots smart","abstract":"We posit that embodied artificial intelligence is not only a computational,\nbut also a materials problem. While the importance of material and structural\nproperties in the control loop are well understood, materials can take an\nactive role during control by tight integration of sensors, actuators,\ncomputation and communication. We envision such materials to abstract\nfunctionality, therefore making the construction of intelligent robots more\nstraightforward and robust. For example, robots could be made of bones that\nmeasure load, muscles that move, skin that provides the robot with information\nabout the kind and location of tactile sensations ranging from pressure, to\ntexture and damage, eyes that extract high-level information, and brain\nmaterial that provides computation in a scalable manner. Such materials will\nnot resemble any existing engineered materials, but rather the heterogeneous\ncomponents out of which their natural counterparts are made. We describe the\nstate-of-the-art in so-called \"robotic materials\", their opportunities for\nrevolutionizing applications ranging from manipulation to autonomous driving,\nand open challenges the robotics community needs to address in collaboration\nwith allies, such as wireless sensor network researchers and polymer\nscientists.","primary_category":"cs","categories":["cs.RO"],"authors":["Correll Nikolaus","Heckman Christoffer"],"created":"2017-11-01","updated":"2017-12-28","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1711.00571","title":"Efficient $\\widetilde{O}(n\/\\epsilon)$ Spectral Sketches for the\n  Laplacian and its Pseudoinverse","abstract":"In this paper we consider the problem of efficiently computing\n$\\epsilon$-sketches for the Laplacian and its pseudoinverse. Given a Laplacian\nand an error tolerance $\\epsilon$, we seek to construct a function $f$ such\nthat for any vector $x$ (chosen obliviously from $f$), with high probability\n$(1-\\epsilon) x^\\top A x \\leq f(x) \\leq (1 + \\epsilon) x^\\top A x$ where $A$ is\neither the Laplacian or its pseudoinverse. Our goal is to construct such a\nsketch $f$ efficiently and to store it in the least space possible.\n  We provide nearly-linear time algorithms that, when given a Laplacian matrix\n$\\mathcal{L} \\in \\mathbb{R}^{n \\times n}$ and an error tolerance $\\epsilon$,\nproduce $\\tilde{O}(n\/\\epsilon)$-size sketches of both $\\mathcal{L}$ and its\npseudoinverse. Our algorithms improve upon the previous best sketch size of\n$\\widetilde{O}(n \/ \\epsilon^{1.6})$ for sketching the Laplacian form by Andoni\net al (2015) and $O(n \/ \\epsilon^2)$ for sketching the Laplacian pseudoinverse\nby Batson, Spielman, and Srivastava (2008).\n  Furthermore we show how to compute all-pairs effective resistances from\n$\\widetilde{O}(n\/\\epsilon)$ size sketch in $\\widetilde{O}(n^2\/\\epsilon)$ time.\nThis improves upon the previous best running time of\n$\\widetilde{O}(n^2\/\\epsilon^2)$ by Spielman and Srivastava (2008).","primary_category":"cs","categories":["cs.DS","math.OC"],"authors":["Jambulapati Arun","Sidford Aaron"],"created":"2017-11-01","updated":"2018-01-07","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1711.00728","title":"Crossing Behaviour of Social Groups: Insights from Observations at\n  Non-signalized Intersection","abstract":"Environmental, demographical and psychological factors have a demonstrated\nimpact on risky crossing behaviour. In this work we focus on the potential\ninfluence of social factors on the considered phenomenon (i.e. group crossing\ndecision). We present the results of a video-recorded observation about the\ncrossing behaviour of singles and dyads at non-signalized intersections.\nResults showed that crossing behaviour is characterized by three distinct\nphases: (i) approaching, (ii) appraising (decision making) and (iii) crossing.\nDyads walk slower than single pedestrians in all phases. The crossing behaviour\nof dyads is characterized by the emergence of a leader who takes the decision\nto cross first, followed by the companion. However, there is no difference\nbetween the accepted safety gap of singles and dyads. Understanding factors\ninfluencing the crossing decision of social groups represents an important\nresult supporting the development of agent-based simulations of\npedestrian-vehicle interactions.","primary_category":"cs","categories":["cs.MA","physics.soc-ph"],"authors":["Gorrini Andrea","Crociani Luca","Vizzari Giuseppe","Bandini Stefania"],"created":"2017-10-31","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1711.01239","title":"Routing Networks: Adaptive Selection of Non-linear Functions for\n  Multi-Task Learning","abstract":"Multi-task learning (MTL) with neural networks leverages commonalities in\ntasks to improve performance, but often suffers from task interference which\nreduces the benefits of transfer. To address this issue we introduce the\nrouting network paradigm, a novel neural network and training algorithm. A\nrouting network is a kind of self-organizing neural network consisting of two\ncomponents: a router and a set of one or more function blocks. A function block\nmay be any neural network - for example a fully-connected or a convolutional\nlayer. Given an input the router makes a routing decision, choosing a function\nblock to apply and passing the output back to the router recursively,\nterminating when a fixed recursion depth is reached. In this way the routing\nnetwork dynamically composes different function blocks for each input. We\nemploy a collaborative multi-agent reinforcement learning (MARL) approach to\njointly train the router and function blocks. We evaluate our model against\ncross-stitch networks and shared-layer baselines on multi-task settings of the\nMNIST, mini-imagenet, and CIFAR-100 datasets. Our experiments demonstrate a\nsignificant improvement in accuracy, with sharper convergence. In addition,\nrouting networks have nearly constant per-task training cost while cross-stitch\nnetworks scale linearly with the number of tasks. On CIFAR-100 (20 tasks) we\nobtain cross-stitch performance levels with an 85% reduction in training time.","primary_category":"cs","categories":["cs.LG","cs.CV","cs.NE"],"authors":["Rosenbaum Clemens","Klinger Tim","Riemer Matthew"],"created":"2017-11-03","updated":"2017-12-31","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1711.01467","title":"Attentional Pooling for Action Recognition","abstract":"We introduce a simple yet surprisingly powerful model to incorporate\nattention in action recognition and human object interaction tasks. Our\nproposed attention module can be trained with or without extra supervision, and\ngives a sizable boost in accuracy while keeping the network size and\ncomputational cost nearly the same. It leads to significant improvements over\nstate of the art base architecture on three standard action recognition\nbenchmarks across still images and videos, and establishes new state of the art\non MPII dataset with 12.5% relative improvement. We also perform an extensive\nanalysis of our attention module both empirically and analytically. In terms of\nthe latter, we introduce a novel derivation of bottom-up and top-down attention\nas low-rank approximations of bilinear pooling methods (typically used for\nfine-grained classification). From this perspective, our attention formulation\nsuggests a novel characterization of action recognition as a fine-grained\nrecognition problem.","primary_category":"cs","categories":["cs.CV"],"authors":["Girdhar Rohit","Ramanan Deva"],"created":"2017-11-04","updated":"2017-12-29","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1711.01731","title":"A Survey on Dialogue Systems: Recent Advances and New Frontiers","abstract":"Dialogue systems have attracted more and more attention. Recent advances on\ndialogue systems are overwhelmingly contributed by deep learning techniques,\nwhich have been employed to enhance a wide range of big data applications such\nas computer vision, natural language processing, and recommender systems. For\ndialogue systems, deep learning can leverage a massive amount of data to learn\nmeaningful feature representations and response generation strategies, while\nrequiring a minimum amount of hand-crafting. In this article, we give an\noverview to these recent advances on dialogue systems from various perspectives\nand discuss some possible research directions. In particular, we generally\ndivide existing dialogue systems into task-oriented and non-task-oriented\nmodels, then detail how deep learning techniques help them with representative\nalgorithms and finally discuss some appealing research directions that can\nbring the dialogue system research into a new frontier.","primary_category":"cs","categories":["cs.CL"],"authors":["Chen Hongshen","Liu Xiaorui","Yin Dawei","Tang Jiliang"],"created":"2017-11-06","updated":"2018-01-11","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1711.02059","title":"Evaluation of research activities of universities of Ukraine and\n  Belarus: a set of bibliometric indicators and its implementation","abstract":"Monitoring bibliometric indicators of University rankings is considered as a\nsubject of a University library activity. In order to fulfill comparative\nassessment of research activities of the universities of Ukraine and Belarus\nthe authors introduced a set of bibliometric indicators. A comparative\nassessment of the research activities of corresponding universities was\nfulfilled; the data on the leading universities are presented. The sensitivity\nof the one of the indicators to rapid changes of the research activity of\nuniversities and the fact that the other one is normalized across the fields of\nscience condition advantage of the proposed set over the one that was used in\npractice of the corresponding national rankings.","primary_category":"cs","categories":["cs.DL"],"authors":["Lazarev Vladimir","Nazarovets Serhii","Skalaban Alexey"],"created":"2017-11-06","updated":" ","doi":"10.26660\/rrbsi.2017.13.3.75"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1711.02448","title":"Cortical microcircuits as gated-recurrent neural networks","abstract":"Cortical circuits exhibit intricate recurrent architectures that are\nremarkably similar across different brain areas. Such stereotyped structure\nsuggests the existence of common computational principles. However, such\nprinciples have remained largely elusive. Inspired by gated-memory networks,\nnamely long short-term memory networks (LSTMs), we introduce a recurrent neural\nnetwork in which information is gated through inhibitory cells that are\nsubtractive (subLSTM). We propose a natural mapping of subLSTMs onto known\ncanonical excitatory-inhibitory cortical microcircuits. Our empirical\nevaluation across sequential image classification and language modelling tasks\nshows that subLSTM units can achieve similar performance to LSTM units. These\nresults suggest that cortical circuits can be optimised to solve complex\ncontextual problems and proposes a novel view on their computational function.\nOverall our work provides a step towards unifying recurrent networks as used in\nmachine learning with their biological counterparts.","primary_category":"cs","categories":["q-bio.NC","cs.NE","stat.ML"],"authors":["Costa Rui Ponte","Assael Yannis M.","Shillingford Brendan","de Freitas Nando","Vogels Tim P."],"created":"2017-11-07","updated":"2018-01-03","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1711.02586","title":"5G Millimeter Wave Cellular System Capacity with Fully Digital\n  Beamforming","abstract":"Due to heavy reliance of millimeter-wave (mmWave) wireless systems on\ndirectional links, Beamforming (BF) with high-dimensional arrays is essential\nfor cellular systems in these frequencies. How to perform the array processing\nin a power efficient manner is a fundamental challenge. Analog and hybrid BF\nrequire fewer analog-to-digital converters (ADCs), but can only communicate in\na small number of directions at a time,limiting directional search, spatial\nmultiplexing and control signaling. Digital BF enables flexible spatial\nprocessing, but must be operated at a low quantization resolution to stay\nwithin reasonable power levels. This paper presents a simple additive white\nGaussian noise (AWGN) model to assess the effect of low resolution quantization\nof cellular system capacity. Simulations with this model reveal that at\nmoderate resolutions (3-4 bits per ADC), there is negligible loss in downlink\ncellular capacity from quantization. In essence, the low-resolution ADCs limit\nthe high SNR, where cellular systems typically do not operate. The findings\nsuggest that low-resolution fully digital BF architectures can be power\nefficient, offer greatly enhanced control plane functionality and comparable\ndata plane performance to analog BF.","primary_category":"cs","categories":["cs.IT","cs.NI","math.IT"],"authors":["Dutta Sourjya","Barati C. Nicolas","Dhananjay Aditya","Rangan Sundeep"],"created":"2017-11-04","updated":"2018-01-02","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1711.03213","title":"CyCADA: Cycle-Consistent Adversarial Domain Adaptation","abstract":"Domain adaptation is critical for success in new, unseen environments.\nAdversarial adaptation models applied in feature spaces discover domain\ninvariant representations, but are difficult to visualize and sometimes fail to\ncapture pixel-level and low-level domain shifts. Recent work has shown that\ngenerative adversarial networks combined with cycle-consistency constraints are\nsurprisingly effective at mapping images between domains, even without the use\nof aligned image pairs. We propose a novel discriminatively-trained\nCycle-Consistent Adversarial Domain Adaptation model. CyCADA adapts\nrepresentations at both the pixel-level and feature-level, enforces\ncycle-consistency while leveraging a task loss, and does not require aligned\npairs. Our model can be applied in a variety of visual recognition and\nprediction settings. We show new state-of-the-art results across multiple\nadaptation tasks, including digit classification and semantic segmentation of\nroad scenes demonstrating transfer from synthetic to real world domains.","primary_category":"cs","categories":["cs.CV"],"authors":["Hoffman Judy","Tzeng Eric","Park Taesung","Zhu Jun-Yan","Isola Phillip","Saenko Kate","Efros Alexei A.","Darrell Trevor"],"created":"2017-11-08","updated":"2017-12-29","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1711.03660","title":"TARCO: Two-Stage Auction for D2D Relay Aided Computation Resource\n  Allocation in Hetnet","abstract":"In heterogeneous cellular network, task scheduling for computation offloading\nis one of the biggest challenges. Most works focus on alleviating heavy burden\nof macro base stations by moving the computation tasks on macro-cell user\nequipment (MUE) to remote cloud or small-cell base stations. But the\nselfishness of network users is seldom considered. Motivated by the cloud edge\ncomputing, this paper provides incentive for task transfer from macro cell\nusers to small cell base stations. The proposed incentive scheme utilizes small\ncell user equipment to provide relay service. The problem of computation\noffloading is modelled as a two-stage auction, in which the remote MUEs with\ncommon social character can form a group and then buy the computation resource\nof small-cell base stations with the relay of small cell user equipment. A\ntwo-stage auction scheme named TARCO is contributed to maximize utilities for\nboth sellers and buyers in the network. The truthful, individual rationality\nand budget balance of the TARCO are also proved in this paper. In addition, two\nalgorithms are proposed to further refine TARCO on the social welfare of the\nnetwork. Extensive simulation results demonstrate that, TARCO is better than\nrandom algorithm by about 104.90% in terms of average utility of MUEs, while\nthe performance of TARCO is further improved up to 28.75% and 17.06% by the\nproposed two algorithms, respectively.","primary_category":"cs","categories":["cs.NI"],"authors":["Chen Long","Wu Jigang","Zhang Xinxiang"],"created":"2017-11-09","updated":" ","doi":"10.1109\/TSC.2018.2792024"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1711.03937","title":"Accelerated Method for Stochastic Composition Optimization with\n  Nonsmooth Regularization","abstract":"Stochastic composition optimization draws much attention recently and has\nbeen successful in many emerging applications of machine learning, statistical\nanalysis, and reinforcement learning. In this paper, we focus on the\ncomposition problem with nonsmooth regularization penalty. Previous works\neither have slow convergence rate or do not provide complete convergence\nanalysis for the general problem. In this paper, we tackle these two issues by\nproposing a new stochastic composition optimization method for composition\nproblem with nonsmooth regularization penalty. In our method, we apply variance\nreduction technique to accelerate the speed of convergence. To the best of our\nknowledge, our method admits the fastest convergence rate for stochastic\ncomposition optimization: for strongly convex composition problem, our\nalgorithm is proved to admit linear convergence; for general composition\nproblem, our algorithm significantly improves the state-of-the-art convergence\nrate from $O(T^{-1\/2})$ to $O((n_1+n_2)^{{2}\/{3}}T^{-1})$. Finally, we apply\nour proposed algorithm to portfolio management and policy evaluation in\nreinforcement learning. Experimental results verify our theoretical analysis.","primary_category":"cs","categories":["cs.LG","math.OC"],"authors":["Huo Zhouyuan","Gu Bin","Liu Ji","Huang Heng"],"created":"2017-11-10","updated":"2017-12-28","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1711.03985","title":"Applications of Deep Learning and Reinforcement Learning to Biological\n  Data","abstract":"Rapid advances of hardware-based technologies during the past decades have\nopened up new possibilities for Life scientists to gather multimodal data in\nvarious application domains (e.g., Omics, Bioimaging, Medical Imaging, and\n[Brain\/Body]-Machine Interfaces), thus generating novel opportunities for\ndevelopment of dedicated data intensive machine learning techniques. Overall,\nrecent research in Deep learning (DL), Reinforcement learning (RL), and their\ncombination (Deep RL) promise to revolutionize Artificial Intelligence. The\ngrowth in computational power accompanied by faster and increased data storage\nand declining computing costs have already allowed scientists in various fields\nto apply these techniques on datasets that were previously intractable for\ntheir size and complexity. This review article provides a comprehensive survey\non the application of DL, RL, and Deep RL techniques in mining Biological data.\nIn addition, we compare performances of DL techniques when applied to different\ndatasets across various application domains. Finally, we outline open issues in\nthis challenging research area and discuss future development perspectives.","primary_category":"cs","categories":["cs.LG","stat.ML"],"authors":["Mahmud Mufti","Kaiser M. Shamim","Hussain Amir","Vassanelli Stefano"],"created":"2017-11-10","updated":"2018-01-07","doi":"10.1109\/TNNLS.2018.2790388"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1711.04213","title":"Skyline Identification in Multi-Armed Bandits","abstract":"We introduce a variant of the classical PAC multi-armed bandit problem. There\nis an ordered set of $n$ arms $A[1],\\dots,A[n]$, each with some stochastic\nreward drawn from some unknown bounded distribution. The goal is to identify\nthe $skyline$ of the set $A$, consisting of all arms $A[i]$ such that $A[i]$\nhas larger expected reward than all lower-numbered arms $A[1],\\dots,A[i-1]$. We\ndefine a natural notion of an $\\varepsilon$-approximate skyline and prove\nmatching upper and lower bounds for identifying an $\\varepsilon$-skyline.\nSpecifically, we show that in order to identify an $\\varepsilon$-skyline from\namong $n$ arms with probability $1-\\delta$, $$\n\\Theta\\bigg(\\frac{n}{\\varepsilon^2} \\cdot \\min\\bigg\\{\n\\log\\bigg(\\frac{1}{\\varepsilon \\delta}\\bigg), \\log\\bigg(\\frac{n}{\\delta}\\bigg)\n\\bigg\\} \\bigg) $$ samples are necessary and sufficient. When $\\varepsilon \\gg\n1\/n$, our results improve over the naive algorithm, which draws enough samples\nto approximate the expected reward of every arm; the algorithm of (Auer et al.,\nAISTATS'16) for Pareto-optimal arm identification is likewise superseded. Our\nresults show that the sample complexity of the skyline problem lies strictly in\nbetween that of best arm identification (Even-Dar et al., COLT'02) and that of\napproximating the expected reward of every arm.","primary_category":"cs","categories":["cs.LG"],"authors":["Cheu Albert","Sundaram Ravi","Ullman Jonathan"],"created":"2017-11-11","updated":"2018-01-09","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1711.04235","title":"Bitcoin and quantum computing","abstract":"Bitcoin is a digital currency and payment system based on classical\ncryptographic technologies which works without a central administrator such as\nin traditional currencies. It has long been questioned what the impact of\nquantum computing would be on Bitcoin, and cryptocurrencies in general. Here,\nwe analyse three primary directions that quantum computers might have an impact\nin: mining, security, and forks. We find that in the near-term the impact of\nquantum computers appear to be rather small for all three directions. The\nimpact of quantum computers would require considerably larger number of qubits\nand breakthroughs in quantum algorithms to reverse existing hash functions.","primary_category":"cs","categories":["quant-ph","cs.CR"],"authors":["Tessler Louis","Byrnes Tim"],"created":"2017-11-11","updated":"2018-01-09","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1711.04474","title":"Persuasion with limited communication capacity","abstract":"We consider a Bayesian persuasion problem where the persuader and the\ndecision maker communicate through an imperfect channel which has a fixed and\nlimited number of messages and is subject to exogenous noise. Imperfect\ncommunication entails a loss of payoff for the persuader. We establish an upper\nbound on the payoffs the persuader can secure by communicating through the\nchannel. We also show that the bound is tight: if the persuasion problem\nconsists of a large number of independent copies of the same base problem, then\nthe persuader can achieve this bound arbitrarily closely by using strategies\nwhich tie all the problems together. We characterize this optimal payoff as a\nfunction of the information-theoretic capacity of the communication channel.","primary_category":"cs","categories":["cs.IT","math.IT","math.OC","math.PR"],"authors":["Treust Ma\u00ebl Le","Tomala Tristan"],"created":"2017-11-13","updated":"2018-01-09","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1711.05401","title":"Revisiting Simple Neural Networks for Learning Representations of\n  Knowledge Graphs","abstract":"We address the problem of learning vector representations for entities and\nrelations in Knowledge Graphs (KGs) for Knowledge Base Completion (KBC). This\nproblem has received significant attention in the past few years and multiple\nmethods have been proposed. Most of the existing methods in the literature use\na predefined characteristic scoring function for evaluating the correctness of\nKG triples. These scoring functions distinguish correct triples (high score)\nfrom incorrect ones (low score). However, their performance vary across\ndifferent datasets. In this work, we demonstrate that a simple neural network\nbased score function can consistently achieve near start-of-the-art performance\non multiple datasets. We also quantitatively demonstrate biases in standard\nbenchmark datasets, and highlight the need to perform evaluation spanning\nvarious datasets.","primary_category":"cs","categories":["cs.AI","cs.LG","stat.ML"],"authors":["Ravishankar Srinivas","Talukdar Partha Pratim"],"created":"2017-11-14","updated":"2018-01-08","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1711.05444","title":"Robust Real-Time Multi-View Eye Tracking","abstract":"Despite significant advances in improving the gaze tracking accuracy under\ncontrolled conditions, the tracking robustness under real-world conditions,\nsuch as large head pose and movements, use of eyeglasses, illumination and eye\ntype variations, remains a major challenge in eye tracking. In this paper, we\nrevisit this challenge and introduce a real-time multi-camera eye tracking\nframework to improve the tracking robustness. First, differently from previous\nwork, we design a multi-view tracking setup that allows for acquiring multiple\neye appearances simultaneously. Leveraging multi-view appearances enables to\nmore reliably detect gaze features under challenging conditions, particularly\nwhen they are obstructed in conventional single-view appearance due to large\nhead movements or eyewear effects. The features extracted on various\nappearances are then used for estimating multiple gaze outputs. Second, we\npropose to combine estimated gaze outputs through an adaptive fusion mechanism\nto compute user's overall point of regard. The proposed mechanism firstly\ndetermines the estimation reliability of each gaze output according to user's\nmomentary head pose and predicted gazing behavior, and then performs a\nreliability-based weighted fusion. We demonstrate the efficacy of our framework\nwith extensive simulations and user experiments on a collected dataset\nfeaturing 20 subjects. Our results show that in comparison with\nstate-of-the-art eye trackers, the proposed framework provides not only a\nsignificant enhancement in accuracy but also a notable robustness. Our\nprototype system runs at 30 frames-per-second (fps) and achieves 1 degree\naccuracy under challenging experimental scenarios, which makes it suitable for\napplications demanding high accuracy and robustness.","primary_category":"cs","categories":["cs.CV","cs.HC"],"authors":["Arar Nuri Murat","Thiran Jean-Philippe"],"created":"2017-11-15","updated":"2018-01-03","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1711.05497","title":"Statman's Hierarchy Theorem","abstract":"In the Simply Typed $\\lambda$-calculus Statman investigates the reducibility\nrelation $\\leq_{\\beta\\eta}$ between types: for $A,B \\in \\mathbb{T}^0$, types\nfreely generated using $\\rightarrow$ and a single ground type $0$, define $A\n\\leq_{\\beta\\eta} B$ if there exists a $\\lambda$-definable injection from the\nclosed terms of type $A$ into those of type $B$. Unexpectedly, the induced\npartial order is the (linear) well-ordering (of order type) $\\omega + 4$.\n  In the proof a finer relation $\\leq_{h}$ is used, where the above injection\nis required to be a B\\\"ohm transformation, and an (a posteriori) coarser\nrelation $\\leq_{h^+}$, requiring a finite family of B\\\"ohm transformations that\nis jointly injective.\n  We present this result in a self-contained, syntactic, constructive and\nsimplified manner. En route similar results for $\\leq_h$ (order type $\\omega +\n5$) and $\\leq_{h^+}$ (order type $8$) are obtained. Five of the equivalence\nclasses of $\\leq_{h^+}$ correspond to canonical term models of Statman, one to\nthe trivial term model collapsing all elements of the same type, and one does\nnot even form a model by the lack of closed terms of many types.","primary_category":"cs","categories":["cs.LO"],"authors":["Westerbaan Bram","Westerbaan Bas","Kuyper Rutger","Tankink Carst","Viehoff Remy","Barendregt Henk"],"created":"2017-11-15","updated":"2017-11-24","doi":"10.23638\/LMCS-13(4:19)2017"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1711.05839","title":"Exact and heuristic algorithms for Cograph Editing","abstract":"We present a dynamic programming algorithm for optimally solving the Cograph\nEditing problem on an $n$-vertex graph that runs in $O(3^n n)$ time and uses\n$O(2^n)$ space. In this problem, we are given a graph $G = (V, E)$ and the task\nis to find a smallest possible set $F \\subseteq V \\times V$ of vertex pairs\nsuch that $(V, E \\bigtriangleup F)$ is a cograph (or $P_4$-free graph), where\n$\\bigtriangleup$ represents the symmetric difference operator. We also describe\na technique for speeding up the performance of the algorithm in practice.\nAdditionally, we present a heuristic for solving the Cograph Editing problem\nwhich produces good results on small to medium datasets. In application it is\nmuch more important to find the ground truth, not some optimal solution. For\nthe first time, we evaluate whether the cograph property is strict enough to\nrecover the true graph from data to which noise has been added.","primary_category":"cs","categories":["cs.DS"],"authors":["White W. Timothy J.","Ludwig Marcus","B\u00f6cker Sebastian"],"created":"2017-11-15","updated":"2018-01-10","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1711.05912","title":"On Channel Reciprocity to Activate Uplink Channel Training for Downlink\n  Wireless Transmission in Tactile Internet Applications","abstract":"We determine, for the first time, the requirement on channel reciprocity to\nactivate uplink channel training, instead of downlink channel training, to\nachieve a higher data rate for the downlink transmission from a multi-antenna\nbase station to a single-antenna user. We first derive novel closed-form\nexpressions for the lower bounds on the data rates achieved by the two channel\ntraining strategies by considering the impact of finite blocklength. The\nperformance comparison result of these two strategies is determined by the\namount of channel reciprocity that is utilized in the uplink channel training.\nWe then derive an approximated expression for the minimum channel reciprocity\nthat enables the uplink channel training to outperform the downlink channel\ntraining. Through numerical results, we demonstrate that this minimum channel\nreciprocity decreases as the blocklength decreases or the number of transmit\nantennas increases, which shows the necessity and benefits of activating the\nuplink channel training for short-packet communications with multiple transmit\nantennas. This work provides pivotal and unprecedented guidelines on choosing\nchannel training strategies and channel reciprocity calibrations, offering\nvaluable insights into latency reduction in the Tactile Internet applications.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Li Chunhui","Yan Shihao","Yang Nan"],"created":"2017-11-15","updated":"2018-01-10","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1711.06535","title":"Community Detection in Dynamic Networks via Adaptive Label Propagation","abstract":"An adaptive label propagation algorithm (ALPA) is proposed to detect and\nmonitor communities in dynamic networks. Unlike the traditional methods by\nre-computing the whole community decomposition after each modification of the\nnetwork, ALPA takes into account the information of historical communities and\nupdates its solution according to the network modifications via a local label\npropagation process, which generally affects only a small portion of the\nnetwork. This makes it respond to network changes at low computational cost.\nThe effectiveness of ALPA has been tested on both synthetic and real-world\nnetworks, which shows that it can successfully identify and track dynamic\ncommunities. Moreover, ALPA could detect communities with high quality and\naccuracy compared to other methods. Therefore, being low-complexity and\nparameter-free, ALPA is a scalable and promising solution for some real-world\napplications of community detection in dynamic networks.","primary_category":"cs","categories":["physics.soc-ph","cs.SI"],"authors":["Han Jihui","Li Wei","Zhao Longfeng","Su Zhu","Zou Yijiang","Deng Weibing"],"created":"2017-11-17","updated":" ","doi":"10.1371\/journal.pone.0188655"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1711.06897","title":"Single-Shot Refinement Neural Network for Object Detection","abstract":"For object detection, the two-stage approach (e.g., Faster R-CNN) has been\nachieving the highest accuracy, whereas the one-stage approach (e.g., SSD) has\nthe advantage of high efficiency. To inherit the merits of both while\novercoming their disadvantages, in this paper, we propose a novel single-shot\nbased detector, called RefineDet, that achieves better accuracy than two-stage\nmethods and maintains comparable efficiency of one-stage methods. RefineDet\nconsists of two inter-connected modules, namely, the anchor refinement module\nand the object detection module. Specifically, the former aims to (1) filter\nout negative anchors to reduce search space for the classifier, and (2)\ncoarsely adjust the locations and sizes of anchors to provide better\ninitialization for the subsequent regressor. The latter module takes the\nrefined anchors as the input from the former to further improve the regression\nand predict multi-class label. Meanwhile, we design a transfer connection block\nto transfer the features in the anchor refinement module to predict locations,\nsizes and class labels of objects in the object detection module. The\nmulti-task loss function enables us to train the whole network in an end-to-end\nway. Extensive experiments on PASCAL VOC 2007, PASCAL VOC 2012, and MS COCO\ndemonstrate that RefineDet achieves state-of-the-art detection accuracy with\nhigh efficiency. Code is available at https:\/\/github.com\/sfzhang15\/RefineDet","primary_category":"cs","categories":["cs.CV"],"authors":["Zhang Shifeng","Wen Longyin","Bian Xiao","Lei Zhen","Li Stan Z."],"created":"2017-11-18","updated":"2018-01-03","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1711.07170","title":"Parameter Reference Loss for Unsupervised Domain Adaptation","abstract":"The success of deep learning in computer vision is mainly attributed to an\nabundance of data. However, collecting large-scale data is not always possible,\nespecially for the supervised labels. Unsupervised domain adaptation (UDA) aims\nto utilize labeled data from a source domain to learn a model that generalizes\nto a target domain of unlabeled data. A large amount of existing work uses\nSiamese network-based models, where two streams of neural networks process the\nsource and the target domain data respectively. Nevertheless, most of these\napproaches focus on minimizing the domain discrepancy, overlooking the\nimportance of preserving the discriminative ability for target domain features.\nAnother important problem in UDA research is how to evaluate the methods\nproperly. Common evaluation procedures require target domain labels for\nhyper-parameter tuning and model selection, contradicting the definition of the\nUDA task. Hence we propose a more reasonable evaluation principle that avoids\nthis contradiction by simply adopting the latest snapshot of a model for\nevaluation. This adds an extra requirement for UDA methods besides the main\nperformance criteria: the stability during training. We design a novel method\nthat connects the target domain stream to the source domain stream with a\nParameter Reference Loss (PRL) to solve these problems simultaneously.\nExperiments on various datasets show that the proposed PRL not only improves\nthe performance on the target domain, but also stabilizes the training\nprocedure. As a result, PRL based models do not need the contradictory model\nselection, and thus are more suitable for practical applications.","primary_category":"cs","categories":["cs.CV","cs.AI"],"authors":["Jin Jiren","Calland Richard G.","Miyato Takeru","Vogel Brian K.","Nakayama Hideki"],"created":"2017-11-20","updated":"2017-12-05","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1711.07324","title":"On DNA Codes using the Ring Z4 + wZ4","abstract":"In this work, we study the DNA codes from the ring R = Z4 + wZ4, where w^2 =\n2+2w with 16 elements. We establish a one to one correspondence between the\nelements of the ring R and all the DNA codewords of length 2 by defining a\ndistance-preserving Gau map phi. Using this map, we give several new classes of\nthe DNA codes which satisfies reverse and reverse complement constraints. Some\nof the constructed DNA codes are optimal.","primary_category":"cs","categories":["cs.IT","math.IT","math.RA"],"authors":["Limbachiya Dixita","Gopal Krishna","Rao Bansari","Gupta Manish K."],"created":"2017-11-20","updated":"2018-01-09","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1711.07617","title":"Dynamic Distributed Storage for Scaling Blockchains","abstract":"Blockchain uses the idea of storing transaction data in the form of a\ndistributed ledger wherein each node in the network stores a current copy of\nthe sequence of transactions in the form of a hash chain. This requirement of\nstoring the entire ledger incurs a high storage cost that grows undesirably\nlarge for high transaction rates and large networks. In this work we use the\nideas of secret key sharing, private key encryption, and distributed storage to\ndesign a coding scheme such that each node stores only a part of the entire\ntransaction thereby reducing the storage cost to a fraction of its original\ncost. When further using dynamic zone allocation, we show the coding scheme can\nalso improve the integrity of the transaction data in the network over current\nschemes. Further, block validation (bitcoin mining) consumes a significant\namount of energy as it is necessary to determine a hash value satisfying a\nspecific set of constraints; we show that using dynamic distributed storage\nreduces these energy costs.","primary_category":"cs","categories":["cs.IT","cs.CR","math.IT"],"authors":["Raman Ravi Kiran","Varshney Lav R."],"created":"2017-11-20","updated":"2018-01-07","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1711.07684","title":"A two-dimensional decomposition approach for matrix completion through\n  gossip","abstract":"Factoring a matrix into two low rank matrices is at the heart of many\nproblems. The problem of matrix completion especially uses it to decompose a\nsparse matrix into two non sparse, low rank matrices which can then be used to\npredict unknown entries of the original matrix. We present a scalable and\ndecentralized approach in which instead of learning two factors for the\noriginal input matrix, we decompose the original matrix into a grid blocks,\neach of whose factors can be individually learned just by communicating\n(gossiping) with neighboring blocks. This eliminates any need for a central\nserver. We show that our algorithm performs well on both synthetic and real\ndatasets.","primary_category":"cs","categories":["cs.LG"],"authors":["Bhutani Mukul","Mishra Bamdev"],"created":"2017-11-21","updated":"2018-01-11","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1711.07970","title":"Deep Learning for Physical Processes: Incorporating Prior Scientific\n  Knowledge","abstract":"We consider the use of Deep Learning methods for modeling complex phenomena\nlike those occurring in natural physical processes. With the large amount of\ndata gathered on these phenomena the data intensive paradigm could begin to\nchallenge more traditional approaches elaborated over the years in fields like\nmaths or physics. However, despite considerable successes in a variety of\napplication domains, the machine learning field is not yet ready to handle the\nlevel of complexity required by such problems. Using an example application,\nnamely Sea Surface Temperature Prediction, we show how general background\nknowledge gained from physics could be used as a guideline for designing\nefficient Deep Learning models. In order to motivate the approach and to assess\nits generality we demonstrate a formal link between the solution of a class of\ndifferential equations underlying a large family of physical phenomena and the\nproposed model. Experiments and comparison with series of baselines including a\nstate of the art numerical approach is then provided.","primary_category":"cs","categories":["cs.AI","cs.LG","stat.ML"],"authors":["de Bezenac Emmanuel","Pajot Arthur","Gallinari Patrick"],"created":"2017-11-21","updated":"2018-01-09","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1711.08238","title":"Multi-Level Recurrent Residual Networks for Action Recognition","abstract":"Most existing Convolutional Neural Networks(CNNs) used for action recognition\nare either difficult to optimize or underuse crucial temporal information.\nInspired by the fact that the recurrent model consistently makes breakthroughs\nin the task related to sequence, we propose a novel Multi-Level Recurrent\nResidual Networks(MRRN) which incorporates three recognition streams. Each\nstream consists of a Residual Networks(ResNets) and a recurrent model. The\nproposed model captures spatiotemporal information by employing both\nalternative ResNets to learn spatial representations from static frames and\nstacked Simple Recurrent Units(SRUs) to model temporal dynamics. Three\ndistinct-level streams learned low-, mid-, high-level representations\nindependently are fused by computing a weighted average of their softmax scores\nto obtain the complementary representations of the video. Unlike previous\nmodels which boost performance at the cost of time complexity and space\ncomplexity, our models have a lower complexity by employing shortcut connection\nand are trained end-to-end with greater efficiency. MRRN displays significant\nperformance improvements compared to CNN-RNN framework baselines and obtains\ncomparable performance with the state-of-the-art, achieving 51.3% on HMDB-51\ndataset and 81.9% on UCF-101 dataset although no additional data.","primary_category":"cs","categories":["cs.CV"],"authors":["Zheng Zhenxing","An Gaoyun","Ruan Qiuqi"],"created":"2017-11-22","updated":"2018-01-03","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1711.09149","title":"Most Complex Deterministic Union-Free Regular Languages","abstract":"A regular language $L$ is union-free if it can be represented by a regular\nexpression without the union operation. A union-free language is deterministic\nif it can be accepted by a deterministic one-cycle-free-path finite automaton;\nthis is an automaton which has one final state and exactly one cycle-free path\nfrom any state to the final state. Jir\\'askov\\'a and Masopust proved that the\nstate complexities of the basic operations reversal, star, product, and boolean\noperations in deterministic union-free languages are exactly the same as those\nin the class of all regular languages. To prove that the bounds are met they\nused five types of automata, involving eight types of transformations of the\nset of states of the automata. We show that for each $n\\ge 3$ there exists one\nternary witness of state complexity $n$ that meets the bound for reversal and\nproduct. Moreover, the restrictions of this witness to binary alphabets meet\nthe bounds for star and boolean operations. We also show that the tight upper\nbounds on the state complexity of binary operations that take arguments over\ndifferent alphabets are the same as those for arbitrary regular languages.\nFurthermore, we prove that the maximal syntactic semigroup of a union-free\nlanguage has $n^n$ elements, as in the case of regular languages, and that the\nmaximal state complexities of atoms of union-free languages are the same as\nthose for regular languages. Finally, we prove that there exists a most complex\nunion-free language that meets the bounds for all these complexity measures.\nAltogether this proves that the complexity measures above cannot distinguish\nunion-free languages from regular languages.","primary_category":"cs","categories":["cs.FL"],"authors":["Brzozowski Janusz A.","Davies Sylvie"],"created":"2017-11-24","updated":"2018-01-02","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1711.09349","title":"Beyond Part Models: Person Retrieval with Refined Part Pooling (and a\n  Strong Convolutional Baseline)","abstract":"Employing part-level features for pedestrian image description offers\nfine-grained information and has been verified as beneficial for person\nretrieval in very recent literature. A prerequisite of part discovery is that\neach part should be well located. Instead of using external cues, e.g., pose\nestimation, to directly locate parts, this paper lays emphasis on the content\nconsistency within each part.\n  Specifically, we target at learning discriminative part-informed features for\nperson retrieval and make two contributions. (i) A network named Part-based\nConvolutional Baseline (PCB). Given an image input, it outputs a convolutional\ndescriptor consisting of several part-level features. With a uniform partition\nstrategy, PCB achieves competitive results with the state-of-the-art methods,\nproving itself as a strong convolutional baseline for person retrieval.\n  (ii) A refined part pooling (RPP) method. Uniform partition inevitably incurs\noutliers in each part, which are in fact more similar to other parts. RPP\nre-assigns these outliers to the parts they are closest to, resulting in\nrefined parts with enhanced within-part consistency. Experiment confirms that\nRPP allows PCB to gain another round of performance boost. For instance, on the\nMarket-1501 dataset, we achieve (77.4+4.2)% mAP and (92.3+1.5)% rank-1\naccuracy, surpassing the state of the art by a large margin.","primary_category":"cs","categories":["cs.CV"],"authors":["Sun Yifan","Zheng Liang","Yang Yi","Tian Qi","Wang Shengjin"],"created":"2017-11-26","updated":"2018-01-09","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1711.09490","title":"Simulating outcomes of interventions using a multipurpose simulation\n  program based on the Evolutionary Causal Matrices and Markov Chain","abstract":"Predicting long-term outcomes of interventions is necessary for educational\nand social policy-making processes that might widely influence our society for\nthe long-term. However, performing such predictions based on data from\nlarge-scale experiments might be challenging due to the lack of time and\nresources. In order to address this issue, computer simulations based on\nEvolutionary Causal Matrices and Markov Chain can be used to predict long-term\noutcomes with relatively small-scale lab data. In this paper, we introduce\nPython classes implementing a computer simulation model and presented some\npilots implementations demonstrating how the model can be utilized for\npredicting outcomes of diverse interventions. We also introduce the\nclass-structured simulation module both with real experimental data and with\nhypothetical data formulated based on social psychological theories. Classes\ndeveloped and tested in the present study provide researchers and practitioners\nwith a feasible and practical method to simulate intervention outcomes\nprospectively.","primary_category":"cs","categories":["stat.AP","cs.CE","cs.CY","cs.SI"],"authors":["Han Hyemin","Lee Kangwook","Soylu Firat"],"created":"2017-11-26","updated":" ","doi":"10.1007\/s10115-017-1151-0"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1711.09494","title":"Skip-Sliding Window Codes","abstract":"Constrained coding is used widely in digital communication and storage\nsystems. In this paper, we study a generalized sliding window constraint called\nthe skip-sliding window. A skip-sliding window (SSW) code is defined in terms\nof the length $L$ of a sliding window, skip length $J$, and cost constraint $E$\nin each sliding window. Each valid codeword of length $L + kJ$ is determined by\n$k+1$ windows of length $L$ where window $i$ starts at $(iJ + 1)$th symbol for\nall non-negative integers $i$ such that $i \\leq k$; and the cost constraint $E$\nin each window must be satisfied. In this work, two methods are given to\nenumerate the size of SSW codes and further refinements are made to reduce the\nenumeration complexity. Using the proposed enumeration methods, the noiseless\ncapacity of binary SSW codes is determined and observations such as greater\ncapacity than other classes of codes are made. Moreover, some noisy capacity\nbounds are given. SSW coding constraints arise in various applications\nincluding simultaneous energy and information transfer.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Wu Ting-Yi","Tandon Anshoo","Varshney Lav R.","Motani Mehul"],"created":"2017-11-26","updated":"2018-01-10","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1711.10122","title":"End-to-end Adversarial Learning for Generative Conversational Agents","abstract":"This paper presents a new adversarial learning method for generative\nconversational agents (GCA) besides a new model of GCA. Similar to previous\nworks on adversarial learning for dialogue generation, our method assumes the\nGCA as a generator that aims at fooling a discriminator that labels dialogues\nas human-generated or machine-generated; however, in our approach, the\ndiscriminator performs token-level classification, i.e. it indicates whether\nthe current token was generated by humans or machines. To do so, the\ndiscriminator also receives the context utterances (the dialogue history) and\nthe incomplete answer up to the current token as input. This new approach makes\npossible the end-to-end training by backpropagation. A self-conversation\nprocess enables to produce a set of generated data with more diversity for the\nadversarial training. This approach improves the performance on questions not\nrelated to the training data. Experimental results with human and adversarial\nevaluations show that the adversarial method yields significant performance\ngains over the usual teacher forcing training.","primary_category":"cs","categories":["cs.CL"],"authors":["Ludwig Oswaldo"],"created":"2017-11-27","updated":"2018-01-08","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1711.10171","title":"Intelligent Notification Systems: A Survey of the State of the Art and\n  Research Challenges","abstract":"Notifications provide a unique mechanism for increasing the effectiveness of\nreal-time information delivery systems. However, notifications that demand\nusers' attention at inopportune moments are more likely to have adverse effects\nand might become a cause of potential disruption rather than proving beneficial\nto users. In order to address these challenges a variety of intelligent\nnotification mechanisms based on monitoring and learning users' behavior have\nbeen proposed. The goal of such mechanisms is maximizing users' receptivity to\nthe delivered information by automatically inferring the right time and the\nright context for sending a certain type of information.\n  This article provides an overview of the current state of the art in the area\nof intelligent notification mechanisms that relies on the awareness of users'\ncontext and preferences. More specifically, we first present a survey of\nstudies focusing on understanding and modeling users' interruptibility and\nreceptivity to notifications from desktops and mobile devices. Then, we discuss\nthe existing challenges and opportunities in developing mechanisms for\nintelligent notification systems in a variety of application scenarios.","primary_category":"cs","categories":["cs.HC"],"authors":["Mehrotra Abhinav","Musolesi Mirco"],"created":"2017-11-28","updated":"2018-01-02","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1711.10267","title":"Differential Generative Adversarial Networks: Synthesizing Non-linear\n  Facial Variations with Limited Number of Training Data","abstract":"In face-related applications with a public available dataset, synthesizing\nnon-linear facial variations (e.g., facial expression, head-pose, illumination,\netc.) through a generative model is helpful in addressing the lack of training\ndata. In reality, however, there is insufficient data to even train the\ngenerative model for face synthesis. In this paper, we propose Differential\nGenerative Adversarial Networks (D-GAN) that can perform photo-realistic face\nsynthesis even when training data is small. Two discriminators are devised to\nensure the generator to approximate a face manifold, which can express face\nchanges as it wants. Experimental results demonstrate that the proposed method\nis robust to the amount of training data and synthesized images are useful to\nimprove the performance of a face expression classifier.","primary_category":"cs","categories":["cs.CV"],"authors":["Gu Geonmo","Kim Seong Tae","Kim Kihyun","Baddar Wissam J.","Ro Yong Man"],"created":"2017-11-28","updated":"2017-12-28","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1711.11032","title":"A Fowler-Nordheim Integrator can Track the Density of Prime Numbers","abstract":"\"Does there exist a naturally occurring counting device that might elucidate\nthe hidden structure of prime numbers ?\" is a question that has fascinated\ncomputer scientists and mathematical physicists for decades. While most recent\nresearch in this area have explored the role of the Riemann zeta-function in\ndifferent formulations of statistical mechanics, condensed matter physics and\nquantum chaotic systems, the resulting devices (quantum or classical) have only\nexisted in theory or the fabrication of the device has been found to be not\nscalable to large prime numbers. Here we report for the first time that any\nhypothetical prime number generator, to our knowledge, has to be a special case\nof a dynamical system that is governed by the physics of Fowler-Nordheim (FN)\nquantum-tunneling. In this paper we report how such a dynamical system can be\nimplemented using a counting process that naturally arises from sequential FN\ntunneling and integration of electrons on a floating-gate (FG) device. The\nself-compensating physics of the FG device makes the operation reliable and\nrepeatable even when tunneling-currents approach levels below 1 attoamperes. We\nreport measured results from different variants of fabricated prototypes, each\nof which shows an excellent match with the asymptotic prime number statistics.\nWe also report similarities between the spectral signatures produced by the FN\ndevice and the spectral statistics of a hypothetical prime number sequence\ngenerator. We believe that the proposed floating-gate device could have future\nimplications in understanding the process that generates prime numbers with\napplications in security and authentication.","primary_category":"cs","categories":["cs.CR","cs.ET","math.DS"],"authors":["Zhou Liang","Kondapalli SriHarsha","Chakrabartty Shantanu"],"created":"2017-11-24","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1711.11205","title":"Aiding the Visually Impaired: Developing an efficient Braille Printer","abstract":"With the large number of partially or completely visually impaired persons in\nsociety, their integration as productive, educated and capable members of\nsociety is hampered heavily by a pervasively high level of braille illiteracy.\nThis problem is further compounded by the fact that braille printers are\nprohibitively expensive - generally starting from two thousand US dollars,\nbeyond the reach of the common man. Over the period of a year, the authors have\ntried to develop a Braille printer which attempts to overcome the problems\ninherent in commercial printers. The purpose of this paper, therefore, is to\nintroduce two prototypes - the first with an emphasis of cost-effectiveness,\nand the second prototype, which is more experimental and aims to eliminate\nseveral demerits of Braille printing. The first prototype has been constructed\nat a cost significantly less than the existing commercial braille printers.\nBoth the prototypes of the device have been constructed, which will be shown.","primary_category":"cs","categories":["cs.HC"],"authors":["Apurva Anubhav","Thakur Palash","Misra Anupam"],"created":"2017-11-29","updated":" ","doi":"10.1109\/ICACCI.2017.8126160"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1711.11427","title":"Errors in Flash-Memory-Based Solid-State Drives: Analysis, Mitigation,\n  and Recovery","abstract":"NAND flash memory is ubiquitous in everyday life today because its capacity\nhas continuously increased and cost has continuously decreased over decades.\nThis positive growth is a result of two key trends: (1) effective process\ntechnology scaling; and (2) multi-level (e.g., MLC, TLC) cell data coding.\nUnfortunately, the reliability of raw data stored in flash memory has also\ncontinued to become more difficult to ensure, because these two trends lead to\n(1) fewer electrons in the flash memory cell floating gate to represent the\ndata; and (2) larger cell-to-cell interference and disturbance effects. Without\nmitigation, worsening reliability can reduce the lifetime of NAND flash memory.\nAs a result, flash memory controllers in solid-state drives (SSDs) have become\nmuch more sophisticated: they incorporate many effective techniques to ensure\nthe correct interpretation of noisy data stored in flash memory cells.\n  In this chapter, we review recent advances in SSD error characterization,\nmitigation, and data recovery techniques for reliability and lifetime\nimprovement. We provide rigorous experimental data from state-of-the-art MLC\nand TLC NAND flash devices on various types of flash memory errors, to motivate\nthe need for such techniques. Based on the understanding developed by the\nexperimental characterization, we describe several mitigation and recovery\ntechniques, including (1) cell-tocell interference mitigation; (2) optimal\nmulti-level cell sensing; (3) error correction using state-of-the-art\nalgorithms and methods; and (4) data recovery when error correction fails. We\nquantify the reliability improvement provided by each of these techniques.\nLooking forward, we briefly discuss how flash memory and these techniques could\nevolve into the future.","primary_category":"cs","categories":["cs.AR"],"authors":["Cai Yu","Ghose Saugata","Haratsch Erich F.","Luo Yixin","Mutlu Onur"],"created":"2017-11-28","updated":"2018-01-05","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.00036","title":"Robust Stereo Visual Inertial Odometry for Fast Autonomous Flight","abstract":"In recent years, vision-aided inertial odometry for state estimation has\nmatured significantly. However, we still encounter challenges in terms of\nimproving the computational efficiency and robustness of the underlying\nalgorithms for applications in autonomous flight with micro aerial vehicles in\nwhich it is difficult to use high quality sensors and pow- erful processors\nbecause of constraints on size and weight. In this paper, we present a\nfilter-based stereo visual inertial odometry that uses the Multi-State\nConstraint Kalman Filter (MSCKF) [1]. Previous work on stereo visual inertial\nodometry has resulted in solutions that are computationally expensive. We\ndemonstrate that our Stereo Multi-State Constraint Kalman Filter (S-MSCKF) is\ncomparable to state-of-art monocular solutions in terms of computational cost,\nwhile providing signifi- cantly greater robustness. We evaluate our S-MSCKF\nalgorithm and compare it with state-of-art methods including OKVIS, ROVIO, and\nVINS-MONO on both the EuRoC dataset, and our own experimental datasets\ndemonstrating fast autonomous flight with maximum speed of 17.5m\/s in indoor\nand outdoor environments. Our implementation of the S-MSCKF is available at\nhttps:\/\/github.com\/KumarRobotics\/msckf_vio.","primary_category":"cs","categories":["cs.RO"],"authors":["Sun Ke","Mohta Kartik","Pfrommer Bernd","Watterson Michael","Liu Sikang","Mulgaonkar Yash","Taylor Camillo J.","Kumar Vijay"],"created":"2017-11-30","updated":"2018-01-10","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.00157","title":"Fundamental Limits on Data Acquisition: Trade-offs between Sample\n  Complexity and Query Difficulty","abstract":"We consider query-based data acquisition and the corresponding information\nrecovery problem, where the goal is to recover $k$ binary variables\n(information bits) from parity measurements of those variables. The queries and\nthe corresponding parity measurements are designed using the encoding rule of\nFountain codes. By using Fountain codes, we can design potentially limitless\nnumber of queries, and corresponding parity measurements, and guarantee that\nthe original $k$ information bits can be recovered with high probability from\nany sufficiently large set of measurements of size $n$. In the query design,\nthe average number of information bits that is associated with one parity\nmeasurement is called query difficulty ($\\bar{d}$) and the minimum number of\nmeasurements required to recover the $k$ information bits for a fixed $\\bar{d}$\nis called sample complexity ($n$). We analyze the fundamental trade-offs\nbetween the query difficulty and the sample complexity, and show that the\nsample complexity of $n=c\\max\\{k,(k\\log k)\/\\bar{d}\\}$ for some constant $c>0$\nis necessary and sufficient to recover $k$ information bits with high\nprobability as $k\\to\\infty$.","primary_category":"cs","categories":["cs.IT","eess.SP","math.IT"],"authors":["Chung Hye Won","Lee Ji Oon","Hero Alfred O."],"created":"2017-11-30","updated":"2018-01-02","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.00343","title":"MPI_XSTAR: MPI-based Parallelization of the XSTAR Photoionization\n  Program","abstract":"We describe a program for the parallel implementation of multiple runs of\nXSTAR, a photoionization code that is used to predict the physical properties\nof an ionized gas from its emission and\/or absorption lines. The\nparallelization program, called MPI_XSTAR, has been developed and implemented\nin the C++ language by using the Message Passing Interface (MPI) protocol, a\nconventional standard of parallel computing. We have benchmarked parallel\nmultiprocessing executions of XSTAR, using MPI_XSTAR, against a serial\nexecution of XSTAR, in terms of the parallelization speedup and the computing\nresource efficiency. Our experience indicates that the parallel execution runs\nsignificantly faster than the serial execution, however, the efficiency in\nterms of the computing resource usage decreases with increasing the number of\nprocessors used in the parallel computing.","primary_category":"cs","categories":["astro-ph.HE","astro-ph.IM","cs.DC"],"authors":["Danehkar Ashkbiz","Nowak Michael A.","Lee Julia C.","Smith Randall K."],"created":"2017-11-28","updated":" ","doi":"10.1088\/1538-3873\/aa9dff"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.00443","title":"Deep Neural Network Architectures for Modulation Classification","abstract":"In this work, we investigate the value of employing deep learning for the\ntask of wireless signal modulation recognition. Recently in [1], a framework\nhas been introduced by generating a dataset using GNU radio that mimics the\nimperfections in a real wireless channel, and uses 10 different modulation\ntypes. Further, a convolutional neural network (CNN) architecture was developed\nand shown to deliver performance that exceeds that of expert-based approaches.\nHere, we follow the framework of [1] and find deep neural network architectures\nthat deliver higher accuracy than the state of the art. We tested the\narchitecture of [1] and found it to achieve an accuracy of approximately 75% of\ncorrectly recognizing the modulation type. We first tune the CNN architecture\nof [1] and find a design with four convolutional layers and two dense layers\nthat gives an accuracy of approximately 83.8% at high SNR. We then develop\narchitectures based on the recently introduced ideas of Residual Networks\n(ResNet [2]) and Densely Connected Networks (DenseNet [3]) to achieve high SNR\naccuracies of approximately 83.5% and 86.6%, respectively. Finally, we\nintroduce a Convolutional Long Short-term Deep Neural Network (CLDNN [4]) to\nachieve an accuracy of approximately 88.5% at high SNR.","primary_category":"cs","categories":["cs.LG","stat.ML"],"authors":["Liu Xiaoyu","Yang Diyu","Gamal Aly El"],"created":"2017-12-01","updated":"2018-01-05","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.00711","title":"The local geometry of testing in ellipses: Tight control via localized\n  Kolmogorov widths","abstract":"We study the local geometry of testing a mean vector within a\nhigh-dimensional ellipse against a compound alternative. Given samples of a\nGaussian random vector, the goal is to distinguish whether the mean is equal to\na known vector within an ellipse, or equal to some other unknown vector in the\nellipse. Such ellipse testing problems lie at the heart of several\napplications, including non-parametric goodness-of-fit testing, signal\ndetection in cognitive radio, and regression function testing in reproducing\nkernel Hilbert spaces. While past work on such problems has focused on the\ndifficulty in a global sense, we study difficulty in a way that is localized to\neach vector within the ellipse. Our main result is to give sharp upper and\nlower bounds on the localized minimax testing radius in terms of an explicit\nformula involving the Kolmogorov width of the ellipse intersected with a\nEuclidean ball. When applied to particular examples, our general theorems yield\ninteresting rates that were not known before: as a particular case, for testing\nin Sobolev ellipses of smoothness $\\alpha$, we demonstrate rates that vary from\n$(\\sigma^2)^{\\frac{4 \\alpha}{4 \\alpha + 1}}$, corresponding to the classical\nglobal rate, to the faster rate $(\\sigma^2)^{\\frac{8\n  \\alpha}{8 \\alpha + 1}}$, achievable for vectors at favorable locations within\nthe ellipse. We also show that the optimal test for this problem is achieved by\na linear projection test that is based on an explicit lower-dimensional\nprojection of the observation vector.","primary_category":"cs","categories":["math.ST","cs.IT","math.IT","stat.TH"],"authors":["Wei Yuting","Wainwright Martin J."],"created":"2017-12-03","updated":"2018-01-03","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.01178","title":"Principle of Conservation of Computational Complexity","abstract":"In this manuscript, we derive the principle of conservation of computational\ncomplexity. We measure computational complexity as the number of binary\ncomputations (decisions) required to solve a problem. Every problem then\ndefines a unique solution space measurable in bits. For an exact result,\ndecisions in the solution space can neither be predicted nor discarded, only\ntransferred between input and algorithm. We demonstrate and explain this\nprinciple using the example of the propositional logic satisfiability problem\n($SAT$). It inevitably follows that $SAT \\not\\in P \\Rightarrow P\\neq NP$. We\nalso provide an alternative explanation for the undecidability of the halting\nproblem based on the principle.","primary_category":"cs","categories":["cs.CC"],"authors":["Friedland Gerald","Metere Alfredo"],"created":"2017-12-04","updated":"2018-01-03","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.01447","title":"Gaussian Process bandits with adaptive discretization","abstract":"In this paper, the problem of maximizing a black-box function $f:\\mathcal{X}\n\\to \\mathbb{R}$ is studied in the Bayesian framework with a Gaussian Process\n(GP) prior. In particular, a new algorithm for this problem is proposed, and\nhigh probability bounds on its simple and cumulative regret are established.\nThe query point selection rule in most existing methods involves an exhaustive\nsearch over an increasingly fine sequence of uniform discretizations of\n$\\mathcal{X}$. The proposed algorithm, in contrast, adaptively refines\n$\\mathcal{X}$ which leads to a lower computational complexity, particularly\nwhen $\\mathcal{X}$ is a subset of a high dimensional Euclidean space. In\naddition to the computational gains, sufficient conditions are identified under\nwhich the regret bounds of the new algorithm improve upon the known results.\nFinally an extension of the algorithm to the case of contextual bandits is\nproposed, and high probability bounds on the contextual regret are presented.","primary_category":"cs","categories":["stat.ML","cs.LG"],"authors":["Shekhar Shubhanshu","Javidi Tara"],"created":"2017-12-04","updated":"2018-01-05","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.01905","title":"Simulating Opportunistic Networks: Survey and Future Directions","abstract":"Simulation is one of the most powerful tools we have for evaluating the\nperformance of Opportunistic Networks. In this survey, we focus on available\ntools and models, compare their performance and precision and experimentally\nshow the scalability of different simulators. We also perform a gap analysis of\nstate-of-the-art Opportunistic Network simulations and sketch out possible\nfurther development and lines of research. This survey is targeted at students\nstarting work and research in this area while also serving as a valuable source\nof information for experienced researchers.","primary_category":"cs","categories":["cs.NI"],"authors":["Dede Jens","F\u00f6rster Anna","Hern\u00e1ndez-Orallo Enrique","Herrera-Tapia Jorge","Kuladinithi Koojana","Kuppusamy Vishnupriya","Manzoni Pietro","Muslim Anas bin","Udugama Asanga","Vatandas Zeynep"],"created":"2017-12-05","updated":"2018-01-09","doi":"10.1109\/COMST.2017.2782182"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.02007","title":"Coupling Story to Visualization: Using Textual Analysis as a Bridge\n  Between Data and Interpretation","abstract":"Online writers and journalism media are increasingly combining visualization\n(and other multimedia content) with narrative text to create narrative\nvisualizations. Often, however, the two elements are presented independently of\none another. We propose an approach to automatically integrate text and\nvisualization elements. We begin with a writer's narrative that presumably can\nbe supported with visual data evidence. We leverage natural language\nprocessing, quantitative narrative analysis, and information visualization to\n(1) automatically extract narrative components (who, what, when, where) from\ndata-rich stories, and (2) integrate the supporting data evidence with the text\nto develop a narrative visualization. We also employ bidirectional interaction\nfrom text to visualization and visualization to text to support reader\nexploration in both directions. We demonstrate the approach with a case study\nin the data-rich field of sports journalism.","primary_category":"cs","categories":["cs.HC"],"authors":["Metoyer Ronald","Zhi Qiyu","Janczuk Bart","Scheirer Walter"],"created":"2017-12-05","updated":"2018-01-06","doi":"10.1145\/3172944.3173007"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.02027","title":"Evolutionary Game for Mining Pool Selection in Blockchain Networks","abstract":"In blockchain networks adopting the proof-of-work schemes, the monetary\nincentive is introduced by the Nakamoto consensus protocol to guide the\nbehaviors of the full nodes (i.e., block miners) in the process of maintaining\nthe consensus about the blockchain state. The block miners have to devote their\ncomputation power measured in hash rate in a crypto-puzzle solving competition\nto win the reward of publishing (a.k.a., mining) new blocks. Due to the\nexponentially increasing difficulty of the crypto-puzzle, individual block\nminers tends to join mining pools, i.e., the coalitions of miners, in order to\nreduce the income variance and earn stable profits. In this paper, we study the\ndynamics of mining pool selection in a blockchain network, where mining pools\nmay choose arbitrary block mining strategies. We identify the hash rate and the\nblock propagation delay as two major factors determining the outcomes of mining\ncompetition, and then model the strategy evolution of the individual miners as\nan evolutionary game. We provide the theoretical analysis of the evolutionary\nstability for the pool selection dynamics in a case study of two mining pools.\nThe numerical simulations provide the evidence to support our theoretical\ndiscoveries as well as demonstrating the stability in the evolution of miners'\nstrategies in a general case.","primary_category":"cs","categories":["cs.GT"],"authors":["Liu Xiaojun","Wang Wenbo","Niyato Dusit","Zhao Narisa","Wang Ping"],"created":"2017-12-05","updated":"2017-12-28","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.02151","title":"Generalized Probability Smoothing","abstract":"In this work we consider a generalized version of Probability Smoothing, the\ncore elementary model for sequential prediction in the state of the art PAQ\nfamily of data compression algorithms. Our main contribution is a code length\nanalysis that considers the redundancy of Probability Smoothing with respect to\na Piecewise Stationary Source. The analysis holds for a finite alphabet and\nexpresses redundancy in terms of the total variation in probability mass of the\nstationary distributions of a Piecewise Stationary Source. By choosing\nparameters appropriately Probability Smoothing has redundancy\n$O(S\\cdot\\sqrt{T\\log T})$ for sequences of length $T$ with respect to a\nPiecewise Stationary Source with $S$ segments.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Mattern Christopher"],"created":"2017-12-06","updated":"2018-01-10","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.02342","title":"A Context-Aware User-Item Representation Learning for Item\n  Recommendation","abstract":"Both reviews and user-item interactions (i.e., rating scores) have been\nwidely adopted for user rating prediction. However, these existing techniques\nmainly extract the latent representations for users and items in an independent\nand static manner. That is, a single static feature vector is derived to encode\nher preference without considering the particular characteristics of each\ncandidate item. We argue that this static encoding scheme is difficult to fully\ncapture the users' preference. In this paper, we propose a novel context-aware\nuser-item representation learning model for rating prediction, named CARL.\nNamely, CARL derives a joint representation for a given user-item pair based on\ntheir individual latent features and latent feature interactions. Then, CARL\nadopts Factorization Machines to further model higher-order feature\ninteractions on the basis of the user-item pair for rating prediction.\nSpecifically, two separate learning components are devised in CARL to exploit\nreview data and interaction data respectively: review-based feature learning\nand interaction-based feature learning. In review-based learning component,\nwith convolution operations and attention mechanism, the relevant features for\na user-item pair are extracted by jointly considering their corresponding\nreviews. However, these features are only review-driven and may not be\ncomprehensive. Hence, interaction-based learning component further extracts\ncomplementary features from interaction data alone, also on the basis of\nuser-item pairs. The final rating score is then derived with a dynamic linear\nfusion mechanism. Experiments on five real-world datasets show that CARL\nachieves significantly better rating prediction accuracy than existing\nstate-of-the-art alternatives. Also, with attention mechanism, we show that the\nrelevant information in reviews can be highlighted to interpret the rating\nprediction.","primary_category":"cs","categories":["cs.IR"],"authors":["Wu Libing","Quan Cong","Li Chenliang","Wang Qian","Zheng Bolong"],"created":"2017-12-06","updated":"2017-12-29","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.02781","title":"On Usage of Autoencoders and Siamese Networks for Online Handwritten\n  Signature Verification","abstract":"In this paper, we propose a novel writer-independent global feature\nextraction framework for the task of automatic signature verification which\naims to make robust systems for automatically distinguishing negative and\npositive samples. Our method consists of an autoencoder for modeling the sample\nspace into a fixed length latent space and a Siamese Network for classifying\nthe fixed-length samples obtained from the autoencoder based on the reference\nsamples of a subject as being \"Genuine\" or \"Forged.\" During our experiments,\nusage of Attention Mechanism and applying Downsampling significantly improved\nthe accuracy of the proposed framework. We evaluated our proposed framework\nusing SigWiComp2013 Japanese and GPDSsyntheticOnLineOffLineSignature datasets.\nOn the SigWiComp2013 Japanese dataset, we achieved 8.65% EER that means 1.2%\nrelative improvement compared to the best-reported result. Furthermore, on the\nGPDSsyntheticOnLineOffLineSignature dataset, we achieved average EERs of 0.13%,\n0.12%, 0.21% and 0.25% respectively for 150, 300, 1000 and 2000 test subjects\nwhich indicates improvement of relative EER on the best-reported result by\n95.67%, 95.26%, 92.9% and 91.52% respectively. Apart from the accuracy gain,\nbecause of the nature of our proposed framework which is based on neural\nnetworks and consequently is as simple as some consecutive matrix\nmultiplications, it has less computational cost than conventional methods such\nas DTW and could be used concurrently on devices such as GPU, TPU, etc.","primary_category":"cs","categories":["cs.NE","cs.CV"],"authors":["Ahrabian Kian","Babaali Bagher"],"created":"2017-12-07","updated":"2017-12-29","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.02856","title":"Effective Neural Solution for Multi-Criteria Word Segmentation","abstract":"We present a simple yet elegant solution to train a single joint model on\nmulti-criteria corpora for Chinese Word Segmentation (CWS). Our novel design\nrequires no private layers in model architecture, instead, introduces two\nartificial tokens at the beginning and ending of input sentence to specify the\nrequired target criteria. The rest of the model including Long Short-Term\nMemory (LSTM) layer and Conditional Random Fields (CRFs) layer remains\nunchanged and is shared across all datasets, keeping the size of parameter\ncollection minimal and constant. On Bakeoff 2005 and Bakeoff 2008 datasets, our\ninnovative design has surpassed both single-criterion and multi-criteria\nstate-of-the-art learning results. To the best knowledge, our design is the\nfirst one that has achieved the latest high performance on such large scale\ndatasets. Source codes and corpora of this paper are available on GitHub.","primary_category":"cs","categories":["cs.CL"],"authors":["He Han","Wu Lei","Yan Hua","Gao Zhimin","Feng Yi","Townsend George"],"created":"2017-12-07","updated":"2018-01-04","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.03346","title":"Variational auto-encoding of protein sequences","abstract":"Proteins are responsible for the most diverse set of functions in biology.\nThe ability to extract information from protein sequences and to predict the\neffects of mutations is extremely valuable in many domains of biology and\nmedicine. However the mapping between protein sequence and function is complex\nand poorly understood. Here we present an embedding of natural protein\nsequences using a Variational Auto-Encoder and use it to predict how mutations\naffect protein function. We use this unsupervised approach to cluster natural\nvariants and learn interactions between sets of positions within a protein.\nThis approach generally performs better than baseline methods that consider no\ninteractions within sequences, and in some cases better than the\nstate-of-the-art approaches that use the inverse-Potts model. This generative\nmodel can be used to computationally guide exploration of protein sequence\nspace and to better inform rational and automatic protein design.","primary_category":"cs","categories":["q-bio.QM","cs.LG"],"authors":["Sinai Sam","Kelsic Eric","Church George M.","Nowak Martin A."],"created":"2017-12-09","updated":"2018-01-03","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.04124","title":"Ergodic Capacity of Composite Fading Channels in Cognitive Radios with\n  the Product of $\\kappa$-$\\mu$ and $\\alpha$-$\\mu$ Variates","abstract":"In this study, the product of two independent and non-identically distributed\n(i.n.i.d.) random variables (RVs) for \\k{appa}-{\\mu} fading distribution and\n{\\alpha}-{\\mu} fading distribution is considered. The method of the product\nmodel of RVs has been widely applied in numerous of communications fields, such\nas cascaded fading channels, multiple input multiple output (MIMO) systems,\nradar communications and cognitive radio networks (CRs). The exact series\nexpressions of the product of two i.n.i.d. RVs X for \\k{appa}-{\\mu} variates\nand Y for {\\alpha}-{\\mu} variates are derived instead of Fox H-function to\nsolve the problem that Fox H-function in the RVs product could not be\nimplemented in popular mathematical software packages as Mathematica and Maple.\nNovel Exact close-form expressions of probability density function (PDF) and\ncumulative distribution function (CDF) of proposed models are deduced to\npresent the series expressions of product and generalized composite multipath\nshadowing models. Furthermore, novel exact expressions of the ergodic channel\ncapacity (ECC) are obtained under optimal rate adaptation with constant\ntransmit power (ORA). At last, these analytical results are confirmed with\nmonte-carlo simulations to evaluate spectrum efficiency over generalized\ncomposite shadowing fading scenarios in CRs.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Huang He","al et."],"created":"2017-12-11","updated":"2017-12-29","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.04427","title":"Small-Scale Markets for Bilateral Resource Trading in the Sharing\n  Economy","abstract":"We consider a general small-scale market for agent-to-agent resource sharing,\nin which each agent could either be a server (seller) or a client (buyer) in\neach time period. In every time period, a server has a certain amount of\nresources that any client could consume, and randomly gets matched with a\nclient. Our target is to maximize the resource utilization in such an\nagent-to-agent market, where the agents are strategic. During each transaction,\nthe server gets money and the client gets resources. Hence, trade ratio\nmaximization implies efficiency maximization of our system. We model the\nproposed market system through a Mean Field Game approach and prove the\nexistence of the Mean Field Equilibrium, which can achieve an almost 100% trade\nratio. Finally, we carry out a simulation study motivated by an agent-to-agent\ncomputing market, and a case study on a proposed photovoltaic market, and show\nthe designed market benefits both individuals and the system as a whole.","primary_category":"cs","categories":["cs.GT"],"authors":["Xia Bainan","Shakkottai Srinivas","Subramanian Vijay"],"created":"2017-12-12","updated":"2017-12-29","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.05307","title":"An SDN hybrid architecture for vehicular networks: Application to\n  Intelligent Transport System","abstract":"Vehicular networks are one of the cornerstone of an Intelligent\nTransportation System (ITS). They are expected to provide ubiquitous network\nconnectivity to moving vehicles while supporting various ITS services, some\nwith very stringent requirements in terms of latency and reliability. Two\nvehicular networking technologies are envisioned to jointly support the full\nrange of ITS services : DSRC (Dedicated Short Range Communication) for direct\nvehicle to vehicle\/Road Side Units (RSU) communications and cellular\ntechnologies. To the best of our knowledge, approaches from the literature\nusually divide ITS services on each of these networks according to their\nrequirements and one single network is in charge of supporting the each\nservice. Those that consider both network technologies to offer multi-path\nrouting, load balancing or path splitting for a better quality of experience of\nITS services assume obviously separately controlled networks. Under the\numbrella of SDN (Software Defined Networking), we propose in this paper a\nhybrid network architecture that enables the joint control of the networks\nproviding connectivity to multi-homed vehicles and, also, explore the\nopportunities brought by such an architecture. We show through some use cases,\nthat in addition to the flexibility and fine-grained programmability brought by\nSDN, it opens the way towards the development of effective network control\nalgorithms that are the key towards the successful support of ITS services and\nespecially those with stringent QoS. We also show how these algorithms could\nalso benefit from information related to the environment or context in which\nvehicles evolve (traffic density, planned trajectory, ..), which could be\neasily collected by data providers and made available via the cloud.","primary_category":"cs","categories":["cs.NI"],"authors":["Toufga Soufian","Owezarski Philippe","Abdellatif Slim","Villemur Thierry"],"created":"2017-12-14","updated":"2018-01-08","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.05677","title":"Timely-Throughput Optimal Scheduling with Prediction","abstract":"Motivated by the increasing importance of providing delay-guaranteed services\nin general computing and communication systems, and the recent wide adoption of\nlearning and prediction in network control, in this work, we consider a general\nstochastic single-server multi-user system and investigate the fundamental\nbenefit of predictive scheduling in improving timely-throughput, being the rate\nof packets that are delivered to destinations before their deadlines. By\nadopting an error rate-based prediction model, we first derive a Markov\ndecision process (MDP) solution to optimize the timely-throughput objective\nsubject to an average resource consumption constraint. Based on a packet-level\ndecomposition of the MDP, we explicitly characterize the optimal scheduling\npolicy and rigorously quantify the timely-throughput improvement due to\npredictive-service, which scales as\n$\\Theta(p\\left[C_{1}\\frac{(a-a_{\\max}q)}{p-q}\\rho^{\\tau}+C_{2}(1-\\frac{1}{p})\\right](1-\\rho^{D}))$,\nwhere $a, a_{\\max}, \\rho\\in(0, 1), C_1>0, C_2\\ge0$ are constants, $p$ is the\ntrue-positive rate in prediction, $q$ is the false-negative rate, $\\tau$ is the\npacket deadline and $D$ is the prediction window size. We also conduct\nextensive simulations to validate our theoretical findings. Our results provide\nnovel insights into how prediction and system parameters impact performance and\nprovide useful guidelines for designing predictive low-latency control\nalgorithms.","primary_category":"cs","categories":["cs.NI","cs.SY"],"authors":["Chen Kun","Huang Longbo"],"created":"2017-12-15","updated":"2018-01-05","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.06766","title":"Enabling Work-conserving Bandwidth Guarantees for Multi-tenant\n  Datacenters via Dynamic Tenant-Queue Binding","abstract":"Today's cloud networks are shared among many tenants. Bandwidth guarantees\nand work conservation are two key properties to ensure predictable performance\nfor tenant applications and high network utilization for providers. Despite\nsignificant efforts, very little prior work can really achieve both properties\nsimultaneously even some of them claimed so.\n  In this paper, we present QShare, an in-network based solution to achieve\nbandwidth guarantees and work conservation simultaneously. QShare leverages\nweighted fair queuing on commodity switches to slice network bandwidth for\ntenants, and solves the challenge of queue scarcity through balanced tenant\nplacement and dynamic tenant-queue binding. QShare is readily implementable\nwith existing switching chips. We have implemented a QShare prototype and\nevaluated it via both testbed experiments and simulations. Our results show\nthat QShare ensures bandwidth guarantees while driving network utilization to\nover 91% even under unpredictable traffic demands.","primary_category":"cs","categories":["cs.NI"],"authors":["Liu Zhuotao","Chen Kai","Wu Haitao","Hu Shuihai","Hu Yih-Chun","Wang Yi","Zhang Gong"],"created":"2017-12-18","updated":"2018-01-07","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.07121","title":"Automata Minimization: a Functorial Approach","abstract":"In this paper we regard languages and their acceptors - such as deterministic\nor weighted automata, transducers, or monoids - as functors from input\ncategories that specify the type of the languages and of the machines to\ncategories that specify the type of outputs. Our results are as follows:\n  A) We provide sufficient conditions on the output category so that\nminimization of the corresponding automata is guaranteed.\n  B) We show how to lift adjunctions between the categories for output values\nto adjunctions between categories of automata.\n  C) We show how this framework can be instantiated to unify several phenomena\nin automata theory, starting with determinization, minimization and syntactic\nalgebras. We provide explanations of Choffrut's minimization algorithm for\nsubsequential transducers and of Brzozowski's minimization algorithm in this\nsetting.","primary_category":"cs","categories":["cs.LO","cs.FL"],"authors":["Colcombet Thomas","Petri\u015fan Daniela"],"created":"2017-12-19","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.07168","title":"Real-time deep hair matting on mobile devices","abstract":"Augmented reality is an emerging technology in many application domains.\nAmong them is the beauty industry, where live virtual try-on of beauty products\nis of great importance. In this paper, we address the problem of live hair\ncolor augmentation. To achieve this goal, hair needs to be segmented quickly\nand accurately. We show how a modified MobileNet CNN architecture can be used\nto segment the hair in real-time. Instead of training this network using large\namounts of accurate segmentation data, which is difficult to obtain, we use\ncrowd sourced hair segmentation data. While such data is much simpler to\nobtain, the segmentations there are noisy and coarse. Despite this, we show how\nour system can produce accurate and fine-detailed hair mattes, while running at\nover 30 fps on an iPad Pro tablet.","primary_category":"cs","categories":["cs.CV"],"authors":["Levinshtein Alex","Chang Cheng","Phung Edmund","Kezele Irina","Guo Wenzhangzhi","Aarabi Parham"],"created":"2017-12-19","updated":"2018-01-10","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.07449","title":"In silico generation of novel, drug-like chemical matter using the LSTM\n  neural network","abstract":"The exploration of novel chemical spaces is one of the most important tasks\nof cheminformatics when supporting the drug discovery process. Properly\ndesigned and trained deep neural networks can provide a viable alternative to\nbrute-force de novo approaches or various other machine-learning techniques for\ngenerating novel drug-like molecules. In this article we present a method to\ngenerate molecules using a long short-term memory (LSTM) neural network and\nprovide an analysis of the results, including a virtual screening test. Using\nthe network one million drug-like molecules were generated in 2 hours. The\nmolecules are novel, diverse (contain numerous novel chemotypes), have good\nphysicochemical properties and have good synthetic accessibility, even though\nthese qualities were not specific constraints. Although novel, their structural\nfeatures and functional groups remain closely within the drug-like space\ndefined by the bioactive molecules from ChEMBL. Virtual screening using the\nprofile QSAR approach confirms that the potential of these novel molecules to\nshow bioactivity is comparable to the ChEMBL set from which they were derived.\nThe molecule generator written in Python used in this study is available on\nrequest.","primary_category":"cs","categories":["cs.LG","q-bio.QM"],"authors":["Ertl Peter","Lewis Richard","Martin Eric","Polyakov Valery"],"created":"2017-12-20","updated":"2018-01-08","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.07881","title":"Simulating Patho-realistic Ultrasound Images using Deep Generative\n  Networks with Adversarial Learning","abstract":"Ultrasound imaging makes use of backscattering of waves during their\ninteraction with scatterers present in biological tissues. Simulation of\nsynthetic ultrasound images is a challenging problem on account of inability to\naccurately model various factors of which some include intra-\/inter scanline\ninterference, transducer to surface coupling, artifacts on transducer elements,\ninhomogeneous shadowing and nonlinear attenuation. Current approaches typically\nsolve wave space equations making them computationally expensive and slow to\noperate. We propose a generative adversarial network (GAN) inspired approach\nfor fast simulation of patho-realistic ultrasound images. We apply the\nframework to intravascular ultrasound (IVUS) simulation. A stage 0 simulation\nperformed using pseudo B-mode ultrasound image simulator yields speckle mapping\nof a digitally defined phantom. The stage I GAN subsequently refines them to\npreserve tissue specific speckle intensities. The stage II GAN further refines\nthem to generate high resolution images with patho-realistic speckle profiles.\nWe evaluate patho-realism of simulated images with a visual Turing test\nindicating an equivocal confusion in discriminating simulated from real. We\nalso quantify the shift in tissue specific intensity distributions of the real\nand simulated images to prove their similarity.","primary_category":"cs","categories":["cs.CV"],"authors":["Tom Francis","Sheet Debdoot"],"created":"2017-12-21","updated":"2018-01-08","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.08296","title":"Intelligent Device Discovery in the Internet of Things - Enabling the\n  Robot Society","abstract":"The Internet of Things (IoT) is continuously growing to connect billions of\nsmart devices anywhere and anytime in an Internet-like structure, which enables\na variety of applications, services and interactions between human and objects.\nIn the future, the smart devices are supposed to be able to autonomously\ndiscover a target device with desired features and generate a set of entirely\nnew services and applications that are not supervised or even imagined by human\nbeings. The pervasiveness of smart devices, as well as the heterogeneity of\ntheir design and functionalities, raise a major concern: How can a smart device\nefficiently discover a desired target device? In this paper, we propose a\nSocial-Aware and Distributed (SAND) scheme that achieves a fast, scalable and\nefficient device discovery in the IoT. The proposed SAND scheme adopts a novel\ndevice ranking criteria that measures the device's degree, social relationship\ndiversity, clustering coefficient and betweenness. Based on the device ranking\ncriteria, the discovery request can be guided to travel through critical\ndevices that stand at the major intersections of the network, and thus quickly\nreach the desired target device by contacting only a limited number of\nintermediate devices. With the help of such an intelligent device discovery as\nSAND, the IoT devices, as well as other computing facilities, software and data\non the Internet, can autonomously establish new social connections with each\nother as human being do. They can formulate self-organized computing groups to\nperform required computing tasks, facilitate a fusion of a variety of computing\nservice, network service and data to generate novel applications and services,\nevolve from the individual aritificial intelligence to the collaborative\nintelligence, and eventually enable the birth of a robot society.","primary_category":"cs","categories":["cs.AI"],"authors":["Sunthonlap James","Nguyen Phuoc","Ye Zilong"],"created":"2017-12-21","updated":"2018-01-08","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.08342","title":"Event-based Failure Prediction in Distributed Business Processes","abstract":"Traditionally, research in Business Process Management has put a strong focus\non centralized and intra-organizational processes. However, today's business\nprocesses are increasingly distributed, deviating from a centralized layout,\nand therefore calling for novel methodologies of detecting and responding to\nunforeseen events, such as errors occurring during process runtime. In this\narticle, we demonstrate how to employ event-based failure prediction in\nbusiness processes. This approach allows to make use of the best of both\ntraditional Business Process Management Systems and event-based systems. Our\napproach employs machine learning techniques and considers various types of\nevents. We evaluate our solution using two business process data sets,\nincluding one from a real-world event log, and show that we are able to detect\nerrors and predict failures with high accuracy.","primary_category":"cs","categories":["cs.DC","cs.SE"],"authors":["Borkowski Michael","Fdhila Walid","Nardelli Matteo","Rinderle-Ma Stefanie","Schulte Stefan"],"created":"2017-12-22","updated":"2018-01-09","doi":"10.1016\/j.is.2017.12.005"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.08349","title":"Tracking the Diffusion of Named Entities","abstract":"Existing studies of how information diffuses across social networks have thus\nfar concentrated on analysing and recovering the spread of deterministic\ninnovations such as URLs, hashtags, and group membership. However investigating\nhow mentions of real-world entities appear and spread has yet to be explored,\nlargely due to the computationally intractable nature of performing large-scale\nentity extraction. In this paper we present, to the best of our knowledge, one\nof the first pieces of work to closely examine the diffusion of named entities\non social media, using Reddit as our case study platform. We first investigate\nhow named entities can be accurately recognised and extracted from discussion\nposts. We then use these extracted entities to study the patterns of entity\ncascades and how the probability of a user adopting an entity (i.e. mentioning\nit) is associated with exposures to the entity. We put these pieces together by\npresenting a parallelised diffusion model that can forecast the probability of\nentity adoption, finding that the influence of adoption between users can be\ncharacterised by their prior interactions -- as opposed to whether the users\npropagated entity-adoptions beforehand. Our findings have important\nimplications for researchers studying influence and language, and for community\nanalysts who wish to understand entity-level influence dynamics.","primary_category":"cs","categories":["cs.CL","cs.SI"],"authors":["Derczynski Leon","Rowe Matthew"],"created":"2017-12-22","updated":"2017-12-29","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.08566","title":"Extended Product and Integrated Interleaved Codes","abstract":"A new class of codes, Extended Product (EPC) Codes, consisting of a product\ncode with a number of extra parities added, is presented and applications for\nerasure decoding are discussed. An upper bound on the minimum distance of EPC\ncodes is given, as well as constructions meeting the bound for some relevant\ncases. A special case of EPC codes, Extended Integrated Interleaved (EII)\ncodes, which naturally unify Integrated Interleaved (II) codes and product\ncodes, is defined and studied in detail. It is shown that EII codes often\nimprove the minimum distance of II codes with the same rate, and they enhance\nthe decoding algorithm by allowing decoding on columns as well as on rows. It\nis also shown that EII codes allow for encoding II codes with an uniform\ndistribution of the parity symbols.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Blaum Mario","Hetzler Steven"],"created":"2017-12-21","updated":"2017-12-29","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.08841","title":"Dual Long Short-Term Memory Networks for Sub-Character Representation\n  Learning","abstract":"Characters have commonly been regarded as the minimal processing unit in\nNatural Language Processing (NLP). But many non-latin languages have\nhieroglyphic writing systems, involving a big alphabet with thousands or\nmillions of characters. Each character is composed of even smaller parts, which\nare often ignored by the previous work. In this paper, we propose a novel\narchitecture employing two stacked Long Short-Term Memory Networks (LSTMs) to\nlearn sub-character level representation and capture deeper level of semantic\nmeanings. To build a concrete study and substantiate the efficiency of our\nneural architecture, we take Chinese Word Segmentation as a research case\nexample. Among those languages, Chinese is a typical case, for which every\ncharacter contains several components called radicals. Our networks employ a\nshared radical level embedding to solve both Simplified and Traditional Chinese\nWord Segmentation, without extra Traditional to Simplified Chinese conversion,\nin such a highly end-to-end way the word segmentation can be significantly\nsimplified compared to the previous work. Radical level embeddings can also\ncapture deeper semantic meaning below character level and improve the system\nperformance of learning. By tying radical and character embeddings together,\nthe parameter count is reduced whereas semantic knowledge is shared and\ntransferred between two levels, boosting the performance largely. On 3 out of 4\nBakeoff 2005 datasets, our method surpassed state-of-the-art results by up to\n0.4%. Our results are reproducible, source codes and corpora are available on\nGitHub.","primary_category":"cs","categories":["cs.CL"],"authors":["He Han","Wu Lei","Yang Xiaokun","Yan Hua","Gao Zhimin","Feng Yi","Townsend George"],"created":"2017-12-23","updated":"2018-01-04","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.08971","title":"Human-Centric Data Cleaning [Vision]","abstract":"Data Cleaning refers to the process of detecting and fixing errors in the\ndata. Human involvement is instrumental at several stages of this process,\ne.g., to identify and repair errors, to validate computed repairs, etc. There\nis currently a plethora of data cleaning algorithms addressing a wide range of\ndata errors (e.g., detecting duplicates, violations of integrity constraints,\nmissing values, etc.). Many of these algorithms involve a human in the loop,\nhowever, this latter is usually coupled to the underlying cleaning algorithms.\nThere is currently no end-to-end data cleaning framework that systematically\ninvolves humans in the cleaning pipeline regardless of the underlying cleaning\nalgorithms. In this paper, we highlight key challenges that need to be\naddressed to realize such a framework. We present a design vision and discuss\nscenarios that motivate the need for such a framework to judiciously assist\nhumans in the cleaning process. Finally, we present directions to implement\nsuch a framework.","primary_category":"cs","categories":["cs.DB"],"authors":["Rezig El Kindi","Ouzzani Mourad","Elmagarmid Ahmed K.","Aref Walid G."],"created":"2017-12-24","updated":"2017-12-30","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.09004","title":"RIDI: Robust IMU Double Integration","abstract":"This paper proposes a novel data-driven approach for inertial navigation,\nwhich learns to estimate trajectories of natural human motions just from an\ninertial measurement unit (IMU) in every smartphone. The key observation is\nthat human motions are repetitive and consist of a few major modes (e.g.,\nstanding, walking, or turning). Our algorithm regresses a velocity vector from\nthe history of linear accelerations and angular velocities, then corrects\nlow-frequency bias in the linear accelerations, which are integrated twice to\nestimate positions. We have acquired training data with ground-truth motions\nacross multiple human subjects and multiple phone placements (e.g., in a bag or\na hand). The qualitatively and quantitatively evaluations have demonstrated\nthat our algorithm has surprisingly shown comparable results to full Visual\nInertial navigation. To our knowledge, this paper is the first to integrate\nsophisticated machine learning techniques with inertial navigation, potentially\nopening up a new line of research in the domain of data-driven inertial\nnavigation. We will publicly share our code and data to facilitate further\nresearch.","primary_category":"cs","categories":["cs.CV"],"authors":["Yan Hang","Shan Qi","Furukawa Yasutaka"],"created":"2017-12-24","updated":"2017-12-30","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.09133","title":"Strongly Hierarchical Factorization Machines and ANOVA Kernel Regression","abstract":"High-order parametric models that include terms for feature interactions are\napplied to various data mining tasks, where ground truth depends on\ninteractions of features. However, with sparse data, the high- dimensional\nparameters for feature interactions often face three issues: expensive\ncomputation, difficulty in parameter estimation and lack of structure. Previous\nwork has proposed approaches which can partially re- solve the three issues. In\nparticular, models with factorized parameters (e.g. Factorization Machines) and\nsparse learning algorithms (e.g. FTRL-Proximal) can tackle the first two issues\nbut fail to address the third. Regarding to unstructured parameters,\nconstraints or complicated regularization terms are applied such that\nhierarchical structures can be imposed. However, these methods make the\noptimization problem more challenging. In this work, we propose Strongly\nHierarchical Factorization Machines and ANOVA kernel regression where all the\nthree issues can be addressed without making the optimization problem more\ndifficult. Experimental results show the proposed models significantly\noutperform the state-of-the-art in two data mining tasks: cold-start user\nresponse time prediction and stock volatility prediction.","primary_category":"cs","categories":["cs.LG"],"authors":["Guo Ruocheng","Alvari Hamidreza","Shakarian Paulo"],"created":"2017-12-25","updated":"2018-01-05","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.09161","title":"Segmenting Sky Pixels in Images","abstract":"Outdoor scene parsing models are often trained on ideal datasets and produce\nquality results. However, this leads to a discrepancy when applied to the real\nworld. The quality of scene parsing, particularly sky classification, decreases\nin night time images, images involving varying weather conditions, and scene\nchanges due to seasonal weather. This project focuses on approaching these\nchallenges by using a state-of-the-art model in conjunction with a non-ideal\ndataset: SkyFinder and a subset from SUN database with Sky object. We focus\nspecifically on sky segmentation, the task of determining sky and not-sky\npixels, and improving upon an existing state-of-the-art model: RefineNet. As a\nresult of our efforts, we have seen an improvement of 10-15% in the average MCR\ncompared to the prior methods on SkyFinder dataset. We have also improved from\nan off-the shelf-model in terms of average mIOU by nearly 35%. Further, we\nanalyze our trained models on images w.r.t two aspects: times of day and\nweather, and find that, in spite of facing same challenges as prior methods,\nour trained models significantly outperform them.","primary_category":"cs","categories":["cs.CV"],"authors":["La Place Cecilia","Khan Aisha Urooj","Borji Ali"],"created":"2017-12-25","updated":"2018-01-08","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.09163","title":"Computer Algebra Methods in Control Systems","abstract":"As dynamic and control systems become more complex, relying purely on\nnumerical computations for systems analysis and design might become extremely\nexpensive or totally infeasible. Computer algebra can act as an enabler for\nanalysis and design of such complex systems. It also provides means for\ncharacterization of all solutions and studying them before realizing a\nparticular solution. This note provides a brief survey on some of the\napplications of symbolic computations in control systems analysis and design.","primary_category":"cs","categories":["cs.SY","cs.SC","math.OC"],"authors":["Abbaszadeh Masoud"],"created":"2017-12-25","updated":"2017-12-28","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.09227","title":"A Real-Time Autonomous Highway Accident Detection Model Based on Big\n  Data Processing and Computational Intelligence","abstract":"Due to increasing urban population and growing number of motor vehicles,\ntraffic congestion is becoming a major problem of the 21st century. One of the\nmain reasons behind traffic congestion is accidents which can not only result\nin casualties and losses for the participants, but also in wasted and lost time\nfor the others that are stuck behind the wheels. Early detection of an accident\ncan save lives, provides quicker road openings, hence decreases wasted time and\nresources, and increases efficiency. In this study, we propose a preliminary\nreal-time autonomous accident-detection system based on computational\nintelligence techniques. Istanbul City traffic-flow data for the year 2015 from\nvarious sensor locations are populated using big data processing methodologies.\nThe extracted features are then fed into a nearest neighbor model, a regression\ntree, and a feed-forward neural network model. For the output, the possibility\nof an occurrence of an accident is predicted. The results indicate that even\nthough the number of false alarms dominates the real accident cases, the system\ncan still provide useful information that can be used for status verification\nand early reaction to possible accidents.","primary_category":"cs","categories":["cs.AI","stat.ML"],"authors":["Ozbayoglu A. Murat","Kucukayan Gokhan","Dogdu Erdogan"],"created":"2017-12-26","updated":" ","doi":"10.1109\/BigData.2016.7840798"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.09282","title":"Fog Computing based SDI Framework for Mineral Resources Information\n  Infrastructure Management in India","abstract":"Spatial Data Infrastructure (SDI) is an important concept for sharing spatial\ndata across the web. With cumulative techniques with spatial cloud computing\nand fog computing, SDI has the greater potential and has been emerged as a tool\nfor processing, analysis and transmission of spatial data. The Fog computing is\na paradigm where Fog devices help to increase throughput and reduce latency at\nthe edge of the client with respect to cloud computing environment. This paper\nproposed and developed a fog computing based SDI framework for mining analytics\nfrom spatial big data for mineral resources management in India. We built a\nprototype using Raspberry Pi, an embedded microprocessor. We validated by\ntaking suitable case study of mineral resources management in India by doing\npreliminary analysis including overlay analysis. Results showed that fog\ncomputing hold a great promise for analysis of spatial data. We used open\nsource GIS i.e. QGIS and QIS plugin for reducing the transmission to cloud from\nthe fog node.","primary_category":"cs","categories":["cs.DC"],"authors":["Barik Rabindra K.","Lenka Rakesh K.","Simha N. V. R.","Dubey Harishchandra","Mankodiya Kunal"],"created":"2017-12-26","updated":"2018-01-11","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.09382","title":"Audio to Body Dynamics","abstract":"We present a method that gets as input an audio of violin or piano playing,\nand outputs a video of skeleton predictions which are further used to animate\nan avatar. The key idea is to create an animation of an avatar that moves their\nhands similarly to how a pianist or violinist would do, just from audio. Aiming\nfor a fully detailed correct arms and fingers motion is a goal, however, it's\nnot clear if body movement can be predicted from music at all. In this paper,\nwe present the first result that shows that natural body dynamics can be\npredicted at all. We built an LSTM network that is trained on violin and piano\nrecital videos uploaded to the Internet. The predicted points are applied onto\na rigged avatar to create the animation.","primary_category":"cs","categories":["eess.AS","cs.CV","cs.SD"],"authors":["Shlizerman Eli","Dery Lucio M.","Schoen Hayden","Kemelmacher-Shlizerman Ira"],"created":"2017-12-19","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.09495","title":"Rewriting in Free Hypergraph Categories","abstract":"We study rewriting for equational theories in the context of symmetric\nmonoidal categories where there is a separable Frobenius monoid on each object.\nThese categories, also called hypergraph categories, are increasingly relevant:\nFrobenius structures recently appeared in cross-disciplinary applications,\nincluding the study of quantum processes, dynamical systems and natural\nlanguage processing. In this work we give a combinatorial characterisation of\narrows of a free hypergraph category as cospans of labelled hypergraphs and\nestablish a precise correspondence between rewriting modulo Frobenius structure\non the one hand and double-pushout rewriting of hypergraphs on the other. This\ninterpretation allows to use results on hypergraphs to ensure decidability of\nconfluence for rewriting in a free hypergraph category. Our results generalise\nprevious approaches where only categories generated by a single object (props)\nwere considered.","primary_category":"cs","categories":["cs.LO"],"authors":["Zanasi Fabio"],"created":"2017-12-27","updated":"2018-01-03","doi":"10.4204\/EPTCS.263.2"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.09709","title":"Report: Dynamic Eye Movement Matching and Visualization Tool in Neuro\n  Gesture","abstract":"In the research of the impact of gestures using by a lecturer, one\nchallenging task is to infer the attention of a group of audiences. Two\nimportant measurements that can help infer the level of attention are eye\nmovement data and Electroencephalography (EEG) data. Under the fundamental\nassumption that a group of people would look at the same place if they all pay\nattention at the same time, we apply a method, \"Time Warp Edit Distance\", to\ncalculate the similarity of their eye movement trajectories. Moreover, we also\ncluster eye movement pattern of audiences based on these pair-wised similarity\nmetrics. Besides, since we don't have a direct metric for the \"attention\"\nground truth, a visual assessment would be beneficial to evaluate the\ngesture-attention relationship. Thus we also implement a visualization tool.","primary_category":"cs","categories":["cs.NE","cs.AI","cs.CV"],"authors":["Xu Qiangeng","Kender John"],"created":"2017-12-27","updated":"2018-01-07","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.09722","title":"Satellite-Based Continuous-Variable Quantum Communications:\n  State-of-the-Art and a Predictive Outlook","abstract":"The recent launch of the Micius quantum-enabled satellite heralds a major\nstep forward for long-range quantum communication. Using single-photon\ndiscrete-variable quantum states, this exciting new development proves beyond\nany doubt that all of the quantum protocols previously deployed over limited\nranges in terrestrial experiments can, in fact, be translated to global\ndistances via the use of low-orbit satellites. In this work, we survey the\nimminent extension of space-based quantum communication to the\ncontinuous-variable regime - the quantum regime perhaps most closely related to\nclassical wireless communications. The CV regime offers the potential for\nincreased communication performance and represents the next major step forward\nfor quantum communications and the development of the global quantum internet.","primary_category":"cs","categories":["quant-ph","cs.CR","cs.IT","math.IT"],"authors":["Hosseinidehaj Nedasadat","Malaney Robert","Ng Soon Xin","Hanzo Lajos"],"created":"2017-12-27","updated":"2018-01-08","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.09752","title":"Designing Fair Ranking Schemes","abstract":"Items from a database are often ranked based on a combination of multiple\ncriteria. A user may have the flexibility to accept combinations that weigh\nthese criteria differently, within limits. On the other hand, this choice of\nweights can greatly affect the fairness of the produced ranking. In this paper,\nwe develop a system that helps users choose criterion weights that lead to\ngreater fairness.\n  We consider ranking functions that compute the score of each item as a\nweighted sum of (numeric) attribute values, and then sort items on their score.\nEach ranking function can be expressed as a vector of weights, or as a point in\na multi-dimensional space. For a broad range of fairness criteria, we show how\nto efficiently identify regions in this space that satisfy these criteria.\nUsing this identification method, our system is able to tell users whether\ntheir proposed ranking function satisfies the desired fairness criteria and, if\nit does not, to suggest the smallest modification that does. We develop\nuser-controllable approximation that and indexing techniques that are applied\nduring preprocessing, and support sub-second response times during the online\nphase. Our extensive experiments on real datasets demonstrate that our methods\nare able to find solutions that satisfy fairness criteria effectively and\nefficiently.","primary_category":"cs","categories":["cs.DB"],"authors":["Asudeh Abolfazl","Jagadish H. V.","Stoyanovich Julia","Das Gautam"],"created":"2017-12-27","updated":"2018-01-04","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.09786","title":"A linear programming approach for designing multilevel PWM waveforms","abstract":"This paper considers the problem of designing a multilevel pulse width\nmodulated waveform (PWM) with a prescribed harmonic content. Multilevel PWM\ndesign plays a major role in many diverse engineering disciplines. In power\nelectronics, multilevel PWM design corresponds to determining the inverter\nswitching times and levels for selective harmonic elimination and harmonic\ncompensation. In mechatronics, the same design corresponds to shaping input\nsignals to damp residual vibrations in flexible structures. More generally, in\nmost applications, the aim of PWM design is to minimize the total harmonic\ndistortion while adhering to a prescribed harmonic content. The solution\napproach presented in this paper is based on linear programming with the\nobjective of minimizing the total harmonic distortion. This objective is\nachieved within an arbitrarily small bound of the optimal solution. In\naddition, the linear programming formulation makes the design of such switching\nwaveforms computationally tractable and efficient. Simulations are provided for\ncorroboration.","primary_category":"cs","categories":["cs.SY"],"authors":["Mohan Shravan","Bhikkaji Bharath"],"created":"2017-12-28","updated":"2018-01-02","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.09846","title":"Rating Protocol Design for Extortion and Cooperation in the\n  Crowdsourcing Contest Dilemma","abstract":"Crowdsourcing has emerged as a paradigm for leveraging human intelligence and\nactivity to solve a wide range of tasks. However, strategic workers will find\nenticement in their self-interest to free-ride and attack in a crowdsourcing\ncontest dilemma game. Hence, incentive mechanisms are of great importance to\novercome the inefficiency of the socially undesirable equilibrium. Existing\nincentive mechanisms are not effective in providing incentives for cooperation\nin crowdsourcing competitions due to the following features: heterogeneous\nworkers compete against each other in a crowdsourcing platform with imperfect\nmonitoring. In this paper, we take these features into consideration, and\ndevelop a novel game-theoretic design of rating protocols, which integrates\nbinary rating labels with differential pricing to maximize the requester's\nutility, by extorting selfish workers and enforcing cooperation among them. By\nquantifying necessary and sufficient conditions for the sustainable social\nnorm, we formulate the problem of maximizing the revenue of the requester among\nall sustainable rating protocols, provide design guidelines for optimal rating\nprotocols, and design a low-complexity algorithm to select optimal design\nparameters which are related to differential punishments and pricing schemes.\nSimulation results demonstrate how intrinsic parameters impact on design\nparameters, as well as the performance gain of the proposed rating protocol.","primary_category":"cs","categories":["cs.GT"],"authors":["Lu Jianfeng","Xin Yun","Zhang Zhao","Tang Shaojie","Yan Songyuan","Tang Changbing"],"created":"2017-12-28","updated":"2017-12-29","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.09923","title":"What do we need to build explainable AI systems for the medical domain?","abstract":"Artificial intelligence (AI) generally and machine learning (ML) specifically\ndemonstrate impressive practical success in many different application domains,\ne.g. in autonomous driving, speech recognition, or recommender systems. Deep\nlearning approaches, trained on extremely large data sets or using\nreinforcement learning methods have even exceeded human performance in visual\ntasks, particularly on playing games such as Atari, or mastering the game of\nGo. Even in the medical domain there are remarkable results. The central\nproblem of such models is that they are regarded as black-box models and even\nif we understand the underlying mathematical principles, they lack an explicit\ndeclarative knowledge representation, hence have difficulty in generating the\nunderlying explanatory structures. This calls for systems enabling to make\ndecisions transparent, understandable and explainable. A huge motivation for\nour approach are rising legal and privacy aspects. The new European General\nData Protection Regulation entering into force on May 25th 2018, will make\nblack-box approaches difficult to use in business. This does not imply a ban on\nautomatic learning approaches or an obligation to explain everything all the\ntime, however, there must be a possibility to make the results re-traceable on\ndemand. In this paper we outline some of our research topics in the context of\nthe relatively new area of explainable-AI with a focus on the application in\nmedicine, which is a very special domain. This is due to the fact that medical\nprofessionals are working mostly with distributed heterogeneous and complex\nsources of data. In this paper we concentrate on three sources: images, *omics\ndata and text. We argue that research in explainable-AI would generally help to\nfacilitate the implementation of AI\/ML in the medical domain, and specifically\nhelp to facilitate transparency and trust.","primary_category":"cs","categories":["cs.AI","stat.ML"],"authors":["Holzinger Andreas","Biemann Chris","Pattichis Constantinos S.","Kell Douglas B."],"created":"2017-12-28","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.09943","title":"Toward Continual Learning for Conversational Agents","abstract":"While end-to-end neural conversation models have led to promising advances in\nreducing hand-crafted features and errors induced by the traditional complex\nsystem architecture, they typically require an enormous amount of data due to\nthe lack of modularity. Previous studies adopted a hybrid approach with\nknowledge-based components either to abstract out domain-specific information\nor to augment data to cover more diverse patterns. On the contrary, we propose\nto directly address the problem using recent developments in the space of\ncontinual learning for neural models. Specifically, we adopt a\ndomain-independent neural conversational model and introduce a novel neural\ncontinual learning algorithm that allows a conversational agent to accumulate\nskills across different tasks in a data-efficient way. To the best of our\nknowledge, this is the first work that applies continual learning to\nconversation systems. We verified the efficacy of our method through a\nconversational skill transfer from either synthetic dialogs or human-human\ndialogs to human-computer conversations in a customer support domain.","primary_category":"cs","categories":["cs.CL","cs.AI","cs.HC"],"authors":["Lee Sungjin"],"created":"2017-12-28","updated":"2018-01-09","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.10041","title":"Caching under Content Freshness Constraints","abstract":"Several real-time delay-sensitive applications pose varying degrees of\nfreshness demands on the requested content. The performance of cache\nreplacement policies that are agnostic to these demands is likely to be\nsub-optimal. Motivated by this concern, in this paper, we study caching\npolicies under a request arrival process which incorporates user freshness\ndemands. We consider the performance metric to be the steady-state cache hit\nprobability. We first provide a universal upper bound on the performance of any\ncaching policy. We then analytically obtain the content-wise hit-rates for the\nLeast Popular (LP) policy and provide sufficient conditions for the asymptotic\noptimality of cache performance under this policy. Next, we obtain an accurate\napproximation for the LRU hit-rates in the regime of large content population.\nTo this end, we map the characteristic time of a content in the LRU policy to\nthe classical Coupon Collector's Problem and show that it sharply concentrates\naround its mean. Further, we develop modified versions of these policies which\neject cache redundancies present in the form of stale contents. Finally, we\npropose a new policy which outperforms the above policies by explicitly using\nfreshness specifications of user requests to prioritize among the cached\ncontents. We corroborate our analytical insights with extensive simulations.","primary_category":"cs","categories":["cs.NI"],"authors":["Poojary Pawan","Moharir Sharayu","Jagannathan Krishna"],"created":"2017-12-28","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.10042","title":"Discriminative and Geometry Aware Unsupervised Domain Adaptation","abstract":"Domain adaptation (DA) aims to generalize a learning model across training\nand testing data despite the mismatch of their data distributions. In light of\na theoretical estimation of upper error bound, we argue in this paper that an\neffective DA method should 1) search a shared feature subspace where source and\ntarget data are not only aligned in terms of distributions as most state of the\nart DA methods do, but also discriminative in that instances of different\nclasses are well separated; 2) account for the geometric structure of the\nunderlying data manifold when inferring data labels on the target domain. In\ncomparison with a baseline DA method which only cares about data distribution\nalignment between source and target, we derive three different DA models,\nnamely CDDA, GA-DA, and DGA-DA, to highlight the contribution of Close yet\nDiscriminative DA(CDDA) based on 1), Geometry Aware DA (GA-DA) based on 2), and\nfinally Discriminative and Geometry Aware DA (DGA-DA) implementing jointly 1)\nand 2). Using both synthetic and real data, we show the effectiveness of the\nproposed approach which consistently outperforms state of the art DA methods\nover 36 image classification DA tasks through 6 popular benchmarks. We further\ncarry out in-depth analysis of the proposed DA method in quantifying the\ncontribution of each term of our DA model and provide insights into the\nproposed DA methods in visualizing both real and synthetic data.","primary_category":"cs","categories":["cs.CV"],"authors":["Luo Lingkun","Chen Liming","Hu Shiqiang","Lu Ying","Wang Xiaofang"],"created":"2017-12-28","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.10043","title":"Robust Covariate Shift Prediction with General Losses and Feature Views","abstract":"Covariate shift relaxes the widely-employed independent and identically\ndistributed (IID) assumption by allowing different training and testing input\ndistributions. Unfortunately, common methods for addressing covariate shift by\ntrying to remove the bias between training and testing distributions using\nimportance weighting often provide poor performance guarantees in theory and\nunreliable predictions with high variance in practice. Recently developed\nmethods that construct a predictor that is inherently robust to the\ndifficulties of learning under covariate shift are restricted to minimizing\nlogloss and can be too conservative when faced with high-dimensional learning\ntasks. We address these limitations in two ways: by robustly minimizing various\nloss functions, including non-convex ones, under the testing distribution; and\nby separately shaping the influence of covariate shift according to different\nfeature-based views of the relationship between input variables and example\nlabels. These generalizations make robust covariate shift prediction applicable\nto more task scenarios. We demonstrate the benefits on classification under\ncovariate shift tasks.","primary_category":"cs","categories":["cs.LG","stat.ML"],"authors":["Liu Anqi","Ziebart Brian D."],"created":"2017-12-28","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.10050","title":"Kernel Robust Bias-Aware Prediction under Covariate Shift","abstract":"Under covariate shift, training (source) data and testing (target) data\ndiffer in input space distribution, but share the same conditional label\ndistribution. This poses a challenging machine learning task. Robust Bias-Aware\n(RBA) prediction provides the conditional label distribution that is robust to\nthe worstcase logarithmic loss for the target distribution while matching\nfeature expectation constraints from the source distribution. However,\nemploying RBA with insufficient feature constraints may result in high\ncertainty predictions for much of the source data, while leaving too much\nuncertainty for target data predictions. To overcome this issue, we extend the\nrepresenter theorem to the RBA setting, enabling minimization of regularized\nexpected target risk by a reweighted kernel expectation under the source\ndistribution. By applying kernel methods, we establish consistency guarantees\nand demonstrate better performance of the RBA classifier than competing methods\non synthetically biased UCI datasets as well as datasets that have natural\ncovariate shift.","primary_category":"cs","categories":["cs.LG","cs.AI","stat.ML"],"authors":["Liu Anqi","Fathony Rizal","Ziebart Brian D."],"created":"2017-12-28","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.10056","title":"Inferring Formal Properties of Production Key-Value Stores","abstract":"Production distributed systems are challenging to formally verify, in\nparticular when they are based on distributed protocols that are not rigorously\ndescribed or fully understood. In this paper, we derive models and properties\nfor two core distributed protocols used in eventually consistent production\nkey-value stores such as Riak and Cassandra. We propose a novel modeling called\ncertified program models, where complete distributed systems are captured as\nprograms written in traditional systems languages such as concurrent C.\nSpecifically, we model the read-repair and hinted-handoff recovery protocols as\nconcurrent C programs, test them for conformance with real systems, and then\nverify that they guarantee eventual consistency, modeling precisely the\nspecification as well as the failure assumptions under which the results hold.","primary_category":"cs","categories":["cs.DC","cs.LO"],"authors":["Pek Edgar","Garg Pranav","Rahman Muntasir Raihan","Palmskog Karl","Gupta Indranil","Madhusudan P."],"created":"2017-12-28","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.10058","title":"Abstract Interpretation using a Language of Symbolic Approximation","abstract":"The traditional abstract domain framework for imperative programs suffers\nfrom several shortcomings; in particular it does not allow precise symbolic\nabstractions. To solve these problems, we propose a new abstract interpretation\nframework, based on symbolic expressions used both as an abstraction of the\nprogram, and as the input analyzed by abstract domains. We demonstrate new\napplications of the frame- work: an abstract domain that efficiently propagates\nconstraints across the whole program; a new formalization of functor domains as\napproximate translation, which allows the production of approximate programs,\non which we can perform classical symbolic techniques. We used these to build a\ncomplete analyzer for embedded C programs, that demonstrates the practical\napplicability of the framework.","primary_category":"cs","categories":["cs.SE"],"authors":["Lemerre Matthieu","Bardin S\u00e9bastien"],"created":"2017-12-28","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.10066","title":"Disentangled Representations for Manipulation of Sentiment in Text","abstract":"The ability to change arbitrary aspects of a text while leaving the core\nmessage intact could have a strong impact in fields like marketing and politics\nby enabling e.g. automatic optimization of message impact and personalized\nlanguage adapted to the receiver's profile. In this paper we take a first step\ntowards such a system by presenting an algorithm that can manipulate the\nsentiment of a text while preserving its semantics using disentangled\nrepresentations. Validation is performed by examining trajectories in embedding\nspace and analyzing transformed sentences for semantic preservation while\nexpression of desired sentiment shift.","primary_category":"cs","categories":["cs.CL"],"authors":["Larsson Maria","Nilsson Amanda","K\u00e5geb\u00e4ck Mikael"],"created":"2017-12-22","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.10069","title":"Active Robotic Mapping through Deep Reinforcement Learning","abstract":"We propose an approach to learning agents for active robotic mapping, where\nthe goal is to map the environment as quickly as possible. The agent learns to\nmap efficiently in simulated environments by receiving rewards corresponding to\nhow fast it constructs an accurate map. In contrast to prior work, this\napproach learns an exploration policy based on a user-specified prior over\nenvironment configurations and sensor model, allowing it to specialize to the\nspecifications. We evaluate the approach through a simulated Disaster Mapping\nscenario and find that it achieves performance slightly better than a\nnear-optimal myopic exploration scheme, suggesting that it could be useful in\nmore complicated problem scenarios.","primary_category":"cs","categories":["cs.RO"],"authors":["Barratt Shane"],"created":"2017-12-28","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.10070","title":"Reinforcement Learning with Analogical Similarity to Guide Schema\n  Induction and Attention","abstract":"Research in analogical reasoning suggests that higher-order cognitive\nfunctions such as abstract reasoning, far transfer, and creativity are founded\non recognizing structural similarities among relational systems. Here we\nintegrate theories of analogy with the computational framework of reinforcement\nlearning (RL). We propose a psychology theory that is a computational synergy\nbetween analogy and RL, in which analogical comparison provides the RL learning\nalgorithm with a measure of relational similarity, and RL provides feedback\nsignals that can drive analogical learning. Simulation results support the\npower of this approach.","primary_category":"cs","categories":["cs.AI"],"authors":["Foster James M.","Jones Matt"],"created":"2017-12-28","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.10073","title":"Modelling Noise-Resilient Single-Switch Scanning Systems","abstract":"Single-switch scanning systems allow nonspeaking individuals with motor\ndisabilities to communicate by triggering a single switch (e.g., raising an eye\nbrow). A problem with current single-switch scanning systems is that while they\nresult in reasonable performance in noiseless conditions, for instance via\nsimulation or tests with able-bodied users, they fail to accurately model the\nnoise sources that are introduced when a non-speaking individual with motor\ndisabilities is triggering the switch in a realistic use context. To help\nassist the development of more noise-resilient single-switch scanning systems\nwe have developed a mathematical model of scanning systems which incorporates\nextensive noise modelling. Our model includes an improvement to the standard\nscanning method, which we call fast-scan, which we show via simulation can be\nmore suitable for certain users of scanning systems.","primary_category":"cs","categories":["cs.HC"],"authors":["Nel Emli-Mari","Kristensson Per Ola","MacKay David J. C."],"created":"2017-12-28","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.10077","title":"Aircraft trajectory control with feedback linearization for general\n  nonlinear system","abstract":"The feedback linearization method is further developed for the controller\ndesign on general nonlinear systems. Through the Lyapunov stability theory, the\nintractable nonlinear implicit algebraic control equations are effectively\nsolved, and the asymptotically tracking performance is guaranteed. Moreover, it\nis proved that the controller may be used in an inverse-free version to the\nset-point control. With this method, a nonlinear aircraft outer-loop trajectory\ncontroller is developed. For the concern regarding the controller's robustness,\nthe integral control technique is combined to counteract the adverse effect\nfrom modeling errors. Simulation results verify the well performance of the\nproposed controller.","primary_category":"cs","categories":["cs.SY"],"authors":["Zhang Sheng","Liao Fei","Chen Yanqing","He Kaifeng"],"created":"2017-12-28","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.10081","title":"Low-Level Augmented Bayesian Optimization for Finding the Best Cloud VM","abstract":"With the advent of big data applications, which tends to have longer\nexecution time, choosing the right cloud VM to run these applications has\nsignificant performance as well as economic implications. For example, in our\nlarge-scale empirical study of 107 different workloads on three popular big\ndata systems, we found that a wrong choice can lead to a 20 times slowdown or\nan increase in cost by 10 times.\n  Bayesian optimization is a technique for optimizing expensive (black-box)\nfunctions. Previous attempts have only used instance-level information (such as\n# of cores, memory size) which is not sufficient to represent the search space.\nIn this work, we discover that this may lead to the fragility problem---either\nincurs high search cost or finds only the sub-optimal solution. The central\ninsight of this paper is to use low-level performance information to augment\nthe process of Bayesian Optimization. Our novel low-level augmented Bayesian\nOptimization is rarely worse than current practices and often performs much\nbetter (in 46 of 107 cases). Further, it significantly reduces the search cost\nin nearly half of our case studies.\n  Based on this work, we conclude that it is often insufficient to use\ngeneral-purpose off-the-shelf methods for configuring cloud instances without\naugmenting those methods with essential systems knowledge such as CPU\nutilization, working memory size and I\/O wait time.","primary_category":"cs","categories":["cs.DC"],"authors":["Hsu Chin-Jung","Nair Vivek","Freeh Vincent W.","Menzies Tim"],"created":"2017-12-28","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.10097","title":"Optimizing Wirelessly Powered Crowd Sensing: Trading energy for data","abstract":"To overcome the limited coverage in traditional wireless sensor networks,\n\\emph{mobile crowd sensing} (MCS) has emerged as a new sensing paradigm. To\nachieve longer battery lives of user devices and incentive human involvement,\nthis paper presents a novel approach that seamlessly integrates MCS with\nwireless power transfer, called \\emph{wirelessly powered crowd sensing} (WPCS),\nfor supporting crowd sensing with energy consumption and offering rewards as\nincentives. The optimization problem is formulated to simultaneously maximize\nthe data utility and minimize the energy consumption for service operator, by\njointly controlling wireless-power allocation at the \\emph{access point} (AP)\nas well as sensing-data size, compression ratio, and sensor-transmission\nduration at \\emph{mobile sensor} (MS). Given the fixed compression ratios, the\noptimal power allocation policy is shown to have a \\emph{threshold}-based\nstructure with respect to a defined \\emph{crowd-sensing priority} function for\neach MS. Given fixed sensing-data utilities, the compression policy achieves\nthe optimal compression ratio. Extensive simulations are also presented to\nverify the efficiency of the contributed mechanisms.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Li Xiaoyang","You Changsheng","Andreev Sergey","Gong Yi","Huang Kaibin"],"created":"2017-12-28","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.10107","title":"Objective evaluation metrics for automatic classification of EEG events","abstract":"The evaluation of machine learning algorithms in biomedical fields for\napplications involving sequential data lacks standardization. Common\nquantitative scalar evaluation metrics such as sensitivity and specificity can\noften be misleading depending on the requirements of the application.\nEvaluation metrics must ultimately reflect the needs of users yet be\nsufficiently sensitive to guide algorithm development. Feedback from critical\ncare clinicians who use automated event detection software in clinical\napplications has been overwhelmingly emphatic that a low false alarm rate,\ntypically measured in units of the number of errors per 24 hours, is the single\nmost important criterion for user acceptance. Though using a single metric is\nnot often as insightful as examining performance over a range of operating\nconditions, there is a need for a single scalar figure of merit. In this paper,\nwe discuss the deficiencies of existing metrics for a seizure detection task\nand propose several new metrics that offer a more balanced view of performance.\nWe demonstrate these metrics on a seizure detection task based on the TUH EEG\nCorpus. We show that two promising metrics are a measure based on a concept\nborrowed from the spoken term detection literature, Actual Term-Weighted Value,\nand a new metric, Time-Aligned Event Scoring (TAES), that accounts for the\ntemporal alignment of the hypothesis to the reference annotation. We also\ndemonstrate that state of the art technology based on deep learning, though\nimpressive in its performance, still needs significant improvement before it\nwill meet very strict user acceptance guidelines.","primary_category":"cs","categories":["cs.LG","eess.SP","stat.ML"],"authors":["Ziyabari Saeedeh","Shah Vinit","Golmohammadi Meysam","Obeid Iyad","Picone Joseph"],"created":"2017-12-28","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.10114","title":"An Efficient and Fair Multi-Resource Allocation Mechanism for\n  Heterogeneous Servers","abstract":"Efficient and fair allocation of multiple types of resources is a crucial\nobjective in a cloud\/distributed computing cluster. Users may have diverse\nresource needs. Furthermore, diversity in server properties\/ capabilities may\nmean that only a subset of servers may be usable by a given user. In platforms\nwith such heterogeneity, we identify important limitations in existing\nmulti-resource fair allocation mechanisms, notably Dominant Resource Fairness\n(DRF) and its follow-up work. To overcome such limitations, we propose a new\nserver-based approach; each server allocates resources by maximizing a\nper-server utility function. We propose a specific class of utility functions\nwhich, when appropriately parameterized, adjusts the trade-off between\nefficiency and fairness, and captures a variety of fairness measures (such as\nour recently proposed Per-Server Dominant Share Fairness). We establish\nconditions for the proposed mechanism to satisfy certain properties that are\ngenerally deemed desirable, e.g., envy-freeness, sharing incentive, bottleneck\nfairness, and Pareto optimality. To implement our resource allocation\nmechanism, we develop an iterative algorithm which is shown to be globally\nconvergent. Finally, we show how the proposed mechanism could be implemented in\na distributed fashion. We carry out extensive trace-driven simulations to show\nthe enhanced performance of our proposed mechanism over the existing ones.","primary_category":"cs","categories":["cs.DC"],"authors":["Khamse-Ashari Jalal","Lambadaris Ioannis","Kesidis George","Urgaonkar Bhuvan","Zhao Yiqiang"],"created":"2017-12-28","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.10136","title":"Learning Deep and Compact Models for Gesture Recognition","abstract":"We look at the problem of developing a compact and accurate model for gesture\nrecognition from videos in a deep-learning framework. Towards this we propose a\njoint 3DCNN-LSTM model that is end-to-end trainable and is shown to be better\nsuited to capture the dynamic information in actions. The solution achieves\nclose to state-of-the-art accuracy on the ChaLearn dataset, with only half the\nmodel size. We also explore ways to derive a much more compact representation\nin a knowledge distillation framework followed by model compression. The final\nmodel is less than $1~MB$ in size, which is less than one hundredth of our\ninitial model, with a drop of $7\\%$ in accuracy, and is suitable for real-time\ngesture recognition on mobile devices.","primary_category":"cs","categories":["cs.CV"],"authors":["Mullick Koustav","Namboodiri Anoop M."],"created":"2017-12-29","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.10152","title":"Exploring the significance of using perceptually relevant image\n  decolorization method for scene classification","abstract":"A color image contains luminance and chrominance components representing the\nintensity and color information respectively. The objective of the work\npresented in this paper is to show the significance of incorporating the\nchrominance information for the task of scene classification. An improved\ncolor-to-grayscale image conversion algorithm by effectively incorporating the\nchrominance information is proposed using color-to-gay structure similarity\nindex (C2G-SSIM) and singular value decomposition (SVD) to improve the\nperceptual quality of the converted grayscale images. The experimental result\nanalysis based on the image quality assessment for image decolorization called\nC2G-SSIM and success rate (Cadik and COLOR250 datasets) shows that the proposed\nimage decolorization technique performs better than 8 existing benchmark\nalgorithms for image decolorization. In the second part of the paper, the\neffectiveness of incorporating the chrominance component in scene\nclassification task is demonstrated using the deep belief network (DBN) based\nimage classification system developed using dense scale invariant feature\ntransform (SIFT) as features. The levels of chrominance information\nincorporated by the proposed image decolorization technique is confirmed by the\nimprovement in the overall scene classification accuracy . Also, the overall\nscene classification performance is improved by the combination of models\nobtained using the proposed and the conventional decolorization methods.","primary_category":"cs","categories":["cs.CV"],"authors":["Sowmya V.","Govind D.","Soman K. P."],"created":"2017-12-29","updated":" ","doi":"10.1117\/1.JEI.26.6.063019"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.10155","title":"Secret Sharing for Cloud Data Security","abstract":"Cloud computing helps reduce costs, increase business agility and deploy\nsolutions with a high return on investment for many types of applications.\nHowever, data security is of premium importance to many users and often\nrestrains their adoption of cloud technologies. Various approaches, i.e., data\nencryption, anonymization, replication and verification, help enforce different\nfacets of data security. Secret sharing is a particularly interesting\ncryptographic technique. Its most advanced variants indeed simultaneously\nenforce data privacy, availability and integrity, while allowing computation on\nencrypted data. The aim of this paper is thus to wholly survey secret sharing\nschemes with respect to data security, data access and costs in the\npay-as-you-go paradigm.","primary_category":"cs","categories":["cs.DB","cs.CR"],"authors":["Attasena Varunya","Darmont J\u00e9r\u00f4me","Harbi Nouria"],"created":"2017-12-29","updated":" ","doi":"10.1007\/s00778-017-0470-9"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.10164","title":"Polyp detection inside the capsule endoscopy: an approach for power\n  consumption reduction","abstract":"Capsule endoscopy is a novel and non-invasive method for diagnosis, which\nassists gastroenterologists to monitor the digestive track. Although this new\ntechnology has many advantages over the conventional endoscopy, there are\nweaknesses that limits the usage of this technology. Some weaknesses are due to\nusing small-size batteries. Radio transmitter consumes the largest portion of\nenergy; consequently, a simple way to reduce the power consumption is to reduce\nthe data to be transmitted. Many works are proposed to reduce the amount of\ndata to be transmitted consist of specific compression methods and reduction in\nvideo resolution and frame rate. We proposed a system inside the capsule for\ndetecting informative frames and sending these frames instead of several\nnon-informative frames. In this work, we specifically focused on hardware\nfriendly algorithm (with capability of parallelism and pipeline) for\nimplementation of polyp detection. Two features of positive contrast and\ncustomized edges of polyps are exploited to define whether the frame consists\nof polyp or not. The proposed method is devoid of complex and iterative\nstructure to save power and reduce the response time. Experimental results\nindicate acceptable rate of detection of our work.","primary_category":"cs","categories":["eess.IV","cs.CV"],"authors":["Khorsandi Mohammad Amin","Karimi Nader","Samavi Shadrokh"],"created":"2017-12-29","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.10167","title":"Simple cubic graphs with no short traveling salesman tour","abstract":"Let $tsp(G)$ denote the length of a shortest travelling salesman tour in a\ngraph $G$. We prove that for any $\\varepsilon>0$, there exists a simple\n$2$-connected planar cubic graph $G_1$ such that $tsp(G_1)\\ge\n(1.25-\\varepsilon)\\cdot|V(G_1)|$, a simple $2$-connected bipartite cubic graph\n$G_2$ such that $tsp(G_2)\\ge (1.2-\\varepsilon)\\cdot|V(G_2)|$, and a simple\n$3$-connected cubic graph $G_3$ such that $tsp(G_3)\\ge\n(1.125-\\varepsilon)\\cdot|V(G_3)|$.","primary_category":"cs","categories":["cs.DM"],"authors":["Luko\u0165ka Robert","Maz\u00e1k J\u00e1n"],"created":"2017-12-29","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.10179","title":"RedDwarfData: a simplified dataset of StarCraft matches","abstract":"The game Starcraft is one of the most interesting arenas to test new machine\nlearning and computational intelligence techniques; however, StarCraft matches\ntake a long time and creating a good dataset for training can be hard. Besides,\nanalyzing match logs to extract the main characteristics can also be done in\nmany different ways to the point that extracting and processing data itself can\ntake an inordinate amount of time and of course, depending on what you choose,\ncan bias learning algorithms. In this paper we present a simplified dataset\nextracted from the set of matches published by Robinson and Watson, which we\nhave called RedDwarfData, containing several thousand matches processed to\nframes, so that temporal studies can also be undertaken. This dataset is\navailable from GitHub under a free license. An initial analysis and appraisal\nof these matches is also made.","primary_category":"cs","categories":["cs.AI"],"authors":["Merelo-Guerv\u00f3s Juan J.","Fern\u00e1ndez-Ares Antonio","Caballero Antonio \u00c1lvarez","Garc\u00eda-S\u00e1nchez Pablo","Rivas Victor"],"created":"2017-12-29","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.10190","title":"Detecting Cross-Lingual Plagiarism Using Simulated Word Embeddings","abstract":"Cross-lingual plagiarism (CLP) occurs when texts written in one language are\ntranslated into a different language and used without acknowledging the\noriginal sources. One of the most common methods for detecting CLP requires\nonline machine translators (such as Google or Microsoft translate) which are\nnot always available, and given that plagiarism detection typically involves\nlarge document comparison, the amount of translations required would overwhelm\nan online machine translator, especially when detecting plagiarism over the\nweb. In addition, when translated texts are replaced with their synonyms, using\nonline machine translators to detect CLP would result in poor performance. This\npaper addresses the problem of cross-lingual plagiarism detection (CLPD) by\nproposing a model that uses simulated word embeddings to reproduce the\npredictions of an online machine translator (Google translate) when detecting\nCLP. The simulated embeddings comprise of translated words in different\nlanguages mapped in a common space, and replicated to increase the prediction\nprobability of retrieving the translations of a word (and their synonyms) from\nthe model. Unlike most existing models, the proposed model does not require\nparallel corpora, and accommodates multiple languages (multi-lingual). We\ndemonstrated the effectiveness of the proposed model in detecting CLP in\nstandard datasets that contain CLP cases, and evaluated its performance against\na state-of-the-art baseline that relies on online machine translator (T+MA\nmodel). Evaluation results revealed that the proposed model is not only\neffective in detecting CLP, it outperformed the baseline. The results indicate\nthat CLP could be detected with state-of-the-art performances by leveraging the\nprediction accuracy of an internet translator with word embeddings, without\nrelying on internet translators.","primary_category":"cs","categories":["cs.CL","cs.IR"],"authors":["Thompson Victor"],"created":"2017-12-29","updated":"2018-01-03","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.10191","title":"Coupling of Magneto-Thermal and Mechanical Superconducting Magnet Models\n  by Means of Mesh-Based Interpolation","abstract":"In this paper we present an algorithm for the coupling of magneto-thermal and\nmechanical finite element models representing superconducting accelerator\nmagnets. The mechanical models are used during the design of the mechanical\nstructure as well as the optimization of the magnetic field quality under\nnominal conditions. The magneto-thermal models allow for the analysis of\ntransient phenomena occurring during quench initiation, propagation, and\nprotection. Mechanical analysis of quenching magnets is of high importance\nconsidering the design of new protection systems and the study of new\nsuperconductor types. We use field\/circuit coupling to determine temperature\nand electromagnetic force evolution during the magnet discharge. These\nquantities are provided as a load to existing mechanical models. The models are\ndiscretized with different meshes and, therefore, we employ a mesh-based\ninterpolation method to exchange coupled quantities. The coupling algorithm is\nillustrated with a simulation of a mechanical response of a standalone\nhigh-field dipole magnet protected with CLIQ (Coupling-Loss Induced Quench)\ntechnology.","primary_category":"cs","categories":["physics.acc-ph","cs.CE","math.NA","physics.comp-ph"],"authors":["Maciejewski Micha\u0142","Bayrasy Pascal","Wolf Klaus","Wilczek Micha\u0142","Auchmann Bernhard","Griesemer Tina","Bortot Lorenzo","Prioli Marco","Navarro Alejandro Manuel Fernandez","Sch\u00f6ps Sebastian","Garcia Idoia Cortes","Verweij Arjan"],"created":"2017-12-29","updated":" ","doi":"10.1109\/TASC.2017.2786721"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.10193","title":"A multi-candidate electronic voting scheme with unlimited participants","abstract":"In this paper a new multi-candidate electronic voting scheme is constructed\nwith unlimited participants. The main idea is to express a ballot to allow\nvoting for up to k out of the m candidates and unlimited participants. The\npurpose of vote is to select more than one winner among $m$ candidates. Our\nresult is complementary to the result by Sun peiyong$'$ s scheme, in the sense,\ntheir scheme is not amenable for large-scale electronic voting due to flaw of\nballot structure. In our scheme the vote is split and hidden, and tallying is\nmade for $G\\ddot{o}del$ encoding in decimal base without any trusted third\nparty, and the result does not rely on any traditional cryptography or\ncomputational intractable assumption. Thus the proposed scheme not only solves\nthe problem of ballot structure, but also achieves the security including\nperfect ballot secrecy, receipt-free, robustness, fairness and\ndispute-freeness.","primary_category":"cs","categories":["cs.CR"],"authors":["Zhao Xi","Ding Yong","Zhao Quanyu"],"created":"2017-12-29","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.10201","title":"Metascheduling of HPC Jobs in Day-Ahead Electricity Markets","abstract":"High performance grid computing is a key enabler of large scale collaborative\ncomputational science. With the promise of exascale computing, high performance\ngrid systems are expected to incur electricity bills that grow super-linearly\nover time. In order to achieve cost effectiveness in these systems, it is\nessential for the scheduling algorithms to exploit electricity price\nvariations, both in space and time, that are prevalent in the dynamic\nelectricity price markets. In this paper, we present a metascheduling algorithm\nto optimize the placement of jobs in a compute grid which consumes electricity\nfrom the day-ahead wholesale market. We formulate the scheduling problem as a\nMinimum Cost Maximum Flow problem and leverage queue waiting time and\nelectricity price predictions to accurately estimate the cost of job execution\nat a system. Using trace based simulation with real and synthetic workload\ntraces, and real electricity price data sets, we demonstrate our approach on\ntwo currently operational grids, XSEDE and NorduGrid. Our experimental setup\ncollectively constitute more than 433K processors spread across 58 compute\nsystems in 17 geographically distributed locations. Experiments show that our\napproach simultaneously optimizes the total electricity cost and the average\nresponse time of the grid, without being unfair to users of the local batch\nsystems.","primary_category":"cs","categories":["cs.DC"],"authors":["Murali Prakash","Vadhiyar Sathish"],"created":"2017-12-29","updated":" ","doi":"10.1109\/TPDS.2017.2769082"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.10210","title":"Dynamic Load-Balancing Vertical Control for Large-Scale Software-Defined\n  Internet of Things","abstract":"As the global Internet of things increasingly is popular with consumers and\nbusiness environment, network flow management has become an important topic to\noptimize the performance on Internet of Things. The rigid existing Internet of\nthings (IoT) architecture blocks current traffic management technology to\nprovide a real differentiated service for large-scale IoT. Software-defined\nInternet of Things (SD-IoT) is a new computing paradigm that separates control\nplane and data plane, and enables centralized logic control. In this paper, we\nfirst present a general framework for SD-IoT, which consists of two main\ncomponents: SD-IoT controllers and SD-IoT switches. The controllers of SD-IoT\nuses resource pooling technology, and the pool is responsible for the\ncentralized control of the entire network. The switches of SD-IoT integrate\nwith the gateway functions, which is responsible for data access and\nforwarding. The SD-IoT controller pool is designed as a vertical control\narchitecture, which includes the main control layer and the base control layer.\nThe controller (main controller) of the main control layer interacts upward\nwith the application layer, interacts with the base control layer downwards,\nand the controller (base controller) of the basic control layer interacts with\nthe data forwarding layer. We propose a dynamic balancing algorithm of the main\ncontroller based on election mechanism and a dynamic load balancing algorithm\nof the basic controller based on the balanced delay, respectively. The\nexperimental results show that the dynamic balancing algorithm based on the\nelection mechanism can ensure the consistency of the messages between the main\ncontrollers, and the dynamic load balancing algorithm based on the balanced\ndelay can balance between these different workloads in the basic controllers.","primary_category":"cs","categories":["cs.NI"],"authors":["Zhang Lianming","Zhong Xiaoxun","Wei Yehua","Yang Kun"],"created":"2017-12-29","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.10211","title":"Learning Deep Similarity Models with Focus Ranking for Fabric Image\n  Retrieval","abstract":"Fabric image retrieval is beneficial to many applications including clothing\nsearching, online shopping and cloth modeling. Learning pairwise image\nsimilarity is of great importance to an image retrieval task. With the\nresurgence of Convolutional Neural Networks (CNNs), recent works have achieved\nsignificant progresses via deep representation learning with metric embedding,\nwhich drives similar examples close to each other in a feature space, and\ndissimilar ones apart from each other. In this paper, we propose a novel\nembedding method termed focus ranking that can be easily unified into a CNN for\njointly learning image representations and metrics in the context of\nfine-grained fabric image retrieval. Focus ranking aims to rank similar\nexamples higher than all dissimilar ones by penalizing ranking disorders via\nthe minimization of the overall cost attributed to similar samples being ranked\nbelow dissimilar ones. At the training stage, training samples are organized\ninto focus ranking units for efficient optimization. We build a large-scale\nfabric image retrieval dataset (FIRD) with about 25,000 images of 4,300\nfabrics, and test the proposed model on the FIRD dataset. Experimental results\nshow the superiority of the proposed model over existing metric embedding\nmodels.","primary_category":"cs","categories":["cs.CV"],"authors":["Deng Daiguo","Wang Ruomei","Wu Hefeng","He Huayong","Li Qi","Luo Xiaonan"],"created":"2017-12-29","updated":" ","doi":"10.1016\/j.imavis.2017.12.005"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.10218","title":"On Asymptotic Analysis of Zero-Delay Energy-Distortion Tradeoff Under\n  Additive White Gaussian Noise","abstract":"Asymptotic energy-distortion performance of zero-delay communication\nscenarios under additive white Gaussian noise is investigated. Using\nhigh-resolution analysis for quantizer design, the higher-order term in the\nlogarithm of the distortion (termed the {\\em energy-distortion dispersion}) is\noptimized while keeping the leading term (i.e., {\\em energy-distortion\nexponent}) at its optimal value. For uniform and Gaussian sources, significant\ngains are observed compared to na\\\"{i}vely performed quantization, i.e., aimed\nat optimizing the source coding performance instead of the end-to-end\ndistortion in joint source-channel coding.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Sevin\u00e7 Ceren","Tuncel Ertem"],"created":"2017-12-29","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.10219","title":"Quantum secret sharing for a multipartite system under energy\n  dissipation","abstract":"We propose a protocol for multipartite secret sharing of quantum information\nthrough an \\textit{amplitude damping} quantum channel. This network is, for\nexample, of two organizations communicating with their own employees connected\nvia classical channels locally. We consider a GHZ state distributed among four\nmembers in an asymmetric fashion where the members of a sub-party collaborate\nto decode the received information at their end. The target is to send two bits\nof information in \\textit{one execution} of the protocol. Firstly, we consider\nan ideal channel and observe that our protocol enables decoding of a secret\n2-bit information with unit probability. This is accomplished by one of the\nsenders by the use of a globally operated \\textit{quantum teleportation\noperator}. Secondly, we implement the same protocol in a realistic scenario\nunder energy dissipation by the use of a parameterized \\textit{amplitude\ndamping channel} with variable noise. This noise is associated with energy\ndissipation and hence, loss of probability to distinguish and decode the\ninformation at the receiving end. Finally, we make this task possible through\nan optimization algorithm. Various channel \\textit{quality measures} are also\nquantitatively ascertained.","primary_category":"cs","categories":["quant-ph","cs.IT","math.IT"],"authors":["Singh Siddhant","Srivastava Shivang","Panigrahi Prasanta K."],"created":"2017-12-29","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.10224","title":"Scalable Multi-Domain Dialogue State Tracking","abstract":"Dialogue state tracking (DST) is a key component of task-oriented dialogue\nsystems. DST estimates the user's goal at each user turn given the interaction\nuntil then. State of the art approaches for state tracking rely on deep\nlearning methods, and represent dialogue state as a distribution over all\npossible slot values for each slot present in the ontology. Such a\nrepresentation is not scalable when the set of possible values are unbounded\n(e.g., date, time or location) or dynamic (e.g., movies or usernames).\nFurthermore, training of such models requires labeled data, where each user\nturn is annotated with the dialogue state, which makes building models for new\ndomains challenging. In this paper, we present a scalable multi-domain deep\nlearning based approach for DST. We introduce a novel framework for state\ntracking which is independent of the slot value set, and represent the dialogue\nstate as a distribution over a set of values of interest (candidate set)\nderived from the dialogue history or knowledge. Restricting these candidate\nsets to be bounded in size addresses the problem of slot-scalability.\nFurthermore, by leveraging the slot-independent architecture and transfer\nlearning, we show that our proposed approach facilitates quick adaptation to\nnew domains.","primary_category":"cs","categories":["cs.CL"],"authors":["Rastogi Abhinav","Hakkani-Tur Dilek","Heck Larry"],"created":"2017-12-29","updated":"2018-01-02","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.10230","title":"On quality of implementation of Fortran 2008 complex intrinsic functions\n  on branch cuts","abstract":"Branch cuts in complex functions in combination with signed zero and signed\ninfinity have important uses in fracture mechanics, jet flow and aerofoil\nanalysis. We present benchmarks for validating Fortran 2008 complex functions -\nLOG, SQRT, ASIN, ACOS, ATAN, ASINH, ACOSH and ATANH - on branch cuts with\narguments of all 3 IEEE floating point binary formats: binary32, binary64 and\nbinary128. Results are reported with 8 Fortran 2008 compilers: GCC, Flang,\nCray, Oracle, PGI, Intel, NAG and IBM. Multiple test failures were revealed,\ne.g. wrong signs of results or unexpected overflow, underflow, or NaN. We\nconclude that the quality of implementation of these Fortran 2008 intrinsics in\nmany compilers is not yet sufficient to remove the need for special code for\nbranch cuts. The test results are complemented by conformal maps of the branch\ncuts and detailed derivations of the values of these functions on branch cuts,\nto be used as a reference. The benchmarks are freely available from\ncmplx.sf.net. This work will be of interest to engineers who use complex\nfunctions, as well as to compiler and maths library developers.","primary_category":"cs","categories":["cs.MS","cs.NA"],"authors":["Shterenlikht Anton"],"created":"2017-12-29","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.10232","title":"Dependence Structure Analysis Of Meta-level Metrics in YouTube Videos: A\n  Vine Copula Approach","abstract":"This paper uses vine copula to analyze the multivariate statistical\ndependence in a massive YouTube dataset consisting of 6 million videos over 25\nthousand channels. Specifically we study the statistical dependency of 7\nYouTube meta-level metrics: view count, number of likes, number of comments,\nlength of video title, number of subscribers, click rates, and average\npercentage watching. Dependency parameters such as the Kendall's tau and tail\ndependence coefficients are computed to evaluate the pair-wise dependence of\nthese meta-level metrics. The vine copula model yields several interesting\ndependency structures. We show that view count and number of likes' are in the\ncentral position of the dependence structure. Conditioned on these two metrics,\nthe other five meta-level metrics are virtually independent of each other.\nAlso, Sports, Gaming, Fashion, Comedy videos have similar dependence structure\nto each other, while the News category exhibits a strong tail dependence. We\nalso study Granger causality effects and upload dynamics and their impact on\nview count. Our findings provide a useful understanding of user engagement in\nYouTube.","primary_category":"cs","categories":["cs.SI"],"authors":["Krishnamurthy Vikram","Duan Yan"],"created":"2017-12-29","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.10233","title":"Unifying Theories of Reactive Design Contracts","abstract":"Design-by-contract is an important technique for model-based design in which\na composite system is specified by a collection of contracts that specify the\nbehavioural assumptions and guarantees of each component. In this paper, we\ndescribe a unifying theory for reactive design contracts that provides the\nbasis for modelling and verification of reactive systems. We provide a language\nfor expression and composition of contracts that is supported by a rich\ncalculational theory. In contrast with other semantic models in the literature,\nour theory of contracts allow us to specify both the evolution of state\nvariables and the permissible interactions with the environment. Moreover, our\nmodel of interaction is abstract, and supports, for instance, discrete time,\ncontinuous time, and hybrid computational models. Being based in Unifying\nTheories of Programming (UTP), our theory can be composed with further\ncomputational theories to support semantics for multi-paradigm languages.\nPractical reasoning support is provided via our proof framework, Isabelle\/UTP,\nincluding a proof tactic that reduces a conjecture about a reactive program to\nthree predicates, characterising its assumptions and guarantees about\nintermediate and final observations. Our work advances the state-of-the-art in\nsemantics for reactive languages, description of their contractual\nspecifications, and compositional verification.","primary_category":"cs","categories":["cs.LO"],"authors":["Foster Simon","Cavalcanti Ana","Canham Samuel","Woodcock Jim","Zeyda Frank"],"created":"2017-12-29","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.10243","title":"Threat Modeling Data Analysis in Socio-technical Systems","abstract":"Our decision-making processes are becoming more data driven, based on data\nfrom multiple sources, of different types, processed by a variety of\ntechnologies. As technology becomes more relevant for decision processes, the\nmore likely they are to be subjects of attacks aimed at disrupting their\nexecution or changing their outcome. With the increasing complexity and\ndependencies on technical components, such attempts grow more sophisticated and\ntheir impact will be more severe. This is especially important in scenarios\nwith shared goals, which had to be previously agreed to, or decisions with\nbroad social impact. We need to think about our decisions-making and underlying\ndata analysis processes in a systemic way to correctly evaluate benefits and\nrisks of specific solutions and to design them to be resistant to attacks. To\nreach these goals, we can apply experiences from threat modeling analysis used\nin software security. We will need to adapt these practices to new types of\nthreats, protecting different assets and operating in socio-technical systems.\nWith these changes, threat modeling can become a foundation for implementing\ndetailed technical, organizational or legal mitigations and making our\ndecisions more reliable and trustworthy.","primary_category":"cs","categories":["cs.CY"],"authors":["Ostwald Tomasz"],"created":"2017-12-29","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.10248","title":"Deep Learning Interior Tomography for Region-of-Interest Reconstruction","abstract":"Interior tomography for the region-of-interest (ROI) imaging has advantages\nof using a small detector and reducing X-ray radiation dose. However, standard\nanalytic reconstruction suffers from severe cupping artifacts due to existence\nof null space in the truncated Radon transform. Existing penalized\nreconstruction methods may address this problem but they require extensive\ncomputations due to the iterative reconstruction. Inspired by the recent deep\nlearning approaches to low-dose and sparse view CT, here we propose a deep\nlearning architecture that removes null space signals from the FBP\nreconstruction. Experimental results have shown that the proposed method\nprovides near-perfect reconstruction with about 7-10 dB improvement in PSNR\nover existing methods in spite of significantly reduced run-time complexity.","primary_category":"cs","categories":["cs.CV","cs.AI","cs.LG","stat.ML"],"authors":["Han Yoseob","Gu Jawook","Ye Jong Chul"],"created":"2017-12-29","updated":"2018-01-03","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.10261","title":"Optimal Lower Bounds for Sketching Graph Cuts","abstract":"We study the space complexity of sketching cuts and Laplacian quadratic forms\nof graphs. We show that any data structure which approximately stores the sizes\nof all cuts in an undirected graph on $n$ vertices up to a $1+\\epsilon$ error\nmust use $\\Omega(n\\log n\/\\epsilon^2)$ bits of space in the worst case,\nimproving the $\\Omega(n\/\\epsilon^2)$ bound of Andoni et al. and matching the\nbest known upper bound achieved by spectral sparsifiers. Our proof is based on\na rigidity phenomenon for cut (and spectral) approximation which may be of\nindependent interest: any two $d-$regular graphs which approximate each other's\ncuts significantly better than a random graph approximates the complete graph\nmust overlap in a constant fraction of their edges.","primary_category":"cs","categories":["cs.DS","cs.DM"],"authors":["Carlson Charles","Kolla Alexandra","Srivastava Nikhil","Trevisan Luca"],"created":"2017-12-29","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.10280","title":"First Draft on the xInf Model for Universal Physical Computation and\n  Reverse Engineering of Natural Intelligence","abstract":"Turing Machines are universal computing machines in theory. It has been a\nlong debate whether Turing Machines can simulate the consciousness mind\nbehaviors in the materialistic universe. Three different hypotheses come out of\nsuch debate, in short:(A) Can; (B) Cannot; (C) Super-Turing machines can.\nBecause Turing Machines or other kinds of theoretical computing models are\nabstract objects while behaviors are real observables, this debate involves at\nleast three distinct fields of science and technology: physics, computer\nengineering, and experimental neuroscience. However, the languages used in\nthese different fields are highly heterogeneous and not easily interpretable\nfor each other, making it very difficult to reach partial agreements regarding\nthis debate, Therefore, the main goal of this manuscript is to establish a\nproper language that can translate among those different fields. First, I\npropose a theoretical model for analyzing how theoretical computing machines\nwould physically run in physical time. This model, termed as the xInf, is at\nfirst place Turing-complete in theory, and depending on the properties of\nphysical time, it can be either Turing-equivalent or Super-Turing in the\nphysical universe. The xInf Model is demonstrated to be a suitable universal\nlanguage to translate among physics, computer engineering, and neuroscience.\nFinally, I propose a conjecture that there exists a Minimal Complete Set of\nrules in the xInf Model that enables the construction of a physical machine\nusing inorganic materials that can pass the Turing Test in physical time. I\ncannot demonstrate whether such a conjecture to be testified or falsified on\npaper using finite-order logic, my only solution is physical time itself, i.e.\nan evolutionary competition will eventually tell the conclusion.","primary_category":"cs","categories":["q-bio.NC","cs.AI"],"authors":["Jia Hongbo"],"created":"2017-12-26","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.10282","title":"Boosting the Actor with Dual Critic","abstract":"This paper proposes a new actor-critic-style algorithm called Dual\nActor-Critic or Dual-AC. It is derived in a principled way from the Lagrangian\ndual form of the Bellman optimality equation, which can be viewed as a\ntwo-player game between the actor and a critic-like function, which is named as\ndual critic. Compared to its actor-critic relatives, Dual-AC has the desired\nproperty that the actor and dual critic are updated cooperatively to optimize\nthe same objective function, providing a more transparent way for learning the\ncritic that is directly related to the objective function of the actor. We then\nprovide a concrete algorithm that can effectively solve the minimax\noptimization problem, using techniques of multi-step bootstrapping, path\nregularization, and stochastic dual ascent algorithm. We demonstrate that the\nproposed algorithm achieves the state-of-the-art performances across several\nbenchmarks.","primary_category":"cs","categories":["cs.LG"],"authors":["Dai Bo","Shaw Albert","He Niao","Li Lihong","Song Le"],"created":"2017-12-29","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.10284","title":"Large-Scale Experiment on the Importance of Social Learning and\n  Unimodality in the Wisdom of the Crowd","abstract":"In this study, we build on previous research to understand the conditions\nwithin which the Wisdom of the Crowd (WoC) improves or worsens as a result of\nshowing individuals the predictions of their peers. Our main novel\ncontributions are: 1) a dataset of unprecedented size and detail; 2) we observe\nthe novel effect of the importance of the unimodality of the social information\nshown to individuals: if one does not see only one clear peak in the\ndistribution of the crowd's predictions, the WoC is worsened after social\nexposure; and 3) we estimate social learning weights that we use to show that\nthere exists individuals who are much better at learning from the crowd and can\nbe filtered to improve collective accuracy.","primary_category":"cs","categories":["cs.SI","physics.soc-ph","stat.AP"],"authors":["Adjodah Dhaval","Chong Shi Kai","Leng Yan","Krafft Peter","Pentland Alex"],"created":"2017-12-29","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.10293","title":"Compute--Forward Multiple Access (CFMA): Practical Code Design","abstract":"We present a practical strategy that aims to attain rate points on the\ndominant face of the multiple access channel capacity using a standard low\ncomplexity decoder. This technique is built upon recent theoretical\ndevelopments of Zhu and Gastpar on compute-forward multiple access (CFMA) which\nachieves the capacity of the multiple access channel using a sequential\ndecoder. We illustrate this strategy with off-the-shelf LDPC codes. In the\nfirst stage of decoding, the receiver first recovers a linear combination of\nthe transmitted codewords using the sum-product algorithm (SPA). In the second\nstage, by using the recovered sum-of-codewords as side information, the\nreceiver recovers one of the two codewords using a modified SPA, ultimately\nrecovering both codewords. The main benefit of recovering the sum-of-codewords\ninstead of the codeword itself is that it allows to attain points on the\ndominant face of the multiple access channel capacity without the need of\nrate-splitting or time sharing while maintaining a low complexity in the order\nof a standard point-to-point decoder. This property is also shown to be crucial\nfor some applications, e.g., interference channels. For all the simulations\nwith single-layer binary codes, our proposed practical strategy is shown to be\nwithin \\SI{1.7}{\\decibel} of the theoretical limits, without explicit\noptimization on the off-the-self LDPC codes.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Sula Erixhen","Zhu Jingge","Pastore Adriano","Lim Sung Hoon","Gastpar Michael"],"created":"2017-12-29","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1712.10309","title":"Methods for Detecting Paraphrase Plagiarism","abstract":"Paraphrase plagiarism is one of the difficult challenges facing plagiarism\ndetection systems. Paraphrasing occur when texts are lexically or syntactically\naltered to look different, but retain their original meaning. Most plagiarism\ndetection systems (many of which are commercial based) are designed to detect\nword co-occurrences and light modifications, but are unable to detect severe\nsemantic and structural alterations such as what is seen in many academic\ndocuments. Hence many paraphrase plagiarism cases go undetected. In this paper,\nwe approached the problem of paraphrase plagiarism by proposing methods for\ndetecting the most common techniques (phenomena) used in paraphrasing texts\n(namely; lexical substitution, insertion\/deletion and word and phrase\nreordering), and combined the methods into a paraphrase detection model. We\nevaluated our proposed methods and model on collections containing paraphrase\ntexts. Experimental results show significant improvement in performance when\nthe methods were combined (the proposed model) as opposed to running them\nindividually. The results also show that the proposed paraphrase detection\nmodel outperformed a standard baseline (based on greedy string tilling), and\nprevious studies.","primary_category":"cs","categories":["cs.IR","cs.CL"],"authors":["Thompson Victor"],"created":"2017-12-29","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00005","title":"Analytical Inverter Delay Modeling Using Matlab's Curve Fitting Toolbox","abstract":"This paper presents a new analytical propagation delay model for deep\nsubmicron CMOS inverters. The model is inspired by the key observation that the\ninverter delay is a complicated function of several process parameters as well\nas load capacitance. These relationships are considered by fitting functions\nfor each parameter derived from the Curve Fitting Toolbox in Matlab. Compared\nto SPICE simulations based on the BSIM4 transistor model, the analytical delay\nmodel shows very good accuracy with an average error less than 2% over a wide\nrange of process parameters and output loads. Hence, the proposed model can be\nefficiently used for different technology nodes as well as statistical gate\ndelay characterisation.","primary_category":"cs","categories":["cs.OH","cs.AR"],"authors":["Schneider Walter"],"created":"2017-12-29","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00025","title":"A Deep Belief Network Based Machine Learning System for Risky Host\n  Detection","abstract":"To assure cyber security of an enterprise, typically SIEM (Security\nInformation and Event Management) system is in place to normalize security\nevent from different preventive technologies and flag alerts. Analysts in the\nsecurity operation center (SOC) investigate the alerts to decide if it is truly\nmalicious or not. However, generally the number of alerts is overwhelming with\nmajority of them being false positive and exceeding the SOC's capacity to\nhandle all alerts. There is a great need to reduce the false positive rate as\nmuch as possible. While most previous research focused on network intrusion\ndetection, we focus on risk detection and propose an intelligent Deep Belief\nNetwork machine learning system. The system leverages alert information,\nvarious security logs and analysts' investigation results in a real enterprise\nenvironment to flag hosts that have high likelihood of being compromised. Text\nmining and graph based method are used to generate targets and create features\nfor machine learning. In the experiment, Deep Belief Network is compared with\nother machine learning algorithms, including multi-layer neural network, random\nforest, support vector machine and logistic regression. Results on real\nenterprise data indicate that the deep belief network machine learning system\nperforms better than other algorithms for our problem and is six times more\neffective than current rule-based system. We also implement the whole system\nfrom data collection, label creation, feature engineering to host score\ngeneration in a real enterprise production environment.","primary_category":"cs","categories":["cs.CR","cs.LG","stat.ML"],"authors":["Feng Wangyan","Wu Shuning","Li Xiaodan","Kunkle Kevin"],"created":"2017-12-29","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00035","title":"LaMMos - Latching Mechanism based on Motorized-screw for Reconfigurable\n  Robots and Exoskeleton Suits","abstract":"Reconfigurable robots refer to a category of robots that their components\n(individual joints and links) can be assembled in multiple configurations and\ngeometries. Most of existing latching mechanisms are based on physical tools\nsuch as hooks, cages or magnets, which limit the payload capacity. Therefore,\nrobots re- quire a latching mechanism which can help to reconfigure itself\nwithout sacrificing the payload capability. This paper presents a latching\nmechanism based on the flexible screw attaching principle. In which, actuators\nare used to move the robot links and joints while connecting them with a\nmotorized-screw and dis- connecting them by unfastening the screw. The brackets\nused in our mechanism configuration helps to hold maximum force up to 5000N.\nThe LaMMos - Latching Mechanism based on Motorized- screw has been applied to\nthe DeWaLoP - Developing Water Loss Prevention in-pipe robot. It helps the\nrobot to shrink its body to crawl into the pipe with minimum diameter, by\nrecon- figuring the leg positions. And it helps to recover the legs positions\nto original status once the robot is inside the pipe. Also, LaMMos add\nstiffness to the robot legs by dynamically integrate them to the structure.\nAdditionally, we present an application of the LaMMos mechanism to exoskeleton\nsuits, for easing the mo- tors from the joints when carrying heavy weights for\nlong periods of time. This mechanism offers many interesting opportunities for\nrobotics research in terms of functionality, pay- load and size.","primary_category":"cs","categories":["cs.RO"],"authors":["Mateos Luis A."],"created":"2017-12-27","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00036","title":"An introduction to Graph Data Management","abstract":"A graph database is a database where the data structures for the schema\nand\/or instances are modeled as a (labeled)(directed) graph or generalizations\nof it, and where querying is expressed by graph-oriented operations and type\nconstructors. In this article we present the basic notions of graph databases,\ngive an historical overview of its main development, and study the main current\nsystems that implement them.","primary_category":"cs","categories":["cs.DB"],"authors":["Angles Renzo","Gutierrez Claudio"],"created":"2017-12-29","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00048","title":"Characterizing optimal hierarchical policy inference on graphs via\n  non-equilibrium thermodynamics","abstract":"Hierarchies are of fundamental interest in both stochastic optimal control\nand biological control due to their facilitation of a range of desirable\ncomputational traits in a control algorithm and the possibility that they may\nform a core principle of sensorimotor and cognitive control systems. However, a\ntheoretically justified construction of state-space hierarchies over all\nspatial resolutions and their evolution through a policy inference process\nremains elusive. Here, a formalism for deriving such normative representations\nof discrete Markov decision processes is introduced in the context of graphs.\nThe resulting hierarchies correspond to a hierarchical policy inference\nalgorithm approximating a discrete gradient flow between state-space trajectory\ndensities generated by the prior and optimal policies.","primary_category":"cs","categories":["cs.SY","cs.AI","q-bio.NC"],"authors":["McNamee Daniel"],"created":"2017-12-29","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00061","title":"Multichannel Robot Speech Recognition Database: MChRSR","abstract":"In real human robot interaction (HRI) scenarios, speech recognition\nrepresents a major challenge due to robot noise, background noise and\ntime-varying acoustic channel. This document describes the procedure used to\nobtain the Multichannel Robot Speech Recognition Database (MChRSR). It is\ncomposed of 12 hours of multichannel evaluation data recorded in a real mobile\nHRI scenario. This database was recorded with a PR2 robot performing different\ntranslational and azimuthal movements. Accordingly, 16 evaluation sets were\nobtained re-recording the clean set of the Aurora 4 database in different\nmovement conditions.","primary_category":"cs","categories":["cs.HC","cs.RO"],"authors":["Novoa Jos\u00e9","Escudero Juan Pablo","Fredes Josu\u00e9","Wuth Jorge","Mahu Rodrigo","Yoma N\u00e9stor Becerra"],"created":"2017-12-29","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00062","title":"Dendritic error backpropagation in deep cortical microcircuits","abstract":"Animal behaviour depends on learning to associate sensory stimuli with the\ndesired motor command. Understanding how the brain orchestrates the necessary\nsynaptic modifications across different brain areas has remained a longstanding\npuzzle. Here, we introduce a multi-area neuronal network model in which\nsynaptic plasticity continuously adapts the network towards a global desired\noutput. In this model synaptic learning is driven by a local dendritic\nprediction error that arises from a failure to predict the top-down input given\nthe bottom-up activities. Such errors occur at apical dendrites of pyramidal\nneurons where both long-range excitatory feedback and local inhibitory\npredictions are integrated. When local inhibition fails to match excitatory\nfeedback an error occurs which triggers plasticity at bottom-up synapses at\nbasal dendrites of the same pyramidal neurons. We demonstrate the learning\ncapabilities of the model in a number of tasks and show that it approximates\nthe classical error backpropagation algorithm. Finally, complementing this\ncortical circuit with a disinhibitory mechanism enables attention-like stimulus\ndenoising and generation. Our framework makes several experimental predictions\non the function of dendritic integration and cortical microcircuits, is\nconsistent with recent observations of cross-area learning, and suggests a\nbiological implementation of deep learning.","primary_category":"cs","categories":["q-bio.NC","cs.LG","cs.NE"],"authors":["Sacramento Jo\u00e3o","Costa Rui Ponte","Bengio Yoshua","Senn Walter"],"created":"2017-12-29","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00074","title":"Randomized Communication in Radio Networks","abstract":"A communication network is called a radio network if its nodes exchange\nmessages in the following restricted way. First, a send operation performed by\na node delivers copies of the same message to all directly reachable nodes.\nSecondly, a node can successfully receive an incoming message only if exactly\none of its neighbors sent a message in that step. It is this semantics of how\nports at nodes send and receive messages that defines the networks rather than\nthe fact that only radio waves are used as a medium of communication; but if\nthat is the case then just a single frequency is used. We discuss algorithmic\naspects of exchanging information in such networks, concentrating on\ndistributed randomized protocols. Specific problems and solutions depend a lot\non the topology of the underlying reachability graph and how much the nodes\nknow about it. In single-hop networks each pair of nodes can communicate\ndirectly. This kind of networks is also known as the multiple access channel.\nPopular broadcasting protocols used on such channels are Aloha and the\nexponential backoff. Multi-hop networks may have arbitrary topology and packets\nneed to be routed hopping through a sequence of adjacent nodes. Distributed\nprotocols run by such networks are usually robust enough not to expect the\nnodes to know their neighbors. These ad-hoc networks and protocols model the\nsituation when nodes are mobile and do not rely on a fixed infrastructure.","primary_category":"cs","categories":["cs.NI"],"authors":["Chlebus Bogdan S."],"created":"2017-12-29","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00075","title":"Logarithmic Frequency Scaling and Consistent Frequency Coverage for the\n  Selection of Auditory Filterbank Center Frequencies","abstract":"This paper provides new insights into the problem of selecting filter center\nfrequencies for the auditory filterbanks. We propose to use a constant\nfrequency distance and a consistent frequency coverage as the two metrics that\nmotivate the logarithmic frequency scaling and a regularized selection of\ncenter frequencies. The frequency scaling and the consistent frequency coverage\nhave been derived based on a common harmonic speaker signal model. Furthermore,\nwe have found that the existing linear equivalent rectangular bandwidth (ERB)\nfunction as well as any possible linear ERB approximation can also lead to a\nconsistent frequency coverage. The results are verified and demonstrated using\nthe gammatone filterbank.","primary_category":"cs","categories":["eess.AS","cs.SD"],"authors":["Lin Shoufeng"],"created":"2017-12-29","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00077","title":"Face Synthesis from Visual Attributes via Sketch using Conditional VAEs\n  and GANs","abstract":"Automatic synthesis of faces from visual attributes is an important problem\nin computer vision and has wide applications in law enforcement and\nentertainment. With the advent of deep generative convolutional neural networks\n(CNNs), attempts have been made to synthesize face images from attributes and\ntext descriptions. In this paper, we take a different approach, where we\nformulate the original problem as a stage-wise learning problem. We first\nsynthesize the facial sketch corresponding to the visual attributes and then we\nreconstruct the face image based on the synthesized sketch. The proposed\nAttribute2Sketch2Face framework, which is based on a combination of deep\nConditional Variational Autoencoder (CVAE) and Generative Adversarial Networks\n(GANs), consists of three stages: (1) Synthesis of facial sketch from\nattributes using a CVAE architecture, (2) Enhancement of coarse sketches to\nproduce sharper sketches using a GAN-based framework, and (3) Synthesis of face\nfrom sketch using another GAN-based network. Extensive experiments and\ncomparison with recent methods are performed to verify the effectiveness of the\nproposed attribute-based three stage face synthesis method.","primary_category":"cs","categories":["cs.CV"],"authors":["Di Xing","Patel Vishal M."],"created":"2017-12-29","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00094","title":"A Loop-Based Methodology for Reducing Computational Redundancy in\n  Workload Sets","abstract":"The design of general purpose processors relies heavily on a workload\ngathering step in which representative programs are collected from various\napplication domains. Processor performance, when running the workload set, is\nprofiled using simulators that model the targeted processor architecture.\nHowever, simulating the entire workload set is prohibitively time-consuming,\nwhich precludes considering a large number of programs. To reduce simulation\ntime, several techniques in the literature have exploited the internal program\nrepetitiveness to extract and execute only representative code segments.\nExisting so- lutions are based on reducing cross-program computational\nredundancy or on eliminating internal-program redundancy to decrease execution\ntime. In this work, we propose an orthogonal and complementary loop- centric\nmethodology that targets loop-dominant programs by exploiting internal-program\ncharacteristics to reduce cross-program computational redundancy. The approach\nemploys a newly developed framework that extracts and analyzes core loops\nwithin workloads. The collected characteristics model memory behavior,\ncomputational complexity, and data structures of a program, and are used to\nconstruct a signature vector for each program. From these vectors,\ncross-workload similarity metrics are extracted, which are processed by a novel\nheuristic to exclude similar programs and reduce redundancy within the set.\nFinally, a reverse engineering approach that synthesizes executable\nmicro-benchmarks having the same instruction mix as the loops in the original\nworkload is introduced. A tool that automates the flow steps of the proposed\nmethodology is developed. Simulation results demonstrate that applying the\nproposed methodology to a set of workloads reduces the set size by half, while\npreserving the main characterizations of the initial workloads.","primary_category":"cs","categories":["cs.PF"],"authors":["Shaccour Elie M.","Mansour Mohammad M."],"created":"2017-12-30","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00095","title":"Paid Peering, Settlement-Free Peering, or Both?","abstract":"With the rapid growth of congestion-sensitive and data-intensive\napplications, traditional settlement-free peering agreements with best-effort\ndelivery often do not meet the QoS requirements of content providers (CPs).\nMeanwhile, Internet access providers (IAPs) feel that revenues from end-users\nare not sufficient to recoup the upgrade costs of network infrastructures.\nConsequently, some IAPs have begun to offer CPs a new type of peering\nagreement, called paid peering, under which they provide CPs with better data\ndelivery quality for a fee. In this paper, we model a network platform where an\nIAP makes decisions on the peering types offered to CPs and the prices charged\nto CPs and end-users. We study the optimal peering schemes for the IAP, i.e.,\nto offer CPs both the paid and settlement-free peering to choose from or only\none of them, as the objective is profit or welfare maximization. Our results\nshow that 1) the IAP should always offer the paid and settlement-free peering\nunder the profit-optimal and welfare-optimal schemes, respectively, 2) whether\nto simultaneously offer the other peering type is largely driven by the type of\ndata traffic, e.g., text or video, and 3) regulators might want to encourage\nthe IAP to allocate more network capacity to the settlement-free peering for\nincreasing user welfare.","primary_category":"cs","categories":["cs.NI"],"authors":["Wang Xin","Xu Yinlong","Ma Richard T. B."],"created":"2017-12-30","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00096","title":"Towards automated patient data cleaning using deep learning: A\n  feasibility study on the standardization of organ labeling","abstract":"Data cleaning consumes about 80% of the time spent on data analysis for\nclinical research projects. This is a much bigger problem in the era of big\ndata and machine learning in the field of medicine where large volumes of data\nare being generated. We report an initial effort towards automated patient data\ncleaning using deep learning: the standardization of organ labeling in\nradiation therapy. Organs are often labeled inconsistently at different\ninstitutions (sometimes even within the same institution) and at different time\nperiods, which poses a problem for clinical research, especially for\nmulti-institutional collaborative clinical research where the acquired patient\ndata is not being used effectively. We developed a convolutional neural network\n(CNN) to automatically identify each organ in the CT image and then label it\nwith the standardized nomenclature presented at AAPM Task Group 263. We tested\nthis model on the CT images of 54 patients with prostate and 100 patients with\nhead and neck cancer who previously received radiation therapy. The model\nachieved 100% accuracy in detecting organs and assigning standardized labels\nfor the patients tested. This work shows the feasibility of using deep learning\nin patient data cleaning that enables standardized datasets to be generated for\neffective intra- and interinstitutional collaborative clinical research.","primary_category":"cs","categories":["physics.med-ph","cs.CV","cs.LG","cs.NE"],"authors":["Rozario Timothy","Long Troy","Chen Mingli","Lu Weiguo","Jiang Steve"],"created":"2017-12-30","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00100","title":"Abrupt transitions in collaborative social networks","abstract":"Despite the wide use of networks as a versatile tool for exploring complex\nsocial systems, little is known about how to detect and forecast abrupt changes\nin social systems. In this report, we develop an early warning approach based\non network properties to detect such changes. By analysing three collaborative\nsocial networks---one co-stardom, one patent and one scientific collaborative\nnetwork, we discover that abrupt transitions inherent in these networks can\nserve as a good early warning signal, indicating, respectively, the dissolution\nof the Soviet Union, the emergence of the \"soft matter\" research field, and the\nmerging of two scientific communities. We then develop a clique growth model\nthat explains the universal properties of these real networks and find that\nthey belong to a new universality class, described by the Gumbel distribution.","primary_category":"cs","categories":["physics.soc-ph","cs.SI"],"authors":["Fan Jingfang","Meng Jun","Ding Yimin","Du Guangle","Li Daqing","Cohen Reuven","Chen Xiaosong","Ye Fangfu","Havlin Shlomo"],"created":"2017-12-30","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00101","title":"Parameter-free online learning via model selection","abstract":"We introduce an efficient algorithmic framework for model selection in online\nlearning, also known as parameter-free online learning. Departing from previous\nwork, which has focused on highly structured function classes such as nested\nballs in Hilbert space, we propose a generic meta-algorithm framework that\nachieves online model selection oracle inequalities under minimal structural\nassumptions. We give the first computationally efficient parameter-free\nalgorithms that work in arbitrary Banach spaces under mild smoothness\nassumptions; previous results applied only to Hilbert spaces. We further derive\nnew oracle inequalities for matrix classes, non-nested convex sets, and\n$\\mathbb{R}^{d}$ with generic regularizers. Finally, we generalize these\nresults by providing oracle inequalities for arbitrary non-linear classes in\nthe online supervised learning model. These results are all derived through a\nunified meta-algorithm scheme using a novel \"multi-scale\" algorithm for\nprediction with expert advice based on random playout, which may be of\nindependent interest.","primary_category":"cs","categories":["cs.LG","stat.ML"],"authors":["Foster Dylan J.","Kale Satyen","Mohri Mehryar","Sridharan Karthik"],"created":"2017-12-30","updated":"2018-01-03","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00106","title":"Content Placement in Cache Networks Using Graph-Coloring","abstract":"Small cell densification is one of the effective ideas addressing the demand\nfor higher capacity in cellular networks. The major problem faced in such\nnetworks is the wireless backhaul link and its limited capacity. Caching most\npopular files in the memories of small cells base station (SBSs) is an\neffective solution to this problem. One of the main challenges in caching is\nchoosing the files that are going to be stored in the memory of SBS. In this\npaper, we model the described caching problem as a graph. This graph is divided\ninto four sub-graphs including placement, access, SBSs and delivery graphs. By\nmaking some modifications to the SBS graph, we convert it to a graph that can\nbe colored. Coloring of the generated graph is NP-hard and we use an algorithm\nproposed in graph-coloring area to color it. To overcome the complexity of\nabove coloring technique, we then propose a simple graph-coloring method based\non two point processes, Matern Core-type I and II. We model our network with a\nnew weighted graph which simply can be colored and after that the files are\ncached accordingly. We evaluate the performance of our proposed methods through\nsimulations. Our results show that by employing out proposed method in a\ntypical considered SBSs network, the load on the macro base station can be\nreduced by around $25 \\%$, at the distribution parameter of popularity of files\nequals to $0.6$, compared to conventional policy which caches the most popular\ncontent every where.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Javedankherad Mostafa","Zeinalpour-Yazdi Zolfa"],"created":"2017-12-30","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00110","title":"Online Multicast Traffic Engineering for Software-Defined Networks","abstract":"Previous research on SDN traffic engineering mostly focuses on static\ntraffic, whereas dynamic traffic, though more practical, has drawn much less\nattention. Especially, online SDN multicast that supports IETF dynamic group\nmembership (i.e., any user can join or leave at any time) has not been\nexplored. Different from traditional shortest-path trees (SPT) and graph\ntheoretical Steiner trees (ST), which concentrate on routing one tree at any\ninstant, online SDN multicast traffic engineering is more challenging because\nit needs to support dynamic group membership and optimize a sequence of\ncorrelated trees without the knowledge of future join and leave, whereas the\nscalability of SDN due to limited TCAM is also crucial. In this paper,\ntherefore, we formulate a new optimization problem, named Online Branch-aware\nSteiner Tree (OBST), to jointly consider the bandwidth consumption, SDN\nmulticast scalability, and rerouting overhead. We prove that OBST is NP-hard\nand does not have a $|D_{max}|^{1-\\epsilon}$-competitive algorithm for any\n$\\epsilon >0$, where $|D_{max}|$ is the largest group size at any time. We\ndesign a $|D_{max}|$-competitive algorithm equipped with the notion of the\nbudget, the deposit, and Reference Tree to achieve the tightest bound. The\nsimulations and implementation on real SDNs with YouTube traffic manifest that\nthe total cost can be reduced by at least 25% compared with SPT and ST, and the\ncomputation time is small for massive SDN.","primary_category":"cs","categories":["cs.NI"],"authors":["Chiang Sheng-Hao","Kuo Jian-Jhih","Shen Shan-Hsiang","Yang De-Nian","Chen Wen-Tsuen"],"created":"2017-12-30","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00119","title":"Towards co-evolution of fitness predictors and Deep Neural Networks","abstract":"Deep neural networks proved to be a very useful and powerful tool with many\npractical applications. They especially excel at learning from large data sets\nwith labeled samples. However, in order to achieve good learning results, the\nnetwork architecture has to be carefully designed. Creating an optimal topology\nrequires a lot of experience and knowledge. Unfortunately there are no\npractically applicable algorithms which could help in this situation. Using an\nevolutionary process to develop new network topologies might solve this\nproblem. The limiting factor in this case is the speed of evaluation of a\nsingle specimen (a single network architecture), which includes learning based\non the whole large dataset. In this paper we propose to overcome this problem\nby using a fitness prediction technique: use subsets of the original training\nset to conduct the training process and use its results as an approximation of\nspecimen's fitness. We discuss the feasibility of this approach in context of\nthe desired fitness predictor features and analyze whether subsets obtained in\nan evolutionary process can be used to estimate the fitness of the network\ntopology. Finally we draw conclusions from our experiments and outline plans\nfor future work.","primary_category":"cs","categories":["cs.NE"],"authors":["Funika W\u0142odzimierz","Koperek Pawe\u0142"],"created":"2017-12-30","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00121","title":"Resource Allocation for Downlink NOMA Systems: Key Techniques and Open\n  Issues","abstract":"This article presents advances in resource allocation (RA) for downlink\nnon-orthogonal multiple access (NOMA) systems, focusing on user pairing (UP)\nand power allocation (PA) algorithms. The former pairs the users to obtain the\nhigh capacity gain by exploiting the channel gain difference between the users,\nwhile the later allocates power to users in each cluster to balance system\nthroughput and user fairness. Additionally, the article introduces the concept\nof cluster fairness and proposes the divideand- next largest difference-based\nUP algorithm to distribute the capacity gain among the NOMA clusters in a\ncontrolled manner. Furthermore, performance comparison between multiple-input\nmultiple-output NOMA (MIMO-NOMA) and MIMO-OMA is conducted when users have\npre-defined quality of service. Simulation results are presented, which\nvalidate the advantages of NOMA over OMA. Finally, the article provides avenues\nfor further research on RA for downlink NOMA.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Islam S. M. Riazul","Zeng Ming","Dobre Octavia A.","Kwak Kyung-Sup"],"created":"2017-12-30","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00129","title":"Why the Equifax Breach Should Not Have Mattered","abstract":"Data security, which is concerned with the prevention of unauthorized access\nto computers, databases, and websites, helps protect digital privacy and ensure\ndata integrity. It is extremely difficult, however, to make security\nwatertight, and security breaches are not uncommon. The consequences of stolen\ncredentials go well beyond the leakage of other types of information because\nthey can further compromise other systems. This paper criticizes the practice\nof using clear-text identity attributes, such as Social Security or driver's\nlicense numbers -- which are in principle not even secret -- as acceptable\nauthentication tokens or assertions of ownership, and proposes a simple\nprotocol that straightforwardly applies public-key cryptography to make\nidentity claims verifiable, even when they are issued remotely via the\nInternet. This protocol has the potential of elevating the business practices\nof credit providers, rental agencies, and other service companies that have\nhitherto exposed consumers to the risk of identity theft, to where identity\ntheft becomes virtually impossible.","primary_category":"cs","categories":["cs.CR","cs.CY"],"authors":["Lohstroh Marten"],"created":"2017-12-30","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00145","title":"Dynamic Interference Steering in Heterogeneous Cellular Networks","abstract":"With the development of diverse wireless communication technologies,\ninterference has become a key impediment in network performance, thus making\neffective interference management (IM) essential to accommodate a rapidly\nincreasing number of subscribers with diverse services. Although there have\nbeen numerous IM schemes proposed thus far, none of them are free of some form\nof cost. It is, therefore, important to balance the benefit brought by and cost\nof each adopted IM scheme by adapting its operating parameters to various\nnetwork deployments and dynamic channel conditions.\n  We propose a novel IM scheme, called dynamic interference steering (DIS), by\nrecognizing the fact that interference can be not only suppressed or mitigated\nbut also steered in a particular direction. Specifically, DIS exploits both\nchannel state information (CSI) and the data contained in the interfering\nsignal to generate a signal that modifies the spatial feature of the original\ninterference to partially or fully cancel the interference appearing at the\nvictim receiver. By intelligently determining the strength of the steering\nsignal, DIS can steer the interference in an optimal direction to balance the\ntransmitter's power used for IS and the desired signal's transmission. DIS is\nshown via simulation to be able to make better use of the transmit power, hence\nenhancing users' spectral efficiency (SE) effectively.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Li Zhao","Shu Canyu","Guo Fengjuan","Shin Kang G.","Liu Jia"],"created":"2017-12-30","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00159","title":"Does the Cross-Talk Between Nonlinear Modes Limit the Performance of\n  NFDM Systems?","abstract":"We show a non-negligible cross-talk between nonlinear modes in Nonlinear\nFrequency-Division Multiplexed system when data is modulated over the nonlinear\nFourier spectrum, both the continuous spectrum and the discrete spectrum, and\ntransmitted over a lumped amplified fiber link. We evaluate the performance\nloss if the cross-talks are neglected.","primary_category":"cs","categories":["eess.SP","cs.IT","math.IT"],"authors":["Aref Vahid","Le Son T.","Buelow Henning"],"created":"2017-12-30","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00168","title":"The origins of Zipf's meaning-frequency law","abstract":"In his pioneering research, G. K. Zipf observed that more frequent words tend\nto have more meanings, and showed that the number of meanings of a word grows\nas the square root of its frequency. He derived this relationship from two\nassumptions: that words follow Zipf's law for word frequencies (a power law\ndependency between frequency and rank) and Zipf's law of meaning distribution\n(a power law dependency between number of meanings and rank). Here we show that\na single assumption on the joint probability of a word and a meaning suffices\nto infer Zipf's meaning-frequency law or relaxed versions. Interestingly, this\nassumption can be justified as the outcome of a biased random walk in the\nprocess of mental exploration.","primary_category":"cs","categories":["cs.CL","cs.IT","math.IT","physics.soc-ph"],"authors":["Ferrer-i-Cancho Ramon","Vitevitch Michael S."],"created":"2017-12-30","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00182","title":"A Real-time and Registration-free Framework for Dynamic Shape\n  Instantiation","abstract":"Real-time 3D navigation during minimally invasive procedures is an essential\nyet challenging task, especially when considerable tissue motion is involved.\nTo balance image acquisition speed and resolution, only 2D images or\nlow-resolution 3D volumes can be used clinically. In this paper, a real-time\nand registration-free framework for dynamic shape instantiation, generalizable\nto multiple anatomical applications, is proposed to instantiate high-resolution\n3D shapes of an organ from a single 2D image intra-operatively. Firstly, an\napproximate optimal scan plane was determined by analyzing the pre-operative 3D\nstatistical shape model (SSM) of the anatomy with sparse principal component\nanalysis (SPCA) and considering practical constraints . Secondly, kernel\npartial least squares regression (KPLSR) was used to learn the relationship\nbetween the pre-operative 3D SSM and a synchronized 2D SSM constructed from 2D\nimages obtained at the approximate optimal scan plane. Finally, the derived\nrelationship was applied to the new intra-operative 2D image obtained at the\nsame scan plane to predict the high-resolution 3D shape intra-operatively. A\nmajor feature of the proposed framework is that no extra registration between\nthe pre-operative 3D SSM and the synchronized 2D SSM is required. Detailed\nvalidation was performed on studies including the liver and right ventricle\n(RV) of the heart. The derived results (mean accuracy of 2.19mm on patients and\ncomputation speed of 1ms) demonstrate its potential clinical value for\nreal-time, high-resolution, dynamic and 3D interventional guidance.","primary_category":"cs","categories":["cs.CV"],"authors":["Zhou Xiao-Yun","Yang Guang-Zhong","Lee Su-Lin"],"created":"2017-12-30","updated":" ","doi":"10.1016\/j.media.2017.11.009"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00184","title":"H4-Writer: A Text Entry Method Designed For Gaze Controlled Environment\n  with Low KSPC and Spatial Footprint","abstract":"This paper presents a new text entry technique, namely H4-Writer, designed\nfor gaze controlled environments and aimed at reducing average KSPC . and\nspatial footprint. It also presents an empirical evaluation of this proposed\nsystem by using three different input devices: mouse, gamepad, and eye tracker.\nThe experiment was conducted using 9 participants and the obtained data were\nused to compare the entry speeds, efficiency and KSPC of H4-Writer for all the\ndevices. Over three blocks, the average entry speed was 3.54 wpm for the mouse,\n3.33 wpm for the gamepad and only 2.11 wpm for the eye tracker. While the eye\ntracker fared poorly compared to the mouse and the gamepad on entry speed, it\nshowed significant improvement in entry speed over progressing blocks\nindicating increase in entry speed with practice. A full longitudinal study was\nconducted to indicate this.\n  The average KSPC of all the three devices over all the text phrases entered\nwas 2.62, which is significantly lower compared to other hand writing\nrecognizing text entry techniques like EdgeWrite. An analysis of the blocks\nrevealed improvement in error rate, efficiency and KSPC values with progressing\nblock numbers as the participants got more acclimatized with the key codes for\ncorresponding characters.","primary_category":"cs","categories":["cs.HC"],"authors":["Saqur Raeid"],"created":"2017-12-30","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00185","title":"A dynamic network model with persistent links and node-specific latent\n  variables, with an application to the interbank market","abstract":"We propose a dynamic network model where two mechanisms control the\nprobability of a link between two nodes: (i) the existence or absence of this\nlink in the past, and (ii) node-specific latent variables (dynamic fitnesses)\ndescribing the propensity of each node to create links. Assuming a Markov\ndynamics for both mechanisms, we propose an Expectation-Maximization algorithm\nfor model estimation and inference of the latent variables. The estimated\nparameters and fitnesses can be used to forecast the presence of a link in the\nfuture. We apply our methodology to the e-MID interbank network for which the\ntwo linkage mechanisms are associated with two different trading behaviors in\nthe process of network formation, namely preferential trading and trading\ndriven by node-specific characteristics. The empirical results allow to\nrecognise preferential lending in the interbank market and indicate how a\nmethod that does not account for time-varying network topologies tends to\noverestimate preferential linkage.","primary_category":"cs","categories":["cs.SI","physics.soc-ph","q-fin.ST","stat.ML"],"authors":["Mazzarisi Piero","Barucca Paolo","Lillo Fabrizio","Tantari Daniele"],"created":"2017-12-30","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00194","title":"Maximum Throughput of Multiple Access Channels in Adversarial\n  Environments","abstract":"We consider deterministic distributed broadcasting on multiple access\nchannels in the framework of adversarial queuing. Packets are injected\ndynamically by an adversary that is constrained by the injection rate and the\nnumber of packets that may be injected simultaneously; the latter we call\nburstiness. The maximum injection rate that an algorithm can handle in a stable\nmanner is called the throughput of the algorithm. We develop an algorithm that\nachieves throughput $1$ for any number of stations against leaky-bucket\nadversaries. The algorithm has $O(n^2+\\text{burstiness})$ packets queued\nsimultaneously at any time, where $n$ is the number of stations; this upper\nbound is proved to be best possible. An algorithm is called fair when each\npacket is eventually broadcast. We show that no algorithm can be both stable\nand fair for a system of at least two stations against leaky-bucket\nadversaries. We study in detail small systems of exactly two and three stations\nagainst window adversaries to exhibit differences in quality of broadcast among\nclasses of algorithms. For two stations, we show that fair latency can be\nachieved by a full sensing algorithm, while there is no stable acknowledgment\nbased algorithm. For three stations, we show that fair latency can be achieved\nby a general algorithm, while no full sensing algorithm can be stable. Finally,\nwe show that algorithms that either are fair or do not have the queue sizes\naffect the order of transmissions cannot be stable in systems of at least four\nstations against window adversaries.","primary_category":"cs","categories":["cs.NI"],"authors":["Chlebus Bogdan S.","Kowalski Dariusz R.","Rokicki Mariusz A."],"created":"2017-12-30","updated":" ","doi":"10.1007\/s00446-009-0086-4"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00196","title":"On approximating the stationary distribution of time-reversible Markov\n  chains","abstract":"Approximating the stationary probability of a state in a Markov chain through\nMarkov chain Monte Carlo techniques is, in general, inefficient. Standard\nrandom walk approaches require $\\tilde{O}(\\tau\/\\pi(v))$ operations to\napproximate the probability $\\pi(v)$ of a state $v$ in a chain with mixing time\n$\\tau$, and even the best available techniques still have complexity\n$\\tilde{O}(\\tau^{1.5}\/\\pi(v)^{0.5})$, and since these complexities depend\ninversely on $\\pi(v)$, they can grow beyond any bound in the size of the chain\nor in its mixing time. In this paper we show that, for time-reversible Markov\nchains, there exists a simple randomized approximation algorithm that breaks\nthis \"small-$\\pi(v)$ barrier\".","primary_category":"cs","categories":["cs.DM"],"authors":["Bressan Marco","Peserico Enoch","Pretto Luca"],"created":"2017-12-30","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00202","title":"Efficiently Enumerating all Maximal Cliques with Bit-Parallelism","abstract":"The maximal clique enumeration (MCE) problem has numerous applications in\nbiology, chemistry, sociology, and graph modeling. Though this problem is well\nstudied, most current research focuses on finding solutions in large sparse\ngraphs or very dense graphs, while sacrificing efficiency on the most difficult\nmedium-density benchmark instances that are representative of data sets often\nencountered in practice. We show that techniques that have been successfully\napplied to the maximum clique problem give significant speed gains over the\nstate-of-the-art MCE algorithms on these instances. Specifically, we show that\na simple greedy pivot selection based on a fixed maximum-degree first ordering\nof vertices, when combined with bit-parallelism, performs consistently better\nthan the theoretical worst-case optimal pivoting of the state-of-the-art\nalgorithms of Tomita et al. [Theoretical Computer Science, 2006] and Naud\\'e\n[Theoretical Computer Science, 2016].\n  Experiments show that our algorithm is faster than the worst-case optimal\nalgorithm of Tomita et al. on 60 out of 74 standard structured and random\nbenchmark instances: we solve 48 instances 1.2 to 2.2 times faster, and solve\nthe remaining 12 instances 3.6 to 47.6 times faster. We also see consistent\nspeed improvements over the algorithm of Naud\\'e: solving 61 instances 1.2 to\n2.4 times faster. To the best of our knowledge, we are the first to achieve\nsuch speed-ups compared to these state-of-the-art algorithms on these standard\nbenchmarks.","primary_category":"cs","categories":["cs.DS"],"authors":["Segundo Pablo San","Artieda Jorge","Strash Darren"],"created":"2017-12-30","updated":" ","doi":"10.1016\/j.cor.2017.12.006"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00215","title":"Learning Continuous User Representations through Hybrid Filtering with\n  doc2vec","abstract":"Players in the online ad ecosystem are struggling to acquire the user data\nrequired for precise targeting. Audience look-alike modeling has the potential\nto alleviate this issue, but models' performance strongly depends on quantity\nand quality of available data. In order to maximize the predictive performance\nof our look-alike modeling algorithms, we propose two novel hybrid filtering\ntechniques that utilize the recent neural probabilistic language model\nalgorithm doc2vec. We apply these methods to data from a large mobile ad\nexchange and additional app metadata acquired from the Apple App store and\nGoogle Play store. First, we model mobile app users through their app usage\nhistories and app descriptions (user2vec). Second, we introduce context\nawareness to that model by incorporating additional user and app-related\nmetadata in model training (context2vec). Our findings are threefold: (1) the\nquality of recommendations provided by user2vec is notably higher than current\nstate-of-the-art techniques. (2) User representations generated through hybrid\nfiltering using doc2vec prove to be highly valuable features in supervised\nmachine learning models for look-alike modeling. This represents the first\napplication of hybrid filtering user models using neural probabilistic language\nmodels, specifically doc2vec, in look-alike modeling. (3) Incorporating context\nmetadata in the doc2vec model training process to introduce context awareness\nhas positive effects on performance and is superior to directly including the\ndata as features in the downstream supervised models.","primary_category":"cs","categories":["cs.IR","cs.AI","cs.CL"],"authors":["Stiebellehner Simon","Wang Jun","Yuan Shuai"],"created":"2017-12-30","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00218","title":"Game-theoretic Network Centrality: A Review","abstract":"Game-theoretic centrality is a flexible and sophisticated approach to\nidentify the most important nodes in a network. It builds upon the methods from\ncooperative game theory and network theory. The key idea is to treat nodes as\nplayers in a cooperative game, where the value of each coalition is determined\nby certain graph-theoretic properties. Using solution concepts from cooperative\ngame theory, it is then possible to measure how responsible each node is for\nthe worth of the network.\n  The literature on the topic is already quite large, and is scattered among\ngame-theoretic and computer science venues. We review the main game-theoretic\nnetwork centrality measures from both bodies of literature and organize them\ninto two categories: those that are more focused on the connectivity of nodes,\nand those that are more focused on the synergies achieved by nodes in groups.\nWe present and explain each centrality, with a focus on algorithms and\ncomplexity.","primary_category":"cs","categories":["cs.AI","cs.GT"],"authors":["Tarkowski Mateusz K.","Michalak Tomasz P.","Rahwan Talal","Wooldridge Michael"],"created":"2017-12-30","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00222","title":"Limitation of SDMA in Ultra-Dense Small Cell Networks","abstract":"Benefitting from multi-user gain brought by multi-antenna techniques, space\ndivision multiple access (SDMA) is capable of significantly enhancing spatial\nthroughput (ST) in wireless networks. Nevertheless, we show in this letter\nthat, even when SDMA is applied, ST would diminish to be zero in ultra-dense\nnetworks (UDN), where small cell base stations (BSs) are fully densified. More\nimportantly, we compare the performance of SDMA, single-user beamforming\n(SU-BF) (one user is served in each cell) and full SDMA (the number of served\nusers equals the number of equipped antennas). Surprisingly, it is shown that\nSU-BF achieves the highest ST and critical density, beyond which ST starts to\ndegrade, in UDN. The results in this work could shed light on the fundamental\nlimitation of SDMA in UDN.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Liu Junyu","Sheng Min","Li Jiandong"],"created":"2017-12-30","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00223","title":"Integrating semi-supervised label propagation and random forests for\n  multi-atlas based hippocampus segmentation","abstract":"A novel multi-atlas based image segmentation method is proposed by\nintegrating a semi-supervised label propagation method and a supervised random\nforests method in a pattern recognition based label fusion framework. The\nsemi-supervised label propagation method takes into consideration local and\nglobal image appearance of images to be segmented and segments the images by\npropagating reliable segmentation results obtained by the supervised random\nforests method. Particularly, the random forests method is used to train a\nregression model based on image patches of atlas images for each voxel of the\nimages to be segmented. The regression model is used to obtain reliable\nsegmentation results to guide the label propagation for the segmentation. The\nproposed method has been compared with state-of-the-art multi-atlas based image\nsegmentation methods for segmenting the hippocampus in MR images. The\nexperiment results have demonstrated that our method obtained superior\nsegmentation performance.","primary_category":"cs","categories":["cs.CV"],"authors":["Zheng Qiang","Fan Yong"],"created":"2017-12-30","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00224","title":"Transfer learning for diagnosis of congenital abnormalities of the\n  kidney and urinary tract in children based on Ultrasound imaging data","abstract":"Classification of ultrasound (US) kidney images for diagnosis of congenital\nabnormalities of the kidney and urinary tract (CAKUT) in children is a\nchallenging task. It is desirable to improve existing pattern classification\nmodels that are built upon conventional image features. In this study, we\npropose a transfer learning-based method to extract imaging features from US\nkidney images in order to improve the CAKUT diagnosis in children.\nParticularly, a pre-trained deep learning model (imagenet-caffe-alex) is\nadopted for transfer learning-based feature extraction from 3-channel feature\nmaps computed from US images, including original images, gradient features, and\ndistanced transform features. Support vector machine classifiers are then built\nupon different sets of features, including the transfer learning features,\nconventional imaging features, and their combination. Experimental results have\ndemonstrated that the combination of transfer learning features and\nconventional imaging features yielded the best classification performance for\ndistinguishing CAKUT patients from normal controls based on their US kidney\nimages.","primary_category":"cs","categories":["cs.CV"],"authors":["Zheng Qiang","Tasian Gregory","Fan Yong"],"created":"2017-12-30","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00237","title":"Deterministic Computations on a PRAM with Static Processor and Memory\n  Faults","abstract":"We consider Parallel Random Access Machine (PRAM) which has some processors\nand memory cells faulty. The faults considered are static, i.e., once the\nmachine starts to operate, the operational\/faulty status of PRAM components\ndoes not change. We develop a deterministic simulation of a fully operational\nPRAM on a similar faulty machine which has constant fractions of faults among\nprocessors and memory cells. The simulating PRAM has $n$ processors and $m$\nmemory cells, and simulates a PRAM with $n$ processors and a constant fraction\nof $m$ memory cells. The simulation is in two phases: it starts with\npreprocessing, which is followed by the simulation proper performed in a\nstep-by-step fashion. Preprocessing is performed in time $O((\\frac{m}{n}+ \\log\nn)\\log n)$. The slowdown of a step-by-step part of the simulation is $O(\\log\nm)$.","primary_category":"cs","categories":["cs.DC"],"authors":["Chlebus Bogdan S.","Gasieniec Leszek","Pelc Andrzej"],"created":"2017-12-31","updated":"2018-01-10","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00250","title":"A Systematic Mapping Study on Requirements Engineering in Software\n  Ecosystems","abstract":"Software ecosystems (SECOs) and open innovation processes have been claimed\nas a way forward for the software industry. A proper understanding of\nrequirements is as important for these IT-systems as for more traditional ones.\nThis paper presents a mapping study on the issues of requirements engineering\nand quality aspects in SECOs and analyzes emerging ideas. Our findings indicate\nthat among the various phases or subtasks of requirements engineering, most of\nthe SECO specific research has been accomplished on elicitation, analysis, and\nmodeling. On the other hand, requirements selection, prioritization,\nverification, and traceability has attracted few published studies. Among the\nvarious quality attributes, most of the SECOs research has been performed on\nsecurity, performance and testability. On the other hand, reliability, safety,\nmaintainability, transparency, usability attracted few published studies. The\npaper provides a review of the academic literature about SECO-related\nrequirements engineering activities, modeling approaches, and quality\nattributes, positions the source publications in a taxonomy of issues and\nidentifies gaps where there has been little research.","primary_category":"cs","categories":["cs.SE"],"authors":["Vegendla Aparna","Duc Anh Nguyen","Gao Shang","Sindre Guttorm"],"created":"2017-12-31","updated":" ","doi":"10.4018\/JITR.2018010104"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00254","title":"A New Approach for Measuring Sentiment Orientation based on\n  Multi-Dimensional Vector Space","abstract":"This study implements a vector space model approach to measure the sentiment\norientations of words. Two representative vectors for positive\/negative\npolarity are constructed using high-dimensional vec-tor space in both an\nunsupervised and a semi-supervised manner. A sentiment ori-entation value per\nword is determined by taking the difference between the cosine distances\nagainst the two reference vec-tors. These two conditions (unsupervised and\nsemi-supervised) are compared against an existing unsupervised method (Turney,\n2002). As a result of our experi-ment, we demonstrate that this novel ap-proach\nsignificantly outperforms the pre-vious unsupervised approach and is more\npractical and data efficient as well.","primary_category":"cs","categories":["cs.CL"],"authors":["Kim Youngsam","Shin Hyopil"],"created":"2017-12-31","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00256","title":"Context aware saliency map generation using semantic segmentation","abstract":"Saliency map detection, as a method for detecting important regions of an\nimage, is used in many applications such as image classification and\nrecognition. We propose that context detection could have an essential role in\nimage saliency detection. This requires extraction of high level features. In\nthis paper a saliency map is proposed, based on image context detection using\nsemantic segmentation as a high level feature. Saliency map from semantic\ninformation is fused with color and contrast based saliency maps. The final\nsaliency map is then generated. Simulation results for Pascal-voc11 image\ndataset show 99% accuracy in context detection. Also final saliency map\nproduced by our proposed method shows acceptable results in detecting salient\npoints.","primary_category":"cs","categories":["cs.CV"],"authors":["Ahmadi Mahdi","Hajabdollahi Mohsen","Karimi Nader","Samavi Shadrokh"],"created":"2017-12-31","updated":"2018-01-03","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00259","title":"PolicySpace: a modeling platform","abstract":"Public Policy involves proposing changes to existing practices, alternatives,\nnew habits. Citizens and institutions react accordingly, accepting, refuting or\nadapting. Agent-based modeling is a tool that can enrich the policy analysis\npackage explicitly considering dynamics, space and individual-level\ninteractions. This paper presents a modeling platform called PolicySpace that\nmodels public policies within an empirical, spatial environment using data from\n46 metropolitan regions in Brazil. We describe the basics of the model, its\nagents and markets, the tax scheme, the parametrization, and how to run the\nmodel. Finally, we validate the model and demonstrate an application of the\nfiscal analysis. Besides providing the basics of the platform, our results\nindicate the relevance of the rules of taxes transfer for cities' quality of\nlife.","primary_category":"cs","categories":["cs.MA"],"authors":["Furtado Bernardo Alves"],"created":"2017-12-31","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00269","title":"Interactive Video Object Segmentation in the Wild","abstract":"In this paper we present our system for human-in-the-loop video object\nsegmentation. The backbone of our system is a method for one-shot video object\nsegmentation. While fast, this method requires an accurate pixel-level\nsegmentation of one (or several) frames as input. As manually annotating such a\nsegmentation is impractical, we propose a deep interactive image segmentation\nmethod, that can accurately segment objects with only a handful of clicks. On\nthe GrabCut dataset, our method obtains 90% IOU with just 3.8 clicks on\naverage, setting the new state of the art. Furthermore, as our method\niteratively refines an initial segmentation, it can effectively correct frames\nwhere the video object segmentation fails, thus allowing users to quickly\nobtain high quality results even on challenging sequences. Finally, we\ninvestigate usage patterns and give insights in how many steps users take to\nannotate frames, what kind of corrections they provide, etc., thus giving\nimportant insights for further improving interactive video segmentation.","primary_category":"cs","categories":["cs.CV"],"authors":["Benard Arnaud","Gygli Michael"],"created":"2017-12-31","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00282","title":"Using Deep Neural Network Approximate Bayesian Network","abstract":"We present a new method to approximate posterior probabilities of Bayesian\nNetwork using Deep Neural Network. Experiment results on several public\nBayesian Network datasets shows that Deep Neural Network is capable of learning\njoint probability distri- bution of Bayesian Network by learning from a few\nobservation and posterior probability distribution pairs with high accuracy.\nCompared with traditional approximate method likelihood weighting sampling\nalgorithm, our method is much faster and gains higher accuracy in medium sized\nBayesian Network. Another advantage of our method is that our method can be\nparallelled much easier in GPU without extra effort. We also ex- plored the\nconnection between the accuracy of our model and the number of training\nexamples. The result shows that our model saturate as the number of training\nexamples grow and we don't need many training examples to get reasonably good\nresult. Another contribution of our work is that we have shown discriminative\nmodel like Deep Neural Network can approximate generative model like Bayesian\nNetwork.","primary_category":"cs","categories":["cs.LG","stat.ML"],"authors":["Jia Jie","Zhou Honggang","Li Yunchun"],"created":"2017-12-31","updated":"2018-01-11","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00283","title":"Restricted Boltzmann Machines for Robust and Fast Latent Truth Discovery","abstract":"We address the problem of latent truth discovery, LTD for short, where the\ngoal is to discover the underlying true values of entity attributes in the\npresence of noisy, conflicting or incomplete information. Despite a multitude\nof algorithms to address the LTD problem that can be found in literature, only\nlittle is known about their overall performance with respect to effectiveness\n(in terms of truth discovery capabilities), efficiency and robustness. A\npractical LTD approach should satisfy all these characteristics so that it can\nbe applied to heterogeneous datasets of varying quality and degrees of\ncleanliness.\n  We propose a novel algorithm for LTD that satisfies the above requirements.\nThe proposed model is based on Restricted Boltzmann Machines, thus coined\nLTD-RBM. In extensive experiments on various heterogeneous and publicly\navailable datasets, LTD-RBM is superior to state-of-the-art LTD techniques in\nterms of an overall consideration of effectiveness, efficiency and robustness.","primary_category":"cs","categories":["cs.LG","stat.ML"],"authors":["Broelemann Klaus","Gottron Thomas","Kasneci Gjergji"],"created":"2017-12-31","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00289","title":"Deep Stacked Networks with Residual Polishing for Image Inpainting","abstract":"Deep neural networks have shown promising results in image inpainting even if\nthe missing area is relatively large. However, most of the existing inpainting\nnetworks introduce undesired artifacts and noise to the repaired regions. To\nsolve this problem, we present a novel framework which consists of two stacked\nconvolutional neural networks that inpaint the image and remove the artifacts,\nrespectively. The first network considers the global structure of the damaged\nimage and coarsely fills the blank area. Then the second network modifies the\nrepaired image to cancel the noise introduced by the first network. The\nproposed framework splits the problem into two distinct partitions that can be\noptimized separately, therefore it can be applied to any inpainting algorithm\nby changing the first network. Second stage in our framework which aims at\npolishing the inpainted images can be treated as a denoising problem where a\nwide range of algorithms can be employed. Our results demonstrate that the\nproposed framework achieves significant improvement on both visual and\nquantitative evaluations.","primary_category":"cs","categories":["cs.CV"],"authors":["Demir Ugur","Unal Gozde"],"created":"2017-12-31","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00293","title":"Neurally Plausible Model of Robot Reaching Inspired by Infant Motor\n  Babbling","abstract":"In this paper we present a neurally plausible model of robot reaching\ninspired by human infant reaching that is based on embodied artificial\nintelligence, which emphasizes the importance of the sensory-motor interaction\nof an agent and the world. This model encompasses both learning sensory-motor\ncorrelations through motor babbling and also arm motion planning using\nspreading activation. This model is organized in three layers of neural maps\nwith parallel structures representing the same sensory-motor space. The motor\nbabbling period shapes the structure of the three neural maps as well as the\nconnections within and between them. We describe an implementation of this\nmodel and an investigation of this implementation using a simple reaching task\non a humanoid robot. The robot has learned successfully to plan reaching\nmotions from a test set with high accuracy and smoothness.","primary_category":"cs","categories":["cs.RO"],"authors":["Mahoor Zahra","MacLennan Bruce","McBride Allen"],"created":"2017-12-31","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00297","title":"Time-Aware Publish\/Subscribe for Networks of Mobile Devices","abstract":"Smart mobile devices are increasingly ubiquitous and are the primary source\nof user-generated content, and current communication infrastructures are\nfailing in keeping up with the rising demand for the avid sharing of such\ncontent. To alleviate this problem and fully harness the amount of resources\ncurrently available at the network edge, mobile edge paradigms started to\nemerge. Though, application developers still struggle to tap that potential at\nthe edge due to the lack of adequate communication and interaction\nabstractions. Thus, we propose a high-level abstraction that can be easily\nexploited by developers to design mobile edge applications focused on data\ndissemination. In this paper, we propose Thyme, a novel extended topic-based,\ntime-aware publish\/subscribe system for networks of mobile devices. In Thyme,\ntime is a rst order dimension. Each subscription has an associated time frame,\nstarting and ending either in the future, present, or past. Making the past\navailable requires both subscriptions and publications to be persistently\nstored. We present the design of Thyme and evaluate it using simulation,\ndiscussing and characterizing the scenarios best suited for its use.","primary_category":"cs","categories":["cs.DC"],"authors":["Silva Jo\u00e3o A.","Paulino Herv\u00e9","Louren\u00e7o Jo\u00e3o M.","Leit\u00e3o Jo\u00e3o","Pregui\u00e7a Nuno"],"created":"2017-12-31","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00308","title":"Cyclic group based mutual authentication protocol for RFID system","abstract":"Widespread deployment of RFID system arises security and privacy concerns of\nusers. There are several proposals are in the literature to avoid these\nconcerns, but most of them provides reasonable privacy at the cost of search\ncomplexity on the server side. The search complexity increases linearly with\nthe number of tags in the system. Some schemes use a group based approach to\nsolve the search complexity problem. In this paper, we proposed a group based\nauthentication protocol for RFID system which is based on some characteristics\nof cyclic groups. The scheme uses only bitwise XOR and mod operation for the\ncomputational work. Also, the scheme does not use any pseudo-number generator\non the tag-side. We use two benchmark metric based on anonymity set to measure\nthe privacy level of the system when some tags are compromised by an adversary.\nWe present some simulation results which show that the scheme preserves high\nlevel of privacy and discloses very less amount of information when some tags\nare compromised. Furthermore, it's formal and informal analysis shows that our\nscheme preserves information privacy as well as un-traceability and also\nwithstand against various well known attacks.","primary_category":"cs","categories":["cs.CR"],"authors":["Maurya Pramod Kumar","Bagchi Satya"],"created":"2017-12-31","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00310","title":"On Binary Distributed Hypothesis Testing","abstract":"We consider the problem of distributed binary hypothesis testing of two\nsequences that are generated by an i.i.d. doubly-binary symmetric source. Each\nsequence is observed by a different terminal. The two hypotheses correspond to\ndifferent levels of correlation between the two source components, i.e., the\ncrossover probability between the two. The terminals communicate with a\ndecision function via rate-limited noiseless links. We analyze the tradeoff\nbetween the exponential decay of the two error probabilities associated with\nthe hypothesis test and the communication rates. We first consider the\nside-information setting where one encoder is allowed to send the full\nsequence. For this setting, previous work exploits the fact that a decoding\nerror of the source does not necessarily lead to an erroneous decision upon the\nhypothesis. We provide improved achievability results by carrying out a tighter\nanalysis of the effect of binning error; the results are also more complete as\nthey cover the full exponent tradeoff and all possible correlations. We then\nturn to the setting of symmetric rates for which we utilize Korner-Marton\ncoding to generalize the results, with little degradation with respect to the\nperformance with a one-sided constraint (side-information setting).","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Haim Eli","Kochman Yuval"],"created":"2017-12-31","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00322","title":"Blackboard Meets Dijkstra for Optimization of Web Service Workflows","abstract":"This paper presents the integration of Dijkstra's algorithm within a\nBlackboard framework to optimize the selection of web services from service\nproviders. In addition, methods are presented how dynamic changes during the\nworkflow execution can be handled; specifically, how changes of the service\nparameters have effects on the system. For justification of our approach, and\nto show practical feasibility, a sample implementation is presented.","primary_category":"cs","categories":["cs.DC"],"authors":["Vorhemus Christian","Schikuta Erich"],"created":"2017-12-31","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00328","title":"Reconstruction of the Path Graph","abstract":"Let $P$ be a set of $n \\geq 5$ points in convex position in the plane. The\npath graph $G(P)$ of $P$ is an abstract graph whose vertices are non-crossing\nspanning paths of $P$, such that two paths are adjacent if one can be obtained\nfrom the other by deleting an edge and adding another edge.\n  We prove that the automorphism group of $G(P)$ is isomorphic to $D_{n}$, the\ndihedral group of order $2n$. The heart of the proof is an algorithm that first\nidentifies the vertices of $G(P)$ that correspond to boundary paths of $P$,\nwhere the identification is unique up to an automorphism of $K(P)$ as a\ngeometric graph, and then identifies (uniquely) all edges of each path\nrepresented by a vertex of $G(P)$. The complexity of the algorithm is $O(N \\log\nN)$ where $N$ is the number of vertices of $G(P)$.","primary_category":"cs","categories":["math.CO","cs.CG"],"authors":["Keller Chaya","Stein Yael"],"created":"2017-12-31","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00354","title":"SAFFRON: A Semi-Automated Framework for Software Requirements\n  Prioritization","abstract":"Due to dynamic nature of current software development methods, changes in\nrequirements are embraced and given proper consideration. However, this\ntriggers the rank reversal problem which involves re-prioritizing requirements\nbased on stakeholders' feedback. It incurs significant cost because of time\nelapsed in large number of human interactions. To solve this issue, a\nSemi-Automated Framework for soFtware Requirements priOritizatioN (SAFFRON) is\npresented in this paper. For a particular requirement, SAFFRON predicts\nappropriate stakeholders' ratings to reduce human interactions. Initially,\nitem-item collaborative filtering is utilized to estimate similarity between\nnew and previously elicited requirements. Using this similarity, stakeholders\nwho are most likely to rate requirements are determined. Afterwards,\ncollaborative filtering based on latent factor model is used to predict ratings\nof those stakeholders. The proposed approach is implemented and tested on RALIC\ndataset. The results illustrate consistent correlation, similar to state of the\nart approaches, with the ground truth. In addition, SAFFRON requires 13.5-27%\nless human interaction for re-prioritizing requirements.","primary_category":"cs","categories":["cs.SE"],"authors":["Asif Syed Ali","Masud Zarif","Easmin Rubaida","Gias Alim Ul"],"created":"2017-12-31","updated":" ","doi":"10.14569\/IJACSA.2017.081265"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00356","title":"How will the Internet of Things enable Augmented Personalized Health?","abstract":"Internet-of-Things (IoT) is profoundly redefining the way we create, consume,\nand share information. Health aficionados and citizens are increasingly using\nIoT technologies to track their sleep, food intake, activity, vital body\nsignals, and other physiological observations. This is complemented by IoT\nsystems that continuously collect health-related data from the environment and\ninside the living quarters. Together, these have created an opportunity for a\nnew generation of healthcare solutions. However, interpreting data to\nunderstand an individual's health is challenging. It is usually necessary to\nlook at that individual's clinical record and behavioral information, as well\nas social and environmental information affecting that individual. Interpreting\nhow well a patient is doing also requires looking at his adherence to\nrespective health objectives, application of relevant clinical knowledge and\nthe desired outcomes.\n  We resort to the vision of Augmented Personalized Healthcare (APH) to exploit\nthe extensive variety of relevant data and medical knowledge using Artificial\nIntelligence (AI) techniques to extend and enhance human health to presents\nvarious stages of augmented health management strategies: self-monitoring,\nself-appraisal, self-management, intervention, and disease progress tracking\nand prediction. kHealth technology, a specific incarnation of APH, and its\napplication to Asthma and other diseases are used to provide illustrations and\ndiscuss alternatives for technology-assisted health management. Several\nprominent efforts involving IoT and patient-generated health data (PGHD) with\nrespect converting multimodal data into actionable information (big data to\nsmart data) are also identified. Roles of three components in an evidence-based\nsemantic perception approach- Contextualization, Abstraction, and\nPersonalization are discussed.","primary_category":"cs","categories":["cs.CY","cs.AI"],"authors":["Sheth Amit","Jaimini Utkarshani","Yip Hong Yung"],"created":"2017-12-31","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00361","title":"SenseNet: 3D Objects Database and Tactile Simulator","abstract":"The majority of artificial intelligence research, as it relates from which to\nbiological senses has been focused on vision. The recent explosion of machine\nlearning and in particular, dee p learning, can be partially attributed to the\nrelease of high quality data sets for algorithm s from which to model the world\non. Thus, most of these datasets are comprised of images. We believe that\nfocusing on sensorimotor systems and tactile feedback will create algorithms\nthat better mimic human intelligence. Here we present SenseNet: a collection of\ntactile simulators and a large scale dataset of 3D objects for manipulation.\nSenseNet was created for the purpose of researching and training Artificial\nIntelligences (AIs) to interact with the environment via sensorimotor neural\nsystems and tactile feedback. We aim to accelerate that same explosion in image\nprocessing, but for the domain of tactile feedback and sensorimotor research.\nWe hope that SenseNet can offer researchers in both the machine learning and\ncomputational neuroscience communities brand new opportunities and avenues to\nexplore.","primary_category":"cs","categories":["cs.AI","cs.RO"],"authors":["Toy Jason"],"created":"2017-12-31","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00365","title":"Broadcasting Spanning Forests on a Multiple-Access Channel","abstract":"The problem of finding a spanning forest of a graph in a\ndistributed-processing environment is studied. If an input graph is weighted,\nthen the goal is to find a minimum-weight spanning forest. The processors\ncommunicate by broadcasting. The output consists of the edges that make a\nspanning forest and have been broadcast on the network. Input edges are\ndistributed among the processors, with each edge held by one processor.\n  The underlying broadcast network is implemented as a multiple-access channel.\nIf exactly one processor attempts to perform a broadcast, then the broadcast is\nsuccessful. A message broadcast successfully is delivered to all the processors\nin one step. If more than one processors broadcast simultaneously, then the\nmessages interfere with each other and no processor can receive any of them.\n  Optimality of algorithmic solutions is investigated, by way of comparing\ndeterministic with randomized algorithms, and adaptive with oblivious ones.\nLower bounds are proved that either justify the optimality of specific\nalgorithms or show that the optimal performance depends on a class of\nalgorithms.","primary_category":"cs","categories":["cs.DS","cs.NI"],"authors":["Chlebus Bogdan S.","Golab Karol","Kowalski Dariusz R."],"created":"2017-12-31","updated":" ","doi":"10.1007\/s00224-003-1149-8"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00377","title":"Help Me Find a Job: A Graph-based Approach for Job Recommendation at\n  Scale","abstract":"Online job boards are one of the central components of modern recruitment\nindustry. With millions of candidates browsing through job postings everyday,\nthe need for accurate, effective, meaningful, and transparent job\nrecommendations is apparent more than ever. While recommendation systems are\nsuccessfully advancing in variety of online domains by creating social and\ncommercial value, the job recommendation domain is less explored. Existing\nsystems are mostly focused on content analysis of resumes and job descriptions,\nrelying heavily on the accuracy and coverage of the semantic analysis and\nmodeling of the content in which case, they end up usually suffering from\nrigidity and the lack of implicit semantic relations that are uncovered from\nusers' behavior and could be captured by Collaborative Filtering (CF) methods.\nFew works which utilize CF do not address the scalability challenges of\nreal-world systems and the problem of cold-start. In this paper, we propose a\nscalable item-based recommendation system for online job recommendations. Our\napproach overcomes the major challenges of sparsity and scalability by\nleveraging a directed graph of jobs connected by multi-edges representing\nvarious behavioral and contextual similarity signals. The short lived nature of\nthe items (jobs) in the system and the rapid rate in which new users and jobs\nenter the system make the cold-start a serious problem hindering CF methods. We\naddress this problem by harnessing the power of deep learning in addition to\nuser behavior to serve hybrid recommendations. Our technique has been leveraged\nby CareerBuilder.com which is one of the largest job boards in the world to\ngenerate high-quality recommendations for millions of users.","primary_category":"cs","categories":["cs.IR","cs.SI"],"authors":["Shalaby Walid","AlAila BahaaEddin","Korayem Mohammed","Pournajaf Layla","AlJadda Khalifeh","Quinn Shannon","Zadrozny Wlodek"],"created":"2017-12-31","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00384","title":"Error-Robust Multi-View Clustering","abstract":"In the era of big data, data may come from multiple sources, known as\nmulti-view data. Multi-view clustering aims at generating better clusters by\nexploiting complementary and consistent information from multiple views rather\nthan relying on the individual view. Due to inevitable system errors caused by\ndata-captured sensors or others, the data in each view may be erroneous.\nVarious types of errors behave differently and inconsistently in each view.\nMore precisely, error could exhibit as noise and corruptions in reality.\nUnfortunately, none of the existing multi-view clustering approaches handle all\nof these error types. Consequently, their clustering performance is\ndramatically degraded. In this paper, we propose a novel Markov chain method\nfor Error-Robust Multi-View Clustering (EMVC). By decomposing each view into a\nshared transition probability matrix and error matrix and imposing structured\nsparsity-inducing norms on error matrices, we characterize and handle typical\ntypes of errors explicitly. To solve the challenging optimization problem, we\npropose a new efficient algorithm based on Augmented Lagrangian Multipliers and\nprove its convergence rigorously. Experimental results on various synthetic and\nreal-world datasets show the superiority of the proposed EMVC method over the\nbaseline methods and its robustness against different types of errors.","primary_category":"cs","categories":["cs.LG"],"authors":["Najafi Mehrnaz","He Lifang","Yu Philip S."],"created":"2017-12-31","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00387","title":"Diversity Analysis of Millimeter-Wave Massive MIMO Systems","abstract":"This paper is concerned with asymptotic diversity analysis for\nmillimeter-wave (mmWave) massive MIMO systems. First, for a single-user mmWave\nsystem employing distributed antenna subarray architecture in which the\ntransmitter and receiver consist of Kt and Kr subarrays, respectively, a\ndiversity gain theorem is established when the numbers of antennas at subarrays\ngo to infinity. Specifically, assuming that all subchannels have the same\nnumber of propagation paths L, the theorem states that by employing such a\ndistributed antenna-subarray architecture, a diversity gain of KrKtL-Ns+1 can\nbe achieved, where Ns is the number of data streams. This result means that\ncompared to the co-located antenna architecture, using the distributed\nantenna-subarray architecture can scale up the diversity gain or multiplexing\ngain proportionally to KrKt. The diversity gain analysis is then extended to\nthe multiuser scenario as well as the scenario with conventional\npartially-connected RF structure in the literature. Simulation results obtained\nwith the hybrid analog\/digital processing corroborate the analysis results and\nshow that the distributed subarray architecture indeed yields significantly\nbetter diversity performance than the co-located antenna architectures.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Yue Dian-Wu","Xu Shuai","Nguyen Ha H."],"created":"2017-12-31","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00389","title":"Throughput Enhancement by Concurrent Transmission in WPAN with Multiple\n  Antennas","abstract":"To achieve high rate of Multi-Giga-bits-per-second for multimedia\napplications at personal area level, 60 GHz communication technologies are most\npotential candidates. Due to some special characteristics of 60 GHz band of\nfrequencies and use of multiple directional antennas,the network level and user\nlevel throughput can be increased tremendously by identifying and scheduling\nthe non interfering transmission requests for concurrent transmissions. Instead\nof direct communication between source and destination, by traversing the\ntraffic flow on optimum path (consists of light weight multiple-relying-hops),\ncan further increase the throughput and balances the load condition across the\nnetwork. In this paper we present a scheduling scheme for concurrent\ntransmission of non interfering transmission requests on instantaneous optimum\npath. Performance of scheme is investigated for different path loss exponents.","primary_category":"cs","categories":["cs.NI"],"authors":["Bilal Muhammad","Kang Moonsoo"],"created":"2017-12-31","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00390","title":"Time Aware Least Recent Used (TLRU) Cache Management Policy in ICN","abstract":"The information centric networks (ICN) can be viewed as a network of caches.\nConversely, ICN type of cache networks has distinctive features e.g, contents\npopularity, usability time of content and other factors inflicts some diverse\nrequirements for cache eviction policies. In this paper we defined four\nimportant characteristics of a suitable eviction policy for ICN. We analysed\nwell known eviction policies in view of defined characteristics. Based upon\nanalysis we propose a new eviction scheme which is well suitable for ICN type\nof cache networks.","primary_category":"cs","categories":["cs.NI"],"authors":["Bilal Muhammad","Kang Shin-Gak"],"created":"2017-12-31","updated":" ","doi":"10.1109\/ICACT.2014.6779016"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00394","title":"Generalized Compression Strategy for the Downlink Cloud Radio Access\n  Network","abstract":"This paper studies the downlink of a cloud radio access network (C-RAN) in\nwhich a centralized processor (CP) communicates with mobile users through base\nstations (BSs) that are connected to the CP via finite-capacity fronthaul\nlinks. Information theoretically, the downlink of a C-RAN is modeled as a\ntwo-hop broadcast-relay network. Among the various transmission and relaying\nstrategies for such model, this paper focuses on the compression strategy, in\nwhich the CP centrally encodes the signals to be broadcasted jointly by the\nBSs, then compresses and sends these signals to the BSs through the fronthaul\nlinks. This paper characterizes an achievable rate region for a generalized\ncompression strategy with Marton's multicoding for broadcasting and\nmultivariate compression for fronthaul transmission. We then compare this rate\nregion with the distributed decode-forward (DDF) scheme, which achieves the\ncapacity of the general relay networks to within a constant gap, and show that\nthe difference lies in that DDF performs Marton's multicoding and multivariate\ncompression jointly as opposed to successively as in the compression strategy.\nA main result of this paper is that under the assumption that the fronthaul\nlinks are subject to a \\emph{sum} capacity constraint this difference is\nimmaterial, so the successive encoding based compression strategy can already\nachieve the capacity region of the C-RAN to within a constant gap, where the\ngap is independent of the channel parameters and the power constraints at the\nBSs. For the special case of the Gaussian network, we further establish that\nunder individual fronthaul constraints, the compression strategy achieves to\nwithin a constant gap to the \\emph{sum} capacity of the C-RAN.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Patil Pratik","Yu Wei"],"created":"2017-12-31","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00398","title":"Scalable Hash-Based Estimation of Divergence Measures","abstract":"We propose a scalable divergence estimation method based on hashing. Consider\ntwo continuous random variables $X$ and $Y$ whose densities have bounded\nsupport. We consider a particular locality sensitive random hashing, and\nconsider the ratio of samples in each hash bin having non-zero numbers of Y\nsamples. We prove that the weighted average of these ratios over all of the\nhash bins converges to f-divergences between the two samples sets. We show that\nthe proposed estimator is optimal in terms of both MSE rate and computational\ncomplexity. We derive the MSE rates for two families of smooth functions; the\nH\\\"{o}lder smoothness class and differentiable functions. In particular, it is\nproved that if the density functions have bounded derivatives up to the order\n$d\/2$, where $d$ is the dimension of samples, the optimal parametric MSE rate\nof $O(1\/N)$ can be achieved. The computational complexity is shown to be\n$O(N)$, which is optimal. To the best of our knowledge, this is the first\nempirical divergence estimator that has optimal computational complexity and\nachieves the optimal parametric MSE estimation rate.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Noshad Morteza","Hero Alfred O."],"created":"2018-01-01","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00406","title":"Reduced Dimensional Optimal Vector Linear Index Codes for Index Coding\n  Problems with Symmetric Neighboring and Consecutive Side-information","abstract":"A single unicast index coding problem (SUICP) with symmetric neighboring and\nconsecutive side-information (SNCS) has $K$ messages and $K$ receivers, the\n$k$th receiver $R_k$ wanting the $k$th message $x_k$ and having the\nside-information $\\mathcal{K}_k=\\{x_{k-U},\\dots,x_{k-2},x_{k-1}\\}\\cup\\{x_{k+1},\nx_{k+2},\\dots,x_{k+D}\\}$. The single unicast index coding problem with\nsymmetric neighboring and consecutive side-information, SUICP(SNCS), is\nmotivated by topological interference management problems in wireless\ncommunication networks. Maleki, Cadambe and Jafar obtained the symmetric\ncapacity of this SUICP(SNCS) and proposed optimal length codes by using\nVandermonde matrices. In our earlier work, we gave optimal length\n$(U+1)$-dimensional vector linear index codes for SUICP(SNCS) satisfying some\nconditions on $K,D$ and $U$ \\cite{VaR1}. In this paper, for SUICP(SNCS) with\narbitrary $K,D$ and $U$, we construct optimal length\n$\\frac{U+1}{\\text{gcd}(K,D-U,U+1)}$-dimensional vector linear index codes. We\nprove that the constructed vector linear index code is of minimal dimension if\n$\\text{gcd}(K-D+U,U+1)$ is equal to $\\text{gcd}(K,D-U,U+1)$. The proposed\nconstruction gives optimal length scalar linear index codes for the SUICP(SNCS)\nif $(U+1)$ divides both $K$ and $D-U$. The proposed construction is independent\nof field size and works over every field. We give a low-complexity decoding for\nthe SUICP(SNCS). By using the proposed decoding method, every receiver is able\nto decode its wanted message symbol by simply adding some index code symbols\n(broadcast symbols).","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Vaddi Mahesh Babu","Rajan B. Sundar"],"created":"2018-01-01","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00410","title":"Enhanced ${q}$-Least Mean Square","abstract":"In this work, a new class of stochastic gradient algorithm is developed based\non $q$-calculus. Unlike the existing $q$-LMS algorithm, the proposed approach\nfully utilizes the concept of $q$-calculus by incorporating time-varying $q$\nparameter. The proposed enhanced $q$-LMS ($Eq$-LMS) algorithm utilizes a novel,\nparameterless concept of error-correlation energy and normalization of signal\nto ensure high convergence, stability and low steady-state error. The proposed\nalgorithm automatically adapts the learning rate with respect to the error. For\nthe evaluation purpose the system identification problem is considered.\nExtensive experiments show better performance of the proposed $Eq$-LMS\nalgorithm compared to the standard $q$-LMS approach.","primary_category":"cs","categories":["math.OC","cs.SY","stat.OT"],"authors":["Khan Shujaat","Sadiq Alishba","Naseem Imran","Togneri Roberto","Bennamoun Mohammed"],"created":"2018-01-01","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00418","title":"Directional Modulation Design Based on Crossed-Dipole Arrays for Two\n  Signals With Orthogonal Polarisations","abstract":"Directional modulation (DM) is a physical layer security technique based on\nantenna arrays and so far the polarisation information has not been considered\nin its designs. To increase the channel capacity, we consider exploiting the\npolarisation information and send two different signals simultaneously at the\nsame direction, same frequency, but with different polarisations. These two\nsignals can also be considered as one composite signal using the four\ndimensional (4-D) modulation scheme across the two polarisation diversity\nchannels. In this paper, based on cross-dipole arrays, we formulate the design\nto find a set of common weight coefficients to achieve directional modulation\nfor such a composite signal and examples are provided to verify the\neffectiveness of the proposed method.","primary_category":"cs","categories":["eess.SP","cs.IT","math.IT"],"authors":["Zhang Bo","Liu Wei","Lan Xiang"],"created":"2018-01-01","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00431","title":"Ultra-Reliable Cooperative Short-Packet Communications with Wireless\n  Energy Transfer","abstract":"We analyze a cooperative wireless communication system with finite block\nlength and finite battery energy, under quasi-static Rayleigh fading. Source\nand relay nodes are powered by a wireless energy transfer (WET) process, while\nusing the harvested energy to feed their circuits, send pilot signals to\nestimate channels at receivers, and for wireless information transmission\n(WIT). Other power consumption sources beyond data transmission power are\nconsidered. The error probability is investigated under perfect\/imperfect\nchannel state information (CSI), while reaching accurate closed-form\napproximations in ideal direct communication system setups. We consider\nultra-reliable communication (URC) scenarios under discussion for the next\nfifth-generation (5G) of wireless systems. The numerical results show the\nexistence of an optimum pilot transmit power for channel estimation, which\nincreases with the harvested energy. We also show the importance of\ncooperation, even taking into account the multiplexing loss, in order to meet\nthe error and latency constraints of the URC systems.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["L\u00f3pez Onel L. A.","Fern\u00e1ndez Evelio M. G.","Souza Richard D.","Alves Hirley"],"created":"2018-01-01","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00432","title":"A Comparative Study of LOWESS and RBF Approximations for Visualization","abstract":"Approximation methods are widely used in many fields and many techniques have\nbeen published already. This comparative study presents a comparison of LOWESS\n(Locally weighted scatterplot smoothing) and RBF (Radial Basis Functions)\napproximation methods on noisy data as they use different approaches. The RBF\napproach is generally convenient for high dimensional scattered data sets. The\nLOWESS method needs finding a subset of nearest points if data are scattered.\nThe experiments proved that LOWESS approximation gives slightly better results\nthan RBF in the case of lower dimension, while in the higher dimensional case","primary_category":"cs","categories":["cs.GR"],"authors":["Smolik Michal","Skala Vaclav","Nedved Ondrej"],"created":"2018-01-01","updated":" ","doi":"10.1007\/978-3-319-42108-7_31"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00435","title":"Analysis and Code Design for the Binary CEO Problem under Logarithmic\n  Loss","abstract":"In this paper, we propose an efficient coding scheme for the binary Chief\nExecutive Officer (CEO) problem under logarithmic loss criterion. Courtade and\nWeissman obtained the exact rate-distortion bound for a two-link binary CEO\nproblem under this criterion. We find the optimal test-channel model and its\nparameters for the encoder of each link by using the given bound. Furthermore,\nan efficient encoding scheme based on compound LDGM-LDPC codes is presented to\nachieve the theoretical rates. In the proposed encoding scheme, a binary\nquantizer using LDGM codes and a syndrome-decoding employing LDPC codes are\napplied. An iterative decoding is also presented as a fusion center to\nreconstruct the observation bits. The proposed decoder consists of a\nsum-product algorithm with a side information from other decoder and a soft\nestimator. The output of the CEO decoder is the probability of source bits\nconditional to the received sequences of both links. This method outperforms\nthe majority-based estimation of the source bits utilized in the prior studies\nof the binary CEO problem. Our numerical examples verify a close performance of\nthe proposed coding scheme to the theoretical bound in several cases.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Nangir Mahdi","Asvadi Reza","Ahmadian-Attari Mahmoud","Chen Jun"],"created":"2018-01-01","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00441","title":"A Fast Algorithm for Line Clipping by Convex Polyhedron in E3","abstract":"A new algorithm for line clipping against convex polyhedron is given. The\nsuggested algorithm is faster for higher number of facets of the given\npolyhedron than the traditional Cyrus-Beck's and others algorithms with\ncomplexity O(N) . The suggested algorithm has O(N) complexity in the worst N\ncase and expected O(sqrt(N))) complexity. The speed up is achieved because of\n'known order' of triangles. Some principal results of comparisons of selected\nalgorithms are presented and give some imagination how the proposed algorithm\ncould be used effectively.","primary_category":"cs","categories":["cs.GR"],"authors":["Skala Vaclav"],"created":"2018-01-01","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00442","title":"O(lgN) Line Clipping Algorithm in E2","abstract":"A new O(lg N) line clipping algorithm in E2 against a convex window is\npresented. The main advantage of the presented algorithm is the principal\nacceleration of the line clipping problem solution. A comparison of the\nproposed algorithm with others shows a significant improvement in run-time.\nExperimental results for selected known algorithms are also shown.","primary_category":"cs","categories":["cs.GR"],"authors":["Skala Vaclav"],"created":"2018-01-01","updated":" ","doi":"10.1016\/0097-8493(94)90064-7"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00443","title":"Capacity Characterization of UAV-Enabled Two-User Broadcast Channel","abstract":"Although prior works have exploited the UAV's mobility to enhance the\nwireless communication performance under different setups, the fundamental\ncapacity limits of UAV-enabled\/aided multiuser communication systems have not\nyet been characterized. To fill this gap, we consider in this paper a\nUAV-enabled two-user broadcast channel (BC), where a UAV flying at a constant\naltitude is deployed to send independent information to two users at different\nfixed locations on the ground. We aim to characterize the capacity region of\nthis new type of BC over a given UAV flight duration, by jointly optimizing the\nUAV's trajectory and transmit power\/rate allocations over time, subject to the\nUAV's maximum speed and maximum transmit power constraints. First, to draw\nessential insights, we consider two special cases with asymptotically large\/low\nUAV flight duration\/speed, respectively. For the former case, it is shown that\na simple hover-fly-hover (HFH) UAV trajectory with time division multiple\naccess (TDMA) based orthogonal multiuser transmission is capacity-achieving,\nwhile in the latter case, the UAV should hover at a fixed location that is\nnearer to the user with larger achievable rate and in general superposition\ncoding (SC) based non-orthogonal transmission with interference cancellation at\nthe receiver of the nearer user is required. Next, we consider the general case\nwith finite UAV speed and flight duration. We show that the optimal UAV\ntrajectory should follow a general HFH structure, i.e., the UAV successively\nhovers at a pair of initial and final locations above the line segment of the\ntwo users each with a certain amount of time and flies unidirectionally between\nthem at the maximum speed, and SC is generally needed.","primary_category":"cs","categories":["cs.IT","math.HO","math.IT","math.OC"],"authors":["Wu Qingqing","Xu Jie","Zhang Rui"],"created":"2018-01-01","updated":"2018-01-06","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00444","title":"Common Throughput Maximization in UAV-Enabled OFDMA Systems with Delay\n  Consideration","abstract":"The use of unmanned aerial vehicles (UAVs) as communication platforms is of\ngreat practical significance in future wireless networks, especially for\non-demand deployment in temporary events and emergency situations. Although\nprior works have shown the performance improvement by exploiting the UAV's\nmobility, they mainly focus on delay-tolerant applications. As delay\nrequirements fundamentally limit the UAV's mobility, it remains unknown whether\nthe UAV is able to provide any performance gain in delay-constrained\ncommunication scenarios. Motivated by this, we study in this paper a\nUAV-enabled orthogonal frequency division multiple access (OFDMA) network where\na UAV is dispatched as a mobile base station (BS) to serve a group of users on\nthe ground. We consider a minimum-rate ratio (MRR) for each user, defined as\nthe minimum instantaneous rate required over the average achievable throughput,\nto flexibly adjust the percentage of its delay-constrained data traffic. Under\na given set of constraints on the users' MRRs, we aim to maximize the minimum\naverage throughput of all users by jointly optimizing the UAV trajectory and\nOFDMA resource allocation. First, we show that the max-min throughput in\ngeneral decreases as the users' MRR constraints become more stringent, which\nreveals a fundamental throughput-delay tradeoff in UAV-enabled communications.\nNext, we propose an iterative parameter-assisted block coordinate descent\nmethod to optimize the UAV trajectory and OFDMA resource allocation\nalternately, by applying the successive convex optimization and the Lagrange\nduality, respectively. Furthermore, an efficient and systematic UAV trajectory\ninitialization scheme is proposed based on a simple circular trajectory.\nFinally, simulation results are provided to verify our theoretical findings and\ndemonstrate the effectiveness of our proposed designs.","primary_category":"cs","categories":["cs.IT","math.DS","math.HO","math.IT","math.OC"],"authors":["Wu Qingqing","Zhang Rui"],"created":"2018-01-01","updated":"2018-01-06","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00448","title":"Level-Shifted Neural Encoded Analog-to-Digital Converter","abstract":"This paper presents the new approach in implementation of analog-to-digital\nconverter (ADC) that is based on Hopfield neural-network architecture. Hopfield\nneural ADC (NADC) is a type of recurrent neural network that is effective in\nsolving simple optimization problems, such as analog-to-digital conversion. The\nmain idea behind the proposed design is to use multiple 2-bit Hopfield NADCs\noperating as quantizers in parallel, where analog input signal to each\nsuccessive 2-bit Hopfield ADC block is passed through a voltage level shifter.\nThis is followed by a neural network encoder to remove the quantization errors.\nIn traditional Hopfield NADC based designs, increasing the number of bits could\nrequire proper scaling of the network parameters, in particular digital output\noperating region. Furthermore, the resolution improvement of traditional\nHopfield NADC creates digital error that increases with the increasing number\nof bits. The proposed design is scalable in number of bits and number of\nquantization levels, and can maintain the magnitude of digital output code\nwithin a manageable operating voltage range.","primary_category":"cs","categories":["cs.ET"],"authors":["Tankimanova Aigerim","Maan Akshay Kumar","James Alex Pappachen"],"created":"2018-01-01","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00451","title":"Facial emotion recognition using min-max similarity classifier","abstract":"Recognition of human emotions from the imaging templates is useful in a wide\nvariety of human-computer interaction and intelligent systems applications.\nHowever, the automatic recognition of facial expressions using image template\nmatching techniques suffer from the natural variability with facial features\nand recording conditions. In spite of the progress achieved in facial emotion\nrecognition in recent years, the effective and computationally simple feature\nselection and classification technique for emotion recognition is still an open\nproblem. In this paper, we propose an efficient and straightforward facial\nemotion recognition algorithm to reduce the problem of inter-class pixel\nmismatch during classification. The proposed method includes the application of\npixel normalization to remove intensity offsets followed-up with a Min-Max\nmetric in a nearest neighbor classifier that is capable of suppressing feature\noutliers. The results indicate an improvement of recognition performance from\n92.85% to 98.57% for the proposed Min-Max classification method when tested on\nJAFFE database. The proposed emotion recognition technique outperforms the\nexisting template matching methods.","primary_category":"cs","categories":["cs.CV"],"authors":["Krestinskaya Olga","James Alex Pappachen"],"created":"2018-01-01","updated":" ","doi":"10.1109\/ICACCI.2017.8125932"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00453","title":"Automated rating of recorded classroom presentations using speech\n  analysis in kazakh","abstract":"Effective presentation skills can help to succeed in business, career and\nacademy. This paper presents the design of speech assessment during the oral\npresentation and the algorithm for speech evaluation based on criteria of\noptimal intonation. As the pace of the speech and its optimal intonation varies\nfrom language to language, developing an automatic identification of language\nduring the presentation is required. Proposed algorithm was tested with\npresentations delivered in Kazakh language. For testing purposes the features\nof Kazakh phonemes were extracted using MFCC and PLP methods and created a\nHidden Markov Model (HMM) [5], [5] of Kazakh phonemes. Kazakh vowel formants\nwere defined and the correlation between the deviation rate in fundamental\nfrequency and the liveliness of the speech to evaluate intonation of the\npresentation was analyzed. It was established that the threshold value between\nmonotone and dynamic speech is 0.16 and the error for intonation evaluation is\n19%.","primary_category":"cs","categories":["cs.CL","cs.AI"],"authors":["Izbassarova Akzharkyn","Irmanova Aidana","James A. P."],"created":"2018-01-01","updated":" ","doi":"10.1109\/ICACCI.2017.8125872"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00454","title":"Quality assessment metrics for edge detection and edge-aware filtering:\n  A tutorial review","abstract":"The quality assessment of edges in an image is an important topic as it helps\nto benchmark the performance of edge detectors, and edge-aware filters that are\nused in a wide range of image processing tasks. The most popular image quality\nmetrics such as Mean squared error (MSE), Peak signal-to-noise ratio (PSNR) and\nStructural similarity (SSIM) metrics for assessing and justifying the quality\nof edges. However, they do not address the structural and functional accuracy\nof edges in images with a wide range of natural variabilities. In this review,\nwe provide an overview of all the most relevant performance metrics that can be\nused to benchmark the quality performance of edges in images. We identify four\nmajor groups of metrics and also provide a critical insight into the evaluation\nprotocol and governing equations.","primary_category":"cs","categories":["cs.CV"],"authors":["Sadykova Diana","James Alex Pappachen"],"created":"2018-01-01","updated":" ","doi":"10.1109\/ICACCI.2017.8126200"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00455","title":"Automated image segmentation for detecting cell spreading for\n  metastasizing assessments of cancer development","abstract":"The automated segmentation of cells in microscopic images is an open research\nproblem that has important implications for studies of the developmental and\ncancer processes based on in vitro models. In this paper, we present the\napproach for segmentation of the DIC images of cultured cells using G-neighbor\nsmoothing followed by Kauwahara filtering and local standard deviation approach\nfor boundary detection. NIH FIJI\/ImageJ tools are used to create the ground\ntruth dataset. The results of this work indicate that detection of cell\nboundaries using segmentation approach even in the case of realistic\nmeasurement conditions is a challenging problem.","primary_category":"cs","categories":["cs.CV"],"authors":["Kauanova Sholpan","Vorobjev Ivan","James Alex Pappachen"],"created":"2018-01-01","updated":" ","doi":"10.1109\/ICACCI.2017.8126203"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00471","title":"TWAM: A Certifying Abstract Machine for Logic Programs","abstract":"Type-preserving (or typed) compilation uses typing derivations to certify\ncorrectness properties of compilation. We have designed and implemented a\ntype-preserving compiler for a simply-typed dialect of Prolog we call T-Prolog.\nThe crux of our approach is a new certifying abstract machine which we call the\nTyped Warren Abstract Machine (TWAM). The TWAM has a dependent type system\nstrong enough to specify the semantics of a logic program in the logical\nframework LF. We present a soundness metatheorem which constitutes a partial\ncorrectness guarantee: well-typed programs implement the logic program\nspecified by their type. This metatheorem justifies our design and\nimplementation of a certifying compiler from T-Prolog to TWAM.","primary_category":"cs","categories":["cs.PL","cs.LO"],"authors":["Bohrer Brandon","Crary Karl"],"created":"2018-01-01","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00472","title":"Auto-Generation of Pipelined Hardware Designs for Polar Encoder","abstract":"This paper presents a general framework for auto-generation of pipelined\npolar encoder architectures. The proposed framework could be well represented\nby a general formula. Given arbitrary code length $N$ and the level of\nparallelism $M$, the formula could specify the corresponding hardware\narchitecture. We have written a compiler which could read the formula and then\nautomatically generate its register-transfer level (RTL) description suitable\nfor FPGA or ASIC implementation. With this hardware generation system, one\ncould explore the design space and make a trade-off between cost and\nperformance. Our experimental results have demonstrated the efficiency of this\nauto-generator for polar encoder architectures.","primary_category":"cs","categories":["cs.AR"],"authors":["Zhong Zhiwei","You Xiaohu","Zhang Chuan"],"created":"2018-01-01","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00476","title":"Aggregated Channels Network for Real-Time Pedestrian Detection","abstract":"Convolutional neural networks (CNNs) have demonstrated their superiority in\nnumerous computer vision tasks, yet their computational cost results\nprohibitive for many real-time applications such as pedestrian detection which\nis usually performed on low-consumption hardware. In order to alleviate this\ndrawback, most strategies focus on using a two-stage cascade approach.\nEssentially, in the first stage a fast method generates a significant but\nreduced amount of high quality proposals that later, in the second stage, are\nevaluated by the CNN. In this work, we propose a novel detection pipeline that\nfurther benefits from the two-stage cascade strategy. More concretely, the\nenriched and subsequently compressed features used in the first stage are\nreused as the CNN input. As a consequence, a simpler network architecture,\nadapted for such small input sizes, allows to achieve real-time performance and\nobtain results close to the state-of-the-art while running significantly faster\nwithout the use of GPU. In particular, considering that the proposed pipeline\nruns in frame rate, the achieved performance is highly competitive. We\nfurthermore demonstrate that the proposed pipeline on itself can serve as an\neffective proposal generator.","primary_category":"cs","categories":["cs.CV"],"authors":["Ghorban Farzin","Mar\u00edn Javier","Su Yu","Colombo Alessandro","Kummert Anton"],"created":"2018-01-01","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00496","title":"On the tensor rank of $3\\times 3$ permanent and determinant","abstract":"The tensor rank and border rank of the $3 \\times 3$ determinant tensor is\nknown to be $5$ if characteristic is not two. In this paper, we show that the\ntensor rank remains $5$ for fields of characteristic two as well. We also\ninclude an analysis of $5 \\times 5$ and $7 \\times 7$ determinant and permanent\ntensors, as well as the symmetric $3 \\times 3$ permanent and determinant\ntensors. We end with some remarks on binary tensors.","primary_category":"cs","categories":["math.CO","cs.CC"],"authors":["Krishna Siddharth","Makam Visu"],"created":"2018-01-01","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00500","title":"Chance-Constrained Outage Scheduling using a Machine Learning Proxy","abstract":"Outage scheduling aims at defining, over a horizon of several months to\nyears, when different components needing maintenance should be taken out of\noperation. Its objective is to minimize operation-cost expectation while\nsatisfying reliability-related constraints. We propose a distributed\nscenario-based chance-constrained optimization formulation for this problem. To\ntackle tractability issues arising in large networks, we use machine learning\nto build a proxy for predicting outcomes of power system operation processes in\nthis context. On the IEEE-RTS79 and IEEE-RTS96 networks, our solution obtains\ncheaper and more reliable plans than other candidates.","primary_category":"cs","categories":["cs.CE"],"authors":["Dalal Gal","Gilboa Elad","Mannor Shie","Wehenkel Louis"],"created":"2018-01-01","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00508","title":"Depth-Adaptive Computational Policies for Efficient Visual Tracking","abstract":"Current convolutional neural networks algorithms for video object tracking\nspend the same amount of computation for each object and video frame. However,\nit is harder to track an object in some frames than others, due to the varying\namount of clutter, scene complexity, amount of motion, and object's\ndistinctiveness against its background. We propose a depth-adaptive\nconvolutional Siamese network that performs video tracking adaptively at\nmultiple neural network depths. Parametric gating functions are trained to\ncontrol the depth of the convolutional feature extractor by minimizing a joint\nloss of computational cost and tracking error. Our network achieves accuracy\ncomparable to the state-of-the-art on the VOT2016 benchmark. Furthermore, our\nadaptive depth computation achieves higher accuracy for a given computational\ncost than traditional fixed-structure neural networks. The presented framework\nextends to other tasks that use convolutional neural networks and enables\ntrading speed for accuracy at runtime.","primary_category":"cs","categories":["cs.CV"],"authors":["Ying Chris","Fragkiadaki Katerina"],"created":"2018-01-01","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00518","title":"Statistical and Computational Limits for Sparse Matrix Detection","abstract":"This paper investigates the fundamental limits for detecting a\nhigh-dimensional sparse matrix contaminated by white Gaussian noise from both\nthe statistical and computational perspectives. We consider $p\\times p$\nmatrices whose rows and columns are individually $k$-sparse. We provide a tight\ncharacterization of the statistical and computational limits for sparse matrix\ndetection, which precisely describe when achieving optimal detection is easy,\nhard, or impossible, respectively. Although the sparse matrices considered in\nthis paper have no apparent submatrix structure and the corresponding\nestimation problem has no computational issue at all, the detection problem has\na surprising computational barrier when the sparsity level $k$ exceeds the\ncubic root of the matrix size $p$: attaining the optimal detection boundary is\ncomputationally at least as hard as solving the planted clique problem.\n  The same statistical and computational limits also hold in the sparse\ncovariance matrix model, where each variable is correlated with at most $k$\nothers. A key step in the construction of the statistically optimal test is a\nstructural property for sparse matrices, which can be of independent interest.","primary_category":"cs","categories":["math.ST","cs.IT","math.IT","stat.TH"],"authors":["Cai T. Tony","Wu Yihong"],"created":"2018-01-01","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00522","title":"A Fair Adaptive Data Rate Algorithm for LoRaWAN","abstract":"LoRaWAN exhibits several characteristics that can lead to an unfair\ndistribution of the Data Extracted Rate (DER) among nodes. Firstly, the capture\neffect leads to a strong signal suppressing a weaker signal at the gateway and\nsecondly, the spreading codes used are not perfectly orthogonal, causing packet\nloss if an interfering signal is strong enough. In these conditions, nodes\nexperiencing higher attenuation are less likely to see their packets received\ncorrectly. We develop FADR, a Fair Adaptive Data Rate algorithm for LoRaWAN\nthat exploits the different Spreading Factors (SFs) and Transmission Powers\n(TPs) settings available in LoRa to achieve a fair Data Extraction Rate among\nall nodes while at the same time avoiding excessively high TPs. Simulations\nshow that FADR, in highly congested cells, achieves 300% higher fairness than\nthe minimum airtime allocation approach and 22% higher fairness than Brechts\napproach, while consuming almost 22% lower energy.","primary_category":"cs","categories":["cs.NI"],"authors":["Abdelfadeel Khaled Q.","Cionca Victor","Pesch Dirk"],"created":"2018-01-01","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00524","title":"Learning Deep Structured Multi-Scale Features using Attention-Gated CRFs\n  for Contour Prediction","abstract":"Recent works have shown that exploiting multi-scale representations deeply\nlearned via convolutional neural networks (CNN) is of tremendous importance for\naccurate contour detection. This paper presents a novel approach for predicting\ncontours which advances the state of the art in two fundamental aspects, i.e.\nmulti-scale feature generation and fusion. Different from previous works\ndirectly consider- ing multi-scale feature maps obtained from the inner layers\nof a primary CNN architecture, we introduce a hierarchical deep model which\nproduces more rich and complementary representations. Furthermore, to refine\nand robustly fuse the representations learned at different scales, the novel\nAttention-Gated Conditional Random Fields (AG-CRFs) are proposed. The\nexperiments ran on two publicly available datasets (BSDS500 and NYUDv2)\ndemonstrate the effectiveness of the latent AG-CRF model and of the overall\nhierarchical framework.","primary_category":"cs","categories":["cs.CV"],"authors":["Xu Dan","Ouyang Wanli","Alameda-Pineda Xavier","Ricci Elisa","Wang Xiaogang","Sebe Nicu"],"created":"2018-01-01","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00532","title":"Learning Multimodal Word Representation via Dynamic Fusion Methods","abstract":"Multimodal models have been proven to outperform text-based models on\nlearning semantic word representations. Almost all previous multimodal models\ntypically treat the representations from different modalities equally. However,\nit is obvious that information from different modalities contributes\ndifferently to the meaning of words. This motivates us to build a multimodal\nmodel that can dynamically fuse the semantic representations from different\nmodalities according to different types of words. To that end, we propose three\nnovel dynamic fusion methods to assign importance weights to each modality, in\nwhich weights are learned under the weak supervision of word association pairs.\nThe extensive experiments have demonstrated that the proposed methods\noutperform strong unimodal baselines and state-of-the-art multimodal models.","primary_category":"cs","categories":["cs.CL"],"authors":["Wang Shaonan","Zhang Jiajun","Zong Chengqing"],"created":"2018-01-01","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00535","title":"Scale-free Loopy Structure is Resistant to Noise in Consensus Dynamics\n  in Complex Networks","abstract":"The vast majority of real-world networks are scale-free, loopy, and sparse,\nwith a power-law degree distribution and a constant average degree. In this\npaper, we study first-order consensus dynamics in binary scale-free networks,\nwhere vertices are subject to white noise. We focus on the coherence of\nnetworks characterized in terms of the $H_2$-norm, which quantifies how closely\nagents track the consensus value. We first provide a lower bound of coherence\nof a network in terms of its average degree, which is independent of the\nnetwork order. We then study the coherence of some sparse, scale-free\nreal-world networks, which approaches a constant. We also study numerically the\ncoherence of Barab\\'asi-Albert networks and high-dimensional random Apollonian\nnetworks, which also converges to a constant when the networks grow. Finally,\nbased on the connection of coherence and the Kirchhoff index, we study\nanalytically the coherence of two deterministically-growing sparse networks and\nobtain the exact expressions, which tend to small constants. Our results\nindicate that the effect of noise on the consensus dynamics in power-law\nnetworks is negligible. We argue that scale-free topology, together with loopy\nstructure, is responsible for the strong robustness with respect to noisy\nconsensus dynamics in power-law networks.","primary_category":"cs","categories":["cs.SY","cs.SI"],"authors":["Yi Yuhao","Zhang Zhongzhi","Patterson Stacy"],"created":"2018-01-01","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00540","title":"M2: Malleable Metal as a Service","abstract":"Existing bare-metal cloud services that provide users with physical nodes\nhave a number of serious disadvantage over their virtual alternatives,\nincluding slow provisioning times, difficulty for users to release nodes and\nthen reuse them to handle changes in demand, and poor tolerance to failures. We\nintroduce M2, a bare-metal cloud service that uses network-mounted boot drives\nto overcome these disadvantages. We describe the architecture and\nimplementation of M2 and compare its agility, scalability, and performance to\nexisting systems. We show that M2 can reduce provisioning time by over 50%\nwhile offering richer functionality, and comparable run-time performance with\nrespect to tools that provision images into local disks. M2 is open source and\navailable at https:\/\/github.com\/CCI-MOC\/ims.","primary_category":"cs","categories":["cs.DC"],"authors":["Mohan Apoorve","Turk Ata","Gudimetla Ravi S.","Tikale Sahil","Hennesey Jason","Kaynar Ugur","Cooperman Gene","Desnoyers Peter","Krieger Orran"],"created":"2018-01-01","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00554","title":"Did you hear that? Adversarial Examples Against Automatic Speech\n  Recognition","abstract":"Speech is a common and effective way of communication between humans, and\nmodern consumer devices such as smartphones and home hubs are equipped with\ndeep learning based accurate automatic speech recognition to enable natural\ninteraction between humans and machines. Recently, researchers have\ndemonstrated powerful attacks against machine learning models that can fool\nthem to produceincorrect results. However, nearly all previous research in\nadversarial attacks has focused on image recognition and object detection\nmodels. In this short paper, we present a first of its kind demonstration of\nadversarial attacks against speech classification model. Our algorithm performs\ntargeted attacks with 87% success by adding small background noise without\nhaving to know the underlying model parameter and architecture. Our attack only\nchanges the least significant bits of a subset of audio clip samples, and the\nnoise does not change 89% the human listener's perception of the audio clip as\nevaluated in our human study.","primary_category":"cs","categories":["cs.CL","cs.CR"],"authors":["Alzantot Moustafa","Balaji Bharathan","Srivastava Mani"],"created":"2018-01-02","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00563","title":"Block Diagonalization Type Precoding Algorithms for IEEE 802.11ac\n  Systems","abstract":"Block diagonalization (BD) based precoding schemes are well-known linear\ntransmit strategies employed in the downlink of multi-user multiple-input\nmultipleoutput (MU-MIMO) systems. BD type precoding algorithms employed at the\ntransmit side effect the suppression of multi-user interference (MUI) by the\ndecomposition of MU-MIMO broadcast channel into multiple single-user MIMO\n(SU-MIMO) channels followed by parallelization of the SU-MIMO channels to\nobtain independent streams of each user. Given that the design of linear\nprecoding algorithms has made significant progress, the implementation of these\ntechniques in standards for wireless local area networks (WLAN) remains an open\nquestion. In this work, schemes for implementation of BD based precoding\ntechniques in the framework of IEEE 802.11ac standard are proposed followed by\nperformance evaluation of these techniques in the proposed framework. I analyze\nthe sum-rate and the bit-error-rate (BER) performance of the techniques in my\nframework and obtain computational complexity-wise as well as performance-wise\noptimal algorithm for my system.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Majumdar Ishhanie"],"created":"2018-01-02","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00588","title":"Improving Stock Market Prediction via Heterogeneous Information Fusion","abstract":"Traditional stock market prediction approaches commonly utilize the\nhistorical price-related data of the stocks to forecast their future trends. As\nthe Web information grows, recently some works try to explore financial news to\nimprove the prediction. Effective indicators, e.g., the events related to the\nstocks and the people's sentiments towards the market and stocks, have been\nproved to play important roles in the stocks' volatility, and are extracted to\nfeed into the prediction models for improving the prediction accuracy. However,\na major limitation of previous methods is that the indicators are obtained from\nonly a single source whose reliability might be low, or from several data\nsources but their interactions and correlations among the multi-sourced data\nare largely ignored.\n  In this work, we extract the events from Web news and the users' sentiments\nfrom social media, and investigate their joint impacts on the stock price\nmovements via a coupled matrix and tensor factorization framework.\nSpecifically, a tensor is firstly constructed to fuse heterogeneous data and\ncapture the intrinsic relations among the events and the investors' sentiments.\nDue to the sparsity of the tensor, two auxiliary matrices, the stock\nquantitative feature matrix and the stock correlation matrix, are constructed\nand incorporated to assist the tensor decomposition. The intuition behind is\nthat stocks that are highly correlated with each other tend to be affected by\nthe same event. Thus, instead of conducting each stock prediction task\nseparately and independently, we predict multiple correlated stocks\nsimultaneously through their commonalities, which are enabled via sharing the\ncollaboratively factorized low rank matrices between matrices and the tensor.\nEvaluations on the China A-share stock data and the HK stock data in the year\n2015 demonstrate the effectiveness of the proposed model.","primary_category":"cs","categories":["cs.SI","physics.soc-ph","q-fin.ST"],"authors":["Zhang Xi","Zhang Yunjia","Wang Senzhang","Yao Yuntao","Fang Binxing","Yu Philip S."],"created":"2018-01-02","updated":" ","doi":"10.1016\/j.knosys.2017.12.025"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00597","title":"Exploiting Investors Social Network for Stock Prediction in China's\n  Market","abstract":"Recent works have shown that social media platforms are able to influence the\ntrends of stock price movements. However, existing works have majorly focused\non the U.S. stock market and lacked attention to certain emerging countries\nsuch as China, where retail investors dominate the market. In this regard, as\nretail investors are prone to be influenced by news or other social media,\npsychological and behavioral features extracted from social media platforms are\nthought to well predict stock price movements in the China's market. Recent\nadvances in the investor social network in China enables the extraction of such\nfeatures from web-scale data. In this paper, on the basis of tweets from\nXueqiu, a popular Chinese Twitter-like social platform specialized for\ninvestors, we analyze features with regard to collective sentiment and\nperception on stock relatedness and predict stock price movements by employing\nnonlinear models. The features of interest prove to be effective in our\nexperiments.","primary_category":"cs","categories":["cs.CE","q-fin.GN"],"authors":["Zhang Xi","Shi Jiawei","Wang Di","Fang Binxing"],"created":"2018-01-02","updated":" ","doi":"10.1016\/j.jocs.2017.10.013"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00600","title":"Static Free Space Detection with Laser Scanner using Occupancy Grid Maps","abstract":"Drivable free space information is vital for autonomous vehicles that have to\nplan evasive maneuvers in real-time. In this paper, we present a new efficient\nmethod for environmental free space detection with laser scanner based on 2D\noccupancy grid maps (OGM) to be used for Advanced Driving Assistance Systems\n(ADAS) and Collision Avoidance Systems (CAS). Firstly, we introduce an enhanced\ninverse sensor model tailored for high-resolution laser scanners for building\nOGM. It compensates the unreflected beams and deals with the ray casting to\ngrid cells accuracy and computational effort problems. Secondly, we introduce\nthe 'vehicle on a circle for grid maps' map alignment algorithm that allows\nbuilding more accurate local maps by avoiding the computationally expensive\ninaccurate operations of image sub-pixel shifting and rotation. The resulted\ngrid map is more convenient for ADAS features than existing methods, as it\nallows using less memory sizes, and hence, results into a better real-time\nperformance. Thirdly, we present an algorithm to detect what we call the\n'in-sight edges'. These edges guarantee modeling the free space area with a\nsingle polygon of a fixed number of vertices regardless the driving situation\nand map complexity. The results from real world experiments show the\neffectiveness of our approach.","primary_category":"cs","categories":["cs.RO"],"authors":["Eraqi Hesham M.","Honer Jens","Zuther Sebastian"],"created":"2018-01-02","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00602","title":"Accurate reconstruction of image stimuli from human fMRI based on the\n  decoding model with capsule network architecture","abstract":"In neuroscience, all kinds of computation models were designed to answer the\nopen question of how sensory stimuli are encoded by neurons and conversely, how\nsensory stimuli can be decoded from neuronal activities. Especially, functional\nMagnetic Resonance Imaging (fMRI) studies have made many great achievements\nwith the rapid development of the deep network computation. However, comparing\nwith the goal of decoding orientation, position and object category from\nactivities in visual cortex, accurate reconstruction of image stimuli from\nhuman fMRI is a still challenging work. In this paper, the capsule network\n(CapsNet) architecture based visual reconstruction (CNAVR) method is developed\nto reconstruct image stimuli. The capsule means containing a group of neurons\nto perform the better organization of feature structure and representation,\ninspired by the structure of cortical mini column including several hundred\nneurons in primates. The high-level capsule features in the CapsNet includes\ndiverse features of image stimuli such as semantic class, orientation, location\nand so on. We used these features to bridge between human fMRI and image\nstimuli. We firstly employed the CapsNet to train the nonlinear mapping from\nimage stimuli to high-level capsule features, and from high-level capsule\nfeatures to image stimuli again in an end-to-end manner. After estimating the\nserviceability of each voxel by encoding performance to accomplish the\nselecting of voxels, we secondly trained the nonlinear mapping from\ndimension-decreasing fMRI data to high-level capsule features. Finally, we can\npredict the high-level capsule features with fMRI data, and reconstruct image\nstimuli with the CapsNet. We evaluated the proposed CNAVR method on the dataset\nof handwritten digital images, and exceeded about 10% than the accuracy of all\nexisting state-of-the-art methods on the structural similarity index (SSIM).","primary_category":"cs","categories":["cs.CV","cs.AI","q-bio.NC"],"authors":["Qiao Kai","Zhang Chi","Wang Linyuan","Yan Bin","Chen Jian","Zeng Lei","Tong Li"],"created":"2018-01-02","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00605","title":"Scene-Adapted Plug-and-Play Algorithm with Guaranteed Convergence:\n  Applications to Data Fusion in Imaging","abstract":"The recently proposed plug-and-play (PnP) framework allows leveraging recent\ndevelopments in image denoising to tackle other, more involved, imaging inverse\nproblems. In a PnP method, a black-box denoiser is plugged into an iterative\nalgorithm, taking the place of a formal denoising step that corresponds to the\nproximity operator of some convex regularizer. While this approach offers\nflexibility and excellent performance, convergence of the resulting algorithm\nmay be hard to analyze, as most state-of-the-art denoisers lack an explicit\nunderlying objective function. In this paper, we propose a PnP approach where a\nscene-adapted prior (i.e., where the denoiser is targeted to the specific scene\nbeing imaged) is plugged into ADMM (alternating direction method of\nmultipliers), and prove convergence of the resulting algorithm. Finally, we\napply the proposed framework in two different imaging inverse problems:\nhyperspectral sharpening\/fusion and image deblurring from blurred\/noisy image\npairs.","primary_category":"cs","categories":["cs.CV"],"authors":["Teodoro Afonso M.","Bioucas-Dias Jos\u00e9 M.","Figueiredo M\u00e1rio A. T."],"created":"2018-01-02","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00606","title":"Secrecy Capacity-Memory Tradeoff of Erasure Broadcast Channels","abstract":"This paper derives upper and lower bounds on the secrecy capacity-memory\ntradeoff of a wiretap erasure broadcast channel (BC) with Kw weak receivers and\nKs strong receivers, where weak receivers, respectively strong receivers, have\nsame erasure probabilities and cache sizes. The lower bounds are achieved by\nschemes that meticulously combine joint cache-channel coding with wiretap\ncoding and key-aided one-time pads. The presented upper bound holds more\ngenerally for arbitrary degraded BCs and arbitrary cache sizes. When only weak\nreceivers have cache memories, upper and lower bounds coincide for small and\nlarge cache memories, thus providing the exact secrecy capacity-memory tradeoff\nfor this setup. The derived bounds allow to further conclude that the secrecy\ncapacity is positive even when the eavesdropper is stronger than all the\nlegitimate receivers with cache memories. Moreover, they show that the secrecy\ncapacity-memory tradeoff can be significantly smaller than its non-secure\ncounterpart, but it grows much faster when cache memories are small. The paper\nalso presents a lower bound on the global secrecy capacity-memory tradeoff\nwhere one is allowed to optimize the cache assignment subject to a total cache\nbudget. It is close to the best known lower bound without secrecy constraint.\nFor small total cache budget, the global secrecy capacity-memory tradeoff is\nachieved by assigning all the available cache memory uniformly over all\nreceivers if the eavesdropper is stronger than all legitimate receivers, and it\nis achieved by assigning the cache memory uniformly only over the weak\nreceivers if the eavesdropper is weaker than the strong receivers.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Kamel Sarah","Sarkiss Mireille","Wigger Mich\u00e8le","Othman Ghaya Rekaya-Ben"],"created":"2018-01-02","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00625","title":"An Attentive Sequence Model for Adverse Drug Event Extraction from\n  Biomedical Text","abstract":"Adverse reaction caused by drugs is a potentially dangerous problem which may\nlead to mortality and morbidity in patients. Adverse Drug Event (ADE)\nextraction is a significant problem in biomedical research. We model ADE\nextraction as a Question-Answering problem and take inspiration from Machine\nReading Comprehension (MRC) literature, to design our model. Our objective in\ndesigning such a model, is to exploit the local linguistic context in clinical\ntext and enable intra-sequence interaction, in order to jointly learn to\nclassify drug and disease entities, and to extract adverse reactions caused by\na given drug. Our model makes use of a self-attention mechanism to facilitate\nintra-sequence interaction in a text sequence. This enables us to visualize and\nunderstand how the network makes use of the local and wider context for\nclassification.","primary_category":"cs","categories":["cs.CL"],"authors":["Ramamoorthy Suriyadeepan","Murugan Selvakumar"],"created":"2018-01-02","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00631","title":"Deep Learning: A Critical Appraisal","abstract":"Although deep learning has historical roots going back decades, neither the\nterm \"deep learning\" nor the approach was popular just over five years ago,\nwhen the field was reignited by papers such as Krizhevsky, Sutskever and\nHinton's now classic (2012) deep network model of Imagenet. What has the field\ndiscovered in the five subsequent years? Against a background of considerable\nprogress in areas such as speech recognition, image recognition, and game\nplaying, and considerable enthusiasm in the popular press, I present ten\nconcerns for deep learning, and suggest that deep learning must be supplemented\nby other techniques if we are to reach artificial general intelligence.","primary_category":"cs","categories":["cs.AI","cs.LG","stat.ML"],"authors":["Marcus Gary"],"created":"2018-01-02","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00632","title":"Character-level Recurrent Neural Networks in Practice: Comparing\n  Training and Sampling Schemes","abstract":"Recurrent neural networks are nowadays successfully used in an abundance of\napplications, going from text, speech and image processing to recommender\nsystems. Backpropagation through time is the algorithm that is commonly used to\ntrain these networks on specific tasks. Many deep learning frameworks have\ntheir own implementation of training and sampling procedures for recurrent\nneural networks, while there are in fact multiple other possibilities to choose\nfrom and other parameters to tune. In existing literature this is very often\noverlooked or ignored. In this paper we therefore give an overview of possible\ntraining and sampling schemes for character-level recurrent neural networks to\nsolve the task of predicting the next token in a given sequence. We test these\ndifferent schemes on a variety of datasets, neural network architectures and\nparameter settings, and formulate a number of take-home recommendations. The\nchoice of training and sampling scheme turns out to be subject to a number of\ntrade-offs, such as training stability, sampling time, model performance and\nimplementation effort, but is largely independent of the data. Perhaps the most\nsurprising result is that transferring hidden states for correctly initializing\nthe model on subsequences often leads to unstable training behavior depending\non the dataset.","primary_category":"cs","categories":["cs.LG","cs.CL","stat.ML"],"authors":["De Boom Cedric","Demeester Thomas","Dhoedt Bart"],"created":"2018-01-02","updated":"2018-01-09","doi":"10.1007\/s00521-017-3322-z"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00635","title":"Image denoising through bivariate shrinkage function in framelet domain","abstract":"Denoising of coefficients in a sparse domain (e.g. wavelet) has been\nresearched extensively because of its simplicity and effectiveness. Literature\nmainly has focused on designing the best global threshold. However, this paper\nproposes a new denoising method using bivariate shrinkage function in framelet\ndomain. In the proposed method, maximum aposteriori probability is used for\nestimate of the denoised coefficient and non-Gaussian bivariate function is\napplied to model the statistics of framelet coefficients. For every framelet\ncoefficient, there is a corresponding threshold depending on the local\nstatistics of framelet coefficients. Experimental results show that using\nbivariate shrinkage function in framelet domain yields significantly superior\nimage quality and higher PSNR than some well-known denoising methods.","primary_category":"cs","categories":["eess.IV","cs.CV"],"authors":["Shahdoosti Hamid Reza"],"created":"2018-01-02","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00641","title":"Triangle-mapping Analysis on Spatial Competition and Cooperation of\n  Chinese Cities","abstract":"In this paper, we empirically analyze the spatial distribution of Chinese\ncities using a method based on triangle transition. This method uses a regular\ntriangle mapping from the observed cities and its three neighboring cities to\nanalyze their distribution of mapping positions. We find that obvious\ncenter-gathering tendency for the relationship between cities and its nearest\nthree cities, indicating the spatial competition between cities. Moreover, we\nobserved the competitive trends between neighboring cities with similar\neconomic volume, and the remarkable cooperative tendency between neighboring\ncities with large difference on economy. The threshold of the ratio of the two\ncities' economic volume on the transition from competition to cooperation is\nabout 1.2. These findings are helpful in the understanding of the cities\neconomic relationship, especially in the study of competition and cooperation\nbetween cities.","primary_category":"cs","categories":["physics.soc-ph","cs.CY","stat.AP"],"authors":["Liu Pan","Han Xiao-Pu","L\u00fc Linyuan"],"created":"2018-01-02","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00649","title":"Validation of Hardware Security and Trust: A Survey","abstract":"With ever advancing in digital system, security has been emerged as a major\nconcern. Many researchers all around the world come up with solutions to\naddress various challenges that are crucial for industry and market. The aim of\nthis survey is a brief review of challenges of security validation as well as\ndefine and classify Hardware Trojans. Then, we provide more details about\nvarious validation techniques for hardware security and trust.","primary_category":"cs","categories":["cs.CR"],"authors":["Behnam Payman"],"created":"2018-01-02","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00687","title":"Scilla: a Smart Contract Intermediate-Level LAnguage","abstract":"This paper outlines key design principles of Scilla---an intermediate-level\nlanguage for verified smart contracts.\n  Scilla provides a clean separation between the communication aspect of smart\ncontracts on a blockchain, allowing for the rich interaction patterns, and a\nprogramming component, which enjoys principled semantics and is amenable to\nformal verification. Scilla is not meant to be a high-level programming\nlanguage, and we are going to use it as a translation target for high-level\nlanguages, such as Solidity, for performing program analysis and verification,\nbefore further compilation to an executable bytecode.\n  We describe the automata-based model of Scilla, present its programming\ncomponent and show how contract definitions in terms of automata streamline the\nprocess of mechanised verification of their safety and temporal properties.","primary_category":"cs","categories":["cs.PL"],"authors":["Sergey Ilya","Kumar Amrit","Hobor Aquinas"],"created":"2018-01-02","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00688","title":"Learning audio and image representations with bio-inspired trainable\n  feature extractors","abstract":"Recent advancements in pattern recognition and signal processing concern the\nautomatic learning of data representations from labeled training samples.\nTypical approaches are based on deep learning and convolutional neural\nnetworks, which require large amount of labeled training samples. In this work,\nwe propose novel feature extractors that can be used to learn the\nrepresentation of single prototype samples in an automatic configuration\nprocess. We employ the proposed feature extractors in applications of audio and\nimage processing, and show their effectiveness on benchmark data sets.","primary_category":"cs","categories":["cs.CV","cs.AI","cs.SD","eess.AS","eess.IV"],"authors":["Strisciuglio Nicola"],"created":"2018-01-02","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00690","title":"DeepMind Control Suite","abstract":"The DeepMind Control Suite is a set of continuous control tasks with a\nstandardised structure and interpretable rewards, intended to serve as\nperformance benchmarks for reinforcement learning agents. The tasks are written\nin Python and powered by the MuJoCo physics engine, making them easy to use and\nmodify. We include benchmarks for several learning algorithms. The Control\nSuite is publicly available at https:\/\/www.github.com\/deepmind\/dm_control . A\nvideo summary of all tasks is available at http:\/\/youtu.be\/rAai4QzcYbs .","primary_category":"cs","categories":["cs.AI"],"authors":["Tassa Yuval","Doron Yotam","Muldal Alistair","Erez Tom","Li Yazhe","Casas Diego de Las","Budden David","Abdolmaleki Abbas","Merel Josh","Lefrancq Andrew","Lillicrap Timothy","Riedmiller Martin"],"created":"2018-01-02","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00693","title":"Denoising Adversarial Autoencoders: Classifying Skin Lesions Using\n  Limited Labelled Training Data","abstract":"We propose a novel deep learning model for classifying medical images in the\nsetting where there is a large amount of unlabelled medical data available, but\nlabelled data is in limited supply. We consider the specific case of\nclassifying skin lesions as either malignant or benign. In this setting, the\nproposed approach -- the semi-supervised, denoising adversarial autoencoder --\nis able to utilise vast amounts of unlabelled data to learn a representation\nfor skin lesions, and small amounts of labelled data to assign class labels\nbased on the learned representation. We analyse the contributions of both the\nadversarial and denoising components of the model and find that the combination\nyields superior classification performance in the setting of limited labelled\ntraining data.","primary_category":"cs","categories":["cs.CV"],"authors":["Creswell Antonia","Pouplin Alison","Bharath Anil A"],"created":"2018-01-02","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00694","title":"The New Threats of Information Hiding: the Road Ahead","abstract":"Compared to cryptography, steganography is a less discussed domain. However,\nthere is a recent trend of exploiting various information hiding techniques to\nempower malware, for instance to bypass security frameworks of mobile devices\nor to exfiltrate sensitive data. This is mostly due to the need to counteract\nincreasingly sophisticated security mechanisms, such as code analysis, runtime\ncountermeasures, or real-time traffic inspection tools. In this perspective,\nthis paper presents malware exploiting information hiding in a broad sense,\ni.e., it does not focus on classical covert channels, but also discusses other\ncamouflage techniques. Differently from other works, this paper solely focuses\non real-world threats observed in the 2011 - 2017 timeframe. The observation\nindicates a growing number of malware equipped with some form of data hiding\ncapabilities and a lack of effective and universal countermeasures.","primary_category":"cs","categories":["cs.CR"],"authors":["Cabaj K.","Caviglione L.","Mazurczyk W.","Wendzel S.","Woodward A.","Zander S."],"created":"2018-01-02","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00702","title":"A total uncertainty measure for D numbers based on belief intervals","abstract":"As a generalization of Dempster-Shafer theory, the theory of D numbers is a\nnew theoretical framework for uncertainty reasoning. Measuring the uncertainty\nof knowledge or information represented by D numbers is an unsolved issue in\nthat theory. In this paper, inspired by distance based uncertainty measures for\nDempster-Shafer theory, a total uncertainty measure for a D number is proposed\nbased on its belief intervals. The proposed total uncertainty measure can\nsimultaneously capture the discord, and non-specificity, and non-exclusiveness\ninvolved in D numbers. And some basic properties of this total uncertainty\nmeasure, including range, monotonicity, generalized set consistency, are also\npresented.","primary_category":"cs","categories":["cs.AI"],"authors":["Deng Xinyang","Jiang Wen"],"created":"2017-12-25","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00708","title":"Restricted Deformable Convolution based Road Scene Semantic Segmentation\n  Using Surround View Cameras","abstract":"Understanding the surrounding environment of the vehicle is still one of the\nchallenges for autonomous driving. This paper addresses 360-degree road scene\nsemantic segmentation using surround view cameras, which are widely equipped in\nexisting production cars. First, in order to address large distortion problem\nin the fisheye images, Restricted Deformable Convolution (RDC) is proposed for\nsemantic segmentation, which can effectively model geometric transformations by\nlearning the shapes of convolutional filters conditioned on the input feature\nmap. Second, in order to obtain a large-scale training set of surround view\nimages, a novel method called zoom augmentation is proposed to transform\nconventional images to fisheye images. Finally, an RDC based semantic\nsegmentation model is built. The model is trained for real-world surround view\nimages through a multi-task learning architecture by combining real-world\nimages with transformed images. Experiments demonstrate the effectiveness of\nthe RDC to handle images with large distortions, and the proposed approach\nshows a good performance using surround view cameras with the help of the\ntransformed images.","primary_category":"cs","categories":["cs.CV"],"authors":["Deng Liuyuan","Yang Ming","Li Hao","Li Tianyi","Hu Bing","Wang Chunxiang"],"created":"2018-01-02","updated":"2018-01-03","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00711","title":"Network-Scale Traffic Modeling and Forecasting with Graphical Lasso and\n  Neural Networks","abstract":"Traffic flow forecasting, especially the short-term case, is an important\ntopic in intelligent transportation systems (ITS). This paper does a lot of\nresearch on network-scale modeling and forecasting of short-term traffic flows.\nFirstly, we propose the concepts of single-link and multi-link models of\ntraffic flow forecasting. Secondly, we construct four prediction models by\ncombining the two models with single-task learning and multi-task learning. The\ncombination of the multi-link model and multi-task learning not only improves\nthe experimental efficiency but also the prediction accuracy. Moreover, a new\nmulti-link single-task approach that combines graphical lasso (GL) with neural\nnetwork (NN) is proposed. GL provides a general methodology for solving\nproblems involving lots of variables. Using L1 regularization, GL builds a\nsparse graphical model making use of the sparse inverse covariance matrix. In\naddition, Gaussian process regression (GPR) is a classic regression algorithm\nin Bayesian machine learning. Although there is wide research on GPR, there are\nfew applications of GPR in traffic flow forecasting. In this paper, we apply\nGPR to traffic flow forecasting and show its potential. Through sufficient\nexperiments, we compare all of the proposed approaches and make an overall\nassessment at last.","primary_category":"cs","categories":["cs.LG","stat.ML"],"authors":["Sun Shiliang","Huang Rongqing","Gao Ya"],"created":"2017-12-24","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00712","title":"Multi-Objective Vehicle Routing Problem Applied to Large Scale Post\n  Office Deliveries","abstract":"The number of optimization techniques in the combinatorial domain is large\nand diversified. Nevertheless, real-world based benchmarks for testing\nalgorithms are few. This work creates an extensible real-world mail delivery\nbenchmark to the Vehicle Routing Problem (VRP) in a planar graph embedded in\nthe 2D Euclidean space. Such problem is multi-objective on a roadmap with up to\n25 vehicles and 30,000 deliveries per day. Each instance models one generic day\nof mail delivery, allowing both comparison and validation of optimization\nalgorithms for routing problems. The benchmark may be extended to model other\nscenarios.","primary_category":"cs","categories":["cs.AI","cs.CC"],"authors":["Meira Luis A. A.","Martins Paulo S.","Menzori Mauro","Zeni Guilherme A."],"created":"2017-12-23","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00716","title":"Computing Hitting Set Kernels By AC^0-Circuits","abstract":"Given a hypergraph $H = (V,E)$, what is the smallest subset $X \\subseteq V$\nsuch that $e \\cap X \\neq \\emptyset$ holds for all $e \\in E$? This problem,\nknown as the hitting set problem, is a basic problem in parameterized\ncomplexity theory. There are well-known kernelization algorithms for it, which\nget a hypergraph $H$ and a number $k$ as input and output a hypergraph $H'$\nsuch that (1) $H$ has a hitting set of size $k$ if, and only if, $H'$ has such\na hitting set and (2) the size of $H'$ depends only on $k$ and on the maximum\ncardinality $d$ of edges in $H$. The algorithms run in polynomial time, but are\nhighly sequential. Recently, it has been shown that one of them can be\nparallelized to a certain degree: one can compute hitting set kernels in\nparallel time $O(d)$ -- but it was conjectured that this is the best parallel\nalgorithm possible. We refute this conjecture and show how hitting set kernels\ncan be computed in constant parallel time. For our proof, we introduce a new,\ngeneralized notion of hypergraph sunflowers and show how iterated applications\nof the color coding technique can sometimes be collapsed into a single\napplication.","primary_category":"cs","categories":["cs.CC","cs.DS"],"authors":["Bannach Max","Tantau Till"],"created":"2018-01-02","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00723","title":"Deep Learning for Identifying Potential Conceptual Shifts for\n  Co-creative Drawing","abstract":"We present a system for identifying conceptual shifts between visual\ncategories, which will form the basis for a co-creative drawing system to help\nusers draw more creative sketches. The system recognizes human sketches and\nmatches them to structurally similar sketches from categories to which they do\nnot belong. This would allow a co-creative drawing system to produce an\nambiguous sketch that blends features from both categories.","primary_category":"cs","categories":["cs.LG","cs.AI","stat.ML"],"authors":["Karimi Pegah","Davis Nicholas","Grace Kazjon","Maher Mary Lou"],"created":"2018-01-02","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00727","title":"Accounting for hidden common causes when inferring cause and effect from\n  observational data","abstract":"Identifying causal relationships from observation data is difficult, in large\npart, due to the presence of hidden common causes. In some cases, where just\nthe right patterns of conditional independence and dependence lie in the\ndata---for example, Y-structures---it is possible to identify cause and effect.\nIn other cases, the analyst deliberately makes an uncertain assumption that\nhidden common causes are absent, and infers putative causal relationships to be\ntested in a randomized trial. Here, we consider a third approach, where there\nare sufficient clues in the data such that hidden common causes can be\ninferred.","primary_category":"cs","categories":["cs.AI","stat.AP"],"authors":["Heckerman David"],"created":"2018-01-02","updated":"2018-01-03","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00734","title":"Complexity Theory, Game Theory, and Economics","abstract":"This document collects the lecture notes from my mini-course \"Complexity\nTheory, Game Theory, and Economics,\" taught at the Bellairs Research Institute\nof McGill University, Holetown, Barbados, February 19--23, 2017, as the 29th\nMcGill Invitational Workshop on Computational Complexity.\n  The goal of this mini-course is twofold: (i) to explain how complexity theory\nhas helped illuminate several barriers in economics and game theory; and (ii)\nto illustrate how game-theoretic questions have led to new and interesting\ncomplexity theory, including recent several breakthroughs. It consists of two\nfive-lecture sequences: the Solar Lectures, focusing on the communication and\ncomputational complexity of computing equilibria; and the Lunar Lectures,\nfocusing on applications of complexity theory in game theory and economics. No\nbackground in game theory is assumed.","primary_category":"cs","categories":["cs.CC","cs.GT","econ.EM"],"authors":["Roughgarden Tim"],"created":"2018-01-02","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00743","title":"Um Sistema Multiagente no Combate ao Braqueamento de Capitais","abstract":"Money laundering is a crime that makes it possible to finance other crimes,\nfor this reason, it is important for criminal organizations and their combat is\nprioritized by nations around the world. The anti-money laundering process has\nnot evolved as expected because it has prioritized only the signaling of\nsuspicious transactions. The constant increasing in the volume of transactions\nhas overloaded the indispensable human work of final evaluation of the\nsuspicions. This article presents a multiagent system that aims to go beyond\nthe capture of suspicious transactions, seeking to assist the human expert in\nthe analysis of suspicions. The agents created use data mining techniques to\ncreate transactional behavioral profiles; apply rules generated in learning\nprocess in conjunction with specific rules based on legal aspects and profiles\ncreated to capture suspicious transactions; and analyze these suspicious\ntransactions indicating to the human expert those that require more detailed\nanalysis.","primary_category":"cs","categories":["cs.MA","cs.AI"],"authors":["Alexandre Claudio","Balsa Jo\u00e3o"],"created":"2018-01-02","updated":" ","doi":"10.17013\/risti.25.1-17"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00760","title":"The cover time of a biased random walk on a random cubic graph","abstract":"We study a random walk that prefers tou se unvisited edges in the context of\nrandom cubic graphs. We establish asymptotically correct estimates for the\nvertex and edge cover times, these being $\\approx n\\log n$ and $\\approx\n\\frac32n\\log n$ respectively.","primary_category":"cs","categories":["math.CO","cs.DS"],"authors":["Cooper Colin","Frieze Alan","Johansson Tony"],"created":"2018-01-02","updated":"2018-01-03","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00777","title":"Effective algorithms for homogeneous utility functions","abstract":"Under the assumption of (positive) homogeneity (PH in the sequel) of the\ncorresponding utility functions, we construct polynomial time algorithms for\nthe weak separability, the collective consumption behavior and some related\nproblems. These problems are known to be at least $NP$-hard if the homogeneity\nassumption is dropped.\n  Keywords: the utility function, the economic indices theory, the collective\naxiom of revealed preference, the weak separability property, the class of the\ndifferential form of the demand.","primary_category":"cs","categories":["cs.DS"],"authors":["Shananin Alexander","Tarasov Sergey"],"created":"2017-12-29","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00779","title":"Machine Learning for Building Energy and Indoor Environment: A\n  Perspective","abstract":"Machine learning is a promising technique for many practical applications. In\nthis perspective, we illustrate the development and application for machine\nlearning. It is indicated that the theories and applications of machine\nlearning method in the field of energy conservation and indoor environment are\nnot mature, due to the difficulty of the determination for model structure with\nbetter prediction. In order to significantly contribute to the problems, we\nutilize the ANN model to predict the indoor culturable fungi concentration,\nwhich achieves the better accuracy and convenience. The proposal of hybrid\nmethod is further expand the application fields of machine learning method.\nFurther, ANN model based on HTS was successfully applied for the optimization\nof building energy system. We hope that this novel method could capture more\nattention from investigators via our introduction and perspective, due to its\npotential development with accuracy and reliability. However, its feasibility\nin other fields needs to be promoted further.","primary_category":"cs","categories":["cs.CY","cs.LG"],"authors":["Liu Zhijian","Wu Di","Wei Hongyu","Cao Guoqing"],"created":"2017-12-30","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00814","title":"Secretary problem: graphs, matroids and greedoids","abstract":"In the paper the generalisation of the well known \"secretary problem\" is\nconsidered. The aim of the paper is to give a generalised model in such a way\nthat the chosen set of the possible best $k$ elements have to be independent of\nall rejected elements. This condition is formulated using the theory of\ngreedoids and in their special cases -- matroids and antimatroids. Examples of\nsome special cases of greedoids (uniform, graphical matroids and binary trees)\nare considered.","primary_category":"cs","categories":["cs.DM","math.CO"],"authors":["Kordecki Wojciech"],"created":"2018-01-02","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00815","title":"Advice from the Oracle: Really Intelligent Information Retrieval","abstract":"What is \"intelligent\" information retrieval? Essentially this is asking what\nis intelligence, in this article I will attempt to show some of the aspects of\nhuman intelligence, as related to information retrieval. I will do this by the\ndevice of a semi-imaginary Oracle. Every Observatory has an oracle, someone who\nis a distinguished scientist, has great administrative responsibilities, acts\nas mentor to a number of less senior people, and as trusted advisor to even the\nmost accomplished scientists, and knows essentially everyone in the field. In\nan appendix I will present a brief summary of the Statistical Factor Space\nmethod for text indexing and retrieval, and indicate how it will be used in the\nAstrophysics Data System Abstract Service. 2018 Keywords: Personal Digital\nAssistant; Supervised Topic Models","primary_category":"cs","categories":["cs.AI","astro-ph.IM","physics.soc-ph"],"authors":["Kurtz Michael J."],"created":"2018-01-02","updated":" ","doi":"10.1007\/978-0-585-33110-2_3"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00820","title":"Stratified Transfer Learning for Cross-domain Activity Recognition","abstract":"In activity recognition, it is often expensive and time-consuming to acquire\nsufficient activity labels. To solve this problem, transfer learning leverages\nthe labeled samples from the source domain to annotate the target domain which\nhas few or none labels. Existing approaches typically consider learning a\nglobal domain shift while ignoring the intra-affinity between classes, which\nwill hinder the performance of the algorithms. In this paper, we propose a\nnovel and general cross-domain learning framework that can exploit the\nintra-affinity of classes to perform intra-class knowledge transfer. The\nproposed framework, referred to as Stratified Transfer Learning (STL), can\ndramatically improve the classification accuracy for cross-domain activity\nrecognition. Specifically, STL first obtains pseudo labels for the target\ndomain via majority voting technique. Then, it performs intra-class knowledge\ntransfer iteratively to transform both domains into the same subspaces.\nFinally, the labels of target domain are obtained via the second annotation. To\nevaluate the performance of STL, we conduct comprehensive experiments on three\nlarge public activity recognition datasets~(i.e. OPPORTUNITY, PAMAP2, and UCI\nDSADS), which demonstrates that STL significantly outperforms other\nstate-of-the-art methods w.r.t. classification accuracy (improvement of 7.68%).\nFurthermore, we extensively investigate the performance of STL across different\ndegrees of similarities and activity levels between domains. And we also\ndiscuss the potential of STL in other pervasive computing applications to\nprovide empirical experience for future research.","primary_category":"cs","categories":["cs.CV","cs.LG"],"authors":["Wang Jindong","Chen Yiqiang","Hu Lisha","Peng Xiaohui","Yu Philip S."],"created":"2017-12-25","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00824","title":"A Novel Approach to Skew-Detection and Correction of English Alphabets\n  for OCR","abstract":"Optical Character Recognition has been a challenging field in the advent of\ndigital computers. It is needed where information is to be readable both to\nhumans and machines. The process of OCR is composed of a set of pre and post\nprocessing steps that decide the level of accuracy of recognition. This paper\ndeals with one of the pre-processing steps involved in the OCR process i.e.\nSkew (Slant) Detection and Correction. The proposed algorithm implemented for\nskew-detection is termed as the COG (Centre of Gravity) method and for that of\nskew-correction is Sub-Pixel Shifting method. The algorithm has been kept\nsimple and optimized for efficient skew-detection and correction. The\nperformance analysis of the algorithm after testing has been aptly\ndemonstrated.","primary_category":"cs","categories":["cs.CV"],"authors":["Chinara Chinmay","Nath Nishant","Mishra Subhajeet","Sahoo Sangram Keshari","Ali Farida Ashraf"],"created":"2018-01-02","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00826","title":"ruptures: change point detection in Python","abstract":"ruptures is a Python library for offline change point detection. This package\nprovides methods for the analysis and segmentation of non-stationary signals.\nImplemented algorithms include exact and approximate detection for various\nparametric and non-parametric models. ruptures focuses on ease of use by\nproviding a well-documented and consistent interface. In addition, thanks to\nits modular structure, different algorithms and models can be connected and\nextended within this package.","primary_category":"cs","categories":["stat.CO","cs.MS"],"authors":["Truong Charles","Oudre Laurent","Vayatis Nicolas"],"created":"2018-01-02","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00829","title":"On Optimizing Operator Fusion Plans for Large-Scale Machine Learning in\n  SystemML","abstract":"Many large-scale machine learning (ML) systems allow specifying custom ML\nalgorithms by means of linear algebra programs, and then automatically generate\nefficient execution plans. In this context, optimization opportunities for\nfused operators---in terms of fused chains of basic operators---are ubiquitous.\nThese opportunities include (1) fewer materialized intermediates, (2) fewer\nscans of input data, and (3) the exploitation of sparsity across chains of\noperators. Automatic operator fusion eliminates the need for hand-written fused\noperators and significantly improves performance for complex or previously\nunseen chains of operations. However, existing fusion heuristics struggle to\nfind good fusion plans for complex DAGs or hybrid plans of local and\ndistributed operations. In this paper, we introduce an optimization framework\nfor systematically reason about fusion plans that considers materialization\npoints in DAGs, sparsity exploitation, different fusion template types, as well\nas local and distributed operations. In detail, we contribute algorithms for\n(1) candidate exploration of valid fusion plans, (2) cost-based candidate\nselection, and (3) code generation of local and distributed operations over\ndense, sparse, and compressed data. Our experiments in SystemML show end-to-end\nperformance improvements with optimized fusion plans of up to 21x compared to\nhand-written fused operators, with negligible optimization and code generation\noverhead.","primary_category":"cs","categories":["cs.DB"],"authors":["Boehm Matthias","Reinwald Berthold","Hutchison Dylan","Evfimievski Alexandre V.","Sen Prithviraj"],"created":"2018-01-02","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00831","title":"Optimizing the Number of Fog Nodes for Cloud-Fog-Thing Networks","abstract":"Going from theory to practice in fog networking raises the question of the\noptimum number of fog nodes that will be upgraded from the existing nodes. This\npaper finds the optimum number of fog nodes for a given total number of\nordinary nodes residing in the area of interest for different channel\nconditions. Determining the optimum number of fog nodes is quite beneficial,\nbecause it can strongly affect the SINR, and thus the average data rate and\ntransmission delay. The numerical results indicate that the average data rate\nincreases nearly an order of magnitude for an optimized number of fog nodes in\ncase of shadowing and fading. It is further shown that the optimum number of\nfog nodes does not increase in direct proportion to the increase in the total\nnumber of nodes. Furthermore, the optimum number of fog nodes decreases when\nchannels have high path loss exponents. These findings suggest that the fog\nnodes must be selected among those that have the highest computation capability\nfor densely deployed networks and high path loss exponents channels.","primary_category":"cs","categories":["cs.NI"],"authors":["Balevi Eren","Gitlin Richard D."],"created":"2018-01-02","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00840","title":"High Performance Architecture for Flow-Table Lookup in SDN on FPGA","abstract":"We propose Range-based Ternary Search Tree (RTST), a tree-based approach for\nflow-table lookup in SDN network. RTST builds upon flow-tables in SDN switches\nto provide a fast lookup among flows. We present a parallel multi-pipeline\narchitecture for implementing RTST that benefits from high throughput and low\nlatency. The proposed RTST and architecture achieve a memory efficiency of 1\nbyte of memory for each byte of flow. We also present a set of techniques to\nsupport dynamic updates. Experimental results show that RTST can be used to\nimprove the performance of flow-lookup. It achieves a throughput of 670 Million\nPackets Per Second (MPPS), for a 1 K 15-tuple flow-table, on a state-of-the-art\nFPGA.","primary_category":"cs","categories":["cs.NI"],"authors":["Hatamia Rashid","Bahramgiria Hossein","Khonsari Ahmad"],"created":"2018-01-02","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00841","title":"Exploring Architectures, Data and Units For Streaming End-to-End Speech\n  Recognition with RNN-Transducer","abstract":"We investigate training end-to-end speech recognition models with the\nrecurrent neural network transducer (RNN-T): a streaming, all-neural,\nsequence-to-sequence architecture which jointly learns acoustic and language\nmodel components from transcribed acoustic data. We explore various model\narchitectures and demonstrate how the model can be improved further if\nadditional text or pronunciation data are available. The model consists of an\n`encoder', which is initialized from a connectionist temporal\nclassification-based (CTC) acoustic model, and a `decoder' which is partially\ninitialized from a recurrent neural network language model trained on text data\nalone. The entire neural network is trained with the RNN-T loss and directly\noutputs the recognized transcript as a sequence of graphemes, thus performing\nend-to-end speech recognition. We find that performance can be improved further\nthrough the use of sub-word units (`wordpieces') which capture longer context\nand significantly reduce substitution errors. The best RNN-T system, a\ntwelve-layer LSTM encoder with a two-layer LSTM decoder trained with 30,000\nwordpieces as output targets achieves a word error rate of 8.5\\% on\nvoice-search and 5.2\\% on voice-dictation tasks and is comparable to a\nstate-of-the-art baseline at 8.3\\% on voice-search and 5.4\\% voice-dictation.","primary_category":"cs","categories":["cs.CL","cs.SD","eess.AS"],"authors":["Rao Kanishka","Sak Ha\u015fim","Prabhavalkar Rohit"],"created":"2018-01-02","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00843","title":"The geometry of rank decompositions of matrix multiplication II:\n  $3\\times 3$ matrices","abstract":"This is the second in a series of papers on rank decompositions of the matrix\nmultiplication tensor. We present new rank $23$ decompositions for the $3\\times\n3$ matrix multiplication tensor $M_{\\langle 3\\rangle}$. All our decompositions\nhave symmetry groups that include the standard cyclic permutation of factors\nbut otherwise exhibit a range of behavior. One of them has 11 cubes as summands\nand admits an unexpected symmetry group of order 12. We establish basic\ninformation regarding symmetry groups of decompositions and outline two\napproaches for finding new rank decompositions of $M_{\\langle n\\rangle}$ for\nlarger $n$.","primary_category":"cs","categories":["cs.CC"],"authors":["Ballard Grey","Ikenmeyer Christian","Landsberg J. M.","Ryder Nick"],"created":"2018-01-02","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00853","title":"Revisiting Email Spoofing Attacks","abstract":"The email system is the central battleground against phishing and social\nengineering attacks, and yet email providers still face key challenges to\nauthenticate incoming emails. As a result, attackers can apply spoofing\ntechniques to impersonate a trusted entity to conduct highly deceptive phishing\nattacks. In this work, we study email spoofing to answer three key questions:\n(1) How do email providers detect and handle forged emails? (2) Under what\nconditions can forged emails penetrate the defense to reach user inbox? (3)\nOnce the forged email gets in, how email providers warn users? Is the warning\ntruly effective?\n  We answer these questions through end-to-end measurements on 35 popular email\nproviders (used by billions of users), and extensive user studies (N = 913)\nthat consist of both simulated and real-world phishing experiments. We have\nfour key findings. First, most popular email providers have the necessary\nprotocols to detect spoofing, but still allow forged emails to get into user\ninbox (e.g., Yahoo Mail, iCloud, Gmail). Second, once a forged email gets in,\nmost email providers have no warnings for users, particularly on mobile email\napps. Some providers (e.g., Gmail Inbox) even have misleading UIs that make the\nforged email look authentic. Third, a few email providers (9\/35) have\nimplemented visual security cues for unverified emails, which demonstrate a\npositive impact to reduce risky user actions. Comparing simulated experiments\nwith realistic phishing tests, we observe that the impact of security cue is\nless significant when users are caught off guard in the real-world setting.","primary_category":"cs","categories":["cs.CR"],"authors":["Hu Hang","Wang Gang"],"created":"2018-01-02","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00858","title":"Utilizing Semantic Visual Landmarks for Precise Vehicle Navigation","abstract":"This paper presents a new approach for integrating semantic information for\nvision-based vehicle navigation. Although vision-based vehicle navigation\nsystems using pre-mapped visual landmarks are capable of achieving submeter\nlevel accuracy in large-scale urban environment, a typical error source in this\ntype of systems comes from the presence of visual landmarks or features from\ntemporal objects in the environment, such as cars and pedestrians. We propose a\ngated factor graph framework to use semantic information associated with visual\nfeatures to make decisions on outlier\/ inlier computation from three\nperspectives: the feature tracking process, the geo-referenced map building\nprocess, and the navigation system using pre-mapped landmarks. The class\ncategory that the visual feature belongs to is extracted from a pre-trained\ndeep learning network trained for semantic segmentation. The feasibility and\ngenerality of our approach is demonstrated by our implementations on top of two\nvision-based navigation systems. Experimental evaluations validate that the\ninjection of semantic information associated with visual landmarks using our\napproach achieves substantial improvements in accuracy on GPS-denied navigation\nsolutions for large-scale urban scenarios","primary_category":"cs","categories":["cs.CV"],"authors":["Murali Varun","Chiu Han-Pang","Samarasekera Supun"],"created":"2018-01-02","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00879","title":"A Novel Feature Descriptor for Image Retrieval by Combining Modified\n  Color Histogram and Diagonally Symmetric Co-occurrence Texture Pattern","abstract":"In this paper, we have proposed a novel feature descriptors combining color\nand texture information collectively. In our proposed color descriptor\ncomponent, the inter-channel relationship between Hue (H) and Saturation (S)\nchannels in the HSV color space has been explored which was not done earlier.\nWe have quantized the H channel into a number of bins and performed the voting\nwith saturation values and vice versa by following a principle similar to that\nof the HOG descriptor, where orientation of the gradient is quantized into a\ncertain number of bins and voting is done with gradient magnitude. This helps\nus to study the nature of variation of saturation with variation in Hue and\nnature of variation of Hue with the variation in saturation. The texture\ncomponent of our descriptor considers the co-occurrence relationship between\nthe pixels symmetric about both the diagonals of a 3x3 window. Our work is\ninspired from the work done by Dubey et al.[1]. These two components, viz.\ncolor and texture information individually perform better than existing texture\nand color descriptors. Moreover, when concatenated the proposed descriptors\nprovide significant improvement over existing descriptors for content base\ncolor image retrieval. The proposed descriptor has been tested for image\nretrieval on five databases, including texture image databases - MIT VisTex\ndatabase and Salzburg texture database and natural scene databases Corel 1K,\nCorel 5K and Corel 10K. The precision and recall values experimented on these\ndatabases are compared with some state-of-art local patterns. The proposed\nmethod provided satisfactory results from the experiments.","primary_category":"cs","categories":["cs.CV"],"authors":["Bhunia Ayan Kumar","Bhattacharyya Avirup","Banerjee Prithaj","Roy Partha Pratim","Murala Subrahmanyam"],"created":"2018-01-02","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00886","title":"Recovery of Point Clouds on Surfaces: Application to Image\n  Reconstruction","abstract":"We introduce a framework for the recovery of points on a smooth surface in\nhigh-dimensional space, with application to dynamic imaging. We assume the\nsurface to be the zero-level set of a bandlimited function. We show that the\nexponential maps of the points on the surface satisfy annihilation relations,\nimplying that they lie in a finite dimensional subspace. We rely on nuclear\nnorm minimization of the maps to recover the points from noisy and undersampled\nmeasurements. Since this direct approach suffers from the curse of\ndimensionality, we introduce an iterative reweighted algorithm that uses the\n\"kernel trick\". The resulting algorithm has similarities to iterative\nalgorithms used in graph signal processing (GSP); this framework can be seen as\na continuous domain alternative to discrete GSP theory. The use of the\nalgorithm in recovering free breathing and ungated cardiac data shows the\npotential of this framework in practical applications.","primary_category":"cs","categories":["cs.CV"],"authors":["Poddar Sunrita","Jacob Mathews"],"created":"2018-01-02","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00905","title":"Neural Networks in Adversarial Setting and Ill-Conditioned Weight Space","abstract":"Recently, Neural networks have seen a huge surge in its adoption due to their\nability to provide high accuracy on various tasks. On the other hand, the\nexistence of adversarial examples have raised suspicions regarding the\ngeneralization capabilities of neural networks. In this work, we focus on the\nweight matrix learnt by the neural networks and hypothesize that ill\nconditioned weight matrix is one of the contributing factors in neural\nnetwork's susceptibility towards adversarial examples. For ensuring that the\nlearnt weight matrix's condition number remains sufficiently low, we suggest\nusing orthogonal regularizer. We show that this indeed helps in increasing the\nadversarial accuracy on MNIST and F-MNIST datasets.","primary_category":"cs","categories":["cs.LG","cs.CV","stat.ML"],"authors":["Singh Mayank","Sinha Abhishek","Krishnamurthy Balaji"],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00906","title":"Circuit Complexity of Bounded Planar Cutwidth Graph Matching","abstract":"Recently, perfect matching in bounded planar cutwidth bipartite graphs\n(\\BGGM) was shown to be in ACC$^0$ by Hansen et al.. They also conjectured that\nthe problem is in AC$^0$.\n  In this paper, we disprove their conjecture by showing that the problem is\nnot in AC$^0[p^{\\alpha}]$ for every prime $p$. Our results show that the\nprevious upper bound is almost tight. Our techniques involve giving a reduction\nfrom Parity to BGGM. A further improvement in lower bounds is difficult since\nwe do not have an algebraic characterization for AC$^0[m]$ where $m$ is not a\nprime power. Moreover, this will also imply a separation of AC$^0[m]$ from P.\nOur results also imply a better lower bound for perfect matching in general\nbounded planar cutwidth graphs.","primary_category":"cs","categories":["cs.CC"],"authors":["Ojha Aayush","Tewari Raghunath"],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00910","title":"Rapid Information Transfer in Networks with Delayed Self Reinforcement","abstract":"The cohesiveness of response to external stimuli depends on rapid\ndistortion-free information transfer across the network. Aligning with the\ninformation from the network has been used to model such information transfer.\nNevertheless, the rate of such diffusion-type, neighbor-based information\ntransfer is limited by the update rate at which each individual can sense and\nprocess information. Moreover, models of the diffusion-type information\ntransfer do not predict the superfluid-like information transfer observed in\nnature. The contribution of this article is to show that self reinforcement,\nwhere each individual augments its neighbor-averaged information update using\nits previous update, can (i) increase the information-transfer rate without\nrequiring an increased, individual update-rate; and (ii) capture the observed\nsuperfluid-like information transfer. This improvement in the\ninformation-transfer rate without modification of the network structure or\nincrease of the bandwidth of each agent can lead to better understanding and\ndesign of networks with fast response.","primary_category":"cs","categories":["cs.SY","nlin.AO"],"authors":["Devasia Santosh"],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00920","title":"More on the dynamics of the symbolic square root map","abstract":"In our earlier paper [A square root map on Sturmian words, Electron. J.\nCombin. 24.1 (2017)], we introduced a symbolic square root map. Every optimal\nsquareful infinite word $s$ contains exactly six minimal squares and can be\nwritten as a product of these squares: $s = X_1^2 X_2^2 \\cdots$. The square\nroot $\\sqrt{s}$ of $s$ is the infinite word $X_1 X_2 \\cdots$ obtained by\ndeleting half of each square. We proved that the square root map preserves the\nlanguages of Sturmian words (which are optimal squareful words). The dynamics\nof the square root map on a Sturmian subshift are well understood. In our\nearlier work, we introduced another type of subshift of optimal squareful words\nwhich together with the square root map form a dynamical system. In this paper,\nwe study these dynamical systems in more detail and compare their properties to\nthe Sturmian case. The main results are characterizations of periodic points\nand the limit set. The results show that while there is some similarity it is\npossible for the square root map to exhibit quite different behavior compared\nto the Sturmian case.","primary_category":"cs","categories":["cs.FL","math.DS"],"authors":["Peltom\u00e4ki Jarkko","Whiteland Markus"],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00924","title":"Joint Content Delivery and Caching Placement via Dynamic Programming","abstract":"In this paper, downlink delivery of popular content is optimized with the\nassistance of wireless cache nodes. Specifically, the requests of one file is\nmodeled as a Poisson point process with finite lifetime, and two downlink\ntransmission modes are considered: (1) the base station multicasts file\nsegments to the requesting users and selected cache nodes; (2) the base station\nproactively multicasts file segments to the selected cache nodes without\nrequests from users. Hence the cache nodes with decoded files can help to\noffload the traffic upon the next file request via other air interfaces, e.g.\nWiFi. Without proactive caching placement, we formulate the downlink traffic\noffloading as a Markov decision process with random number of stages, and\npropose a revised Bellman's equation to obtain the optimal control policy. In\norder to address the prohibitively huge state space, we also introduce a\nlow-complexity sub-optimal solution based on linear approximation of the value\nfunctions, where the gap between the approximated value functions and the real\nones is bounded analytically. The approximated value functions can be\ncalculated from analytical expressions given the spatial distribution of\nrequesting users. Moreover, we propose a learning-based algorithm to evaluate\nthe approximated value functions for unknown distribution of requesting users.\nFinally, a proactive caching placement algorithm is introduced to exploit the\ntemporal diversity of shadowing effect. It is shown by simulation that the\nproposed low-complexity algorithm based on approximated value functions can\nsignificantly reduce the resource consumption at the base station, and the\nproactive caching placement can further improve the performance.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Lv Bojie","Huang Lexiang","Wang Rui"],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00932","title":"Power Analysis Based Side Channel Attack","abstract":"Power analysis is a branch of side channel attacks where power consumption\ndata is used as the side channel to attack the system. First using a device\nlike an oscilloscope power traces are collected when the cryptographic device\nis doing the cryptographic operation. Then those traces are statistically\nanalysed using methods such as Correlation Power Analysis (CPA) to derive the\nsecret key of the system. Being possible to break Advanced Encryption Standard\n(AES) in few minutes, power analysis attacks have become a serious security\nissue for cryptographic devices such as smart card.\n  As the first phase of our project, we build a testbed for doing research on\npower analysis attacks. As power analysis is a practical type of attack in\norder to do any research, a testbed is the first requirement. Since building a\ntest bed is a complicated process, having a pre-built testbed would save the\ntime of future researchers. The second phase of our project is to attack the\nlatest cryptographic algorithm called Speck which has been released by National\nSecurity Agency (NSA) for use in embedded systems. In spite it has lot of\ndifferences to AES making impossible to directly use the power analysis\napproach used for AES, we introduce novel approaches to break Speck in less\nthan an hour. In the third phase of the project, we select few already\nintroduced countermeasures and practically attack them on our testbed to do a\ncomparative analysis. We show that software countermeasures such as random\ninstruction injection and randomly shuffling S-boxes are good enough for their\nsimplicity and cost. But we identify the possible threat due to the problem of\ngenerating a good seed for the pseudo-random algorithm running on the\nmicrocontroller. We attempt to address this issue by using a hardware-based\ntrue random generator that amplifies a random electrical signal and samples to\ngenerate a proper seed.","primary_category":"cs","categories":["cs.CR"],"authors":["Gamaarachchi Hasindu","Ganegoda Harsha"],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00933","title":"New Directions for Trust in the Certificate Authority Ecosystem","abstract":"Many of the benefits we derive from the Internet require trust in the\nauthenticity of HTTPS connections. Unfortunately, the public key certification\necosystem that underwrites this trust has failed us on numerous occasions.\nTowards an exploration of the root causes we present an update to the common\nknowledge about the Certificate Authority (CA) ecosystem. Based on our findings\nthe certificate ecosystem currently undergoes a drastic transformation. Big\nsteps towards ubiquitous encryption were made, however, on the expense of trust\nfor authentication of communication partners. Furthermore we describe systemic\nproblems rooted in misaligned incentives between players in the ecosystem. We\ndepict that proposed security extensions do not correctly realign these\nincentives. As such we argue that it is worth considering alternative methods\nof authentication. As a first step in this direction we propose an\ninsurance-based mechanism and we demonstrate that it is technically feasible.","primary_category":"cs","categories":["cs.CR"],"authors":["Malchow Jan-Ole","G\u00fcldenring Benjamin","Roth Volker"],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00936","title":"Online Job Scheduling in Distributed Machine Learning Clusters","abstract":"Nowadays large-scale distributed machine learning systems have been deployed\nto support various analytics and intelligence services in IT firms. To train a\nlarge dataset and derive the prediction\/inference model, e.g., a deep neural\nnetwork, multiple workers are run in parallel to train partitions of the input\ndataset, and update shared model parameters. In a shared cluster handling\nmultiple training jobs, a fundamental issue is how to efficiently schedule jobs\nand set the number of concurrent workers to run for each job, such that server\nresources are maximally utilized and model training can be completed in time.\nTargeting a distributed machine learning system using the parameter server\nframework, we design an online algorithm for scheduling the arriving jobs and\ndeciding the adjusted numbers of concurrent workers and parameter servers for\neach job over its course, to maximize overall utility of all jobs, contingent\non their completion times. Our online algorithm design utilizes a primal-dual\nframework coupled with efficient dual subroutines, achieving good long-term\nperformance guarantees with polynomial time complexity. Practical effectiveness\nof the online algorithm is evaluated using trace-driven simulation and testbed\nexperiments, which demonstrate its outperformance as compared to commonly\nadopted scheduling algorithms in today's cloud systems.","primary_category":"cs","categories":["cs.DC"],"authors":["Bao Yixin","Peng Yanghua","Wu Chuan","Li Zongpeng"],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00938","title":"A Look at the Time Delays in CVSS Vulnerability Scoring","abstract":"This empirical paper examines the time delays that occur between the\npublication of Common Vulnerabilities and Exposures (CVEs) in the National\nVulnerability Database (NVD) and the Common Vulnerability Scoring System (CVSS)\ninformation attached to published CVEs. According to the empirical results\nbased on regularized regression analysis of over eighty thousand archived\nvulnerabilities, (i) the CVSS content does not statistically influence the time\ndelays, which, however, (ii) are strongly affected by a decreasing annual\ntrend. In addition to these results, the paper contributes to the empirical\nresearch tradition of software vulnerabilities by a couple of insights on\nmisuses of statistical methodology.","primary_category":"cs","categories":["cs.CR"],"authors":["Ruohonen Jukka"],"created":"2018-01-03","updated":" ","doi":"10.1016\/j.aci.2017.12.002"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00939","title":"Topological Tracking of Connected Components in Image Sequences","abstract":"Persistent homology provides information about the lifetime of homology\nclasses along a filtration of cell complexes. Persistence barcode is a\ngraphical representation of such information. A filtration might be determined\nby time in a set of spatiotemporal data, but classical methods for computing\npersistent homology do not respect the fact that we can not move backwards in\ntime. In this paper, taking as input a time-varying sequence of two-dimensional\n(2D) binary digital images, we develop an algorithm for encoding, in the\nso-called {\\it spatiotemporal barcode}, lifetime of connected components (of\neither the foreground or background) that are moving in the image sequence over\ntime (this information may not coincide with the one provided by the\npersistence barcode). This way, given a connected component at a specific time\nin the sequence, we can track the component backwards in time until the moment\nit was born, by what we call a {\\it spatiotemporal path}. The main contribution\nof this paper with respect to our previous works lies in a new algorithm that\ncomputes spatiotemporal paths directly, valid for both foreground and\nbackground and developed in a general context, setting the ground for a future\nextension for tracking higher dimensional topological features in $nD$ binary\ndigital image sequences.","primary_category":"cs","categories":["cs.CV"],"authors":["Gonzalez-Diaz Rocio","Jimenez Maria-Jose","Medrano Belen"],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00947","title":"Modulus Zero-Forcing Detection for MIMO Channels","abstract":"We propose a modulus based zero-forcing (MZF) detection for multi-input\nmulti-output (MIMO) channels. Traditionally, a ZF detector nulls out all\ninterferences from other layers when detecting a current layer, which can yield\nsuboptimal detection-performance due to the noise-enhancement issue. In many\ncommunication systems, finite alphabets such as M\nquadrature-amplitude-modulation (QAM) are widely used, which comprises \\sqrt{M}\npulse-amplitude-modulation (PAM) symbols for the real and imaginary parts. With\nfinite alphabets, one feasible way to improve ZF detection is to allow\ncontrollable interferences that can be removed away by modulus operations.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Hu Sha","Rusek Fredrik"],"created":"2018-01-03","updated":"2018-01-10","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00965","title":"Phase Transition of Convex Programs for Linear Inverse Problems with\n  Multiple Prior Constraints","abstract":"A sharp phase transition emerges in convex programs when solving the linear\ninverse problem, which aims to recover a structured signal from its linear\nmeasurements. This paper studies this phenomenon in theory under Gaussian\nrandom measurements. Different from previous studies, in this paper, we\nconsider convex programs with multiple prior constraints. These programs are\nencountered in many cases, for example, when the signal is sparse and its\n$\\ell_2$ norm is known beforehand, or when the signal is sparse and\nnon-negative simultaneously. Given such a convex program, to analyze its phase\ntransition, we introduce a new set and a new cone, called the prior restricted\nset and prior restricted cone, respectively. Our results reveal that the phase\ntransition of a convex problem occurs at the statistical dimension of its prior\nrestricted cone. Moreover, to apply our theoretical results in practice, we\npresent two recipes to accurately estimate the statistical dimension of the\nprior restricted cone. These two recipes work under different conditions, and\nwe give a detailed analysis for them. To further illustrate our results, we\napply our theoretical results and the estimation recipes to study the phase\ntransition of two specific problems, and obtain computable formulas for the\nstatistical dimension and related error bounds. Simulations are provided to\ndemonstrate our results.","primary_category":"cs","categories":["cs.IT","math.IT","math.OC"],"authors":["Zhang Huan","Liu Yulong","Lei Hong"],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00968","title":"Joint convolutional neural pyramid for depth map super-resolution","abstract":"High-resolution depth map can be inferred from a low-resolution one with the\nguidance of an additional high-resolution texture map of the same scene.\nRecently, deep neural networks with large receptive fields are shown to benefit\napplications such as image completion. Our insight is that super resolution is\nsimilar to image completion, where only parts of the depth values are precisely\nknown. In this paper, we present a joint convolutional neural pyramid model\nwith large receptive fields for joint depth map super-resolution. Our model\nconsists of three sub-networks, two convolutional neural pyramids concatenated\nby a normal convolutional neural network. The convolutional neural pyramids\nextract information from large receptive fields of the depth map and guidance\nmap, while the convolutional neural network effectively transfers useful\nstructures of the guidance image to the depth image. Experimental results show\nthat our model outperforms existing state-of-the-art algorithms not only on\ndata pairs of RGB\/depth images, but also on other data pairs like\ncolor\/saliency and color-scribbles\/colorized images.","primary_category":"cs","categories":["cs.CV","cs.GR"],"authors":["Xiao Yi","Cao Xiang","Zhu Xianyi","Yang Renzhi","Zheng Yan"],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00984","title":"Sentence Object Notation: Multilingual sentence notation based on\n  Wordnet","abstract":"The representation of sentences is a very important task. It can be used as a\nway to exchange data inter-applications. One main characteristic, that a\nnotation must have, is a minimal size and a representative form. This can\nreduce the transfer time, and hopefully the processing time as well.\n  Usually, sentence representation is associated to the processed language. The\ngrammar of this language affects how we represent the sentence. To avoid\nlanguage-dependent notations, we have to come up with a new representation\nwhich don't use words, but their meanings. This can be done using a lexicon\nlike wordnet, instead of words we use their synsets. As for syntactic\nrelations, they have to be universal as much as possible.\n  Our new notation is called STON \"SenTences Object Notation\", which somehow\nhas similarities to JSON. It is meant to be minimal, representative and\nlanguage-independent syntactic representation. Also, we want it to be readable\nand easy to be created. This simplifies developing simple automatic generators\nand creating test banks manually. Its benefit is to be used as a medium between\ndifferent parts of applications like: text summarization, language translation,\netc. The notation is based on 4 languages: Arabic, English, Franch and\nJapanese; and there are some cases where these languages don't agree on one\nrepresentation. Also, given the diversity of grammatical structure of different\nworld languages, this annotation may fail for some languages which allows more\nfuture improvements.","primary_category":"cs","categories":["cs.CL","cs.AI"],"authors":["Aries Abdelkrime","Zegour Djamel Eddine","Hidouci Walid Khaled"],"created":"2018-01-03","updated":"2018-01-10","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00988","title":"Joint Uplink and Downlink Resource Configuration for Ultra-reliable and\n  Low-latency Communications","abstract":"Supporting ultra-reliable and low-latency communications (URLLC) is one of\nthe major goals for the fifth-generation cellular networks. Since spectrum\nusage efficiency is always a concern, and large bandwidth is required for\nensuring stringent quality-of-service (QoS), we minimize the total bandwidth\nunder the QoS constraints of URLLC. We first propose a packet delivery\nmechanism for URLLC. To reduce the required bandwidth for ensuring queueing\ndelay, we consider a statistical multiplexing queueing mode, where the packets\nto be sent to different devices are waiting in one queue at the base station,\nand broadcast mode is adopted in downlink transmission. In this way, downlink\nbandwidth is shared among packets of multiple devices. In uplink transmission,\ndifferent subchannels are allocated to different devices to avoid strong\ninterference. Then, we jointly optimize uplink and downlink bandwidth\nconfiguration and delay components to minimize the total bandwidth required to\nguarantee the overall packet loss and end-to-end delay, which includes uplink\nand downlink transmission delays, queueing delay and backhaul delay. We propose\na two-step method to find the optimal solution. Simulation and numerical\nresults validate our analysis and show remarkable performance gain by jointly\noptimizing uplink and downlink configuration.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["She Changyang","Yang Chenyang","Quek Tony Q. S."],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.00992","title":"The Capacity on Degraded Relay Broadcast Channel","abstract":"The relay broadcast channel (RBC) is considered, in which a transmitter\ncommunicates with two receivers with the assistance of a relay. Based on\ndifferent degradation orders among the relay and the receivers' outputs, three\ntypes of physically degraded RBCs (PDRBCs) are introduced. Inner bounds and\nouter bounds are derived on the capacity region of the presented three types.\nThe bounds are tight for two types of PDRBCs: 1) one receiver's output is a\ndegraded form of the other receiver's output, and the relay's output is a\ndegraded form of the weaker receiver's output; 2) one receiver's output is a\ndegraded form of the relay's output, and the other receiver's output is a\ndegraded form of the relay's output. For the Gaussian PDRBC, the bounds match,\ni.e., establish its capacity region.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Wang Ke","Wu Youlong","Ma Yingying"],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01000","title":"ViZDoom: DRQN with Prioritized Experience Replay, Double-Q Learning, &\n  Snapshot Ensembling","abstract":"ViZDoom is a robust, first-person shooter reinforcement learning environment,\ncharacterized by a significant degree of latent state information. In this\npaper, double-Q learning and prioritized experience replay methods are tested\nunder a certain ViZDoom combat scenario using a competitive deep recurrent\nQ-network (DRQN) architecture. In addition, an ensembling technique known as\nsnapshot ensembling is employed using a specific annealed learning rate to\nobserve differences in ensembling efficacy under these two methods. Annealed\nlearning rates are important in general to the training of deep neural network\nmodels, as they shake up the status-quo and counter a model's tending towards\nlocal optima. While both variants show performance exceeding those of built-in\nAI agents of the game, the known stabilizing effects of double-Q learning are\nillustrated, and priority experience replay is again validated in its\nusefulness by showing immediate results early on in agent development, with the\ncaveat that value overestimation is accelerated in this case. In addition, some\nunique behaviors are observed to develop for priority experience replay (PER)\nand double-Q (DDQ) variants, and snapshot ensembling of both PER and DDQ proves\na valuable method for improving performance of the ViZDoom Marine.","primary_category":"cs","categories":["cs.AI"],"authors":["Schulze Christopher","Schulze Marcus"],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01012","title":"Graph Pattern Matching for Dynamic Team Formation","abstract":"Finding a list of k teams of experts, referred to as top-k team formation,\nwith the required skills and high collaboration compatibility has been\nextensively studied. However, existing methods have not considered the specific\ncollaboration relationships among different team members, i.e., structural\nconstraints, which are typically needed in practice. In this study, we first\npropose a novel graph pattern matching approach for top-k team formation, which\nincorporates both structural constraints and capacity bounds. Second, we\nformulate and study the dynamic top-k team formation problem due to the growing\nneed of a dynamic environment. Third, we develop an unified incremental\napproach, together with an optimization technique, to handle continuous pattern\nand data updates, separately and simultaneously, which has not been explored\nbefore. Finally, using real-life and synthetic data, we conduct an extensive\nexperimental study to show the effectiveness and efficiency of our graph\npattern matching approach for (dynamic) top-k team formation.","primary_category":"cs","categories":["cs.DB"],"authors":["Ma Shuai","Li Jia","Hu Chunming","Liu Xudong","Huai Jinpeng"],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01017","title":"Particle Clustering Machine: A Dynamical System Based Approach","abstract":"Identification of the clusters from an unlabeled data set is one of the most\nimportant problems in Unsupervised Machine Learning. The state of the art\nclustering algorithms are based on either the statistical properties or the\ngeometric properties of the data set. In this work, we propose a novel method\nto cluster the data points using dynamical systems theory. After constructing a\ngradient dynamical system using interaction potential, we prove that the\nasymptotic dynamics of this system will determine the cluster centers, when the\ndynamical system is initialized at the data points. Most of the existing\nheuristic-based clustering techniques suffer from a disadvantage, namely the\nstochastic nature of the solution. Whereas, the proposed algorithm is\ndeterministic, and the outcome would not change over multiple runs of the\nproposed algorithm with the same input data. Another advantage of the proposed\nmethod is that the number of clusters, which is difficult to determine in\npractice, does not have to be specified in advance. Simulation results with are\npresented, and comparisons are made with the existing methods.","primary_category":"cs","categories":["cs.LG","math.OC"],"authors":["Dasgupta Sambarta","Ebrahimi Keivan","Vaidya Umesh"],"created":"2017-12-29","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01019","title":"Proteomics Analysis of FLT3-ITD Mutation in Acute Myeloid Leukemia Using\n  Deep Learning Neural Network","abstract":"Deep Learning can significantly benefit cancer proteomics and genomics. In\nthis study, we attempt to determine a set of critical proteins that are\nassociated with the FLT3-ITD mutation in newly-diagnosed acute myeloid leukemia\npatients. A Deep Learning network consisting of autoencoders forming a\nhierarchical model from which high-level features are extracted without labeled\ntraining data. Dimensional reduction reduced the number of critical proteins\nfrom 231 to 20. Deep Learning found an excellent correlation between FLT3-ITD\nmutation with the levels of these 20 critical proteins (accuracy 97%,\nsensitivity 90%, specificity 100%). Our Deep Learning network could hone in on\n20 proteins with the strongest association with FLT3-ITD. The results of this\nstudy allow a novel approach to determine critical protein pathways in the\nFLT3-ITD mutation, and provide proof-of-concept for an accurate approach to\nmodel big data in cancer proteomics and genomics.","primary_category":"cs","categories":["q-bio.QM","cs.LG","stat.ML"],"authors":["Liang Christine A.","Chen Lei","Wahed Amer","Nguyen Andy N. D."],"created":"2017-12-29","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01025","title":"How Does Bug-Handling Effort Differ Among Different Programming\n  Languages?","abstract":"Handling bugs is an essential part of software development. The impact of\nprogramming language on this task has long been a topic of much debate. For\nexample, some people hold the view that bugs in Python are easy to handle\nbecause its code is easy to read and understand, while some others believe the\nabsence of static typing in Python will lead to higher bug-handling effort.\n  This paper presents the first large-scale study to investigate whether the\necosystems of different (categories of) programming language would require\ndifferent bug-handling effort. The focus is on correlation analysis rather than\ncausal analysis. With 600 most popular projects in 10 languages downloaded from\nGitHub (summing up to 70,816,938 SLOC and 3,096,009 commits), the experimental\nresults indicate various interesting findings. First, different languages\nrequire different bug-handling effort. For example, Java and C# tend to require\nless time but more line\/file modification, Python and PHP tend to require less\ntime and less line\/file modification, while Ruby and JavaScript tend to require\nmore time as well as more line\/file modification. Second, weak\/dynamic\nlanguages tend to require more time than strong\/static languages, while static\nlanguages tend to require more absolute line\/file modification. A toy\npredictive model also provides proof that the inclusion of programming\nlanguages could improve the effectiveness when predicting the bug-handling\neffort of a project.","primary_category":"cs","categories":["cs.SE"],"authors":["Zhang Jie","Li Feng","Hao Dan","Wang Meng","Zhang Lu"],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01039","title":"Computing the Inverse Mellin Transform of Holonomic Sequences using\n  Kovacic's Algorithm","abstract":"We describe how the extension of a solver for linear differential equations\nby Kovacic's algorithm helps to improve a method to compute the inverse Mellin\ntransform of holonomic sequences. The method is implemented in the computer\nalgebra package HarmonicSums.","primary_category":"cs","categories":["cs.SC","math-ph","math.CO","math.MP"],"authors":["Ablinger Jakob"],"created":"2018-01-02","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01048","title":"Impact Assessment of Hypothesized Cyberattacks on Interconnected Bulk\n  Power Systems","abstract":"The first-ever Ukraine cyberattack on power grid has proven its devastation\nby hacking into their critical cyber assets. With administrative privileges\naccessing substation networks\/local control centers, one intelligent way of\ncoordinated cyberattacks is to execute a series of disruptive switching\nexecutions on multiple substations using compromised supervisory control and\ndata acquisition (SCADA) systems. These actions can cause significant impacts\nto an interconnected power grid. Unlike the previous power blackouts, such\nhigh-impact initiating events can aggravate operating conditions, initiating\ninstability that may lead to system-wide cascading failure. A systemic\nevaluation of \"nightmare\" scenarios is highly desirable for asset owners to\nmanage and prioritize the maintenance and investment in protecting their\ncyberinfrastructure. This survey paper is a conceptual expansion of real-time\nmonitoring, anomaly detection, impact analyses, and mitigation (RAIM) framework\nthat emphasizes on the resulting impacts, both on steady-state and dynamic\naspects of power system stability. Hypothetically, we associate the\ncombinatorial analyses of steady state on substations\/components outages and\ndynamics of the sequential switching orders as part of the permutation. The\nexpanded framework includes (1) critical\/noncritical combination verification,\n(2) cascade confirmation, and (3) combination re-evaluation. This paper ends\nwith a discussion of the open issues for metrics and future design pertaining\nthe impact quantification of cyber-related contingencies.","primary_category":"cs","categories":["cs.CR","cs.SY"],"authors":["Ten Chee-Wooi","Yamashita Koji","Yang Zhiyuan","Vasilakos Athanasios V.","Ginter Andrew"],"created":"2018-01-03","updated":" ","doi":"10.1109\/TSG.2017.2656068"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01051","title":"Spot the Difference by Object Detection","abstract":"In this paper, we propose a simple yet effective solution to a change\ndetection task that detects the difference between two images, which we call\n\"spot the difference\". Our approach uses CNN-based object detection by stacking\ntwo aligned images as input and considering the differences between the two\nimages as objects to detect. An early-merging architecture is used as the\nbackbone network. Our method is accurate, fast and robust while using very\ncheap annotation. We verify the proposed method on the task of change detection\nbetween the digital design and its photographic image of a book. Compared to\nverification based methods, our object detection based method outperforms other\nmethods by a large margin and gives extra information of location. We compress\nthe network and achieve 24 times acceleration while keeping the accuracy.\nBesides, as we synthesize the training data for detection using weakly labeled\nimages, our method does not need expensive bounding box annotation.","primary_category":"cs","categories":["cs.CV"],"authors":["Wu Junhui","Ye Yun","Chen Yu","Weng Zhi"],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01054","title":"Computational complexity lower bounds of certain discrete Radon\n  transform approximations","abstract":"For the computational model where only additions are allowed, the\n$\\Omega(n^2\\log n)$ lower bound on operations count with respect to image size\n$n\\times n$ is obtained for two types of the discrete Radon transform\nimplementations: the fast Hough transform and a generic strip pattern class\nwhich includes the classical Hough transform, implying the fast Hough transform\nalgorithm asymptotic optimality. The proofs are based on a specific result from\nthe boolean circuits complexity theory and are generalized for the case of\nboolean $\\vee$ binary operation.","primary_category":"cs","categories":["cs.CC","cs.CV"],"authors":["Khanipov Timur M."],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01055","title":"Gaps between prime numbers and tensor rank of multiplication in finite\n  fields","abstract":"We present effective upper bounds on the symmetric bilinear complexity of\nmultiplication in extensions of a base finite field Fp2 of prime square order,\nobtained by combining estimates on gaps between prime numbers together with an\noptimal construction of auxiliary divisors for multiplication algorithms by\nevaluation-interpolation on curves. Most of this material dates back to a 2011\nunpublished work of the author, but it still provides the best results on this\ntopic at the present time.\n  Then a few updates are given in order to take recent developments into\naccount, including comparison with a similar work of Ballet and Zykin,\ngeneralization to classical bilinear complexity over Fp, and to short\nmultiplication of polynomials, as well as a discussion of open questions on\ngaps between prime numbers or more generally values of certain arithmetic\nfunctions.","primary_category":"cs","categories":["math.NT","cs.CC"],"authors":["Randriam Hugues"],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01058","title":"Polynomial-based rotation invariant features","abstract":"One of basic difficulties of machine learning is handling unknown rotations\nof objects, for example in image recognition. A related problem is evaluation\nof similarity of shapes, for example of two chemical molecules, for which\ndirect approach requires costly pairwise rotation alignment and comparison.\nRotation invariants are useful tools for such purposes, allowing to extract\nfeatures describing shape up to rotation, which can be used for example to\nsearch for similar rotated patterns, or fast evaluation of similarity of shapes\ne.g. for virtual screening, or machine learning including features directly\ndescribing shape. A standard approach are rotationally invariant cylindrical or\nspherical harmonics, which can be seen as based on polynomials on sphere,\nhowever, they provide very few invariants - only one per degree of polynomial.\nThere will be discussed a general approach to construct arbitrarily large sets\nof rotation invariants of polynomials, for degree $D$ in $\\mathbb{R}^n$ up to\n$O(n^D)$ independent invariants instead of $O(D)$ offered by standard\napproaches, possibly also a complete set: providing not only necessary, but\nalso sufficient condition for differing only by rotation (and reflectional\nsymmetry).","primary_category":"cs","categories":["cs.LG"],"authors":["Duda Jarek"],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01059","title":"Slowing Down Top Trees for Better Worst-Case Bounds","abstract":"We consider the top tree compression scheme introduced by Bille et al. [ICALP\n2013] and construct an infinite family of trees on $n$ nodes labeled from an\nalphabet of size $\\sigma$, for which the size of the top DAG is\n$\\Theta(\\frac{n}{\\log_\\sigma n}\\log\\log_\\sigma n)$. Our construction matches a\npreviously known upper bound and exhibits a weakness of this scheme, as the\ninformation-theoretic lower bound is $\\Omega(\\frac{n}{\\log_\\sigma n})$. This\nsettles an open problem stated by Lohrey et al. [arXiv 2017], who designed a\nmore involved version achieving the lower bound. We show that this can be also\nguaranteed by a very minor modification of the original scheme: informally, one\nonly needs to ensure that different parts of the tree are not compressed too\nquickly. Arguably, our version is more uniform, and in particular, the\ncompression procedure is oblivious to the value of $\\sigma$.","primary_category":"cs","categories":["cs.DS"],"authors":["Dudek Bart\u0142omiej","Gawrychowski Pawe\u0142"],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01061","title":"Intrinsic Gaussian processes on complex constrained domains","abstract":"We propose a class of intrinsic Gaussian processes (in-GPs) for\ninterpolation, regression and classification on manifolds with a primary focus\non complex constrained domains or irregular shaped spaces arising as subsets or\nsubmanifolds of R, R2, R3 and beyond. For example, in-GPs can accommodate\nspatial domains arising as complex subsets of Euclidean space. in-GPs respect\nthe potentially complex boundary or interior conditions as well as the\nintrinsic geometry of the spaces. The key novelty of the proposed approach is\nto utilise the relationship between heat kernels and the transition density of\nBrownian motion on manifolds for constructing and approximating valid and\ncomputationally feasible covariance kernels. This enables in-GPs to be\npractically applied in great generality, while existing approaches for\nsmoothing on constrained domains are limited to simple special cases. The broad\nutilities of the in-GP approach is illustrated through simulation studies and\ndata examples.","primary_category":"cs","categories":["stat.ML","cs.LG"],"authors":["Niu Mu","Cheung Pokman","Lin Lizhen","Dai Zhenwen","Lawrence Neil","Dunson David"],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01069","title":"Theoretical links between universal and Bayesian compressed sensing\n  algorithms","abstract":"Quantized maximum a posteriori (Q-MAP) is a recently-proposed Bayesian\ncompressed sensing algorithm that, given the source distribution, recovers\n$X^n$ from its linear measurements $Y^m=AX^n$, where $A\\in R^{m\\times n}$\ndenotes the known measurement matrix. On the other hand, Lagrangian minimum\nentropy pursuit (L-MEP) is a universal compressed sensing algorithm that aims\nat recovering $X^n$ from its linear measurements $Y^m=AX^n$, without having\naccess to the source distribution. Both Q-MAP and L-MEP provably achieve the\nminimum required sampling rates, in noiseless cases where such fundamental\nlimits are known. L-MEP is based on minimizing a cost function that consists of\na linear combination of the conditional empirical entropy of a potential\nreconstruction vector and its corresponding measurement error. In this paper,\nusing a first-order linear approximation of the conditional empirical entropy\nfunction, L-MEP is connected with Q-MAP. The established connection between\nL-MEP and Q-MAP leads to variants of Q-MAP which have the same asymptotic\nperformance as Q-MAP in terms of their required sampling rates. Moreover, these\nvariants suggest that Q-MAP is robust to small error in estimating the source\ndistribution. This robustness is theoretically proven and the effect of a\nnon-vanishing estimation error on the required sampling rate is characterized.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Jalali Shirin"],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01073","title":"EXPSPACE-hardness of behavioural equivalences of succinct one-counter\n  nets","abstract":"We note that the remarkable EXPSPACE-hardness result in [G\\\"oller, Haase,\nOuaknine, Worrell, ICALP 2010] ([GHOW10] for short) allows us to answer an open\ncomplexity question for simulation preorder of succinct one counter nets (i.e.,\none counter automata with no zero tests where counter increments and decrements\nare integers written in binary). This problem, as well as bisimulation\nequivalence, turn out to be EXPSPACE-complete. The technique of [GHOW10] was\nreferred to by Hunter [RP 2015] for deriving EXPSPACE-hardness of reachability\ngames on succinct one-counter nets. We first give a direct self-contained\nEXPSPACE-hardness proof for such reachability games (by adjusting a known\nPSPACE-hardness proof for emptiness of alternating finite automata with\none-letter alphabet); then we reduce reachability games to (bi)simulation games\nby using a standard \"defender-choice\" technique.","primary_category":"cs","categories":["cs.LO"],"authors":["Jancar Petr","Osicka Petr","Sawa Zdenek"],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01080","title":"Cooperative Training of Deep Aggregation Networks for RGB-D Action\n  Recognition","abstract":"A novel deep neural network training paradigm that exploits the conjoint\ninformation in multiple heterogeneous sources is proposed. Specifically, in a\nRGB-D based action recognition task, it cooperatively trains a single\nconvolutional neural network (named c-ConvNet) on both RGB visual features and\ndepth features, and deeply aggregates the two kinds of features for action\nrecognition. Differently from the conventional ConvNet that learns the deep\nseparable features for homogeneous modality-based classification with only one\nsoftmax loss function, the c-ConvNet enhances the discriminative power of the\ndeeply learned features and weakens the undesired modality discrepancy by\njointly optimizing a ranking loss and a softmax loss for both homogeneous and\nheterogeneous modalities. The ranking loss consists of intra-modality and\ncross-modality triplet losses, and it reduces both the intra-modality and\ncross-modality feature variations. Furthermore, the correlations between RGB\nand depth data are embedded in the c-ConvNet, and can be retrieved by either of\nthe modalities and contribute to the recognition in the case even only one of\nthe modalities is available. The proposed method was extensively evaluated on\ntwo large RGB-D action recognition datasets, ChaLearn LAP IsoGD and NTU RGB+D\ndatasets, and one small dataset, SYSU 3D HOI, and achieved state-of-the-art\nresults.","primary_category":"cs","categories":["cs.CV"],"authors":["Wang Pichao","Li Wanqing","Wan Jun","Ogunbona Philip","Liu Xinwang"],"created":"2017-12-05","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01081","title":"High Performance Quantum Modular Multipliers","abstract":"We present a novel set of reversible modular multipliers applicable to\nquantum computing, derived from three classical techniques: 1) traditional\ninteger division, 2) Montgomery residue arithmetic, and 3) Barrett reduction.\nEach multiplier computes an exact result for all binary input values, while\nmaintaining the asymptotic resource complexity of a single (non-modular)\ninteger multiplier. We additionally conduct an empirical resource analysis of\nour designs in order to determine the total gate count and circuit depth of\neach fully constructed circuit, with inputs as large as 2048 bits. Our\ncomparative analysis considers both circuit implementations which allow for\narbitrary (controlled) rotation gates, as well as those restricted to a typical\nfault-tolerant gate set.","primary_category":"cs","categories":["quant-ph","cs.ET"],"authors":["Rines Rich","Chuang Isaac"],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01086","title":"Ghanaian Consumers Online Privacy Concerns: Causes and its Effects on\n  E-Commerce Adoption","abstract":"Online privacy has gradually become a concern for internet users over the\nyears as a result of the interconnection of customers devices with other\ndevices supporting the internet technology. This research investigates and\ndiscusses the factors that influence the privacy concerns faced by online\nconsumers of internet services and the possible outcomes of these privacy\nconcerns on the African online market with Ghana being the primary focus.\nResults from this study indicated that only 10.1 percent of respondents felt\nthat the internet was safe for purchase and payment transaction in Ghana.\nHowever, respondents were willing to shop online if e-Commerce was the only\nmeans of getting their products. Respondents also had a high sense of perceived\nvulnerability and their perceived vulnerability to unauthorized data collection\nand misuse of personal information could affect Ghanaian e-Commerce platform\nadoption. The perceived ability of users of e-Commerce platforms in Ghana to\ncontrol data collection and its subsequent use by other third parties was also\nfound to negatively impact customers willingness to wholly transact and share\ntheir personal information online. The perceived vulnerability was found to be\naffected by the high levels of internet illiteracy whiles the perceived ability\nto control the collection of information and use was influenced by both the\ninternet literacy level as well as the level of social awareness of the\nGhanaian internet consumer.","primary_category":"cs","categories":["cs.CY","cs.NI","cs.SI"],"authors":["Tchao E. T.","Diawuo Kwasi","Aggor Christiana Selorm","Kotey Seth Djane"],"created":"2017-12-05","updated":" ","doi":"10.14569\/IJACSA.2017.081120"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01089","title":"3D Face Reconstruction with Region Based Best Fit Blending Using Mobile\n  Phone for Virtual Reality Based Social Media","abstract":"The use of virtual reality (VR) is exponentially increasing and due to that\nmany researchers has started to work on developing new VR based social media.\nFor this purpose it is important to have an avatar of the users which look like\nthem to be easily generated by the devices which are accessible, such as mobile\nphone. In this paper, we propose a novel method of recreating a 3D human face\nmodel captured with a phone camera image or video data. The method focuses more\non model shape than texture in order to make the face recognizable. We detect\n68 facial feature points and use them to separate a face into four regions. For\neach area the best fitting models are found and are further morphed combined to\nfind the best fitting models for each area. These are then combined and further\nmorphed in order to restore the original facial proportions. We also present a\nmethod of texturing the resulting model, where the aforementioned feature\npoints are used to generate a texture for the resulting model","primary_category":"cs","categories":["cs.CV"],"authors":["Anbarjafari Gholamreza","Haamer Rain Eric","Lusi Iiris","Tikk Toomas","Valgma Lembit"],"created":"2017-12-12","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01096","title":"On Periodicity Lemma for Partial Words","abstract":"We investigate the function $L(h,p,q)$, called here the threshold function,\nrelated to periodicity of partial words (words with holes). The value\n$L(h,p,q)$ is defined as the minimum length threshold which guarantees that a\nnatural extension of the periodicity lemma is valid for partial words with $h$\nholes and (strong) periods $p,q$. We show how to evaluate the threshold\nfunction in $O(\\log p + \\log q)$ time, which is an improvement upon the best\npreviously known $O(p+q)$-time algorithm. In a series of papers, the formulae\nfor the threshold function, in terms of $p$ and $q$, were provided for each\nfixed $h \\le 7$. We demystify the generic structure of such formulae, and for\neach value $h$ we express the threshold function in terms of a piecewise-linear\nfunction with $O(h)$ pieces.","primary_category":"cs","categories":["cs.DM","cs.DS","math.CO"],"authors":["Kociumaka Tomasz","Radoszewski Jakub","Rytter Wojciech","Wale\u0144 Tomasz"],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01110","title":"On modal analysis of laminated glass: Usability of simplified methods\n  and enhanced effective thickness","abstract":"This paper focuses on the modal analysis of laminated glass beams. In these\nmultilayer elements, the stiff glass plates are connected by compliant\ninterlayers with frequency\/temperature-dependent behavior. The aim of our study\nis (i) to assess whether approximate techniques can accurately predict the\nbehavior of laminated glass structures and (ii) to propose an easy tool for\nmodal analysis based on the enhanced effective thickness concept by Galuppi and\nRoyer-Carfagni.\n  To this purpose, we consider four approaches to the solution of the related\nnonlinear eigenvalue problem: a complex-eigenvalue solver based on the Newton\nmethod, the modal strain energy method, and two effective thickness concepts. A\ncomparative study of free vibrating laminated glass beams is performed\nconsidering different geometries of cross-sections, boundary conditions, and\nmaterial parameters for interlayers under two ambient temperatures. The\nviscoelastic response of polymer foils is represented by the generalized\nMaxwell model.\n  We show that the simplified approaches predict natural frequencies with an\nacceptable accuracy for most of the examples. However, there is a considerable\nscatter in predicted loss factors. The enhanced effective thickness approach\nadjusted for modal analysis leads to lower errors in both quantities compared\nto the other two simplified procedures, reducing the extreme error in loss\nfactors to one half compared to the modal strain energy method or to one\nquarter compared to the original dynamic effective thickness method.","primary_category":"cs","categories":["cs.CE"],"authors":["Zemanov\u00e1 Alena","Zeman Jan","Janda Tom\u00e1\u0161","Schmidt Jaroslav","\u0160ejnoha Michal"],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01117","title":"Learning from Pseudo-Randomness With an Artificial Neural Network - Does\n  God Play Pseudo-Dice?","abstract":"Inspired by the fact that the neural network, as the mainstream for machine\nlearning, has brought successes in many application areas, here we propose to\nuse this approach for decoding hidden correlation among pseudo-random data and\npredicting events accordingly. With a simple neural network structure and a\ntypical training procedure, we demonstrate the learning and prediction power of\nthe neural network in extremely random environment. Finally, we postulate that\nthe high sensitivity and efficiency of the neural network may allow to\ncritically test if there could be any fundamental difference between quantum\nrandomness and pseudo randomness, which is equivalent to the question: Does God\nplay dice?","primary_category":"cs","categories":["cs.LG","cs.CR"],"authors":["Fan Fenglei","Wang Ge"],"created":"2018-01-04","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01143","title":"Coins and Logic","abstract":"We establish fun parallels between coin-weighing puzzles and\nknights-and-knaves puzzles.","primary_category":"cs","categories":["math.HO","cs.AI","math.CO"],"authors":["Khovanova Tanya"],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01145","title":"Vectorial Boolean functions and linear codes in the context of algebraic\n  attacks","abstract":"In this paper we study the relationship between vectorial (Boolean) functions\nand cyclic codes in the context of algebraic attacks. We first derive a direct\nlink between the annihilators of a vectorial function (in univariate form) and\ncertain $2^{n}$-ary cyclic codes (which we prove that they are LCD codes)\nextending results due to R{\\o}njom and Helleseth. The knowledge of the minimum\ndistance of those codes gives rise to a lower bound on the algebraic immunity\nof the associated vectorial function. Furthermore, we solve an open question\nraised by Mesnager and Cohen. We also present some properties of those cyclic\ncodes (whose generator polynomials determined by vectorial functions) as well\nas their weight enumerator. In addition we generalize the so-called algebraic\ncomplement and study its properties.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Boumezbeur Mouna","Mesnager Sihem","Guenda Kenza"],"created":"2017-12-30","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01155","title":"A Voxel-based Rendering Pipeline for Large 3D Line Sets","abstract":"We present a voxel-based rendering pipeline for large 3D line sets that\nemploys GPU ray-casting to achieve scalable rendering including transparency\nand global illumination effects that cannot be achieved with GPU rasterization.\nEven for opaque lines we demonstrate superior rendering performance compared to\nGPU rasterization of lines, and when transparency is used we can interactively\nrender large amounts of lines that are infeasible to be rendered via\nrasterization. To achieve this, we propose a direction-preserving encoding of\nlines into a regular voxel grid, along with the quantization of directions\nusing face-to-face connectivity in this grid. On the regular grid structure,\nparallel GPU ray-casting is used to determine visible fragments in correct\nvisibility order. To enable interactive rendering of global illumination\neffects like low-frequency shadows and ambient occlusions, illumination\nsimulation is performed during ray-casting on a level-of-detail (LoD) line\nrepresentation that considers the number of lines and their lengths per voxel.\nIn this way we can render effects which are very difficult to render via GPU\nrasterization. A detailed performance and quality evaluation compares our\napproach to rasterization-based rendering of lines.","primary_category":"cs","categories":["cs.GR"],"authors":["Kanzler Mathias","Rautenhaus Marc","Westermann R\u00fcdiger"],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01179","title":"Inferring propagation paths for sparsely observed perturbations on\n  complex networks","abstract":"In a complex system, perturbations propagate by following paths on the\nnetwork of interactions among the system's units. In contrast to what happens\nwith the spreading of epidemics, observations of general perturbations are\noften very sparse in time (there is a single observation of the perturbed\nsystem) and in \"space\" (only a few perturbed and unperturbed units are\nobserved). A major challenge in many areas, from biology to the social\nsciences, is to infer the propagation paths from observations of the effects of\nperturbation under these sparsity conditions. We address this problem and show\nthat it is possible to go beyond the usual approach of using the shortest paths\nconnecting the known perturbed nodes. Specifically, we show that a simple and\ngeneral probabilistic model, which we solved using belief propagation, provides\nfast and accurate estimates of the probabilities of nodes being perturbed.","primary_category":"cs","categories":["cs.SI","physics.soc-ph"],"authors":["Massucci Francesco Alessandro","Wheeler Jonathan","Beltran-Debon Raul","Joven Jorge","Sales-Pardo Marta","Guimera Roger"],"created":"2017-12-04","updated":" ","doi":"10.1126\/sciadv.1501638"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01180","title":"Rooted Divergence-Preserving Branching Bisimilarity is a Congruence","abstract":"We prove that rooted divergence-preserving branching bisimilarity is a\ncongruence for the process specification language consisting of $\\mathbf{0}$,\naction prefix, choice, and the recursion construct $\\mu X.\\_$.","primary_category":"cs","categories":["cs.LO"],"authors":["van Glabbeek Rob","Luttik Bas","Spaninks Linda"],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01185","title":"Dynamic Co-Simulation Methods for Combined Transmission-Distribution\n  System and Integration Time Step Impact on Convergence","abstract":"Combined Transmission and Distribution Systems (CoTDS) simulation for power\nsystems requires development of algorithms and software that are numerically\nstable and at the same time accurately simulate dynamic events that can occur\nin practical systems. The dynamic behavior of transmission and distribution\nsystems are vastly different, especially with the increased deployment of\ndistribution generation. The time scales of simulation can be orders of\nmagnitude apart making the combined simulation extremely challenging. This has\nled to increased research in applying co-simulation techniques for integrated\nsimulation of the two systems. In this paper, a rigorous mathematical analysis\non convergence of numerical methods in co-simulation is presented. Two methods\nfor co-simulation of CoTDS are proposed using parallel and series computation\nof the transmission system and distribution systems. Both these co-simulation\nmethods are validated against total system simulation in a single time-domain\nsimulation environment. The series computation co-simulation method is shown to\nhave better numerical stability at larger integration time steps. The series\ncomputation co-simulation method is additionally validated against commercial\nEMTP software and the results show remarkable correspondence.","primary_category":"cs","categories":["cs.SY","math.NA"],"authors":["Venkatraman Ramakrishnan","Khaitan Siddhartha Kumar","Ajjarapu Venkataramana"],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01198","title":"Fingerprint Distortion Rectification using Deep Convolutional Neural\n  Networks","abstract":"Elastic distortion of fingerprints has a negative effect on the performance\nof fingerprint recognition systems. This negative effect brings inconvenience\nto users in authentication applications. However, in the negative recognition\nscenario where users may intentionally distort their fingerprints, this can be\na serious problem since distortion will prevent recognition system from\nidentifying malicious users. Current methods aimed at addressing this problem\nstill have limitations. They are often not accurate because they estimate\ndistortion parameters based on the ridge frequency map and orientation map of\ninput samples, which are not reliable due to distortion. Secondly, they are not\nefficient and requiring significant computation time to rectify samples. In\nthis paper, we develop a rectification model based on a Deep Convolutional\nNeural Network (DCNN) to accurately estimate distortion parameters from the\ninput image. Using a comprehensive database of synthetic distorted samples, the\nDCNN learns to accurately estimate distortion bases ten times faster than the\ndictionary search methods used in the previous approaches. Evaluating the\nproposed method on public databases of distorted samples shows that it can\nsignificantly improve the matching performance of distorted samples.","primary_category":"cs","categories":["cs.CV"],"authors":["Dabouei Ali","Kazemi Hadi","Iranmanesh Seyed Mehdi","Dawson Jeremi","Nasrabadi Nasser M."],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01203","title":"Spectre Attacks: Exploiting Speculative Execution","abstract":"Modern processors use branch prediction and speculative execution to maximize\nperformance. For example, if the destination of a branch depends on a memory\nvalue that is in the process of being read, CPUs will try guess the destination\nand attempt to execute ahead. When the memory value finally arrives, the CPU\neither discards or commits the speculative computation. Speculative logic is\nunfaithful in how it executes, can access to the victim's memory and registers,\nand can perform operations with measurable side effects.\n  Spectre attacks involve inducing a victim to speculatively perform operations\nthat would not occur during correct program execution and which leak the\nvictim's confidential information via a side channel to the adversary. This\npaper describes practical attacks that combine methodology from side channel\nattacks, fault attacks, and return-oriented programming that can read arbitrary\nmemory from the victim's process. More broadly, the paper shows that\nspeculative execution implementations violate the security assumptions\nunderpinning numerous software security mechanisms, including operating system\nprocess separation, static analysis, containerization, just-in-time (JIT)\ncompilation, and countermeasures to cache timing\/side-channel attacks. These\nattacks represent a serious threat to actual systems, since vulnerable\nspeculative execution capabilities are found in microprocessors from Intel,\nAMD, and ARM that are used in billions of devices.\n  While makeshift processor-specific countermeasures are possible in some\ncases, sound solutions will require fixes to processor designs as well as\nupdates to instruction set architectures (ISAs) to give hardware architects and\nsoftware developers a common understanding as to what computation state CPU\nimplementations are (and are not) permitted to leak.","primary_category":"cs","categories":["cs.CR"],"authors":["Kocher Paul","Genkin Daniel","Gruss Daniel","Haas Werner","Hamburg Mike","Lipp Moritz","Mangard Stefan","Prescher Thomas","Schwarz Michael","Yarom Yuval"],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01204","title":"Predicting Chronic Disease Hospitalizations from Electronic Health\n  Records: An Interpretable Classification Approach","abstract":"Urban living in modern large cities has significant adverse effects on\nhealth, increasing the risk of several chronic diseases. We focus on the two\nleading clusters of chronic disease, heart disease and diabetes, and develop\ndata-driven methods to predict hospitalizations due to these conditions. We\nbase these predictions on the patients' medical history, recent and more\ndistant, as described in their Electronic Health Records (EHR). We formulate\nthe prediction problem as a binary classification problem and consider a\nvariety of machine learning methods, including kernelized and sparse Support\nVector Machines (SVM), sparse logistic regression, and random forests. To\nstrike a balance between accuracy and interpretability of the prediction, which\nis important in a medical setting, we propose two novel methods: K-LRT, a\nlikelihood ratio test-based method, and a Joint Clustering and Classification\n(JCC) method which identifies hidden patient clusters and adapts classifiers to\neach cluster. We develop theoretical out-of-sample guarantees for the latter\nmethod. We validate our algorithms on large datasets from the Boston Medical\nCenter, the largest safety-net hospital system in New England.","primary_category":"cs","categories":["cs.LG"],"authors":["Brisimi Theodora S.","Xu Tingting","Wang Taiyao","Dai Wuyang","Adams William G.","Paschalidis Ioannis Ch."],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01206","title":"Radial basis function collocation method for decoupled fractional\n  Laplacian wave equations","abstract":"Decoupled fractional Laplacian wave equation can describe the seismic wave\npropagation in attenuating media. Fourier pseudospectral implementations, which\nsolve the equation in spatial frequency domain, are the only existing methods\nfor solving the equation. For the earth media with curved boundaries, the\npseudospectral methods could be less attractive to handle the irregular\ncomputational domains. In the paper, we propose a radial basis function\ncollocation method that can easily tackle the irregular domain problems. Unlike\nthe pseudospectral methods, the proposed method solves the equation in physical\nvariable domain. The directional fractional Laplacian is chosen from varied\ndefinitions of fractional Laplacian. Particularly, the vector\nGr\\\"unwald-Letnikov formula is employed to approximate fractional directional\nderivative of radial basis function. The convergence and stability of the\nmethod are numerically investigated by using the synthetic solution and the\nlong-time simulations, respectively. The method's flexibility is studied by\nconsidering homogeneous and multi-layer media having regular and irregular\ngeometric boundaries.","primary_category":"cs","categories":["math.NA","cs.CE","cs.NA"],"authors":["Xu Yiran","Li Jingye","Pang Guofei","Wang Zhikai","Chen Xiaohong"],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01207","title":"Meltdown","abstract":"The security of computer systems fundamentally relies on memory isolation,\ne.g., kernel address ranges are marked as non-accessible and are protected from\nuser access. In this paper, we present Meltdown. Meltdown exploits side effects\nof out-of-order execution on modern processors to read arbitrary kernel-memory\nlocations including personal data and passwords. Out-of-order execution is an\nindispensable performance feature and present in a wide range of modern\nprocessors. The attack works on different Intel microarchitectures since at\nleast 2010 and potentially other processors are affected. The root cause of\nMeltdown is the hardware. The attack is independent of the operating system,\nand it does not rely on any software vulnerabilities. Meltdown breaks all\nsecurity assumptions given by address space isolation as well as\nparavirtualized environments and, thus, every security mechanism building upon\nthis foundation. On affected systems, Meltdown enables an adversary to read\nmemory of other processes or virtual machines in the cloud without any\npermissions or privileges, affecting millions of customers and virtually every\nuser of a personal computer. We show that the KAISER defense mechanism for\nKASLR has the important (but inadvertent) side effect of impeding Meltdown. We\nstress that KAISER must be deployed immediately to prevent large-scale\nexploitation of this severe information leakage.","primary_category":"cs","categories":["cs.CR"],"authors":["Lipp Moritz","Schwarz Michael","Gruss Daniel","Prescher Thomas","Haas Werner","Mangard Stefan","Kocher Paul","Genkin Daniel","Yarom Yuval","Hamburg Mike"],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01228","title":"A Decision-theoretic Approach to Detection-based Target Search with a\n  UAV","abstract":"Search and rescue missions and surveillance require finding targets in a\nlarge area. These tasks often use unmanned aerial vehicles (UAVs) with cameras\nto detect and move towards a target. However, common UAV approaches make two\nsimplifying assumptions. First, they assume that observations made from\ndifferent heights are deterministically correct. In practice, observations are\nnoisy, with the noise increasing as the height used for observations increases.\nSecond, they assume that a motion command executes correctly, which may not\nhappen due to wind and other environmental factors. To address these, we\npropose a sequential algorithm that determines actions in real time based on\nobservations, using partially observable Markov decision processes (POMDPs).\nOur formulation handles both observations and motion uncertainty and errors. We\nrun offline simulations and learn a policy. This policy is run on a UAV to find\nthe target efficiently. We employ a novel compact formulation to represent the\ncoordinates of the drone relative to the target coordinates. Our POMDP policy\nfinds the target up to 3.4 times faster when compared to a heuristic policy.","primary_category":"cs","categories":["cs.AI","cs.RO"],"authors":["Gupta Aayush","Bessonov Daniel","Li Patrick"],"created":"2018-01-03","updated":" ","doi":"10.1109\/IROS.2017.8206423"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01229","title":"Modular Networks for Validating Community Detection Algorithms","abstract":"How can we accurately compare different community detection algorithms? These\nalgorithms cluster nodes in a given network, and their performance is often\nvalidated on benchmark networks with explicit ground-truth communities. Given\nthe lack of cluster labels in real-world networks, a model that generates\nrealistic networks is required for accurate evaluation of these algorithm. In\nthis paper, we present a simple, intuitive, and flexible benchmark generator to\ngenerate intrinsically modular networks for community validation. We show how\nthe generated networks closely comply with the characteristics observed for\nreal networks; whereas their characteristics could be directly controlled to\nmatch wide range of real world networks. We further show how common community\ndetection algorithms rank differently when being evaluated on these benchmarks\ncompared to current available alternatives.","primary_category":"cs","categories":["cs.SI","physics.soc-ph"],"authors":["Fagnan Justin","Abnar Afra","Rabbany Reihaneh","Zaiane Osmar R."],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01235","title":"Depth Not Needed - An Evaluation of RGB-D Feature Encodings for Off-Road\n  Scene Understanding by Convolutional Neural Network","abstract":"Scene understanding for autonomous vehicles is a challenging computer vision\ntask, with recent advances in convolutional neural networks (CNNs) achieving\nresults that notably surpass prior traditional feature driven approaches.\nHowever, limited work investigates the application of such methods either\nwithin the highly unstructured off-road environment or to RGBD input data. In\nthis work, we take an existing CNN architecture designed to perform semantic\nsegmentation of RGB images of urban road scenes, then adapt and retrain it to\nperform the same task with multichannel RGBD images obtained under a range of\nchallenging off-road conditions. We compare two different stereo matching\nalgorithms and five different methods of encoding depth information, including\ndisparity, local normal orientation and HHA (horizontal disparity, height above\nground plane, angle with gravity), to create a total of ten experimental\nvariations of our dataset, each of which is used to train and test a CNN so\nthat classification performance can be evaluated against a CNN trained using\nstandard RGB input.","primary_category":"cs","categories":["cs.CV"],"authors":["Holder Christopher J.","Breckon Toby P.","Wei Xiong"],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01237","title":"A pairwise discriminative task for speech emotion recognition","abstract":"Speech emotion recognition is an important task in human-machine interaction.\nHowever, it faces many challenges such as the ambiguity of emotion expression\nand the lack of training samples. To solve these problems, we propose a novel\n'Pairwise discriminative task', which attempts to learn the similarity and\ndistinction between two audios rather than specific labels. In the task,\npairwise audios are fed into audio encode networks to extract audio vectors,\nfollowed with discrimination networks behind to judge whether audios belong to\nthe same emotion category or not. The system is optimized in an end-to-end\nmanner to minimize the loss function, which cooperates cosine similarity loss\nand cross entropy loss together. To verify the performance of audio\nrepresentation vectors extracted from the system, we test them on IEMOCAP\ndatabase-a common evaluation corpus. We gain 56.33% unweighted accuracy on the\ntest database, which surpasses above 5% compared with traditional end-to-end\nspeech emotion recognition networks.","primary_category":"cs","categories":["cs.HC","cs.SD","eess.AS"],"authors":["Lian Zheng","Li Ya","Tao Jianhua","Huang Jian"],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01249","title":"Cooperative Ambient Backscatter Communications for Green\n  Internet-of-Things","abstract":"Ambient backscatter communication (AmBC) enables a passive backscatter device\nto transmit information to a reader using ambient RF signals, and has emerged\nas a promising solution to green Internet-of-Things (IoT). Conventional AmBC\nreceivers are interested in recovering the information from the ambient\nbackscatter device (A-BD) only. In this paper, we propose a cooperative AmBC\n(CABC) system in which the reader recovers information not only from the A-BD,\nbut also from the RF source. We first establish the system model for the CABC\nsystem from spread spectrum and spectrum sharing perspectives. Then, for flat\nfading channels, we derive the optimal maximum-likelihood (ML) detector,\nsuboptimal linear detectors as well as successive interference-cancellation\n(SIC) based detectors. For frequency-selective fading channels, the system\nmodel for the CABC system over ambient orthogonal frequency division\nmultiplexing (OFDM) carriers is proposed, upon which a low-complexity optimal\nML detector is derived. For both kinds of channels, the bit-error-rate (BER)\nexpressions for the proposed detectors are derived in closed forms. Finally,\nextensive numerical results have shown that, when the A-BD signal and the\nRF-source signal have equal symbol period, the proposed SIC-based detectors can\nachieve near-ML detection performance for typical application scenarios, and\nwhen the A-BD symbol period is longer than the RF-source symbol period, the\nexistence of backscattered signal in the CABC system can enhance the ML\ndetection performance of the RF-source signal, thanks to the beneficial effect\nof the backscatter link when the A-BD transmits at a lower rate than the RF\nsource.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Yang Gang","Zhang Qianqian","Liang Ying-Chang"],"created":"2018-01-04","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01253","title":"Approximate Ranking from Pairwise Comparisons","abstract":"A common problem in machine learning is to rank a set of n items based on\npairwise comparisons. Here ranking refers to partitioning the items into sets\nof pre-specified sizes according to their scores, which includes identification\nof the top-k items as the most prominent special case. The score of a given\nitem is defined as the probability that it beats a randomly chosen other item.\nFinding an exact ranking typically requires a prohibitively large number of\ncomparisons, but in practice, approximate rankings are often adequate.\nAccordingly, we study the problem of finding approximate rankings from pairwise\ncomparisons. We analyze an active ranking algorithm that counts the number of\ncomparisons won, and decides whether to stop or which pair of items to compare\nnext, based on confidence intervals computed from the data collected in\nprevious steps. We show that this algorithm succeeds in recovering approximate\nrankings using a number of comparisons that is close to optimal up to\nlogarithmic factors. We also present numerical results, showing that in\npractice, approximation can drastically reduce the number of comparisons\nrequired to estimate a ranking.","primary_category":"cs","categories":["cs.LG","cs.AI","cs.IT","math.IT","stat.ML"],"authors":["Heckel Reinhard","Simchowitz Max","Ramchandran Kannan","Wainwright Martin J."],"created":"2018-01-04","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01258","title":"Deep Learning Reconstruction for 9-View Dual Energy CT Baggage Scanner","abstract":"For homeland and transportation security applications, 2D X-ray explosive\ndetection system (EDS) have been widely used, but they have limitations in\nrecognizing 3D shape of the hidden objects. Among various types of 3D computed\ntomography (CT) systems to address this issue, this paper is interested in a\nstationary CT using fixed X-ray sources and detectors. However, due to the\nlimited number of projection views, analytic reconstruction algorithms produce\nsevere streaking artifacts. Inspired by recent success of deep learning\napproach for sparse view CT reconstruction, here we propose a novel image and\nsinogram domain deep learning architecture for 3D reconstruction from very\nsparse view measurement. The algorithm has been tested with the real data from\na prototype 9-view dual energy stationary CT EDS carry-on baggage scanner\ndeveloped by GEMSS Medical Systems, Korea, which confirms the superior\nreconstruction performance over the existing approaches.","primary_category":"cs","categories":["cs.CV","cs.AI","cs.LG","stat.ML"],"authors":["Han Yoseob","Kang Jingu","Ye Jong Chul"],"created":"2018-01-04","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01260","title":"Cross-domain Human Parsing via Adversarial Feature and Label Adaptation","abstract":"Human parsing has been extensively studied recently due to its wide\napplications in many important scenarios. Mainstream fashion parsing models\nfocus on parsing the high-resolution and clean images. However, directly\napplying the parsers trained on benchmarks to a particular application scenario\nin the wild, e.g., a canteen, airport or workplace, often gives\nnon-satisfactory performance due to domain shift. In this paper, we explore a\nnew and challenging cross-domain human parsing problem: taking the benchmark\ndataset with extensive pixel-wise labeling as the source domain, how to obtain\na satisfactory parser on a new target domain without requiring any additional\nmanual labeling? To this end, we propose a novel and efficient cross-domain\nhuman parsing model to bridge the cross-domain differences in terms of visual\nappearance and environment conditions and fully exploit commonalities across\ndomains. Our proposed model explicitly learns a feature compensation network,\nwhich is specialized for mitigating the cross-domain differences. A\ndiscriminative feature adversarial network is introduced to supervise the\nfeature compensation to effectively reduce the discrepancy between feature\ndistributions of two domains. Besides, our model also introduces a structured\nlabel adversarial network to guide the parsing results of the target domain to\nfollow the high-order relationships of the structured labels shared across\ndomains. The proposed framework is end-to-end trainable, practical and scalable\nin real applications. Extensive experiments are conducted where LIP dataset is\nthe source domain and 4 different datasets including surveillance videos,\nmovies and runway shows are evaluated as target domains. The results\nconsistently confirm data efficiency and performance advantages of the proposed\nmethod for the cross-domain human parsing problem.","primary_category":"cs","categories":["cs.CV","cs.MM"],"authors":["Liu Si","Sun Yao","Zhu Defa","Ren Guanghui","Chen Yu","Feng Jiashi","Han Jizhong"],"created":"2018-01-04","updated":"2018-01-07","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01262","title":"ICFVR 2017: 3rd International Competition on Finger Vein Recognition","abstract":"In recent years, finger vein recognition has become an important sub-field in\nbiometrics and been applied to real-world applications. The development of\nfinger vein recognition algorithms heavily depends on large-scale real-world\ndata sets. In order to motivate research on finger vein recognition, we\nreleased the largest finger vein data set up to now and hold finger vein\nrecognition competitions based on our data set every year. In 2017,\nInternational Competition on Finger Vein Recognition(ICFVR) is held jointly\nwith IJCB 2017. 11 teams registered and 10 of them joined the final evaluation.\nThe winner of this year dramatically improved the EER from 2.64% to 0.483%\ncompared to the winner of last year. In this paper, we introduce the process\nand results of ICFVR 2017 and give insights on development of state-of-art\nfinger vein recognition algorithms.","primary_category":"cs","categories":["cs.CV"],"authors":["Zhang Yi","Huang Houjun","Zhang Haifeng","Ni Liao","Xu Wei","Ahmed Nasir Uddin","Ahmed Md. Shakil","Jin Yilun","Chen Yingjie","Wen Jingxuan","Li Wenxin"],"created":"2018-01-04","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01263","title":"Improving the Closed-Loop Tracking Performance Using the First-Order\n  Hold Sensing Technique with Experiments","abstract":"This paper proposes a new perspective in the enhancement of the closed-loop\ntracking performance by using the first-order hold (FOH) sensing technique.\nFirstly, the literature review and fundamentals of the FOH are outlined.\nSecondly, the performance of the most commonly used zero-order hold (ZOH) and\nthat of the FOH are compared. Lastly, the detailed implementation of the FOH on\na pendulum tracking setup is presented to verify the superiority of the FOH\nover the ZOH in terms of the steady state tracking error. The results of the\nsimulation and the experiment are in agreement.","primary_category":"cs","categories":["cs.SY"],"authors":["Yang Chifu","Gao Shuang","Xue Zhu"],"created":"2018-01-04","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01275","title":"DeepTriage: Exploring the Effectiveness of Deep Learning for Bug\n  Triaging","abstract":"For a given software bug report, identifying an appropriate developer who\ncould potentially fix the bug is the primary task of a bug triaging process. A\nbug title (summary) and a detailed description is present in most of the bug\ntracking systems. Automatic bug triaging algorithm can be formulated as a\nclassification problem, with the bug title and description as the input,\nmapping it to one of the available developers (classes). The major challenge is\nthat the bug description usually contains a combination of free unstructured\ntext, code snippets, and stack trace making the input data noisy. The existing\nbag-of-words (BOW) feature models do not consider the syntactical and\nsequential word information available in the unstructured text. We propose a\nnovel bug report representation algorithm using an attention based deep\nbidirectional recurrent neural network (DBRNN-A) model that learns a syntactic\nand semantic feature from long word sequences in an unsupervised manner.\nInstead of BOW features, the DBRNN-A based bug representation is then used for\ntraining the classifier. Using an attention mechanism enables the model to\nlearn the context representation over a long word sequence, as in a bug report.\nTo provide a large amount of data to learn the feature learning model, the\nunfixed bug reports (~70% bugs in an open source bug tracking system) are\nleveraged, which were completely ignored in the previous studies. Another\ncontribution is to make this research reproducible by making the source code\navailable and creating a public benchmark dataset of bug reports from three\nopen source bug tracking system: Google Chromium (383,104 bug reports), Mozilla\nCore (314,388 bug reports), and Mozilla Firefox (162,307 bug reports).\nExperimentally we compare our approach with BOW model and machine learning\napproaches and observe that DBRNN-A provides a higher rank-10 average accuracy.","primary_category":"cs","categories":["cs.SE","cs.LG"],"authors":["Mani Senthil","Sankaran Anush","Aralikatte Rahul"],"created":"2018-01-04","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01303","title":"Microscopic Travel Time Analysis of Bottleneck Experiments","abstract":"This contribution provides a microscopic experimental study of pedestrian\nmotion in front of the bottleneck. Identification of individual pedestrians in\nconducted experiments enables to explain the high variance of travel time by\nheterogeneity of the crowd. Some pedestrians are able to push effectively\nthrough the crowd, some get trapped in the crowd for significantly longer time.\nThis ability to push through the crowd is associated with the slope of\nindividual linear model of the dependency of the travel time on the number of\npedestrians in front of the bottleneck. Further detailed study of the origin of\nsuch ability is carried out by means of the route choice, i.e. strategy whether\nto bypass the crowd or to walk directly through it. The study has revealed that\nthe ability to push through the crowd is a combination of aggressiveness in\nconflicts and willingness to overtake the crowd.","primary_category":"cs","categories":["physics.soc-ph","cs.MA","stat.AP"],"authors":["Buk\u00e1\u010dek Marek","Hrab\u00e1k Pavel","Krb\u00e1lek Milan"],"created":"2018-01-04","updated":" ","doi":"10.1080\/23249935.2017.1419423"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01315","title":"PixelLink: Detecting Scene Text via Instance Segmentation","abstract":"Most state-of-the-art scene text detection algorithms are deep learning based\nmethods that depend on bounding box regression and perform at least two kinds\nof predictions: text\/non-text classification and location regression.\nRegression plays a key role in the acquisition of bounding boxes in these\nmethods, but it is not indispensable because text\/non-text prediction can also\nbe considered as a kind of semantic segmentation that contains full location\ninformation in itself. However, text instances in scene images often lie very\nclose to each other, making them very difficult to separate via semantic\nsegmentation. Therefore, instance segmentation is needed to address this\nproblem. In this paper, PixelLink, a novel scene text detection algorithm based\non instance segmentation, is proposed. Text instances are first segmented out\nby linking pixels within the same instance together. Text bounding boxes are\nthen extracted directly from the segmentation result without location\nregression. Experiments show that, compared with regression-based methods,\nPixelLink can achieve better or comparable performance on several benchmarks,\nwhile requiring many fewer training iterations and less training data.","primary_category":"cs","categories":["cs.CV"],"authors":["Deng Dan","Liu Haifeng","Li Xuelong","Cai Deng"],"created":"2018-01-04","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01316","title":"Text Extraction and Retrieval from Smartphone Screenshots: Building a\n  Repository for Life in Media","abstract":"Daily engagement in life experiences is increasingly interwoven with mobile\ndevice use. Screen capture at the scale of seconds is being used in behavioral\nstudies and to implement \"just-in-time\" health interventions. The increasing\npsychological breadth of digital information will continue to make the actual\nscreens that people view a preferred if not required source of data about life\nexperiences. Effective and efficient Information Extraction and Retrieval from\ndigital screenshots is a crucial prerequisite to successful use of screen data.\nIn this paper, we present the experimental workflow we exploited to: (i)\npre-process a unique collection of screen captures, (ii) extract unstructured\ntext embedded in the images, (iii) organize image text and metadata based on a\nstructured schema, (iv) index the resulting document collection, and (v) allow\nfor Image Retrieval through a dedicated vertical search engine application. The\nadopted procedure integrates different open source libraries for traditional\nimage processing, Optical Character Recognition (OCR), and Image Retrieval. Our\naim is to assess whether and how state-of-the-art methodologies can be applied\nto this novel data set. We show how combining OpenCV-based pre-processing\nmodules with a Long short-term memory (LSTM) based release of Tesseract OCR,\nwithout ad hoc training, led to a 74% character-level accuracy of the extracted\ntext. Further, we used the processed repository as baseline for a dedicated\nImage Retrieval system, for the immediate use and application for behavioral\nand prevention scientists. We discuss issues of Text Information Extraction and\nRetrieval that are particular to the screenshot image case and suggest\nimportant future work.","primary_category":"cs","categories":["cs.IR","cs.CV","cs.DL","cs.MM"],"authors":["Chiatti Agnese","Cho Mu Jung","Gagneja Anupriya","Yang Xiao","Brinberg Miriam","Roehrick Katie","Choudhury Sagnik Ray","Ram Nilam","Reeves Byron","Giles C. Lee"],"created":"2018-01-04","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01317","title":"Semantic Segmentation via Highly Fused Convolutional Network with\n  Multiple Soft Cost Functions","abstract":"Semantic image segmentation is one of the most challenged tasks in computer\nvision. In this paper, we propose a highly fused convolutional network, which\nconsists of three parts: feature downsampling, combined feature upsampling and\nmultiple predictions. We adopt a strategy of multiple steps of upsampling and\ncombined feature maps in pooling layers with its corresponding unpooling\nlayers. Then we bring out multiple pre-outputs, each pre-output is generated\nfrom an unpooling layer by one-step upsampling. Finally, we concatenate these\npre-outputs to get the final output. As a result, our proposed network makes\nhighly use of the feature information by fusing and reusing feature maps. In\naddition, when training our model, we add multiple soft cost functions on\npre-outputs and final outputs. In this way, we can reduce the loss reduction\nwhen the loss is back propagated. We evaluate our model on three major\nsegmentation datasets: CamVid, PASCAL VOC and ADE20K. We achieve a\nstate-of-the-art performance on CamVid dataset, as well as considerable\nimprovements on PASCAL VOC dataset and ADE20K dataset","primary_category":"cs","categories":["cs.CV"],"authors":["Yang Tao","Wu Yan","Zhao Junqiao","Guan Linting"],"created":"2018-01-04","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01372","title":"Effective usage of random routing on networks of mobile agents","abstract":"Most existing routing strategies to improve transport efficiency have little\nattention what order should the packets be delivered, just simply used\nfirst-in-first-out queue discipline. However, it is far from optimal. In this\npaper we apply priority queuing discipline to random routing strategy on\nnetworks of mobile agents, in which the packets have high priority to transfer\ndirectly to their destination despite their order in the queue if their\ndestination are within a communication radius. Numerical experiments show that\nit not only remarkably improves network throughput and the packet arriving\nrate, but also reduces average travelling time and the rate of waiting time to\ntravelling time. Our work may be helpful in routing strategy designing on\nnetworks of mobile agents.","primary_category":"cs","categories":["cs.NI"],"authors":["Wu Ganhua","Yang Huijie"],"created":"2017-12-31","updated":"2018-01-10","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01383","title":"Computation of Optimal Control Problems with Terminal Constraint via\n  Variation Evolution","abstract":"Enlightened from the inverse consideration of the stable continuous-time\ndynamics evolution, the Variation Evolving Method (VEM) analogizes the optimal\nsolution to the equilibrium point of an infinite-dimensional dynamic system and\nsolves it in an asymptotically evolving way. In this paper, the compact version\nof the VEM is further developed for the computation of Optimal Control Problems\n(OCPs) with terminal constraint. The corresponding Evolution Partial\nDifferential Equation (EPDE), which describes the variation motion towards the\noptimal solution, is derived, and the costate-free optimality conditions are\nestablished. The explicit analytic expressions of the costates and the Lagrange\nmultipliers adjoining the terminal constraint, related to the states and the\ncontrol variables, are presented. With the semi-discrete method in the field of\nPDE numerical calculation, the EPDE is discretized as finite-dimensional\nInitial-value Problems (IVPs) to be solved, with common Ordinary Differential\nEquation (ODE) numerical integration methods.","primary_category":"cs","categories":["cs.SY"],"authors":["Zhang Sheng","Liao Bo","Liao Fei"],"created":"2018-01-02","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01397","title":"Implementation of Deep Convolutional Neural Network in Multi-class\n  Categorical Image Classification","abstract":"Convolutional Neural Networks has been implemented in many complex machine\nlearning takes such as image classification, object identification, autonomous\nvehicle and robotic vision tasks. However, ConvNet architecture efficiency and\naccuracy depend on a large number of fac- tors. Also, the complex architecture\nrequires a significant amount of data to train and involves with a large number\nof hyperparameters that increases the computational expenses and difficul-\nties. Hence, it is necessary to address the limitations and techniques to\novercome the barriers to ensure that the architecture performs well in complex\nvisual tasks. This article is intended to develop an efficient ConvNet\narchitecture for multi-class image categorical classification applica- tion. In\nthe development of the architecture, large pool of grey scale images are taken\nas input information images and split into training and test datasets. The\nnumerously available technique is implemented to reduce the overfitting and\npoor generalization of the network. The hyperpa- rameters of determined by\nBayesian Optimization with Gaussian Process prior algorithm. ReLu non-linear\nactivation function is implemented after the convolutional layers. Max pooling\nop- eration is carried out to downsampling the data points in pooling layers.\nCross-entropy loss function is used to measure the performance of the\narchitecture where the softmax is used in the classification layer. Mini-batch\ngradient descent with Adam optimizer algorithm is used for backpropagation.\nDeveloped architecture is validated with confusion matrix and classification\nreport.","primary_category":"cs","categories":["cs.CV"],"authors":["Murugan Pushparaja"],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01402","title":"A fully automated framework for lung tumour detection, segmentation and\n  analysis","abstract":"Early and correct diagnosis is a very important aspect of cancer treatment.\nDetection of tumour in Computed Tomography scan is a tedious and tricky task\nwhich requires expert knowledge and a lot of human working hours. As small\nhuman error is present in any work he does, it is possible that a CT scan could\nbe misdiagnosed causing the patient to become terminal. This paper introduces a\nnovel fully automated framework which helps to detect and segment tumour, if\npresent in a lung CT scan series. It also provides useful analysis of the\ndetected tumour such as its approximate volume, centre location and more. The\nframework provides a single click solution which analyses all CT images of a\nsingle patient series in one go. It helps to reduce the work of manually going\nthrough each CT slice and provides quicker and more accurate tumour diagnosis.\nIt makes use of customized image processing and image segmentation methods, to\ndetect and segment the prospective tumour region from the CT scan. It then uses\na trained ensemble classifier to correctly classify the segmented region as\nbeing tumour or not. Tumour analysis further computed can then be used to\ndetermine malignity of the tumour. With an accuracy of 98.14%, the implemented\nframework can be used in various practical scenarios, capable of eliminating\nneed of any expert pathologist intervention.","primary_category":"cs","categories":["cs.CV"],"authors":["Walawalkar Devesh"],"created":"2018-01-04","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01404","title":"String Periods in the Order-Preserving Model","abstract":"The order-preserving model (op-model, in short) was introduced quite recently\nbut has already attracted significant attention because of its applications in\ndata analysis. We introduce several types of periods in this setting\n(op-periods). Then we give algorithms to compute these periods in time $O(n)$,\n$O(n\\log\\log n)$, $O(n \\log^2 \\log n\/\\log \\log \\log n)$, $O(n\\log n)$ depending\non the type of periodicity. In the most general variant the number of different\nperiods can be as big as $\\Omega(n^2)$, and a compact representation is needed.\nOur algorithms require novel combinatorial insight into the properties of such\nperiods.","primary_category":"cs","categories":["cs.DS"],"authors":["Gourdel Garance","Kociumaka Tomasz","Radoszewski Jakub","Rytter Wojciech","Shur Arseny","Wale\u0144 Tomasz"],"created":"2018-01-04","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01415","title":"What have we learned from deep representations for action recognition?","abstract":"As the success of deep models has led to their deployment in all areas of\ncomputer vision, it is increasingly important to understand how these\nrepresentations work and what they are capturing. In this paper, we shed light\non deep spatiotemporal representations by visualizing what two-stream models\nhave learned in order to recognize actions in video. We show that local\ndetectors for appearance and motion objects arise to form distributed\nrepresentations for recognizing human actions. Key observations include the\nfollowing. First, cross-stream fusion enables the learning of true\nspatiotemporal features rather than simply separate appearance and motion\nfeatures. Second, the networks can learn local representations that are highly\nclass specific, but also generic representations that can serve a range of\nclasses. Third, throughout the hierarchy of the network, features become more\nabstract and show increasing invariance to aspects of the data that are\nunimportant to desired distinctions (e.g. motion patterns across various\nspeeds). Fourth, visualizations can be used not only to shed light on learned\nrepresentations, but also to reveal idiosyncracies of training data and to\nexplain failure cases of the system.","primary_category":"cs","categories":["cs.CV"],"authors":["Feichtenhofer Christoph","Pinz Axel","Wildes Richard P.","Zisserman Andrew"],"created":"2018-01-04","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01422","title":"Practical Challenges in Explicit Ethical Machine Reasoning","abstract":"We examine implemented systems for ethical machine reasoning with a view to\nidentifying the practical challenges (as opposed to philosophical challenges)\nposed by the area. We identify a need for complex ethical machine reasoning not\nonly to be multi-objective, proactive, and scrutable but that it must draw on\nheterogeneous evidential reasoning. We also argue that, in many cases, it needs\nto operate in real time and be verifiable. We propose a general architecture\ninvolving a declarative ethical arbiter which draws upon multiple evidential\nreasoners each responsible for a particular ethical feature of the system's\nenvironment. We claim that this architecture enables some separation of\nconcerns among the practical challenges that ethical machine reasoning poses.","primary_category":"cs","categories":["cs.AI"],"authors":["Dennis Louise","Fisher Michael"],"created":"2018-01-04","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01430","title":"SmartTennisTV: Automatic indexing of tennis videos","abstract":"In this paper, we demonstrate a score based indexing approach for tennis\nvideos. Given a broadcast tennis video (BTV), we index all the video segments\nwith their scores to create a navigable and searchable match. Our approach\ntemporally segments the rallies in the video and then recognizes the scores\nfrom each of the segments, before refining the scores using the knowledge of\nthe tennis scoring system. We finally build an interface to effortlessly\nretrieve and view the relevant video segments by also automatically tagging the\nsegmented rallies with human accessible tags such as 'fault' and 'deuce'. The\nefficiency of our approach is demonstrated on BTV's from two major tennis\ntournaments.","primary_category":"cs","categories":["cs.CV","cs.IR"],"authors":["Ghosh Anurag","Jawahar C. V."],"created":"2018-01-04","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01435","title":"The Impact of Mobility Model in the Optimal placement of Sensor Nodes in\n  Wireless Body Sensor Network","abstract":"Power and energy consumption is a fundamental issue in Body Sensor Networks\n(BSNs) since nodes must operate properly and autonomously for a certain period\nof time without battery replacement or change. This is due to the fact that the\nsensors in BSNs are either implanted in the body or are in very near position\nto the body. Thus, the duration of replacing the batteries should be of utmost\nimportance. Most of the existing researches suggested the development of a more\nimproved battery cells or developing an energy aware routing protocol to tackle\nthe energy consumption in WBSN. But this is not the case as most energy\nconsumption in WBSN occur as a result of mobility in routing and sensor node\nplacement. Therefore, improving the battery cells might not solve the energy\nconsumption in WBSN.","primary_category":"cs","categories":["cs.NI"],"authors":["Sadiq B. O.","Adedokun A. E","Abubakar Z. M"],"created":"2018-01-04","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01442","title":"ObamaNet: Photo-realistic lip-sync from text","abstract":"We present ObamaNet, the first architecture that generates both audio and\nsynchronized photo-realistic lip-sync videos from any new text. Contrary to\nother published lip-sync approaches, ours is only composed of fully trainable\nneural modules and does not rely on any traditional computer graphics methods.\nMore precisely, we use three main modules: a text-to-speech network based on\nChar2Wav, a time-delayed LSTM to generate mouth-keypoints synced to the audio,\nand a network based on Pix2Pix to generate the video frames conditioned on the\nkeypoints.","primary_category":"cs","categories":["cs.CV"],"authors":["Kumar Rithesh","Sotelo Jose","Kumar Kundan","de Brebisson Alexandre","Bengio Yoshua"],"created":"2017-12-06","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01443","title":"A semi-supervised fuzzy GrowCut algorithm to segment and classify\n  regions of interest of mammographic images","abstract":"According to the World Health Organization, breast cancer is the most common\nform of cancer in women. It is the second leading cause of death among women\nround the world, becoming the most fatal form of cancer. Mammographic image\nsegmentation is a fundamental task to support image analysis and diagnosis,\ntaking into account shape analysis of mammary lesions and their borders.\nHowever, mammogram segmentation is a very hard process, once it is highly\ndependent on the types of mammary tissues. In this work we present a new\nsemi-supervised segmentation algorithm based on the modification of the GrowCut\nalgorithm to perform automatic mammographic image segmentation once a region of\ninterest is selected by a specialist. In our proposal, we used fuzzy Gaussian\nmembership functions to modify the evolution rule of the original GrowCut\nalgorithm, in order to estimate the uncertainty of a pixel being object or\nbackground. The main impact of the proposed method is the significant reduction\nof expert effort in the initialization of seed points of GrowCut to perform\naccurate segmentation, once it removes the need of selection of background\nseeds. We also constructed an automatic point selection process based on the\nsimulated annealing optimization method, avoiding the need of human\nintervention. The proposed approach was qualitatively compared with other\nstate-of-the-art segmentation techniques, considering the shape of segmented\nregions. In order to validate our proposal, we built an image classifier using\na classical multilayer perceptron. We used Zernike moments to extract segmented\nimage features. This analysis employed 685 mammograms from IRMA breast cancer\ndatabase, using fat and fibroid tissues. Results show that the proposed\ntechnique could achieve a classification rate of 91.28\\% for fat tissues,\nevidencing the feasibility of our approach.","primary_category":"cs","categories":["cs.CV","cs.AI","cs.IR","cs.NE","eess.IV"],"authors":["Cordeiro Filipe Rolim","Santos Wellington Pinheiro dos","Filho Abel Guilhermino da Silva"],"created":"2017-12-03","updated":" ","doi":"10.1016\/j.eswa.2016.08.016"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01446","title":"IMU2Face: Real-time Gesture-driven Facial Reenactment","abstract":"We present IMU2Face, a gesture-driven facial reenactment system. To this end,\nwe combine recent advances in facial motion capture and inertial measurement\nunits (IMUs) to control the facial expressions of a person in a target video\nbased on intuitive hand gestures. IMUs are omnipresent, since modern\nsmart-phones, smart-watches and drones integrate such sensors, e.g., for\nchanging the orientation of the screen content, counting steps, or for flight\nstabilization. Face tracking and reenactment is based on the state-of-the-art\nreal-time Face2Face facial reenactment system. Instead of transferring facial\nexpressions from a source to a target actor, we employ an IMU to track the hand\ngestures of a source actor and use its orientation to modify the target actor's\nexpressions.","primary_category":"cs","categories":["cs.CV"],"authors":["Thies Justus","Zollh\u00f6fer Michael","Nie\u00dfner Matthias"],"created":"2017-12-18","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01449","title":"3D Surface-to-Structure Translation using Deep Convolutional Networks","abstract":"Our demonstration shows a system that estimates internal body structures from\n3D surface models using deep convolutional neural networks trained on CT\n(computed tomography) images of the human body. To take pictures of structures\ninside the body, we need to use a CT scanner or an MRI (Magnetic Resonance\nImaging) scanner. However, assuming that the mutual information between outer\nshape of the body and its inner structure is not zero, we can obtain an\napproximate internal structure from a 3D surface model based on MRI and CT\nimage database. This suggests that we could know where and what kind of disease\na person is likely to have in his\/her body simply by 3D scanning surface of the\nbody. As a first prototype, we developed a system for estimating internal body\nstructures from surface models based on Visible Human Project DICOM CT Datasets\nfrom the University of Iowa Magnetic Resonance Research Facility.","primary_category":"cs","categories":["cs.CV"],"authors":["Moriya Takumi","Saito Kazuyuki","Tanaka Hiroya"],"created":"2017-12-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01450","title":"Quantifying Translation-Invariance in Convolutional Neural Networks","abstract":"A fundamental problem in object recognition is the development of image\nrepresentations that are invariant to common transformations such as\ntranslation, rotation, and small deformations. There are multiple hypotheses\nregarding the source of translation invariance in CNNs. One idea is that\ntranslation invariance is due to the increasing receptive field size of neurons\nin successive convolution layers. Another possibility is that invariance is due\nto the pooling operation. We develop a simple a tool, the\ntranslation-sensitivity map, which we use to visualize and quantify the\ntranslation-invariance of various architectures. We obtain the surprising\nresult that architectural choices such as the number of pooling layers and the\nconvolution filter size have only a secondary effect on the\ntranslation-invariance of a network. Our analysis identifies training data\naugmentation as the most important factor in obtaining translation-invariant\nrepresentations of images using convolutional neural networks.","primary_category":"cs","categories":["cs.CV"],"authors":["Kauderer-Abrams Eric"],"created":"2017-12-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01453","title":"Adaptive kNN using Expected Accuracy for Classification of Geo-Spatial\n  Data","abstract":"The k-Nearest Neighbor (kNN) classification approach is conceptually simple -\nyet widely applied since it often performs well in practical applications.\nHowever, using a global constant k does not always provide an optimal solution,\ne.g., for datasets with an irregular density distribution of data points. This\npaper proposes an adaptive kNN classifier where k is chosen dynamically for\neach instance (point) to be classified, such that the expected accuracy of\nclassification is maximized. We define the expected accuracy as the accuracy of\na set of structurally similar observations. An arbitrary similarity function\ncan be used to find these observations. We introduce and evaluate different\nsimilarity functions. For the evaluation, we use five different classification\ntasks based on geo-spatial data. Each classification task consists of (tens of)\nthousands of items. We demonstrate, that the presented expected accuracy\nmeasures can be a good estimator for kNN performance, and the proposed adaptive\nkNN classifier outperforms common kNN and previously introduced adaptive kNN\nalgorithms. Also, we show that the range of considered k can be significantly\nreduced to speed up the algorithm without negative influence on classification\naccuracy.","primary_category":"cs","categories":["cs.CV","cs.LG"],"authors":["Kibanov Mark","Becker Martin","Mueller Juergen","Atzmueller Martin","Hotho Andreas","Stumme Gerd"],"created":"2017-12-14","updated":" ","doi":"10.1145\/3167132.3167226"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01454","title":"Translation of \"Zur Ermittlung eines Objektes aus zwei Perspektiven mit\n  innerer Orientierung\" by Erwin Kruppa (1913)","abstract":"Erwin Kruppa's 1913 paper, Erwin Kruppa, \"Zur Ermittlung eines Objektes aus\nzwei Perspektiven mit innerer Orientierung\", Sitzungsberichte der\nMathematisch-Naturwissenschaftlichen Kaiserlichen Akademie der Wissenschaften,\nVol. 122 (1913), pp. 1939-1948, which may be translated as \"To determine a 3D\nobject from two perspective views with known inner orientation\", is a landmark\npaper in Computer Vision because it provides the first five-point algorithm for\nrelative pose estimation. Kruppa showed that (a finite number of solutions for)\nthe relative pose between two calibrated images of a rigid object can be\ncomputed from five point matches between the images. Kruppa's work also gained\nattention in the topic of camera self-calibration, as presented in (Maybank and\nFaugeras, 1992). Since the paper is still relevant today (more than a hundred\ncitations within the last ten years) and the paper is not available online, we\nordered a copy from the German National Library in Frankfurt and provide an\nEnglish translation along with the German original. We also adapt the\nterminology to a modern jargon and provide some clarifications (highlighted in\nsans-serif font). For a historical review of geometric computer vision, the\nreader is referred to the recent survey paper (Sturm, 2011).","primary_category":"cs","categories":["cs.CV"],"authors":["Gallego Guillermo","Mueggler Elias","Sturm Peter"],"created":"2017-12-25","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01455","title":"Clustering of Data with Missing Entries","abstract":"The analysis of large datasets is often complicated by the presence of\nmissing entries, mainly because most of the current machine learning algorithms\nare designed to work with full data. The main focus of this work is to\nintroduce a clustering algorithm, that will provide good clustering even in the\npresence of missing data. The proposed technique solves an $\\ell_0$ fusion\npenalty based optimization problem to recover the clusters. We theoretically\nanalyze the conditions needed for the successful recovery of the clusters. We\nalso propose an algorithm to solve a relaxation of this problem using\nsaturating non-convex fusion penalties. The method is demonstrated on simulated\nand real datasets, and is observed to perform well in the presence of large\nfractions of missing entries.","primary_category":"cs","categories":["cs.LG","stat.ML"],"authors":["Poddar Sunrita","Jacob Mathews"],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01467","title":"Deep Reinforcement Learning based Optimal Control of Hot Water Systems","abstract":"Energy consumption for hot water production is a major draw in high\nefficiency buildings. Optimizing this has typically been approached from a\nthermodynamics perspective, decoupled from occupant influence. Furthermore,\noptimization usually presupposes existence of a detailed dynamics model for the\nhot water system. These assumptions lead to suboptimal energy efficiency in the\nreal world. In this paper, we present a novel reinforcement learning based\nmethodology which optimizes hot water production. The proposed methodology is\ncompletely generalizable, and does not require an offline step or human domain\nknowledge to build a model for the hot water vessel or the heating element.\nOccupant preferences too are learnt on the fly. The proposed system is applied\nto a set of 32 houses in the Netherlands where it reduces energy consumption\nfor hot water production by roughly 20% with no loss of occupant comfort.\nExtrapolating, this translates to absolute savings of roughly 200 kWh for a\nsingle household on an annual basis. This performance can be replicated to any\ndomestic hot water system and optimization objective, given that the fairly\nminimal requirements on sensor data are met. With millions of hot water systems\noperational worldwide, the proposed framework has the potential to reduce\nenergy consumption in existing and new systems on a multi Gigawatt-hour scale\nin the years to come.","primary_category":"cs","categories":["cs.SY","stat.AP","stat.ML"],"authors":["Kazmi Hussain","Mehmood Fahad","Lodeweyckx Stefan","Driesen Johan"],"created":"2018-01-04","updated":" ","doi":"10.1016\/j.energy.2017.12.019"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01486","title":"Deep Cross Polarimetric Thermal-to-visible Face Recognition","abstract":"In this paper, we present a deep coupled learning frame- work to address the\nproblem of matching polarimetric ther- mal face photos against a gallery of\nvisible faces. Polariza- tion state information of thermal faces provides the\nmiss- ing textural and geometrics details in the thermal face im- agery which\nexist in visible spectrum. we propose a coupled deep neural network\narchitecture which leverages relatively large visible and thermal datasets to\novercome the problem of overfitting and eventually we train it by a\npolarimetric thermal face dataset which is the first of its kind. The pro-\nposed architecture is able to make full use of the polari- metric thermal\ninformation to train a deep model compared to the conventional shallow\nthermal-to-visible face recogni- tion methods. Proposed coupled deep neural\nnetwork also finds global discriminative features in a nonlinear embed- ding\nspace to relate the polarimetric thermal faces to their corresponding visible\nfaces. The results show the superior- ity of our method compared to the\nstate-of-the-art models in cross thermal-to-visible face recognition\nalgorithms.","primary_category":"cs","categories":["cs.CV"],"authors":["Iranmanesh Seyed Mehdi","Dabouei Ali","Kazemi Hadi","Nasrabadi Nasser M."],"created":"2018-01-04","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01516","title":"Integrated NFV\/SDN Architectures: A Systematic Literature Review","abstract":"Network Functions Virtualization (NFV) and Software-Defined Networking (SDN)\nare new paradigms in the move towards open software and network hardware. While\nNFV aims to virtualize network functions and deploy them into general purpose\nhardware, SDN makes networks programmable by separating the control and data\nplanes. NFV and SDN are complementary technologies capable of providing one\nnetwork solution. SDN can provide connectivity between Virtual Network\nFunctions (VNFs) in a flexible and automated way, whereas NFV can use SDN as\npart of a service function chain. There are many studies designing NFV\/SDN\narchitectures in different environments. Researchers have been trying to\naddress reliability, performance, and scalability problems using different\narchitectural designs. This Systematic Literature Review (SLR) focuses on\nintegrated NFV\/SDN architectures, with the following goals: i) to investigate\nand provide an in-depth review of the state-of-the-art of NFV\/SDN\narchitectures, ii) to synthesize their architectural designs, and iii) to\nidentify areas for further improvements. Broadly, this SLR will encourage\nresearchers to advance the current stage of development (i.e., the\nstate-of-the-practice) of integrated NFV\/SDN architectures, and shed some light\non future research efforts and the challenges faced.","primary_category":"cs","categories":["cs.NI"],"authors":["Bonfim Michel S.","Dias Kelvin L.","Fernandes Stenio F. L."],"created":"2018-01-04","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01521","title":"Correlation between clustering and degree in affiliation networks","abstract":"We are interested in the probability that two randomly selected neighbors of\na random vertex of degree (at least) $k$ are adjacent. We evaluate this\nprobability for a power law random intersection graph, where each vertex is\nprescribed a collection of attributes and two vertices are adjacent whenever\nthey share a common attribute. We show that the probability obeys the scaling\n$k^{-\\delta}$ as $k\\to+\\infty$. Our results are mathematically rigorous. The\nparameter $0\\le \\delta\\le 1$ is determined by the tail indices of power law\nrandom weights defining the links between vertices and attributes.","primary_category":"cs","categories":["cs.SI","math.CO","math.PR","physics.soc-ph"],"authors":["Bloznelis Mindaugas","Petuchovas Justinas"],"created":"2018-01-04","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01528","title":"A deep learning approach for detecting traffic accidents from social\n  media data","abstract":"This paper employs deep learning in detecting the traffic accident from\nsocial media data. First, we thoroughly investigate the 1-year over 3 million\ntweet contents in two metropolitan areas: Northern Virginia and New York City.\nOur results show that paired tokens can capture the association rules inherent\nin the accident-related tweets and further increase the accuracy of the traffic\naccident detection. Second, two deep learning methods: Deep Belief Network\n(DBN) and Long Short-Term Memory (LSTM) are investigated and implemented on the\nextracted token. Results show that DBN can obtain an overall accuracy of 85%\nwith about 44 individual token features and 17 paired token features. The\nclassification results from DBN outperform those of Support Vector Machines\n(SVMs) and supervised Latent Dirichlet allocation (sLDA). Finally, to validate\nthis study, we compare the accident-related tweets with both the traffic\naccident log on freeways and traffic data on local roads from 15,000 loop\ndetectors. It is found that nearly 66% of the accident-related tweets can be\nlocated by the accident log and more than 80% of them can be tied to nearby\nabnormal traffic data. Several important issues of using Twitter to detect\ntraffic accidents have been brought up by the comparison including the location\nand time bias, as well as the characteristics of influential users and\nhashtags.","primary_category":"cs","categories":["cs.SI","stat.OT"],"authors":["Zhang Zhenhua","Heb Qing","Gao Jing","Ni Ming"],"created":"2018-01-04","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01531","title":"Slugbot: An Application of a Novel and Scalable Open Domain Socialbot\n  Framework","abstract":"In this paper we introduce a novel, open domain socialbot for the Amazon\nAlexa Prize competition, aimed at carrying on friendly conversations with users\non a variety of topics. We present our modular system, highlighting our\ndifferent data sources and how we use the human mind as a model for data\nmanagement. Additionally we build and employ natural language understanding and\ninformation retrieval tools and APIs to expand our knowledge bases. We describe\nour semistructured, scalable framework for crafting topic-specific dialogue\nflows, and give details on our dialogue management schemes and scoring\nmechanisms. Finally we briefly evaluate the performance of our system and\nobserve the challenges that an open domain socialbot faces.","primary_category":"cs","categories":["cs.CL","cs.HC"],"authors":["Bowden Kevin K.","Wu Jiaqi","Oraby Shereen","Misra Amita","Walker Marilyn"],"created":"2018-01-04","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01539","title":"DeepIso: A Deep Learning Model for Peptide Feature Detection","abstract":"Liquid chromatography with tandem mass spectrometry (LC-MS\/MS) based\nproteomics is a well-established research field with major applications such as\nidentification of disease biomarkers, drug discovery, drug design and\ndevelopment. In proteomics, protein identification and quantification is a\nfundamental task, which is done by first enzymatically digesting it into\npeptides, and then analyzing peptides by LC-MS\/MS instruments. The peptide\nfeature detection and quantification from an LC-MS map is the first step in\ntypical analysis workflows. In this paper we propose a novel deep learning\nbased model, DeepIso, that uses Convolutional Neural Networks (CNNs) to scan an\nLC-MS map to detect peptide features and estimate their abundance. Existing\ntools are often designed with limited engineered features based on domain\nknowledge, and depend on pretrained parameters which are hardly updated despite\nhuge amount of new coming proteomic data. Our proposed model, on the other\nhand, is capable of learning multiple levels of representation of high\ndimensional data through its many layers of neurons and continuously evolving\nwith newly acquired data. To evaluate our proposed model, we use an antibody\ndataset including a heavy and a light chain, each digested by Asp-N,\nChymotrypsin, Trypsin, thus giving six LC-MS maps for the experiment. Our model\nachieves 93.21% sensitivity with specificity of 99.44% on this dataset. Our\nresults demonstrate that novel deep learning tools are desirable to advance the\nstate-of-the-art in protein identification and quantification.","primary_category":"cs","categories":["q-bio.QM","cs.NE","physics.med-ph"],"authors":["Zohora Fatema Tuz","Tran Ngoc Hieu","Zhang Xianglilan","Xin Lei","Shan Baozhen","Li Ming"],"created":"2017-12-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01552","title":"Asymptotic bounds for spherical codes","abstract":"The set of all error-correcting codes C over a fixed finite alphabet F of\ncardinality q determines the set of code points in the unit square with\ncoordinates (R(C), delta (C)):= (relative transmission rate, relative minimal\ndistance). The central problem of the theory of such codes consists in\nmaximizing simultaneously the transmission rate of the code and the relative\nminimum Hamming distance between two different code words. The classical\napproach to this problem explored in vast literature consists in the inventing\nexplicit constructions of \"good codes\" and comparing new classes of codes with\nearlier ones. Less classical approach studies the geometry of the whole set of\ncode points (R,delta) (with q fixed), at first independently of its\ncomputability properties, and only afterwords turning to the problems of\ncomputability, analogies with statistical physics etc. The main purpose of this\narticle consists in extending this latter strategy to domain of spherical\ncodes.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Manin Yuri I.","Marcolli Matilde"],"created":"2018-01-04","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01554","title":"An Implementation of Back-Propagation Learning on GF11, a Large SIMD\n  Parallel Computer","abstract":"Current connectionist simulations require huge computational resources. We\ndescribe a neural network simulator for the IBM GF11, an experimental SIMD\nmachine with 566 processors and a peak arithmetic performance of 11 Gigaflops.\nWe present our parallel implementation of the backpropagation learning\nalgorithm, techniques for increasing efficiency, performance measurements on\nthe NetTalk text-to-speech benchmark, and a performance model for the\nsimulator. Our simulator currently runs the back-propagation learning algorithm\nat 900 million connections per second, where each \"connection per second\"\nincludes both a forward and backward pass. This figure was obtained on the\nmachine when only 356 processors were working; with all 566 processors\noperational, our simulation will run at over one billion connections per\nsecond. We conclude that the GF11 is well-suited to neural network simulation,\nand we analyze our use of the machine to determine which features are the most\nimportant for high performance.","primary_category":"cs","categories":["cs.LG","cs.DC","cs.NE"],"authors":["Witbrock Michael","Zagha Marco"],"created":"2018-01-04","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01557","title":"Plan in 2D, execute in 3D: An augmented reality solution for cup\n  placement in total hip arthroplasty","abstract":"Reproducibly achieving proper implant alignment is a critical step in total\nhip arthroplasty (THA) procedures that has been shown to substantially affect\npatient outcome. In current practice, correct alignment of the acetabular cup\nis verified in C-arm X-ray images that are acquired in an anterior-posterior\n(AP) view. Favorable surgical outcome is, therefore, heavily dependent on the\nsurgeon's experience in understanding the 3D orientation of a hemispheric\nimplant from 2D AP projection images. This work proposes an easy to use\nintra-operative component planning system based on two C-arm X-ray images that\nis combined with 3D augmented reality (AR) visualization that simplifies\nimpactor and cup placement according to the planning by providing a real-time\nRGBD data overlay. We evaluate the feasibility of our system in a user study\ncomprising four orthopedic surgeons at the Johns Hopkins Hospital, and also\nreport errors in translation, anteversion, and abduction as low as 1.98 mm,\n1.10 degrees, and 0.53 degrees, respectively. The promising performance of this\nAR solution shows that deploying this system could eliminate the need for\nexcessive radiation, simplify the intervention, and enable reproducibly\naccurate placement of acetabular implants.","primary_category":"cs","categories":["cs.CV"],"authors":["Fotouhi Javad","Alexander Clayton P.","Unberath Mathias","Taylor Giacomo","Lee Sing Chun","Fuerst Bernhard","Johnson Alex","Osgood Greg","Taylor Russell H.","Khanuja Harpal","Armand Mehran","Navab Nassir"],"created":"2018-01-04","updated":" ","doi":"10.1117\/1.JMI.5.2.021205"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01560","title":"On-the-fly Augmented Reality for Orthopaedic Surgery Using a Multi-Modal\n  Fiducial","abstract":"Fluoroscopic X-ray guidance is a cornerstone for percutaneous orthopaedic\nsurgical procedures. However, two-dimensional observations of the\nthree-dimensional anatomy suffer from the effects of projective simplification.\nConsequently, many X-ray images from various orientations need to be acquired\nfor the surgeon to accurately assess the spatial relations between the\npatient's anatomy and the surgical tools. In this paper, we present an\non-the-fly surgical support system that provides guidance using augmented\nreality and can be used in quasi-unprepared operating rooms. The proposed\nsystem builds upon a multi-modality marker and simultaneous localization and\nmapping technique to co-calibrate an optical see-through head mounted display\nto a C-arm fluoroscopy system. Then, annotations on the 2D X-ray images can be\nrendered as virtual objects in 3D providing surgical guidance. We\nquantitatively evaluate the components of the proposed system, and finally,\ndesign a feasibility study on a semi-anthropomorphic phantom. The accuracy of\nour system was comparable to the traditional image-guided technique while\nsubstantially reducing the number of acquired X-ray images as well as procedure\ntime. Our promising results encourage further research on the interaction\nbetween virtual and real objects, that we believe will directly benefit the\nproposed method. Further, we would like to explore the capabilities of our\non-the-fly augmented reality support system in a larger study directed towards\ncommon orthopaedic interventions.","primary_category":"cs","categories":["cs.CV"],"authors":["Andress Sebastian","Johnson Alex","Unberath Mathias","Winkler Alexander","Yu Kevin","Fotouhi Javad","Weidert Simon","Osgood Greg","Navab Nassir"],"created":"2018-01-04","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01571","title":"Robust PCA for Anomaly Detection in Cyber Networks","abstract":"This paper uses network packet capture data to demonstrate how Robust\nPrincipal Component Analysis (RPCA) can be used in a new way to detect\nanomalies which serve as cyber-network attack indicators. The approach requires\nonly a few parameters to be learned using partitioned training data and shows\npromise of ameliorating the need for an exhaustive set of examples of different\ntypes of network attacks. For Lincoln Lab's DARPA intrusion detection data set,\nthe method achieves low false-positive rates while maintaining reasonable\ntrue-positive rates on individual packets. In addition, the method correctly\ndetected packet streams in which an attack which was not previously\nencountered, or trained on, appears.","primary_category":"cs","categories":["cs.CR"],"authors":["Paffenroth Randy","Kay Kathleen","Servi Les"],"created":"2018-01-04","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01572","title":"LoopSmart: Smart Visual SLAM Through Surface Loop Closure","abstract":"We present a visual simultaneous localization and mapping (SLAM) framework of\nclosing surface loops. It combines both sparse feature matching and dense\nsurface alignment. Sparse feature matching is used for visual odometry and\nglobally camera pose fine-tuning when dense loops are detected, while dense\nsurface alignment is the way of closing large loops and solving surface\nmismatching problem. To achieve smart dense surface loop closure, a highly\nefficient CUDA-based global point cloud registration method and a map content\ndependent loop verification method are proposed. We run extensive experiments\non different datasets, our method outperforms state-of-the-art ones in terms of\nboth camera trajectory and surface reconstruction accuracy.","primary_category":"cs","categories":["cs.CV"],"authors":["Zhang Guoxiang","Chen YangQuan"],"created":"2018-01-04","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01574","title":"Testing Optimality of Sequential Decision-Making","abstract":"This paper provides a statistical method to test whether a system that\nperforms a binary sequential hypothesis test is optimal in the sense of\nminimizing the average decision times while taking decisions with given\nreliabilities. The proposed method requires samples of the decision times, the\ndecision outcomes, and the true hypotheses, but does not require knowledge on\nthe statistics of the observations or the properties of the decision-making\nsystem. The method is based on fluctuation relations for decision time\ndistributions which are proved for sequential probability ratio tests. These\nrelations follow from the martingale property of probability ratios and hold\nunder fairly general conditions. We illustrate these tests with numerical\nexperiments and discuss potential applications.","primary_category":"cs","categories":["cs.IT","cond-mat.stat-mech","cs.NE","math.IT","physics.bio-ph"],"authors":["D\u00f6rpinghaus Meik","Neri Izaak","Rold\u00e1n \u00c9dgar","Meyr Heinrich","J\u00fclicher Frank"],"created":"2018-01-04","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01579","title":"Hygienic Source-Code Generation Using Functors","abstract":"Existing source-code-generating tools such as Lex and Yacc suffer from\npractical inconveniences because they use disembodied code to implement\nactions. To prevent this problem, such tools could generate closed functors\nthat are then instantiated by the programmer with appropriate action code. This\nresults in all code being type checked in its appropriate context, and it\nassists the type checker in localizing errors correctly. We have implemented a\nlexer generator and parser generator based on this technique for Standard ML,\nOCaml, and Haskell.","primary_category":"cs","categories":["cs.PL"],"authors":["Crary Karl"],"created":"2018-01-04","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01586","title":"A practical tutorial on autoencoders for nonlinear feature fusion:\n  Taxonomy, models, software and guidelines","abstract":"Many of the existing machine learning algorithms, both supervised and\nunsupervised, depend on the quality of the input characteristics to generate a\ngood model. The amount of these variables is also important, since performance\ntends to decline as the input dimensionality increases, hence the interest in\nusing feature fusion techniques, able to produce feature sets that are more\ncompact and higher level. A plethora of procedures to fuse original variables\nfor producing new ones has been developed in the past decades. The most basic\nones use linear combinations of the original variables, such as PCA (Principal\nComponent Analysis) and LDA (Linear Discriminant Analysis), while others find\nmanifold embeddings of lower dimensionality based on non-linear combinations,\nsuch as Isomap or LLE (Linear Locally Embedding) techniques.\n  More recently, autoencoders (AEs) have emerged as an alternative to manifold\nlearning for conducting nonlinear feature fusion. Dozens of AE models have been\nproposed lately, each with its own specific traits. Although many of them can\nbe used to generate reduced feature sets through the fusion of the original\nones, there also AEs designed with other applications in mind.\n  The goal of this paper is to provide the reader with a broad view of what an\nAE is, how they are used for feature fusion, a taxonomy gathering a broad range\nof models, and how they relate to other classical techniques. In addition, a\nset of didactic guidelines on how to choose the proper AE for a given task is\nsupplied, together with a discussion of the software tools available. Finally,\ntwo case studies illustrate the usage of AEs with datasets of handwritten\ndigits and breast cancer.","primary_category":"cs","categories":["cs.LG","cs.NE"],"authors":["Charte David","Charte Francisco","Garc\u00eda Salvador","del Jesus Mar\u00eda J.","Herrera Francisco"],"created":"2018-01-04","updated":" ","doi":"10.1016\/j.inffus.2017.12.007"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01589","title":"Neural Style Transfer for Audio Spectograms","abstract":"There has been fascinating work on creating artistic transformations of\nimages by Gatys. This was revolutionary in how we can in some sense alter the\n'style' of an image while generally preserving its 'content'. In our work, we\npresent a method for creating new sounds using a similar approach, treating it\nas a style-transfer problem, starting from a random-noise input signal and\niteratively using back-propagation to optimize the sound to conform to\nfilter-outputs from a pre-trained neural architecture of interest.\n  For demonstration, we investigate two different tasks, resulting in bandwidth\nexpansion\/compression, and timbral transfer from singing voice to musical\ninstruments. A feature of our method is that a single architecture can generate\nthese different audio-style-transfer types using the same set of parameters\nwhich otherwise require different complex hand-tuned diverse signal processing\npipelines.","primary_category":"cs","categories":["cs.SD","cs.MM","eess.AS"],"authors":["Verma Prateek","Smith Julius O."],"created":"2018-01-04","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01596","title":"Combination of Hyperband and Bayesian Optimization for Hyperparameter\n  Optimization in Deep Learning","abstract":"Deep learning has achieved impressive results on many problems. However, it\nrequires high degree of expertise or a lot of experience to tune well the\nhyperparameters, and such manual tuning process is likely to be biased.\nMoreover, it is not practical to try out as many different hyperparameter\nconfigurations in deep learning as in other machine learning scenarios, because\nevaluating each single hyperparameter configuration in deep learning would mean\ntraining a deep neural network, which usually takes quite long time. Hyperband\nalgorithm achieves state-of-the-art performance on various hyperparameter\noptimization problems in the field of deep learning. However, Hyperband\nalgorithm does not utilize history information of previous explored\nhyperparameter configurations, thus the solution found is suboptimal. We\npropose to combine Hyperband algorithm with Bayesian optimization (which does\nnot ignore history when sampling next trial configuration). Experimental\nresults show that our combination approach is superior to other hyperparameter\noptimization approaches including Hyperband algorithm.","primary_category":"cs","categories":["cs.CV","cs.AI","cs.LG"],"authors":["Wang Jiazhuo","Xu Jason","Wang Xuejun"],"created":"2018-01-04","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01604","title":"Intelligence Graph","abstract":"In fact, there exist three genres of intelligence architectures: logics (e.g.\n\\textit{Random Forest, A$^*$ Searching}), neurons (e.g. \\textit{CNN, LSTM}) and\nprobabilities (e.g. \\textit{Naive Bayes, HMM}), all of which are incompatible\nto each other. However, to construct powerful intelligence systems with various\nmethods, we propose the intelligence graph (short as \\textbf{\\textit{iGraph}}),\nwhich is composed by both of neural and probabilistic graph, under the\nframework of forward-backward propagation. By the paradigm of iGraph, we design\na recommendation model with semantic principle. First, the probabilistic\ndistributions of categories are generated from the embedding representations of\nusers\/items, in the manner of neurons. Second, the probabilistic graph infers\nthe distributions of features, in the manner of probabilities. Last, for the\nrecommendation diversity, we perform an expectation computation then conduct a\nlogic judgment, in the manner of logics. Experimentally, we beat the\nstate-of-the-art baselines and verify our conclusions.","primary_category":"cs","categories":["cs.AI"],"authors":["Xiao Han"],"created":"2018-01-04","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01609","title":"Learning $3$D-FilterMap for Deep Convolutional Neural Networks","abstract":"We present a novel and compact architecture for deep Convolutional Neural\nNetworks (CNNs) in this paper, termed $3$D-FilterMap Convolutional Neural\nNetworks ($3$D-FM-CNNs). The convolution layer of $3$D-FM-CNN learns a compact\nrepresentation of the filters, named $3$D-FilterMap, instead of a set of\nindependent filters in the conventional convolution layer. The filters are\nextracted from the $3$D-FilterMap as overlapping $3$D submatrics with weight\nsharing among nearby filters, and these filters are convolved with the input to\ngenerate the output of the convolution layer for $3$D-FM-CNN. Due to the weight\nsharing scheme, the parameter size of the $3$D-FilterMap is much smaller than\nthat of the filters to be learned in the conventional convolution layer when\n$3$D-FilterMap generates the same number of filters. Our work is fundamentally\ndifferent from the network compression literature that reduces the size of a\nlearned large network in the sense that a small network is directly learned\nfrom scratch. Experimental results demonstrate that $3$D-FM-CNN enjoys a small\nparameter space by learning compact $3$D-FilterMaps, while achieving\nperformance compared to that of the baseline CNNs which learn the same number\nof filters as that generated by the corresponding $3$D-FilterMap.","primary_category":"cs","categories":["cs.LG"],"authors":["Yang Yingzhen","Yang Jianchao","Xu Ning","Han Wei"],"created":"2018-01-04","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01612","title":"Secrecy by Witness-Functions under Equational Theories","abstract":"In this paper, we use the witness-functions to analyze cryptographic\nprotocols for secrecy under nonempty equational theories. The witness-functions\nare safe metrics used to compute security. An analysis with a witness-function\nconsists in making sure that the security of every atomic message does not\ndecrease during its lifecycle in the protocol. The analysis gets more difficult\nunder nonempty equational theories. Indeed, the intruder can take advantage of\nthe algebraic properties of the cryptographic primitives to derive secrets.\nThese properties arise from the use of mathematical functions, such as\nmultiplication, addition, exclusive-or or modular exponentiation in the\ncryptosystems and the protocols. Here, we show how to use the witness-functions\nunder nonempty equational theories and we run an analysis on the\nNeedham-Schroeder-Lowe protocol under the cipher homomorphism. This analysis\nreveals that although this protocol is proved secure under the perfect\nencryption assumption, its security collapses under the homomorphic primitives.\nWe show how the witness-functions help to illustrate an attack scenario on it\nand we propose an amended version to fix it.","primary_category":"cs","categories":["cs.CR"],"authors":["Fattahi Jaouhar","Mejri Mohamed"],"created":"2018-01-04","updated":" ","doi":"10.1109\/ECAI.2015.7301205"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01613","title":"High Throughput Low Delay Wireless Multicast via Multi-Channel Moving\n  Window Codes","abstract":"A fundamental challenge in wireless multicast has been how to simultaneously\nachieve high-throughput and low-delay for reliably serving a large number of\nusers. In this paper, we show how to harness substantial throughput and delay\ngains by exploiting multi-channel resources. We develop a new scheme called\nMulti-Channel Moving Window Codes (MC-MWC) for multi-channel multi-session\nwireless multicast. The salient features of MC-MWC are three-fold. (i) High\nthroughput: we show that MC-MWC achieves order-optimal throughput in the\nmany-user many-channel asymptotic regime. Moreover, the number of channels\nrequired by a conventional channel-allocation based scheme is shown to be\ndoubly-exponentially larger than that required by MC-MWC. (ii) Low delay: using\nlarge deviations theory, we show that the delay of MC-MWC decreases linearly\nwith the number of channels, while the delay reduction of conventional schemes\nis no more than a finite constant. (iii) Low feedback overhead: the feedback\noverhead of MC-MWC is a constant that is independent of both the number of\nreceivers in each session and the number of sessions in the network. Finally,\nour trace-driven simulation and numerical results validate the analytical\nresults and show that the implementation complexity of MC-MWC is low.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Wu Fei","Sun Yin","Chen Lu","Xu Jackie","Srinivasan Kannan","Shroff Ness B."],"created":"2018-01-04","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01615","title":"Total Capture: A 3D Deformation Model for Tracking Faces, Hands, and\n  Bodies","abstract":"We present a unified deformation model for the markerless capture of multiple\nscales of human movement, including facial expressions, body motion, and hand\ngestures. An initial model is generated by locally stitching together models of\nthe individual parts of the human body, which we refer to as the \"Frankenstein\"\nmodel. This model enables the full expression of part movements, including face\nand hands by a single seamless model. Using a large-scale capture of people\nwearing everyday clothes, we optimize the Frankenstein model to create \"Adam\".\nAdam is a calibrated model that shares the same skeleton hierarchy as the\ninitial model but can express hair and clothing geometry, making it directly\nusable for fitting people as they normally appear in everyday life. Finally, we\ndemonstrate the use of these models for total motion tracking, simultaneously\ncapturing the large-scale body movements and the subtle face and hand motion of\na social group of people.","primary_category":"cs","categories":["cs.CV"],"authors":["Joo Hanbyul","Simon Tomas","Sheikh Yaser"],"created":"2018-01-04","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01620","title":"Dynamic Island Model based on Spectral Clustering in Genetic Algorithm","abstract":"How to maintain relative high diversity is important to avoid premature\nconvergence in population-based optimization methods. Island model is widely\nconsidered as a major approach to achieve this because of its flexibility and\nhigh efficiency. The model maintains a group of sub-populations on different\nislands and allows sub-populations to interact with each other via predefined\nmigration policies. However, current island model has some drawbacks. One is\nthat after a certain number of generations, different islands may retain quite\nsimilar, converged sub-populations thereby losing diversity and decreasing\nefficiency. Another drawback is that determining the number of islands to\nmaintain is also very challenging. Meanwhile initializing many sub-populations\nincreases the randomness of island model. To address these issues, we proposed\na dynamic island model~(DIM-SP) which can force each island to maintain\ndifferent sub-populations, control the number of islands dynamically and starts\nwith one sub-population. The proposed island model outperforms the other three\nstate-of-the-art island models in three baseline optimization problems\nincluding job shop scheduler problem, travelling salesmen problem and quadratic\nmultiple knapsack problem.","primary_category":"cs","categories":["cs.NE"],"authors":["Meng Qinxue","Wu Jia","Ellisy John","Kennedy Paul J."],"created":"2018-01-04","updated":" ","doi":"10.1109\/IJCNN.2017.7966059"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01625","title":"Optimal Pilot Symbols Ratio in terms of Spectrum and Energy Efficiency\n  in Uplink CoMP Networks","abstract":"In wireless networks, Spectrum Efficiency (SE) and Energy Efficiency (EE) can\nbe affected by the channel estimation that needs to be well designed in\npractice. In this paper, considering channel estimation error and non-ideal\nbackhaul links, we optimize the pilot symbols ratio in terms of SE and EE in\nuplink Coordinated Multi-point (CoMP) networks. Modeling the channel estimation\nerror, we formulate the SE and EE maximization problems by analyzing the system\ncapacity with imperfect channel estimation. The maximal system capacity in SE\noptimization and the minimal transmit power in EE optimization, which both have\nthe closed-form expressions, are derived by some reasonable approximations to\nreduce the complexity of solving complicated equations. Simulations are carried\nout to validate the superiority of our scheme, verify the accuracy of our\napproximation, and show the effect of pilot symbols ratio.","primary_category":"cs","categories":["cs.IT","eess.SP","math.IT"],"authors":["Zhang Yuhao","Cui Qimei","Wang Ning"],"created":"2018-01-04","updated":" ","doi":"10.1109\/VTCSpring.2017.8108353"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01627","title":"Deep learning for word-level handwritten Indic script identification","abstract":"We propose a novel method that uses convolutional neural networks (CNNs) for\nfeature extraction. Not just limited to conventional spatial domain\nrepresentation, we use multilevel 2D discrete Haar wavelet transform, where\nimage representations are scaled to a variety of different sizes. These are\nthen used to train different CNNs to select features. To be precise, we use 10\ndifferent CNNs that select a set of 10240 features, i.e. 1024\/CNN. With this,\n11 different handwritten scripts are identified, where 1K words per script are\nused. In our test, we have achieved the maximum script identification rate of\n94.73% using multi-layer perceptron (MLP). Our results outperform the\nstate-of-the-art techniques.","primary_category":"cs","categories":["cs.CV"],"authors":["Ukil Soumya","Ghosh Swarnendu","Obaidullah Sk Md","Santosh K. C.","Roy Kaushik","Das Nibaran"],"created":"2018-01-04","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01630","title":"Secure Sensor Design Against Undetected Infiltration: Minimum\n  Impact-Minimum Damage","abstract":"We propose a new defense mechanism against undetected infiltration into\ncontrollers in cyber-physical systems. To this end, we cautiously design the\noutputs of the sensors that monitor the state of the system. Different from the\ndefense mechanisms that seek to detect infiltration, the proposed approach\nseeks to minimize the damage of possible attacks before they have been\ndetected. Controller of a cyber-physical system could have been infiltrated\ninto by an undetected attacker at any time of the operation. Disregarding such\na possibility and disclosing system's state without caution benefits the\nattacker in his\/her malicious objective. Therefore, secure sensor design can\nimprove the security of cyber-physical systems further when incorporated along\nwith other defense mechanisms. We, specifically, consider a controlled\nGauss-Markov process, where the controller could have been infiltrated into at\nany time within the system's operation. In the sense of game-theoretic\nhierarchical equilibrium, we provide a semi-definite programming based\nalgorithm to compute the optimal linear secure sensor outputs and analyze the\nperformance for various scenarios numerically.","primary_category":"cs","categories":["cs.SY"],"authors":["Sayin Muhammed O.","Ba\u015far Tamer"],"created":"2018-01-05","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01633","title":"Understanding Android Obfuscation Techniques: A Large-Scale\n  Investigation in the Wild","abstract":"In this paper, we seek to better understand Android obfuscation and depict a\nholistic view of the usage of obfuscation through a large-scale investigation\nin the wild. In particular, we focus on four popular obfuscation approaches:\nidentifier renaming, string encryption, Java reflection, and packing. To obtain\nthe meaningful statistical results, we designed efficient and lightweight\ndetection models for each obfuscation technique and applied them to our massive\nAPK datasets (collected from Google Play, multiple third-party markets, and\nmalware databases). We have learned several interesting facts from the result.\nFor example, malware authors use string encryption more frequently, and more\napps on third-party markets than Google Play are packed. We are also interested\nin the explanation of each finding. Therefore we carry out in-depth code\nanalysis on some Android apps after sampling. We believe our study will help\ndevelopers select the most suitable obfuscation approach, and in the meantime\nhelp researchers improve code analysis systems in the right direction.","primary_category":"cs","categories":["cs.CR"],"authors":["Dong Shuaike","Li Menghao","Diao Wenrui","Liu Xiangyu","Liu Jian","Li Zhou","Xu Fenghao","Chen Kai","Wang Xiaofeng","Zhang Kehuan"],"created":"2018-01-05","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01648","title":"Energy-Efficient User Access Control and Resource Allocation in HCNs\n  with Non-Ideal Circuitry","abstract":"In this paper, we study the energy-efficient user access control (UAC) based\non resource allocation (RA) in heterogeneous cellular networks (HCNs) with the\nrequired downlink data rate under non-ideal power amplifiers (PAs) and circuit\npower. It is proved that the energy consumption minimization is achieved when\nthe typical user accesses only one base station (BS), while the other BSs\nremain in idle mode on the transmission resource allocated to this user. For\nthis purpose, we reformulate the original non-convex optimization problem into\na series of convex optimization problems where, in each case, the transmit\npower and duration of the accessed BS are determined. Then, the BS with the\nminimal energy consumption is selected for transmission. Considering the\napproximate situation, it is showed that the optimal transmit duration of the\naccessed BS can be estimated in closed form. The benefits of our proposed UAC\nand RA schemes are validated using numerical simulations, which also\ncharacterize the effect that non-ideal PAs have on the total energy consumption\nof different transmission schemes.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Zhang Yuhao","Cui Qimei","Wang Ning"],"created":"2018-01-05","updated":" ","doi":"10.1109\/WCSP.2017.8171187"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01652","title":"Energy Efficiency Maximization for CoMP Joint Transmission with\n  Non-Ideal Power Amplifiers","abstract":"Coordinated multipoint (CoMP) joint transmission (JT) can save a great deal\nof energy especially for cell-edge users due to strengthened received signal,\nbut at the cost of deploying and coordinating cooperative nodes, which degrades\nenergy efficiency (EE), particularly when considerable amount of energy is\nconsumed by nonideal hardware circuit. In this paper, we study energyefficient\ncooperation establishment, including cooperative nodes selection (CNS) and\npower allocation, to satisfy a required data rate in coherent JT-CoMP networks\nwith non-ideal power amplifiers (PAs) and circuit power. The selection priority\nlemma is proved first, and then the formulated discrete combinatorial EE\noptimization is resolved by proposing node selection criterion and deriving\nclosedform expressions of optimal transmission power. Therefore, an efficient\nalgorithm is provided and its superiority is validated by Monte Carlo\nsimulations, which also show the effects of non-ideal PA and the data rate\ndemand on EE and optimal number of active nodes.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Zhang Yuhao","Cui Qimei","Wang Ning"],"created":"2018-01-05","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01663","title":"Energy Efficiency Analysis of Heterogeneous Cellular Networks With Extra\n  Cell Range Expansion","abstract":"The split control and user plane is key to the future heterogeneous cellular\nnetwork (HCN), where the small cells are dedicated for the most data\ntransmission while the macrocells are mainly responsible for the control\nsignaling. Adapting to this technology, we propose a general and tractable\nframework of extra cell range expansion (CRE) by introducing an additional bias\nfactor to enlarge the range of small cells flexibly for the extra offloaded\nmacrousers in a two-tier HCN, where the macrocell and small cell users have\ndifferent required data rates. Using stochastic geometry, we analyze the energy\nefficiency (EE) of the extra CRE with joint low power transmission and resource\npartitioning, where the coverages of EE and data rate are formulated\ntheoretically. Numerical simulations verify that the proposed extra CRE can\nimprove the EE performance of HCN, and also show that deploying more small\ncells can provide benefits for EE coverage, but the EE improvement becomes\nsaturated if the small cell density exceeds a threshold. Instead of\nestablishing the detail configuration, this paper can provide some valuable\ninsights and guidelines to the practical design of future networks, especially\nfor the traffic offloading in HCN.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Zhang Yuhao","Cui Zhiyan","Cui Qimei","Yu Xinlei","Liu Yinjun","Xie Weiliang","Zhao Yong"],"created":"2018-01-05","updated":" ","doi":"10.1109\/ACCESS.2017.2713814"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01681","title":"VulDeePecker: A Deep Learning-Based System for Vulnerability Detection","abstract":"The automatic detection of software vulnerabilities is an important research\nproblem. However, existing solutions to this problem rely on human experts to\ndefine features and often miss many vulnerabilities (i.e., incurring high false\nnegative rate). In this paper, we initiate the study of using deep\nlearning-based vulnerability detection to relieve human experts from the\ntedious and subjective task of manually defining features. Since deep learning\nis motivated to deal with problems that are very different from the problem of\nvulnerability detection, we need some guiding principles for applying deep\nlearning to vulnerability detection. In particular, we need to find\nrepresentations of software programs that are suitable for deep learning. For\nthis purpose, we propose using code gadgets to represent programs and then\ntransform them into vectors, where a code gadget is a number of (not\nnecessarily consecutive) lines of code that are semantically related to each\nother. This leads to the design and implementation of a deep learning-based\nvulnerability detection system, called Vulnerability Deep Pecker\n(VulDeePecker). In order to evaluate VulDeePecker, we present the first\nvulnerability dataset for deep learning approaches. Experimental results show\nthat VulDeePecker can achieve much fewer false negatives (with reasonable false\npositives) than other approaches. We further apply VulDeePecker to 3 software\nproducts (namely Xen, Seamonkey, and Libav) and detect 4 vulnerabilities, which\nare not reported in the National Vulnerability Database but were \"silently\"\npatched by the vendors when releasing later versions of these products; in\ncontrast, these vulnerabilities are almost entirely missed by the other\nvulnerability detection systems we experimented with.","primary_category":"cs","categories":["cs.CR","cs.AI","cs.LG"],"authors":["Li Zhen","Zou Deqing","Xu Shouhuai","Ou Xinyu","Jin Hai","Wang Sujuan","Deng Zhijun","Zhong Yuyi"],"created":"2018-01-05","updated":" ","doi":"10.14722\/ndss.2018.23158"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01687","title":"Accelerated Training for Massive Classification via Dynamic Class\n  Selection","abstract":"Massive classification, a classification task defined over a vast number of\nclasses (hundreds of thousands or even millions), has become an essential part\nof many real-world systems, such as face recognition. Existing methods,\nincluding the deep networks that achieved remarkable success in recent years,\nwere mostly devised for problems with a moderate number of classes. They would\nmeet with substantial difficulties, e.g. excessive memory demand and\ncomputational cost, when applied to massive problems. We present a new method\nto tackle this problem. This method can efficiently and accurately identify a\nsmall number of \"active classes\" for each mini-batch, based on a set of dynamic\nclass hierarchies constructed on the fly. We also develop an adaptive\nallocation scheme thereon, which leads to a better tradeoff between performance\nand cost. On several large-scale benchmarks, our method significantly reduces\nthe training cost and memory demand, while maintaining competitive performance.","primary_category":"cs","categories":["cs.CV"],"authors":["Zhang Xingcheng","Yang Lei","Yan Junjie","Lin Dahua"],"created":"2018-01-05","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01689","title":"Coordinated Motion Planning: Reconfiguring a Swarm of Labeled Robots\n  with Bounded Stretch","abstract":"We present a number of breakthroughs for coordinated motion planning, in\nwhich the objective is to reconfigure a swarm of labeled convex objects by a\ncombination of parallel, continuous, collision-free translations into a given\ntarget arrangement. Problems of this type can be traced back to the classic\nwork of Schwartz and Sharir (1983), who gave a method for deciding the\nexistence of a coordinated motion for a set of disks between obstacles; their\napproach is polynomial in the complexity of the obstacles, but exponential in\nthe number of disks. Other previous work has largely focused on {\\em\nsequential} schedules, in which one robot moves at a time.\n  We provide constant-factor approximation algorithms for minimizing the\nexecution time of a coordinated, {\\em parallel} motion plan for a swarm of\nrobots in the absence of obstacles, provided some amount of separability.\n  Our algorithm achieves {\\em constant stretch factor}: If all robots are at\nmost $d$ units from their respective starting positions, the total duration of\nthe overall schedule is $O(d)$. Extensions include unlabeled robots and\ndifferent classes of robots. We also prove that finding a plan with minimal\nexecution time is NP-hard, even for a grid arrangement without any stationary\nobstacles. On the other hand, we show that for densely packed disks that cannot\nbe well separated, a stretch factor $\\Omega(N^{1\/4})$ may be required. On the\npositive side, we establish a stretch factor of $O(N^{1\/2})$ even in this case.","primary_category":"cs","categories":["cs.CG","cs.DS","cs.RO"],"authors":["Demaine Erik D.","Fekete S\u00e1ndor P.","Keldenich Phillip","Meijer Henk","Scheffer Christian"],"created":"2018-01-05","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01693","title":"Efficient Image Evidence Analysis of CNN Classification Results","abstract":"Convolutional neural networks (CNNs) define the current state-of-the-art for\nimage recognition. With their emerging popularity, especially for critical\napplications like medical image analysis or self-driving cars, confirmability\nis becoming an issue. The black-box nature of trained predictors make it\ndifficult to trace failure cases or to understand the internal reasoning\nprocesses leading to results. In this paper we introduce a novel efficient\nmethod to visualise evidence that lead to decisions in CNNs. In contrast to\nnetwork fixation or saliency map methods, our method is able to illustrate the\nevidence for or against a classifier's decision in input pixel space\napproximately 10 times faster than previous methods. We also show that our\napproach is less prone to noise and can focus on the most relevant input\nregions, thus making it more accurate and interpretable. Moreover, by making\nsimplifications we link our method with other visualisation methods, providing\na general explanation for gradient-based visualisation techniques. We believe\nthat our work makes network introspection more feasible for debugging and\nunderstanding deep convolutional networks. This will increase trust between\nhumans and deep learning models.","primary_category":"cs","categories":["cs.CV"],"authors":["Zhou Keyang","Kainz Bernhard"],"created":"2018-01-05","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01695","title":"Cross-Sensor Iris Recognition: LG4000-to-LG2200 Comparison","abstract":"Cross-sensor comparison experimental results reported here show that the\nprocedure defined and simulated during the Cross-Sensor Comparison Competition\n2013 by our team for migrating \/ upgrading LG2200 based to LG4000 based\nbiometric systems leads to better LG4000-to-LG2200 cross-sensor iris\nrecognition results than previously reported, both in terms of user comfort and\nin terms of system safety. On the other hand, LG2200-to-LG400 migration\/upgrade\nprocedure defined and implemented by us is applicable to solve interoperability\nissues between LG2200 based and LG4000 based systems, but also to other pairs\nof systems having the same shift in the quality of acquired images.","primary_category":"cs","categories":["eess.IV","cs.CV"],"authors":["Popescu-Bodorin Nicolaie","Grigore Lucian Stefanita","Balas Valentina Emilia","Noaica Cristina Madalina","Axenie Ionut","Popa Justinian","Munteanu Cristian","Stroescu Victor","Manu Ionut","Herea Alexandru","Horasanli Kartal","Motoc Iulia Maria"],"created":"2018-01-05","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01698","title":"Moving Vehicle Detection Using AdaBoost and Haar-Like Feature in\n  Surveillance Videos","abstract":"Vehicle detection is a technology which its aim is to locate and show the\nvehicle size in digital images. In this technology, vehicles are detected in\npresence of other things like trees and buildings. It has an important role in\nmany computer vision applications such as vehicle tracking, analyzing the\ntraffic scene and efficient traffic management. In this paper, vehicles\ndetected based on the boosting technique by Viola Jones. Our proposed system is\ntested in some real scenes of surveillance videos with different light\nconditions. The experimental results show that the accuracy,completeness, and\nquality of the proposed vehicle detection method are better than the previous\ntechniques (about 94%, 92%, and 87%, respectively). Thus, our proposed approach\nis robust and efficient to detect vehicles in surveillance videos and their\napplications.","primary_category":"cs","categories":["cs.CV"],"authors":["Moghimi Mohammad Mahdi","Nayeri Maryam","Pourahmadi Majid","Moghimi Mohammad Kazem"],"created":"2018-01-05","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01705","title":"Gatekeeping Algorithms with Human Ethical Bias: The ethics of algorithms\n  in archives, libraries and society","abstract":"In the age of algorithms, I focus on the question of how to ensure algorithms\nthat will take over many of our familiar archival and library tasks, will\nbehave according to human ethical norms that have evolved over many years. I\nstart by characterizing physical archives in the context of related\ninstitutions such as libraries and museums. In this setting I analyze how\nethical principles, in particular about access to information, have been\nformalized and communicated in the form of ethical codes, or: codes of\nconducts. After that I describe two main developments: digitalization, in which\nphysical aspects of the world are turned into digital data, and\nalgorithmization, in which intelligent computer programs turn this data into\npredictions and decisions. Both affect interactions that were once physical but\nnow digital. In this new setting I survey and analyze the ethical aspects of\nalgorithms and how they shape a vision on the future of archivists and\nlibrarians, in the form of algorithmic documentalists, or: codementalists.\nFinally I outline a general research strategy, called IntERMEeDIUM, to obtain\nalgorithms that obey are human ethical values encoded in code of ethics.","primary_category":"cs","categories":["cs.AI"],"authors":["van Otterlo Martijn"],"created":"2018-01-05","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01708","title":"Negative Binomial Matrix Factorization for Recommender Systems","abstract":"We introduce negative binomial matrix factorization (NBMF), a matrix\nfactorization technique specially designed for analyzing over-dispersed count\ndata. It can be viewed as an extension of Poisson matrix factorization (PF)\nperturbed by a multiplicative term which models exposure. This term brings a\ndegree of freedom for controlling the dispersion, making NBMF more robust to\noutliers. We show that NBMF allows to skip traditional pre-processing stages,\nsuch as binarization, which lead to loss of information. Two estimation\napproaches are presented: maximum likelihood and variational Bayes inference.\nWe test our model with a recommendation task and show its ability to predict\nuser tastes with better precision than PF.","primary_category":"cs","categories":["cs.LG","cs.IR","stat.ML"],"authors":["Gouvert Olivier","Oberlin Thomas","F\u00e9votte C\u00e9dric"],"created":"2018-01-05","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01709","title":"Energy Efficiency Maximization of Full-Duplex Two-Way Relay With\n  Non-Ideal Power Amplifiers and Non-Negligible Circuit Power","abstract":"In this paper, we maximize the energy efficiency (EE) of full-duplex (FD)\ntwo-way relay (TWR) systems under non-ideal power amplifiers (PAs) and\nnon-negligible transmission-dependent circuit power. We start with the case\nwhere only the relay operates full duplex and two timeslots are required for\nTWR. Then, we extend to the advanced case, where the relay and the two nodes\nall operate full duplex, and accomplish TWR in a single timeslot. In both\ncases, we establish the intrinsic connections between the optimal transmit\npowers and durations, based on which the original non-convex EE maximization\ncan be convexified and optimally solved. Simulations show the superiority of\nFD-TWR in terms of EE, especially when traffic demand is high. The simulations\nalso reveal that the maximum EE of FD-TWR is more sensitive to the PA\nefficiency, than it is to self-cancellation. The full FD design of FD-TWR is\nsusceptible to traffic imbalance, while the design with only the relay\noperating in the FD mode exhibits strong tolerance.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Cui Qimei","Zhang Yuhao","Ni Wei","Valkama Mikko","Jantti Riku"],"created":"2018-01-05","updated":" ","doi":"10.1109\/TWC.2017.2721372"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01710","title":"On the Resilience of a QKD Key Synchronization Protocol for IPsec","abstract":"This paper presents a practical solution to the problem of limited bandwidth\nin Quantum Key Distribution (QKD)- secured communication through using rapidly\nrekeyed Internet Protocol security (IPsec) links. QKD is a cutting-edge\nsecurity technology that provides mathematically proven security by using\nquantum physical effects and information theoretical axioms to generate a\nguaranteed non-disclosed stream of encryption keys. Although it has been a\nfield of theoretical research for some time, it has only been producing\nmarket-ready solutions for a short period of time. The downside of this\ntechnology is that its key generation rate is only around 52,000 key bits per\nsecond over a distance of 50 km. As this rate limits the data throughput to the\nsame rate, it is substandard for normal modern communications, especially for\nsecurely interconnecting networks. IPsec, on the other hand, is a well-known\nsecurity protocol that uses classical encryption and is capable of exactly\ncreating site-to-site virtual private networks. This paper presents a solution\nthat combines the performance advantages of IPsec with QKD. The combination\nsacrifices only a small portion of QKD security by using the generated keys a\nlimited number of times instead of just once. As a part of this, the solution\nanswers the question of how many data bits per key bit make sensible upper and\nlower boundaries to yield high performance while maintaining high security.\nWhile previous approaches complement the Internet Key Exchange protocol (IKE),\nthis approach simplifies the implementation with a new key synchronization\nconcept, proposing a lightweight protocol that uses relatively few, slim\ncontrol messages and sparse acknowledgement. Furthermore, it provides a\nLinux-based module for the AIT QKD software using the Netlink XFRM Application\nProgrammers Interface to feed the quantum key to the IP***ABSTRACT TRUNCATED TO\n1920 CHARS***","primary_category":"cs","categories":["cs.CR"],"authors":["Marksteiner Stefan","Rainer Benjamin","Maurhart Oliver"],"created":"2018-01-05","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01712","title":"Tree based classification of tabla strokes","abstract":"The paper attempts to validate the effectiveness of tree classifiers to\nclassify tabla strokes especially the ones which are overlapping in nature. It\nuses decision tree, ID3 and random forest as classifiers. A custom made data\nsets of 650 samples of 13 different tabla strokes were used for experimental\npurpose. 31 different features with their mean and variances were extracted for\nclassification. Three data sets consisting of 21361, 18802 and 19543 instances\nrespectively were used for the purpose. Validation has been done using measures\nlike ROC curve and accuracy. The experimental results showed that all the\nclassifiers showing excellent results with random forest outperforming the\nother two. The effectiveness of random forest in classifying strokes which are\noverlapping in nature is done by comparing the known results of that with\nmulti-layer perceptron.","primary_category":"cs","categories":["cs.SD","cs.IR","eess.AS"],"authors":["Deolekar Subodh","Abraham Siby"],"created":"2018-01-05","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01715","title":"Spectral Graph Forge: Graph Generation Targeting Modularity","abstract":"Community structure is an important property that captures inhomogeneities\ncommon in large networks, and modularity is one of the most widely used metrics\nfor such community structure. In this paper, we introduce a principled\nmethodology, the Spectral Graph Forge, for generating random graphs that\npreserves community structure from a real network of interest, in terms of\nmodularity. Our approach leverages the fact that the spectral structure of\nmatrix representations of a graph encodes global information about community\nstructure. The Spectral Graph Forge uses a low-rank approximation of the\nmodularity matrix to generate synthetic graphs that match a target modularity\nwithin user-selectable degree of accuracy, while allowing other aspects of\nstructure to vary. We show that the Spectral Graph Forge outperforms\nstate-of-the-art techniques in terms of accuracy in targeting the modularity\nand randomness of the realizations, while also preserving other local\nstructural properties and node attributes. We discuss extensions of the\nSpectral Graph Forge to target other properties beyond modularity, and its\napplications to anonymization.","primary_category":"cs","categories":["cs.SI","physics.soc-ph"],"authors":["Baldesi Luca","Markopoulou Athina","Butts Carter T."],"created":"2018-01-05","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01725","title":"A Multi-task Learning Approach for Improving Product Title Compression\n  with User Search Log Data","abstract":"It is a challenging and practical research problem to obtain effective\ncompression of lengthy product titles for E-commerce. This is particularly\nimportant as more and more users browse mobile E-commerce apps and more\nmerchants make the original product titles redundant and lengthy for Search\nEngine Optimization. Traditional text summarization approaches often require a\nlarge amount of preprocessing costs and do not capture the important issue of\nconversion rate in E-commerce. This paper proposes a novel multi-task learning\napproach for improving product title compression with user search log data. In\nparticular, a pointer network-based sequence-to-sequence approach is utilized\nfor title compression with an attentive mechanism as an extractive method and\nan attentive encoder-decoder approach is utilized for generating user search\nqueries. The encoding parameters (i.e., semantic embedding of original titles)\nare shared among the two tasks and the attention distributions are jointly\noptimized. An extensive set of experiments with both human annotated data and\nonline deployment demonstrate the advantage of the proposed research for both\ncompression qualities and online business values.","primary_category":"cs","categories":["cs.CL"],"authors":["Wang Jingang","Tian Junfeng","Qiu Long","Li Sheng","Lang Jun","Si Luo","Lan Man"],"created":"2018-01-05","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01738","title":"Energy-efficient resource allocation for hybrid bursty services in\n  multi-relay OFDM networks","abstract":"In this paper, we propose Mapped Two-way Water Filling (MTWF) scheme to\nmaximize Energy Efficiency (EE) for hybrid bursty services with Quality of\nServices (QoS) requirements in Two-Way Multi-Relay (TWMR) OFDM networks. The\nbursty traffic is first analyzed by strictly proved equivalent homogeneous\nPoisson process, based on which the QoS requirements are converted into\nsum-rate constraints. The formulated non-convex EE maximization problem,\nincluding subcarrier assignment, Relay Selection (RS) and rate allocation, is\nNP-hard involving combinatorial optimization. To conduct optimal RS on each\nsubcarrier without priori bursty traffic knowledge, we utilize some approximate\nrelationships under high data rate demands to remove its dependence on two-way\ndata rates, and simplify the whole optimization problem as well. After the\noptimal channel configuration is obtained, which only depends on channel\nconditions, subcarrier assignment is attained through Elitist Selection Genetic\nAlgorithm (ESGA), and rate allocation of each service is fulfilled by deducing\ntwo-way water filling principle. A new equivalent optimization objective\nfunction is proposed next as the simple evaluating index in ESGA to reduce\ncomplexity. Finally, simulations are carried out to verify the superiority and\nconvergence of our scheme, as well as the applicability for different\nscenarios.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Zhang Yuhao","Cui Qimei","Wang Ning","Hou Yanzhao","Xie Weiliang"],"created":"2018-01-05","updated":" ","doi":"10.1007\/s11432-016-9012-7"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01743","title":"A relativistic extension of Hopfield neural networks via the mechanical\n  analogy","abstract":"We propose a modification of the cost function of the Hopfield model whose\nsalient features shine in its Taylor expansion and result in more than pairwise\ninteractions with alternate signs, suggesting a unified framework for handling\nboth with deep learning and network pruning. In our analysis, we heavily rely\non the Hamilton-Jacobi correspondence relating the statistical model with a\nmechanical system. In this picture, our model is nothing but the relativistic\nextension of the original Hopfield model (whose cost function is a quadratic\nform in the Mattis magnetization which mimics the non-relativistic Hamiltonian\nfor a free particle). We focus on the low-storage regime and solve the model\nanalytically by taking advantage of the mechanical analogy, thus obtaining a\ncomplete characterization of the free energy and the associated\nself-consistency equations in the thermodynamic limit. On the numerical side,\nwe test the performances of our proposal with MC simulations, showing that the\nstability of spurious states (limiting the capabilities of the standard Hebbian\nconstruction) is sensibly reduced due to presence of unlearning contributions\nin this extended framework.","primary_category":"cs","categories":["cond-mat.dis-nn","cs.NE","stat.ML"],"authors":["Barra Adriano","Beccaria Matteo","Fachechi Alberto"],"created":"2018-01-05","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01750","title":"Nonparametric Stochastic Contextual Bandits","abstract":"We analyze the $K$-armed bandit problem where the reward for each arm is a\nnoisy realization based on an observed context under mild nonparametric\nassumptions. We attain tight results for top-arm identification and a sublinear\nregret of $\\widetilde{O}\\Big(T^{\\frac{1+D}{2+D}}\\Big)$, where $D$ is the\ncontext dimension, for a modified UCB algorithm that is simple to implement\n($k$NN-UCB). We then give global intrinsic dimension dependent and ambient\ndimension independent regret bounds. We also discuss recovering topological\nstructures within the context space based on expected bandit performance and\nprovide an extension to infinite-armed contextual bandits. Finally, we\nexperimentally show the improvement of our algorithm over existing multi-armed\nbandit approaches for both simulated tasks and MNIST image classification.","primary_category":"cs","categories":["cs.LG","stat.ML"],"authors":["Guan Melody Y.","Jiang Heinrich"],"created":"2018-01-05","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01752","title":"Improving the Secrecy of Distributed Storage Systems using Interference\n  Alignment","abstract":"Regenerating codes based on the approach of interference alignment for\nwireless interference channel achieve the cut-set bound for distributed storage\nsystems. These codes provide data reliability, and perform efficient exact node\nrepair when some node fails. Interference alignment as a concept is especially\nimportant to improve the repair efficiency of a failed node in a minimum\nstorage regenerating (MSR) code. In addition it can improve the stored data\nsecurity in presence of passive intruders. In this paper we construct a new\ncode resilient against a threat model where a passive eavesdropper can access\nthe data stored on a subset of nodes and the downloaded data during the repair\nprocess of a subset of failed nodes. We achieve an optimal secrecy capacity for\nthe new explicit construction of MSR interference alignment code. Hence, we\nshow that the eavesdropper obtains zero information from the original message\nstored across the distributed storage, and that we achieve a perfect secrecy.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Paunkoska Natasa","Marina Ninoslav","Kafedziski Venceslav"],"created":"2018-01-05","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01760","title":"Crossing Generative Adversarial Networks for Cross-View Person\n  Re-identification","abstract":"Person re-identification (\\textit{re-id}) refers to matching pedestrians\nacross disjoint yet non-overlapping camera views. The most effective way to\nmatch these pedestrians undertaking significant visual variations is to seek\nreliably invariant features that can describe the person of interest\nfaithfully. Most of existing methods are presented in a supervised manner to\nproduce discriminative features by relying on labeled paired images in\ncorrespondence. However, annotating pair-wise images is prohibitively expensive\nin labors, and thus not practical in large-scale networked cameras. Moreover,\nseeking comparable representations across camera views demands a flexible model\nto address the complex distributions of images. In this work, we study the\nco-occurrence statistic patterns between pairs of images, and propose to\ncrossing Generative Adversarial Network (Cross-GAN) for learning a joint\ndistribution for cross-image representations in a unsupervised manner. Given a\npair of person images, the proposed model consists of the variational\nauto-encoder to encode the pair into respective latent variables, a proposed\ncross-view alignment to reduce the view disparity, and an adversarial layer to\nseek the joint distribution of latent representations. The learned latent\nrepresentations are well-aligned to reflect the co-occurrence patterns of\npaired images. We empirically evaluate the proposed model against challenging\ndatasets, and our results show the importance of joint invariant features in\nimproving matching rates of person re-id with comparison to semi\/unsupervised\nstate-of-the-arts.","primary_category":"cs","categories":["cs.CV"],"authors":["Zhang Chengyuan","Wu Lin","Wang Yang"],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01763","title":"Optimal Vehicle Dimensioning for Multi-Class Autonomous Electric\n  Mobility On-Demand Systems","abstract":"Autonomous electric mobility on demand (AEMoD) has recently emerged as a\ncyber-physical system aiming to bring automation, electrification, and\non-demand services for the future private transportation market. The expected\nmassive demand for such services and its resulting insufficient charging\ntime\/resources prohibit the use of centralized management and full vehicle\ncharging. A fog-based multi-class solution for these challenges was recently\nsuggested, by enabling per-zone management and partial charging for different\nclasses of AEMoD vehicles. This paper focuses on finding the optimal vehicle\ndimensioning for each zone of these systems in order to guarantee a bounded\nresponse time of its vehicles. Using a queuing model representing the\nmulti-class charging and dispatching processes, we first derive the stability\nconditions and the number of system classes to guarantee the response time\nbound. Decisions on the proportions of each class vehicles to partially\/fully\ncharge, or directly serve customers are then optimized so as to minimize the\nvehicles in-flow to any given zone. Excess waiting times of customers in rare\ncritical events, such as limited charging resources and\/or limited vehicles\navailabilities, are also investigated. Results show the merits of our proposed\nmodel compared to other schemes and in usual and critical scenarios.","primary_category":"cs","categories":["cs.SY","eess.SP"],"authors":["Belakaria Syrine","Ammous Mustafa","Sorour Sameh","Abdel-Rahim Ahmed"],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01767","title":"Subquadratic Encodings for Point Configurations","abstract":"For most algorithms dealing with sets of points in the plane, the only\nrelevant information carried by the input is the combinatorial configuration of\nthe points: the orientation of each triple of points in the set (clockwise,\ncounterclockwise, or collinear). This information is called the order type of\nthe point set. In the dual, realizable order types and abstract order types are\ncombinatorial analogues of line arrangements and pseudoline arrangements. Too\noften in the literature we analyze algorithms in the real-RAM model for\nsimplicity, putting aside the fact that computers as we know them cannot handle\narbitrary real numbers without some sort of encoding. Encoding an order type by\nthe integer coordinates of some realizing point set is known to yield doubly\nexponential coordinates in some cases. Other known encodings can achieve\nquadratic space or fast orientation queries, but not both. In this\ncontribution, we give a compact encoding for abstract order types that allows\nefficient query of the orientation of any triple: the encoding uses O(n^2) bits\nand an orientation query takes O(log n) time in the word-RAM model. This\nencoding is space-optimal for abstract order types. We show how to shorten the\nencoding to O(n^2 (loglog n)^2 \/ log n) bits for realizable order types, giving\nthe first subquadratic encoding for those order types with fast orientation\nqueries. We further refine our encoding to attain O(log n\/loglog n) query time\nwithout blowing up the space requirement. In the realizable case, we show that\nall those encodings can be computed efficiently. Finally, we generalize our\nresults to the encoding of point configurations in higher dimension.","primary_category":"cs","categories":["cs.CG"],"authors":["Cardinal Jean","Chan Timothy M.","Iacono John","Langerman Stefan","Ooms Aur\u00e9lien"],"created":"2018-01-05","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01768","title":"Learning Feature Representations for Keyphrase Extraction","abstract":"In supervised approaches for keyphrase extraction, a candidate phrase is\nencoded with a set of hand-crafted features and machine learning algorithms are\ntrained to discriminate keyphrases from non-keyphrases. Although the\nmanually-designed features have shown to work well in practice, feature\nengineering is a difficult process that requires expert knowledge and normally\ndoes not generalize well. In this paper, we present SurfKE, a feature learning\nframework that exploits the text itself to automatically discover patterns that\nkeyphrases exhibit. Our model represents the document as a graph and\nautomatically learns feature representation of phrases. The proposed model\nobtains remarkable improvements in performance over strong baselines.","primary_category":"cs","categories":["cs.CL","cs.AI"],"authors":["Florescu Corina","Jin Wei"],"created":"2018-01-05","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01793","title":"Selective Fair Scheduling over Fading Channels","abstract":"Imposing fairness in resource allocation incurs a loss of system throughput,\nknown as the Price of Fairness ($PoF$). In wireless scheduling, $PoF$ increases\nwhen serving users with very poor channel quality because the scheduler wastes\nresources trying to be fair. This paper proposes a novel resource allocation\nframework to rigorously address this issue. We introduce selective fairness:\nbeing fair only to selected users, and improving $PoF$ by momentarily blocking\nthe rest. We study the associated admission control problem of finding the user\nselection that minimizes $PoF$ subject to selective fairness, and show that\nthis combinatorial problem can be solved efficiently if the feasibility set\nsatisfies a condition; in our model it suffices that the wireless channels are\nstochastically dominated. Exploiting selective fairness, we design a stochastic\nframework where we minimize $PoF$ subject to an SLA, which ensures that an\nergodic subscriber is served frequently enough. In this context, we propose an\nonline policy that combines the drift-plus-penalty technique with\nGradient-Based Scheduling experts, and we prove it achieves the optimal $PoF$.\nSimulations show that our intelligent blocking outperforms by 40$\\%$ in\nthroughput previous approaches which satisfy the SLA by blocking low-SNR users.","primary_category":"cs","categories":["cs.NI","cs.IT","math.IT"],"authors":["Destounis Apostolos","Paschos Georgios S.","Gesbert David"],"created":"2018-01-05","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01803","title":"Scheduling Policies for Minimizing Age of Information in Broadcast\n  Wireless Networks","abstract":"We consider a wireless broadcast network with a base station sending\ntime-sensitive information to a number of clients through unreliable channels.\nThe Age of Information (AoI), namely the amount of time that elapsed since the\nmost recently delivered packet was generated, captures the freshness of the\ninformation. We formulate a discrete-time decision problem to find a\ntransmission scheduling policy that minimizes the expected weighted sum AoI of\nthe clients in the network.\n  We first show that in symmetric networks a Greedy policy, which transmits the\npacket with highest current age, is optimal. For general networks, we develop\nthree low-complexity scheduling policies: a randomized policy, a Max-Weight\npolicy and a Whittle's Index policy, and derive performance guarantees as a\nfunction of the network configuration. To the best of our knowledge, this is\nthe first work to derive performance guarantees for scheduling policies that\nattempt to minimize AoI in wireless networks with unreliable channels.\nNumerical results show that both Max-Weight and Whittle's Index policies\noutperform the other scheduling policies in every configuration simulated, and\nachieve near optimal performance.","primary_category":"cs","categories":["cs.NI","cs.IT","math.IT"],"authors":["Kadota Igor","Sinha Abhishek","Uysal-Biyikoglu Elif","Singh Rahul","Modiano Eytan"],"created":"2018-01-05","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01814","title":"Automated Conjecturing VII: The Graph Brain Project & Big Mathematics","abstract":"The Graph Brain Project is an experiment in how the use of automated\nmathematical discovery software, databases, large collaboration, and systematic\ninvestigation provide a model for how mathematical research might proceed in\nthe future.\n  Our Project began with the development of a program that can be used to\ngenerate invariant-relation and property-relation conjectures in many areas of\nmathematics. This program can produce conjectures which are not implied by\nexisting (published) theorems. Here we propose a new approach to push forward\nexisting mathematical research goals---using automated mathematical discovery\nsoftware. We suggest how to initiate and harness large-scale collaborative\nmathematics. We envision mathematical research labs similar to what exist in\nother sciences, new avenues for funding, new opportunities for training\nstudents, and a more efficient and effective use of published mathematical\nresearch.\n  And our experiment in graph theory can be imitated in many other areas of\nmathematical research. Big Mathematics is the idea of large, systematic,\ncollaborative research on problems of existing mathematical interest. What is\npossible when we put our skills, tools, and results together systematically?","primary_category":"cs","categories":["cs.AI","math.CO"],"authors":["Bushaw N.","Larson C. E.","Van Cleemput N."],"created":"2017-12-28","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01820","title":"Design and Implementation of a Polar Codes Blind Detection Scheme","abstract":"In blind detection, a set of candidates has to be decoded within a strict\ntime constraint, to identify which transmissions are directed at the user\nequipment. Blind detection is required by the 3GPP LTE\/LTE-Advanced standard,\nand it will be required in the 5th generation wireless communication standard\n(5G) as well. Polar codes have been selected for use in 5G: thus, the issue of\nblind detection of polar codes must be addressed. We propose a polar code blind\ndetection scheme where the user ID is transmitted instead of some of the frozen\nbits. A first, coarse decoding phase helps selecting a subset of candidates\nthat is decoded by a more powerful algorithm: an early stopping criterion is\nalso introduced for the second decoding phase. Simulations results show good\nmissed detection and false alarm rates, along with substantial latency gains\nthanks to early stopping. We then propose an architecture to implement the\ndevised blind detection scheme, based on a tunable decoder that can be used for\nboth phases. The architecture is synthesized and implementation results are\nreported for various system parameters. The reported area occupation and\nlatency, obtained in 65 nm CMOS technology, are able to meet 5G requirements,\nand are guaranteed to meet them with even less resource usage in the latest\ntechnology nodes.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Condo Carlo","Hashemi Seyyed Ali","Ardakani Arash","Ercan Furkan","Gross Warren J."],"created":"2018-01-04","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01825","title":"Towards Understanding and Answering Multi-Sentence Recommendation\n  Questions on Tourism","abstract":"We introduce the first system towards the novel task of answering complex\nmultisentence recommendation questions in the tourism domain. Our solution uses\na pipeline of two modules: question understanding and answering. For question\nunderstanding, we define an SQL-like query language that captures the semantic\nintent of a question; it supports operators like subset, negation, preference\nand similarity, which are often found in recommendation questions. We train and\ncompare traditional CRFs as well as bidirectional LSTM-based models for\nconverting a question to its semantic representation. We extend these models to\na semisupervised setting with partially labeled sequences gathered through\ncrowdsourcing. We find that our best model performs semi-supervised training of\nBiDiLSTM+CRF with hand-designed features and CCM(Chang et al., 2007)\nconstraints. Finally, in an end to end QA system, our answering component\nconverts our question representation into queries fired on underlying knowledge\nsources. Our experiments on two different answer corpora demonstrate that our\nsystem can significantly outperform baselines with up to 20 pt higher accuracy\nand 17 pt higher recall.","primary_category":"cs","categories":["cs.CL"],"authors":["Contractor Danish","Patra Barun","Singla Mausam","Singla Parag"],"created":"2018-01-05","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01828","title":"Shielding Google's language toxicity model against adversarial attacks","abstract":"Lack of moderation in online communities enables participants to incur in\npersonal aggression, harassment or cyberbullying, issues that have been\naccentuated by extremist radicalisation in the contemporary post-truth politics\nscenario. This kind of hostility is usually expressed by means of toxic\nlanguage, profanity or abusive statements. Recently Google has developed a\nmachine-learning-based toxicity model in an attempt to assess the hostility of\na comment; unfortunately, it has been suggested that said model can be deceived\nby adversarial attacks that manipulate the text sequence of the comment. In\nthis paper we firstly characterise such adversarial attacks as using\nobfuscation and polarity transformations. The former deceives by corrupting\ntoxic trigger content with typographic edits, whereas the latter deceives by\ngrammatical negation of the toxic content. Then, we propose a two--stage\napproach to counter--attack these anomalies, bulding upon a recently proposed\ntext deobfuscation method and the toxicity scoring model. Lastly, we conducted\nan experiment with approximately 24000 distorted comments, showing how in this\nway it is feasible to restore toxicity of the adversarial variants, while\nincurring roughly on a twofold increase in processing time. Even though novel\nadversary challenges would keep coming up derived from the versatile nature of\nwritten language, we anticipate that techniques combining machine learning and\ntext pattern recognition methods, each one targeting different layers of\nlinguistic features, would be needed to achieve robust detection of toxic\nlanguage, thus fostering aggression--free digital interaction.","primary_category":"cs","categories":["cs.CL","cs.SI"],"authors":["Rodriguez Nestor","Rojas-Galeano Sergio"],"created":"2018-01-05","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01843","title":"Design and Performance Characterization of RADICAL-Pilot on Titan","abstract":"Many extreme scale scientific applications have workloads comprised of a\nlarge number of individual high-performance tasks. The Pilot abstraction\ndecouples workload specification, resource management, and task execution via\njob placeholders and late-binding. As such, suitable implementations of the\nPilot abstraction can support the collective execution of large number of tasks\non supercomputers. We introduce RADICAL-Pilot (RP) as a portable, modular and\nextensible Python-based Pilot system. We describe RP's design, architecture and\nimplementation. We characterize its performance and show its ability to\nscalably execute workloads comprised of thousands of MPI tasks on Titan--a DOE\nleadership class facility. Specifically, we investigate RP's weak (strong)\nscaling properties up to 131K (65K) cores and 4096 (16384) 32 core tasks.\nRADICAL-Pilot can be used stand-alone, as well as integrated with other tools\nas a runtime system.","primary_category":"cs","categories":["cs.DC"],"authors":["Merzky Andre","Turilli Matteo","Maldonado Manuel","Jha Shantenu"],"created":"2018-01-05","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01866","title":"The Reeb Graph Edit Distance is Universal","abstract":"We consider the setting of Reeb graphs of piecewise linear functions and\nstudy distances between them that are stable, meaning that functions which are\nsimilar in the supremum norm ought to have similar Reeb graphs. We define an\nedit distance for Reeb graphs and prove that it is stable and universal,\nmeaning that it provides an upper bound to any other stable distance. In\ncontrast, via a specific construction, we show that the interleaving distance\nand the functional distortion distance on Reeb graphs are not universal.","primary_category":"cs","categories":["math.AT","cs.CG","math.GT"],"authors":["Bauer Ulrich","Landi Claudia","Memoli Facundo"],"created":"2018-01-05","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01875","title":"Near Optimal Coded Data Shuffling for Distributed Learning","abstract":"Data shuffling between distributed cluster of nodes is one of the critical\nsteps in implementing large-scale learning algorithms. Randomly shuffling the\ndata-set among a cluster of workers allows different nodes to obtain fresh data\nassignments at each learning epoch. This process has been shown to provide\nimprovements in the learning process. However, the statistical benefits of\ndistributed data shuffling come at the cost of extra communication overhead\nfrom the master node to worker nodes, and can act as one of the major\nbottlenecks in the overall time for computation. There has been significant\nrecent interest in devising approaches to minimize this communication overhead.\nOne approach is to provision for extra storage at the computing nodes. The\nother emerging approach is to leverage coded communication to minimize the\noverall communication overhead.\n  The focus of this work is to understand the fundamental trade-off between the\namount of storage and the communication overhead for distributed data\nshuffling. In this work, we first present an information theoretic formulation\nfor the data shuffling problem, accounting for the underlying problem\nparameters (number of workers, $K$, number of data points, $N$, and the\navailable storage, $S$ per node). We then present an information theoretic\nlower bound on the communication overhead for data shuffling as a function of\nthese parameters. We next present a novel coded communication scheme and show\nthat the resulting communication overhead of the proposed scheme is within a\nmultiplicative factor of at most $\\frac{K}{K-1}$ from the information-theoretic\nlower bound. Furthermore, we present the aligned coded shuffling scheme for\nsome storage values, which achieves the optimal storage vs communication\ntrade-off for $K<5$, and further reduces the maximum multiplicative gap down to\n$\\frac{K-\\frac{1}{3}}{K-1}$, for $K\\geq 5$.","primary_category":"cs","categories":["cs.IT","cs.DC","cs.LG","math.IT"],"authors":["Attia Mohamed A.","Tandon Ravi"],"created":"2018-01-05","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01884","title":"Unsupervised Low-Dimensional Vector Representations for Words, Phrases\n  and Text that are Transparent, Scalable, and produce Similarity Metrics that\n  are Complementary to Neural Embeddings","abstract":"Neural embeddings are a popular set of methods for representing words,\nphrases or text as a low dimensional vector (typically 50-500 dimensions).\nHowever, it is difficult to interpret these dimensions in a meaningful manner,\nand creating neural embeddings requires extensive training and tuning of\nmultiple parameters and hyperparameters. We present here a simple unsupervised\nmethod for representing words, phrases or text as a low dimensional vector, in\nwhich the meaning and relative importance of dimensions is transparent to\ninspection. We have created a near-comprehensive vector representation of\nwords, and selected bigrams, trigrams and abbreviations, using the set of\ntitles and abstracts in PubMed as a corpus. This vector is used to create\nseveral novel implicit word-word and text-text similarity metrics. The implicit\nword-word similarity metrics correlate well with human judgement of word pair\nsimilarity and relatedness, and outperform or equal all other reported methods\non a variety of biomedical benchmarks, including several implementations of\nneural embeddings trained on PubMed corpora. Our implicit word-word metrics\ncapture different aspects of word-word relatedness than word2vec-based metrics\nand are only partially correlated (rho = ~0.5-0.8 depending on task and\ncorpus). The vector representations of words, bigrams, trigrams, abbreviations,\nand PubMed title+abstracts are all publicly available from\nhttp:\/\/arrowsmith.psych.uic.edu for release under CC-BY-NC license. Several\npublic web query interfaces are also available at the same site, including one\nwhich allows the user to specify a given word and view its most closely related\nterms according to direct co-occurrence as well as different implicit\nsimilarity metrics.","primary_category":"cs","categories":["cs.CL","cs.IR"],"authors":["Smalheiser Neil R.","Bonifield Gary"],"created":"2018-01-05","updated":"2018-01-09","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01896","title":"Verifying and Synthesizing Constant-Resource Implementations with Types","abstract":"We propose a novel type system for verifying that programs correctly\nimplement constant-resource behavior. Our type system extends recent work on\nautomatic amortized resource analysis (AARA), a set of techniques that\nautomatically derive provable upper bounds on the resource consumption of\nprograms. We devise new techniques that build on the potential method to\nachieve compositionality, precision, and automation.\n  A strict global requirement that a program always maintains constant resource\nusage is too restrictive for most practical applications. It is sufficient to\nrequire that the program's resource behavior remain constant with respect to an\nattacker who is only allowed to observe part of the program's state and\nbehavior. To account for this, our type system incorporates information flow\ntracking into its resource analysis. This allows our system to certify programs\nthat need to violate the constant-time requirement in certain cases, as long as\ndoing so does not leak confidential information to attackers. We formalize this\nguarantee by defining a new notion of resource-aware noninterference, and prove\nthat our system enforces it.\n  Finally, we show how our type inference algorithm can be used to synthesize a\nconstant-time implementation from one that cannot be verified as secure,\neffectively repairing insecure programs automatically. We also show how a\nsecond novel AARA system that computes lower bounds on resource usage can be\nused to derive quantitative bounds on the amount of information that a program\nleaks through its resource use. We implemented each of these systems in\nResource Aware ML, and show that it can be applied to verify constant-time\nbehavior in a number of applications including encryption and decryption\nroutines, database queries, and other resource-aware functionality.","primary_category":"cs","categories":["cs.PL"],"authors":["Ngo Van Chan","Dehesa-Azuara Mario","Fredrikson Matthew","Hoffmann Jan"],"created":"2018-01-05","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01899","title":"Clustering with Outlier Removal","abstract":"Cluster analysis and outlier detection are strongly coupled tasks in data\nmining area. Cluster structure can be easily destroyed by few outliers; on the\ncontrary, the outliers are defined by the concept of cluster, which are\nrecognized as the points belonging to none of the clusters. However, most\nexisting studies handle them separately. In light of this, we consider the\njoint cluster analysis and outlier detection problem, and propose the\nClustering with Outlier Removal (COR) algorithm. Generally speaking, the\noriginal space is transformed into the binary space via generating basic\npartitions in order to define clusters. Then an objective function based\nHoloentropy is designed to enhance the compactness of each cluster with a few\noutliers removed. With further analyses on the objective function, only partial\nof the problem can be handled by K-means optimization. To provide an integrated\nsolution, an auxiliary binary matrix is nontrivally introduced so that COR\ncompletely and efficiently solves the challenging problem via a unified\nK-means- - with theoretical supports. Extensive experimental results on\nnumerous data sets in various domains demonstrate the effectiveness and\nefficiency of COR significantly over the rivals including K-means- - and other\nstate-of-the-art outlier detection methods in terms of cluster validity and\noutlier detection. Some key factors in COR are further analyzed for practical\nuse. Finally, an application on flight trajectory is provided to demonstrate\nthe effectiveness of COR in the real-world scenario.","primary_category":"cs","categories":["cs.LG","stat.ML"],"authors":["Liu Hongfu","Li Jun","Wu Yue","Fu Yun"],"created":"2018-01-05","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01900","title":"Knowledge-based Word Sense Disambiguation using Topic Models","abstract":"Word Sense Disambiguation is an open problem in Natural Language Processing\nwhich is particularly challenging and useful in the unsupervised setting where\nall the words in any given text need to be disambiguated without using any\nlabeled data. Typically WSD systems use the sentence or a small window of words\naround the target word as the context for disambiguation because their\ncomputational complexity scales exponentially with the size of the context. In\nthis paper, we leverage the formalism of topic model to design a WSD system\nthat scales linearly with the number of words in the context. As a result, our\nsystem is able to utilize the whole document as the context for a word to be\ndisambiguated. The proposed method is a variant of Latent Dirichlet Allocation\nin which the topic proportions for a document are replaced by synset\nproportions. We further utilize the information in the WordNet by assigning a\nnon-uniform prior to synset distribution over words and a logistic-normal prior\nfor document distribution over synsets. We evaluate the proposed method on\nSenseval-2, Senseval-3, SemEval-2007, SemEval-2013 and SemEval-2015 English\nAll-Word WSD datasets and show that it outperforms the state-of-the-art\nunsupervised knowledge-based WSD system by a significant margin.","primary_category":"cs","categories":["cs.CL","cs.LG"],"authors":["Chaplot Devendra Singh","Salakhutdinov Ruslan"],"created":"2018-01-05","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01901","title":"On randomized counting versus randomised decision","abstract":"We study the question of which counting problems admit f.p.r.a.s., under a\nstructural complexity perspective. Since problems in #P with NP-complete\ndecision version do not admit f.p.r.a.s. (unless NP = RP), we study subclasses\nof #P, having decision version either in P or in RP. We explore inclusions\nbetween these subclasses and we present all possible worlds with respect to NP\nv.s. RP and RP v.s. P.","primary_category":"cs","categories":["cs.CC"],"authors":["Bakali Eleni"],"created":"2018-01-05","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01903","title":"Local Mixing Time: Distributed Computation and Applications","abstract":"The mixing time of a graph is an important metric, which is not only useful\nin analyzing connectivity and expansion properties of the network, but also\nserves as a key parameter in designing efficient algorithms. We introduce a new\nnotion of mixing of a random walk on a (undirected) graph, called local mixing.\nInformally, the local mixing with respect to a given node $s$, is the mixing of\na random walk probability distribution restricted to a large enough subset of\nnodes --- say, a subset of size at least $n\/\\beta$ for a given parameter\n$\\beta$ --- containing $s$. The time to mix over such a subset by a random walk\nstarting from a source node $s$ is called the local mixing time with respect to\n$s$. The local mixing time captures the local connectivity and expansion\nproperties around a given source node and is a useful parameter that determines\nthe running time of algorithms for partial information spreading, gossip etc.\n  Our first contribution is formally defining the notion of local mixing time\nin an undirected graph. We then present an efficient distributed algorithm\nwhich computes a constant factor approximation to the local mixing time with\nrespect to a source node $s$ in $\\tilde{O}(\\tau_s)$ rounds, where $\\tau_s$ is\nthe local mixing time w.r.t $s$ in an $n$-node regular graph. This bound holds\nwhen $\\tau_s$ is significantly smaller than the conductance of the local mixing\nset (i.e., the set where the walk mixes locally); this is typically the\ninteresting case where the local mixing time is significantly smaller than the\nmixing time (with respect to $s$). We also present a distributed algorithm that\ncomputes the exact local mixing time in $\\tilde{O}(\\tau_s \\mathcal{D})$ rounds,\nwhere $\\mathcal{D} =\\min\\{\\tau_s, D\\}$ and $D$ is the diameter of the graph. We\nfurther show that local mixing time tightly characterizes the complexity of\npartial information spreading.","primary_category":"cs","categories":["cs.DC","cs.DS"],"authors":["Molla Anisur Rahaman","Pandurangan Gopal"],"created":"2018-01-05","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01921","title":"Urban Explorations: Analysis of Public Park Usage using Mobile GPS Data","abstract":"This study analyzes mobile phone data derived from 10 million daily active\nusers across the United States to better understand the spatio-temporal\nactivity patterns of users in Central Park, New York. The aim of this initial\ninvestigation is to create quantifiable measures for understanding public space\nusage in regions of the city that have no natural data source for measuring\nactivity. We analyze the trip behaviors of users across time and different\nregions in the park to find patterns of co-location and shared time and, thus,\npotential social interaction. We find that regions with established amenities\nand points of interest exhibit a higher percentage of shared experiences,\nindicating that institutional amenities act as 'beacons' for users' experiences\nin the park.","primary_category":"cs","categories":["cs.CY"],"authors":["Xu Wenfei"],"created":"2018-01-05","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01928","title":"Tensor Train decomposition on TensorFlow (T3F)","abstract":"Tensor Train decomposition is used across many branches of machine learning,\nbut until now it lacked an implementation with GPU support, batch processing,\nautomatic differentiation, and versatile functionality for Riemannian\noptimization framework, which takes in account the underlying manifold\nstructure in order to construct efficient optimization methods. In this work,\nwe propose a library that aims to fix it and makes machine learning papers that\nrely on Tensor Train decomposition easier to implement. The library includes\n92% test coverage, examples, and API reference documentation.","primary_category":"cs","categories":["cs.MS","cs.NA"],"authors":["Novikov Alexander","Izmailov Pavel","Khrulkov Valentin","Figurnov Michael","Oseledets Ivan"],"created":"2018-01-05","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01933","title":"Improved Style Transfer by Respecting Inter-layer Correlations","abstract":"A popular series of style transfer methods apply a style to a content image\nby controlling mean and covariance of values in early layers of a feature\nstack. This is insufficient for transferring styles that have strong structure\nacross spatial scales like, e.g., textures where dots lie on long curves. This\npaper demonstrates that controlling inter-layer correlations yields visible\nimprovements in style transfer methods. We achieve this control by computing\ncross-layer, rather than within-layer, gram matrices. We find that (a)\ncross-layer gram matrices are sufficient to control within-layer statistics.\nInter-layer correlations improves style transfer and texture synthesis. The\npaper shows numerous examples on \"hard\" real style transfer problems (e.g. long\nscale and hierarchical patterns); (b) a fast approximate style transfer method\ncan control cross-layer gram matrices; (c) we demonstrate that multiplicative,\nrather than additive style and content loss, results in very good style\ntransfer. Multiplicative loss produces a visible emphasis on boundaries, and\nmeans that one hyper-parameter can be eliminated.","primary_category":"cs","categories":["cs.CV"],"authors":["Yeh Mao-Chuang","Tang Shuai"],"created":"2018-01-05","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01937","title":"A Comprehensive Survey of Ontology Summarization: Measures and Methods","abstract":"The Semantic Web is becoming a large scale framework that enables data to be\npublished, shared, and reused in the form of ontologies. The ontology which is\nconsidered as basic building block of semantic web consists of two layers\nincluding data and schema layer. With the current exponential development of\nontologies in both data size and complexity of schemas, ontology understanding\nwhich is playing an important role in different tasks such as ontology\nengineering, ontology learning, etc., is becoming more difficult. Ontology\nsummarization as a way to distill knowledge from an ontology and generate an\nabridge version to facilitate a better understanding is getting more attention\nrecently. There are various approaches available for ontology summarization\nwhich are focusing on different measures in order to produce a proper summary\nfor a given ontology. In this paper, we mainly focus on the common metrics\nwhich are using for ontology summarization and meet the state-of-the-art in\nontology summarization.","primary_category":"cs","categories":["cs.IR","cs.AI"],"authors":["Pouriyeh Seyedamin","Allahyari Mehdi","Kochut Krys","Arabnia Hamid Reza"],"created":"2018-01-05","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01953","title":"Adversarial Perturbation Intensity Achieving Chosen Intra-Technique\n  Transferability Level for Logistic Regression","abstract":"Machine Learning models have been shown to be vulnerable to adversarial\nexamples, ie. the manipulation of data by a attacker to defeat a defender's\nclassifier at test time. We present a novel probabilistic definition of\nadversarial examples in perfect or limited knowledge setting using prior\nprobability distributions on the defender's classifier. Using the asymptotic\nproperties of the logistic regression, we derive a closed-form expression of\nthe intensity of any adversarial perturbation, in order to achieve a given\nexpected misclassification rate. This technique is relevant in a threat model\nof known model specifications and unknown training data. To our knowledge, this\nis the first method that allows an attacker to directly choose the probability\nof attack success. We evaluate our approach on two real-world datasets.","primary_category":"cs","categories":["stat.ML","cs.LG"],"authors":["Gubri Martin"],"created":"2018-01-05","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01970","title":"Using Malware Self-Defence Mechanism to Harden Defence and Remediation\n  Tools","abstract":"Malware are becoming a major problem to every individual and organization in\nthe cyber world. They are advancing in sophistication in many ways. Besides\ntheir advanced abilities to penetrate and stay evasive against detection and\nremediation, they have strong resilience mechanisms that are defying all\nattempts to eradicate them. Malware are also attacking defence of the systems\nand making them defunct. When defences are brought down, the organisation or\nindividual will lose control over the IT assets and defend against the Malware\nperpetuators. In order to gain the capability to defend, it is necessary to\nkeep the defences or remediation tools active and not defunct. Given that\nMalware have proven to be resilient against deployed defences and remediation\ntools, the proposed research advocates to utilize the techniques used by\nMalware to harden the tools in a similar manner. In this paper, it is\ndemonstrated that the proposition of using Malware resilient designs can be\napplied to harden the tools through experiments.","primary_category":"cs","categories":["cs.CR"],"authors":["Pan Jonathan"],"created":"2018-01-06","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01972","title":"Distance formulas capable of unifying Euclidian space and probability\n  space","abstract":"For pattern recognition like image recognition, it has become clear that each\nmachine-learning dictionary data actually became data in probability space\nbelonging to Euclidean space. However, the distances in the Euclidean space and\nthe distances in the probability space are separated and ununified when machine\nlearning is introduced in the pattern recognition. There is still a problem\nthat it is impossible to directly calculate an accurate matching relation\nbetween the sampling data of the read image and the learned dictionary data. In\nthis research, we focused on the reason why the distance is changed and the\nextent of change when passing through the probability space from the original\nEuclidean distance among data belonging to multiple probability spaces\ncontaining Euclidean space. By finding the reason of the cause of the distance\nerror and finding the formula expressing the error quantitatively, a possible\ndistance formula to unify Euclidean space and probability space is found. Based\non the results of this research, the relationship between machine-learning\ndictionary data and sampling data was clearly understood for pattern\nrecognition. As a result, the calculation of collation among data and\nmachine-learning to compete mutually between data are cleared, and complicated\ncalculations became unnecessary. Finally, using actual pattern recognition\ndata, experimental demonstration of a possible distance formula to unify\nEuclidean space and probability space discovered by this research was carried\nout, and the effectiveness of the result was confirmed.","primary_category":"cs","categories":["cs.AI"],"authors":["Gu Zecang","Dong Ling"],"created":"2018-01-06","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01982","title":"Refinements of Levenshtein bounds in $q$-ary Hamming spaces","abstract":"We develop refinements of the Levenshtein bound in $q$-ary Hamming spaces by\ntaking into account the discrete nature of the distances versus the continuous\nbehavior of certain parameters used by Levenshtein. The first relevant cases\nare investigated in detail and new bounds are presented. In particular, we\nderive generalizations and $q$-ary analogs of a MacEliece bound. We provide\nevidence that our approach is as good as the complete linear programming and\ndiscuss how faster are our calculations. Finally, we present a table with\nparameters of codes which, if exist, would attain our bounds.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Boyvalenkov Peter","Danev Danyo","Stoyanova Maya"],"created":"2018-01-06","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01989","title":"The impact of bundling licensed and unlicensed wireless service","abstract":"Unlicensed spectrum has been viewed as a way to increase competition in\nwireless access and promote innovation in new technologies and business models.\nHowever, several recent papers have shown that the openness of such spectrum\ncan also lead to it becoming over congested when used by competing wireless\nservice providers (SPs). This in turn can result in the SPs making no profit\nand may deter them from entering the market. However, this prior work assumes\nthat unlicensed access is a separate service from any service offered using\nlicensed spectrum. Here, we instead consider the more common case were service\nproviders bundle both licensed and unlicensed spectrum as a single service and\noffer this with a single price. We analyze a model for such a market and show\nthat in this case SPs are able to gain higher profit than the case without\nbundling. It is also possible to get higher social welfare with bundling.\nMoreover, we explore the case where SPs are allowed to manage the customers'\naverage percentage of time they receive service on unlicensed spectrum and\ncharacterize the social welfare gap between the profit maximizing and social\nwelfare maximizing setting.","primary_category":"cs","categories":["cs.GT"],"authors":["Wang Xu","Berry Randall"],"created":"2018-01-06","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01996","title":"Energy-Efficient NOMA Enabled Heterogeneous Cloud Radio Access Networks","abstract":"Heterogeneous cloud radio access networks (H-CRANs) are envisioned to be\npromising in the fifth generation (5G) wireless networks. H-CRANs enable users\nto enjoy diverse services with high energy efficiency, high spectral\nefficiency, and low-cost operation, which are achieved by using cloud computing\nand virtualization techniques. However, H-CRANs face many technical challenges\ndue to massive user connectivity, increasingly severe spectrum scarcity and\nenergy-constrained devices. These challenges may significantly decrease the\nquality of service of users if not properly tackled. Non-orthogonal multiple\naccess (NOMA) schemes exploit non-orthogonal resources to provide services for\nmultiple users and are receiving increasing attention for their potential of\nimproving spectral and energy efficiency in 5G networks. In this article a\nframework for energy-efficient NOMA H-CRANs is presented. The enabling\ntechnologies for NOMA H-CRANs are surveyed. Challenges to implement these\ntechnologies and open issues are discussed. This article also presents the\nperformance evaluation on energy efficiency of H-CRANs with NOMA.","primary_category":"cs","categories":["cs.NI","cs.IT","math.IT"],"authors":["Zhou Fuhui","Wu Yongpeng","Hu Rose Qingyang","Wang Yuhao","Wong Kai-Kit"],"created":"2018-01-06","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01997","title":"State of the Art, Taxonomy, and Open Issues on Cognitive Radio Networks\n  with NOMA","abstract":"The explosive growth of mobile devices and the rapid increase of wideband\nwireless services call for advanced communication techniques that can achieve\nhigh spectral efficiency and meet the massive connectivity requirement.\nCognitive radio (CR) and non-orthogonal multiple access (NOMA) are envisioned\nto be important solutions for the fifth generation wireless networks.\nIntegrating NOMA techniques into CR networks (CRNs) has the tremendous\npotential to improve spectral efficiency and increase the system capacity.\nHowever, there are many technical challenges due to the severe interference\ncaused by using NOMA. Many efforts have been made to facilitate the application\nof NOMA into CRNs and to investigate the performance of CRNs with NOMA. This\narticle aims to survey the latest research results along this direction. A\ntaxonomy is devised to categorize the literature based on operation paradigms,\nenabling techniques, design objectives and optimization characteristics.\nMoreover, the key challenges are outlined to provide guidelines for the domain\nresearchers and designers to realize CRNs with NOMA. Finally, the open issues\nare discussed.","primary_category":"cs","categories":["cs.NI","cs.IT","math.IT"],"authors":["Zhou Fuhui","Wu Yongpeng","Liang Ying-Chang","Li Zan","Wang Yuhao","Wong Kai-Kit"],"created":"2018-01-06","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.01999","title":"Using reinforcement learning to learn how to play text-based games","abstract":"The ability to learn optimal control policies in systems where action space\nis defined by sentences in natural language would allow many interesting\nreal-world applications such as automatic optimisation of dialogue systems.\nText-based games with multiple endings and rewards are a promising platform for\nthis task, since their feedback allows us to employ reinforcement learning\ntechniques to jointly learn text representations and control policies. We\npresent a general text game playing agent, testing its generalisation and\ntransfer learning performance and showing its ability to play multiple games at\nonce. We also present pyfiction, an open-source library for universal access to\ndifferent text games that could, together with our agent that implements its\ninterface, serve as a baseline for future research.","primary_category":"cs","categories":["cs.CL"],"authors":["Zelinka Mikul\u00e1\u0161"],"created":"2018-01-06","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02003","title":"Design Exploration of Hybrid CMOS-OxRAM Deep Generative Architectures","abstract":"Deep Learning and its applications have gained tremendous interest recently\nin both academia and industry. Restricted Boltzmann Machines (RBMs) offer a key\nmethodology to implement deep learning paradigms. This paper presents a novel\napproach for realizing hybrid CMOS-OxRAM based deep generative models (DGM). In\nour proposed hybrid DGM architectures, HfOx based (filamentary-type switching)\nOxRAM devices are extensively used for realizing multiple computational and\nnon-computational functions such as: (i) Synapses (weights), (ii) internal\nneuron-state storage, (iii) stochastic neuron activation and (iv) programmable\nsignal normalization. To validate the proposed scheme we have simulated two\ndifferent architectures: (i) Deep Belief Network (DBN) and (ii) Stacked\nDenoising Autoencoder for classification and reconstruction of hand-written\ndigits from a reduced MNIST dataset of 6000 images. Contrastive-divergence (CD)\nspecially optimized for OxRAM devices was used to drive the synaptic weight\nupdate mechanism of each layer in the network. Overall learning rule was based\non greedy-layer wise learning with no back propagation which allows the network\nto be trained to a good pre-training stage. Performance of the simulated hybrid\nCMOS-RRAM DGM model matches closely with software based model for a 2-layers\ndeep network. Top-3 test accuracy achieved by the DBN was 95.5%. MSE of the SDA\nnetwork was 0.003, lower than software based approach. Endurance analysis of\nthe simulated architectures show that for 200 epochs of training (single RBM\nlayer), maximum switching events\/per OxRAM device was ~ 7000 cycles.","primary_category":"cs","categories":["cs.ET","cs.NE"],"authors":["Parmar Vivek","Suri Manan"],"created":"2018-01-06","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02010","title":"On decoding procedures of intertwining codes","abstract":"One of the main weakness of the family of centralizer codes is that its\nlength is always $n^2$. Thus we have taken a new matrix equation code called\nintertwining code. Specialty of this code is the length of it, which is of the\nform $nk$. We establish two decoding methods which can be fitted to\nintertwining codes as well as for any linear codes. We also show an inclusion\nof linear codes into a special class of intertwining codes.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Mukherjee Shyambhu","Pal Joydeb","Bagchi Satya"],"created":"2018-01-06","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02014","title":"A Class of MSR Codes for Clustered Distributed Storage","abstract":"Clustered distributed storage models real data centers where intra- and\ncross-cluster repair bandwidths are different. In this paper, exact-repair\nminimum-storage-regenerating (MSR) codes achieving capacity of clustered\ndistributed storage are designed. Focus is given on two cases: $\\epsilon=0$ and\n$\\epsilon=1\/(n-k)$, where $\\epsilon$ is the ratio of the available cross- and\nintra-cluster repair bandwidths, $n$ is the total number of distributed nodes\nand $k$ is the number of contact nodes in data retrieval. The former represents\nthe scenario where cross-cluster communication is not allowed, while the latter\ncorresponds to the case of minimum cross-cluster bandwidth that is possible\nunder the minimum storage overhead constraint. For the $\\epsilon=0$ case, two\ntypes of locally repairable codes are proven to achieve the MSR point. As for\n$\\epsilon=1\/(n-k)$, an explicit MSR coding scheme is suggested for the\ntwo-cluster situation under the specific condition of $n = 2k$.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Sohn Jy-yong","Choi Beongjun","Moon Jaekyun"],"created":"2018-01-06","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02019","title":"A Survey on Quantum Channel Capacities","abstract":"Quantum information processing exploits the quantum nature of information. It\noffers fundamentally new solutions in the field of computer science and extends\nthe possibilities to a level that cannot be imagined in classical communication\nsystems. For quantum communication channels, many new capacity definitions were\ndeveloped in comparison to classical counterparts. A quantum channel can be\nused to realize classical information transmission or to deliver quantum\ninformation, such as quantum entanglement. Here we review the properties of the\nquantum communication channel, the various capacity measures and the\nfundamental differences between the classical and quantum channels.","primary_category":"cs","categories":["quant-ph","cs.IT","math.IT"],"authors":["Gyongyosi Laszlo","Imre Sandor","Nguyen Hung Viet"],"created":"2018-01-06","updated":" ","doi":"10.1109\/COMST.2017.2786748"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02021","title":"Learning Hierarchical Features for Visual Object Tracking with Recursive\n  Neural Networks","abstract":"Recently, deep learning has achieved very promising results in visual object\ntracking. Deep neural networks in existing tracking methods require a lot of\ntraining data to learn a large number of parameters. However, training data is\nnot sufficient for visual object tracking as annotations of a target object are\nonly available in the first frame of a test sequence. In this paper, we propose\nto learn hierarchical features for visual object tracking by using tree\nstructure based Recursive Neural Networks (RNN), which have fewer parameters\nthan other deep neural networks, e.g. Convolutional Neural Networks (CNN).\nFirst, we learn RNN parameters to discriminate between the target object and\nbackground in the first frame of a test sequence. Tree structure over local\npatches of an exemplar region is randomly generated by using a bottom-up greedy\nsearch strategy. Given the learned RNN parameters, we create two dictionaries\nregarding target regions and corresponding local patches based on the learned\nhierarchical features from both top and leaf nodes of multiple random trees. In\neach of the subsequent frames, we conduct sparse dictionary coding on all\ncandidates to select the best candidate as the new target location. In\naddition, we online update two dictionaries to handle appearance changes of\ntarget objects. Experimental results demonstrate that our feature learning\nalgorithm can significantly improve tracking performance on benchmark datasets.","primary_category":"cs","categories":["cs.CV"],"authors":["Wang Li","Liu Ting","Wang Bing","Yang Xulei","Wang Gang"],"created":"2018-01-06","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02027","title":"A First Step in the Co-Evolution of Blockchain and Ontologies: Towards\n  Engineering an Ontology of Governance at the Blockchain Protocol Level","abstract":"At the beginning of 2018, there is a growing belief that blockchain\ntechnologies constitute a revolutionary innovation in how we transfer value\nelectronically. In that vein, blockchain may be a suitable complement to\nontologies to achieve a big part of the vision of the semantic Web by Tim\nBerners-Lee. We believe that if this complementarity is to be achieved\nblockchain and ontologies must co-evolve. In this paper, we focus on what and\nhow to engineer models, methods, designs, and implementations for this\nco-evolution. As a first step in this co-evolution, we propose a conceptual\ndesign of a governance ontology represented as meta-data tags to be embedded\nand instantiated in a smart contract at the blockchain protocol level. We\ndevelop this design by examining and analyzing smart contracts from the\ninfamous The DAO experiment on the Ethereum blockchain. We believe there are\ntwo contributions of this paper: it serves to inform and implore the blockchain\nand ontology communities to recognize and collaborate with each other; and it\noutlines a roadmap for engineering artifacts to bridge the gap between\nblockchain community focus on protocol-level blockchain interoperability and\nthe ontology community focus on semantic-level interoperability.","primary_category":"cs","categories":["cs.CY"],"authors":["Kim Henry M.","Laskowski Marek","Nan Ning"],"created":"2018-01-06","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02028","title":"Characterization and Efficient Search of Non-Elementary Trapping Sets of\n  LDPC Codes with Applications to Stopping Sets","abstract":"In this paper, we propose a characterization for non-elementary trapping sets\n(NETSs) of low-density parity-check (LDPC) codes. The characterization is based\non viewing a NETS as a hierarchy of embedded graphs starting from an ETS. The\ncharacterization corresponds to an efficient search algorithm that under\ncertain conditions is exhaustive. As an application of the proposed\ncharacterization\/search, we obtain lower and upper bounds on the stopping\ndistance $s_{min}$ of LDPC codes.\n  We examine a large number of regular and irregular LDPC codes, and\ndemonstrate the efficiency and versatility of our technique in finding lower\nand upper bounds on, and in many cases the exact value of, $s_{min}$. Finding\n$s_{min}$, or establishing search-based lower or upper bounds, for many of the\nexamined codes are out of the reach of any existing algorithm.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Hashemi Yoones","Banihashemi Amir H."],"created":"2018-01-06","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02029","title":"A Perspective on Blockchain Smart Contracts: Reducing Uncertainty and\n  Complexity in Value Exchange","abstract":"The blockchain constitutes a technology-based, rather than social or\nregulation based, means to lower uncertainty about one another in order to\nexchange value. However, its use may very well also lead to increased\ncomplexity resulting from having to subsume work that displaced intermediary\ninstitutions had performed. We present our perspective that smart contracts may\nbe used to mitigate this increased complexity. We further posit that smart\ncontracts can be delineated according to complexity: Smart contracts that can\nbe verified objectively without much uncertainty belong in an\ninter-organizational context; those that cannot be objectively verified belong\nin an intra-organizational context. We state that smart contracts that\nimplement a formal (e.g. mathematical or simulation) model are especially\nbeneficial for both contexts: They can be used to express and enforce\ninter-organizational agreements, and their basis in a common formalism may\nensure effective evaluation and comparison between different\nintra-organizational contracts. Finally, we present a case study of our\nperspective by describing Intellichain, which implements formal, agent-based\nsimulation model as a smart contract to provide epidemiological decision\nsupport.","primary_category":"cs","categories":["cs.CY"],"authors":["Kim Henry","Laskowski Marek"],"created":"2018-01-06","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02031","title":"ReMotENet: Efficient Relevant Motion Event Detection for Large-scale\n  Home Surveillance Videos","abstract":"This paper addresses the problem of detecting relevant motion caused by\nobjects of interest (e.g., person and vehicles) in large scale home\nsurveillance videos. The traditional method usually consists of two separate\nsteps, i.e., detecting moving objects with background subtraction running on\nthe camera, and filtering out nuisance motion events (e.g., trees, cloud,\nshadow, rain\/snow, flag) with deep learning based object detection and tracking\nrunning on cloud. The method is extremely slow and therefore not cost\neffective, and does not fully leverage the spatial-temporal redundancies with a\npre-trained off-the-shelf object detector. To dramatically speedup relevant\nmotion event detection and improve its performance, we propose a novel network\nfor relevant motion event detection, ReMotENet, which is a unified, end-to-end\ndata-driven method using spatial-temporal attention-based 3D ConvNets to\njointly model the appearance and motion of objects-of-interest in a video.\nReMotENet parses an entire video clip in one forward pass of a neural network\nto achieve significant speedup. Meanwhile, it exploits the properties of home\nsurveillance videos, e.g., relevant motion is sparse both spatially and\ntemporally, and enhances 3D ConvNets with a spatial-temporal attention model\nand reference-frame subtraction to encourage the network to focus on the\nrelevant moving objects. Experiments demonstrate that our method can achieve\ncomparable or event better performance than the object detection based method\nbut with three to four orders of magnitude speedup (up to 20k times) on GPU\ndevices. Our network is efficient, compact and light-weight. It can detect\nrelevant motion on a 15s surveillance video clip within 4-8 milliseconds on a\nGPU and a fraction of second (0.17-0.39) on a CPU with a model size of less\nthan 1MB.","primary_category":"cs","categories":["cs.CV"],"authors":["Yu Ruichi","Wang Hongcheng","Davis Larry S."],"created":"2018-01-06","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02043","title":"Algorithms for orbit closure separation for invariants and\n  semi-invariants of matrices","abstract":"We consider two group actions on $m$-tuples of $n \\times n$ matrices. The\nfirst is simultaneous conjugation by $\\operatorname{GL}_n$ and the second is\nthe left-right action of $\\operatorname{SL}_n \\times \\operatorname{SL}_n$. We\ngive efficient algorithms to decide if the orbit closures of two points\nintersect. We also improve the known bounds for the degree of separating\ninvariants in these cases.","primary_category":"cs","categories":["math.RA","cs.CC","math.AC"],"authors":["Derksen Harm","Makam Visu"],"created":"2018-01-06","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02054","title":"Explorations in an English Poetry Corpus: A Neurocognitive Poetics\n  Perspective","abstract":"This paper describes a corpus of about 3000 English literary texts with about\n250 million words extracted from the Gutenberg project that span a range of\ngenres from both fiction and non-fiction written by more than 130 authors\n(e.g., Darwin, Dickens, Shakespeare). Quantitative Narrative Analysis (QNA) is\nused to explore a cleaned subcorpus, the Gutenberg English Poetry Corpus (GEPC)\nwhich comprises over 100 poetic texts with around 2 million words from about 50\nauthors (e.g., Keats, Joyce, Wordsworth). Some exemplary QNA studies show\nauthor similarities based on latent semantic analysis, significant topics for\neach author or various text-analytic metrics for George Eliot's poem 'How Lisa\nLoved the King' and James Joyce's 'Chamber Music', concerning e.g. lexical\ndiversity or sentiment analysis. The GEPC is particularly suited for research\nin Digital Humanities, Natural Language Processing or Neurocognitive Poetics,\ne.g. as training and test corpus, or for stimulus development and control.","primary_category":"cs","categories":["cs.CL"],"authors":["Jacobs Arthur M."],"created":"2018-01-06","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02058","title":"Robust Dead Reckoning: Calibration, Covariance Estimation, Fusion and\n  Integrity Monitoring","abstract":"To measure system states and local environment directly with high precision,\nexpensive sensors are required. However, highly accurate system states and\nenvironmental perception can also be achieved using data fusion techniques and\ndigital maps. One crucial task of multi-sensor state estimation is to project\ndifferent sensor measurements into the same temporal, spatial and physical\ndomain, estimate their covariance matrices as well as the exclusion of\nerroneous measurements. This paper presents a generic approach for robust\nestimation of vehicle movement (odometry). We will shortly present our\ncalibration procedure, including the estimation of sensor alignments, offset \/\nscaling errors, covariances \/ correlations and time delays. An improved\nalgorithm for wheel diameter estimation is presented. Additionally an approach\nfor robust odometry will be shown as odometry estimations are fused under known\ncovariances, while outliers are detected using a chi-squared test. Utilizing\nour robust odometry, local environmental views can be associated and fused.\nFurthermore our robust odometry can be used to detect and exclude erroneous\nposition estimates.","primary_category":"cs","categories":["cs.RO"],"authors":["Harr Maximilian","Schaefer Christoph"],"created":"2018-01-06","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02061","title":"Optimal Error Correcting Delivery Scheme for an Optimal Coded Caching\n  Scheme with Small Buffers","abstract":"Optimal delivery scheme for coded caching problems with small buffer sizes\nand the number of users no less than the amount of files in the server was\nproposed by Chen, Fan and Letaief [\"Fundamental limits of caching: improved\nbounds for users with small buffers,\" (IET Communications), 2016]. This scheme\nis referred to as the CFL scheme. In this paper, the link between the server\nand the users is assumed to be error prone only during the delivery phase.\nClosed form expressions for average rate and peak rate of error correcting\ndelivery scheme for CFL prefetching scheme is obtained. An optimal error\ncorrecting delivery scheme for caching problems employing CFL prefetching is\nproposed.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Karat Nujoom Sageer","Thomas Anoop","Rajan B. Sundar"],"created":"2018-01-06","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02062","title":"SLEUTH: Real-time Attack Scenario Reconstruction from COTS Audit Data","abstract":"We present an approach and system for real-time reconstruction of attack\nscenarios on an enterprise host. To meet the scalability and real-time needs of\nthe problem, we develop a platform-neutral, main-memory based, dependency graph\nabstraction of audit-log data. We then present efficient, tag-based techniques\nfor attack detection and reconstruction, including source identification and\nimpact analysis. We also develop methods to reveal the big picture of attacks\nby construction of compact, visual graphs of attack steps. Our system\nparticipated in a red team evaluation organized by DARPA and was able to\nsuccessfully detect and reconstruct the details of the red team's attacks on\nhosts running Windows, FreeBSD and Linux.","primary_category":"cs","categories":["cs.CR"],"authors":["Hossain Md Nahid","Milajerdi Sadegh M","Wang Junao","Eshete Birhanu","Gjomemo Rigel","Sekar R","Stoller Scott","Venkatakrishnan VN"],"created":"2018-01-06","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02068","title":"On the inherent competition between valid and spurious inductive\n  inferences in Boolean data","abstract":"Inductive inference is the process of extracting general rules from specific\nobservations. This problem also arises in the analysis of biological networks,\nsuch as genetic regulatory networks, where the interactions are complex and the\nobservations are incomplete. A typical task in these problems is to extract\ngeneral interaction rules as combinations of Boolean covariates, that explain a\nmeasured response variable. The inductive inference process can be considered\nas an incompletely specified Boolean function synthesis problem. This\nincompleteness of the problem will also generate spurious inferences, which are\na serious threat to valid inductive inference rules. Using random Boolean data\nas a null model, here we attempt to measure the competition between valid and\nspurious inductive inference rules from a given data set. We formulate two\ngreedy search algorithms, which synthesize a given Boolean response variable in\na sparse disjunct normal form, and respectively a sparse generalized algebraic\nnormal form of the variables from the observation data, and we evaluate\nnumerically their performance.","primary_category":"cs","categories":["physics.data-an","cs.AI","cs.LO","q-bio.QM"],"authors":["Andrecut M."],"created":"2018-01-06","updated":" ","doi":"10.1142\/S0129183117501467"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02075","title":"QBM - Mapping User-Specified Functions to Programmable Logic through a\n  QBF Satisfiability Problem","abstract":"This is a brief overview on the background behind the test set formulas\ngenerated by the QBM tool. After establishing its application context, its\nformal approach to the generation of QBF formulas and the concrete test set\nformulas are described. Finally, some related work will be credited and the\nsource to obtain the open-source tool will be identified.","primary_category":"cs","categories":["cs.LO","cs.SE"],"authors":["Preu\u00dfer Thomas B."],"created":"2018-01-06","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02076","title":"Future Mobile Network Architecture: Challenges and Issues","abstract":"The future mobile networks facing many challenges and to cope these\nchallenges, different standards and project has been proposed so far. Most\nrecently Cognitive Networks has opened a new ground to present suitable\narchitecture and mechanism for these challenges. The objective of this paper is\nto identify and discuss the challenges to the future mobile networks and to\ndiscuss some workable solutions to these challenges. Finally, on the basis of\ndiscussion a simple flexible network architecture is proposed.","primary_category":"cs","categories":["cs.NI"],"authors":["Bilal Muhammad","Kang Moonsoo"],"created":"2018-01-06","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02080","title":"An Intelligent Future Mobile Terminal Architecture","abstract":"In this paper, a novel Extended Cognitive Mobile Terminal (ExCogNet-MT)\nscheme is presented. In this scheme, a \"test bench\" at receiver's Mobile\nTerminal (MT) can estimate the channel Signal to Noise Ratio (SNR) and can\ndetect the jamming signal. The estimation scheme compares the Standard\nDeviation (SD) of received signal and processed signal, and on the bases of\nthis comparison the \"test bench\" can determine the BER and corresponding SNR\nvalue of the channel. Simulation results demonstrated that under certain\nscenarios estimated SNR value can be helpful for tuning the parameters of\nprotocol stack of 802.11a and WiMaxm.","primary_category":"cs","categories":["cs.NI"],"authors":["Bilal Muhammad"],"created":"2018-01-06","updated":" ","doi":"10.1109\/ICIET.2010.5625738"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02086","title":"Complexity, Development, and Evolution in Morphogenetic Collective\n  Systems","abstract":"Many living and non-living complex systems can be modeled and understood as\ncollective systems made of heterogeneous components that self-organize and\ngenerate nontrivial morphological structures and behaviors. This chapter\npresents a brief overview of our recent effort that investigated various\naspects of such morphogenetic collective systems. We first propose a\ntheoretical classification scheme that distinguishes four complexity levels of\nmorphogenetic collective systems based on the nature of their components and\ninteractions. We conducted a series of computational experiments using a\nself-propelled particle swarm model to investigate the effects of (1)\nheterogeneity of components, (2) differentiation\/re-differentiation of\ncomponents, and (3) local information sharing among components, on the\nself-organization of a collective system. Results showed that (a) heterogeneity\nof components had a strong impact on the system's structure and behavior, (b)\ndynamic differentiation\/re-differentiation of components and local information\nsharing helped the system maintain spatially adjacent, coherent organization,\n(c) dynamic differentiation\/re-differentiation contributed to the development\nof more diverse structures and behaviors, and (d) stochastic re-differentiation\nof components naturally realized a self-repair capability of self-organizing\nmorphologies. We also explored evolutionary methods to design novel\nself-organizing patterns, using interactive evolutionary computation and\nspontaneous evolution within an artificial ecosystem. These self-organizing\npatterns were found to be remarkably robust against dimensional changes from 2D\nto 3D, although evolution worked efficiently only in 2D settings.","primary_category":"cs","categories":["nlin.AO","cs.MA","q-bio.PE"],"authors":["Sayama Hiroki"],"created":"2018-01-06","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02101","title":"Improving utility of brain tumor confocal laser endomicroscopy:\n  objective value assessment and diagnostic frame detection with convolutional\n  neural networks","abstract":"Confocal laser endomicroscopy (CLE), although capable of obtaining images at\ncellular resolution during surgery of brain tumors in real time, creates as\nmany non-diagnostic as diagnostic images. Non-useful images are often distorted\ndue to relative motion between probe and brain or blood artifacts. Many images,\nhowever, simply lack diagnostic features immediately informative to the\nphysician. Examining all the hundreds or thousands of images from a single case\nto discriminate diagnostic images from nondiagnostic ones can be tedious.\nProviding a real-time diagnostic value assessment of images (fast enough to be\nused during the surgical acquisition process and accurate enough for the\npathologist to rely on) to automatically detect diagnostic frames would\nstreamline the analysis of images and filter useful images for the\npathologist\/surgeon. We sought to automatically classify images as diagnostic\nor non-diagnostic. AlexNet, a deep-learning architecture, was used in a 4-fold\ncross validation manner. Our dataset includes 16,795 images (8572 nondiagnostic\nand 8223 diagnostic) from 74 CLE-aided brain tumor surgery patients. The ground\ntruth for all the images is provided by the pathologist. Average model accuracy\non test data was 91% overall (90.79 % accuracy, 90.94 % sensitivity and 90.87 %\nspecificity). To evaluate the model reliability we also performed receiver\noperating characteristic (ROC) analysis yielding 0.958 average for the area\nunder ROC curve (AUC). These results demonstrate that a deeply trained AlexNet\nnetwork can achieve a model that reliably and quickly recognizes diagnostic CLE\nimages.","primary_category":"cs","categories":["cs.CV"],"authors":["Izadyyazdanabadi Mohammadhassan","Belykh Evgenii","Martirosyan Nikolay","Eschbacher Jennifer","Nakaji Peter","Yang Yezhou","Preul Mark C."],"created":"2018-01-06","updated":" ","doi":"10.1117\/12.2254902"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02107","title":"MIZAN: A Large Persian-English Parallel Corpus","abstract":"One of the most major and essential tasks in natural language processing is\nmachine translation that is now highly dependent upon multilingual parallel\ncorpora. Through this paper, we introduce the biggest Persian-English parallel\ncorpus with more than one million sentence pairs collected from masterpieces of\nliterature. We also present acquisition process and statistics of the corpus,\nand experiment a base-line statistical machine translation system using the\ncorpus.","primary_category":"cs","categories":["cs.CL"],"authors":["Kashefi Omid"],"created":"2018-01-06","updated":"2018-01-10","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02112","title":"Convex Relaxations for Pose Graph Optimization with Outliers","abstract":"Pose Graph Optimization involves the estimation of a set of poses from\npairwise measurements and provides a formalization for many problems arising in\nmobile robotics and geometric computer vision. In this paper, we consider the\ncase in which a subset of the measurements fed to pose graph optimization is\nspurious. Our first contribution is to develop robust estimators that can cope\nwith heavy-tailed measurement noise, hence increasing robustness to the\npresence of outliers. Since the resulting estimators require solving nonconvex\noptimization problems, we further develop convex relaxations that approximately\nsolve those problems via semidefinite programming. We then provide conditions\nunder which the proposed relaxations are exact. Contrarily to existing\napproaches, our convex relaxations do not rely on the availability of an\ninitial guess for the unknown poses, hence they are more suitable for setups in\nwhich such guess is not available (e.g., multi-robot localization, recovery\nafter localization failure). We tested the proposed techniques in extensive\nsimulations, and we show that some of the proposed relaxations are indeed tight\n(i.e., they solve the original nonconvex problem 10 exactly) and ensure\naccurate estimation in the face of a large number of outliers.","primary_category":"cs","categories":["cs.RO","cs.CV"],"authors":["Carlone Luca","Calafiore Giuseppe C."],"created":"2018-01-06","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02117","title":"Network Coding with Link Layer Cooperation in Wireless Mesh Networks","abstract":"In recent years, network coding has emerged as an innovative method that\nhelps wireless network approaches its maximum capacity, by combining multiple\nunicasts in one broadcast. However, the majority of research conducted in this\narea is yet to fully utilize the broadcasting nature of wireless networks, and\nstill assumes fixed route between the source and destination that every packet\nshould travel through. This assumption not only limits coding opportunities,\nbut can also cause buffer overflow in some specific intermediate nodes.\nAlthough some studies considered scattering of the flows dynamically in the\nnetwork, they still face some limitations. This paper explains pros and cons of\nsome prominent research in network coding and proposes FlexONC (Flexible and\nOpportunistic Network Coding) as a solution to such issues. The performance\nresults show that FlexONC outperforms previous methods especially in worse\nquality networks, by better utilizing redundant packets spread in the network.","primary_category":"cs","categories":["cs.NI"],"authors":["Kafaie Somayeh","Chen Yuanzhu","Ahmed Mohamed Hossam","Dobre Octavia A."],"created":"2018-01-06","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02119","title":"Throughput Analysis of Network Coding in Multi-Hop Wireless Mesh\n  Networks Using Queueing Theory","abstract":"In recent years, a significant amount of research has been conducted to\nexplore the benefits of network coding in different scenarios, from both\ntheoretical and simulation perspectives. In this paper, we utilize queueing\ntheory to propose an analytical framework for bidirectional unicast flows in\nmulti-hop wireless mesh networks, and study throughput of inter-flow network\ncoding. We analytically determine performance metrics such as the probability\nof successful transmission in terms of collision probability, and feedback\nmechanism and retransmission. Regarding the coding process, our model uses a\nmulti-class queueing network where coded packets are separated from native\npackets and have a non-preemptive higher priority over native packets, and both\nqueues are in a stable state. Finally, we use simulations to verify the\naccuracy of our analytical model.","primary_category":"cs","categories":["cs.NI"],"authors":["Kafaie Somayeh","Ahmed Mohamed H.","Chen Yuanzhu","Dobre Octavia A."],"created":"2018-01-06","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02120","title":"Network Coding Implementation Details: A Guidance Document","abstract":"In recent years, network coding has become one of the most interesting fields\nand has attracted considerable attention from both industry and academia. The\nidea of network coding is based on the concept of allowing intermediate nodes\nto encode and combine incoming packets instead of only copy and forward them.\nThis approach, by augmenting the multicast and broadcast efficiency of\nmulti-hop wireless networks, increases the capacity of the network and improves\nits throughput and robustness. While a wide variety of papers described\napplications of network coding in different types of networks such as delay\ntolerant networks, peer to peer networks and wireless sensor networks, the\ndetailed practical implementation of network coding has not been noted in most\npapers. Since applying network coding in real scenarios requires an acceptable\nunderstanding of mathematics and algebra, especially linear equations, reduced\nrow echelon matrices, field and its operations, this paper provides a\ncomprehensive guidance for the implementation of almost all required concepts\nin network coding. The paper explains the implementation details of network\ncoding in real scenarios and describes the effect of the field size on network\ncoding.","primary_category":"cs","categories":["cs.NI","cs.IT","math.IT"],"authors":["Kafaie Somayeh","Chen Yuanzhu Peter","Dobre Octavia A.","Ahmed Mohamed Hossam"],"created":"2018-01-06","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02121","title":"Architecture Based Classification of Leaf Images","abstract":"Plant classification and identification has so far been an important and\ndifficult task. In this paper, an efficient and systematic approach for\nextracting the leaf architecture characters from captured digital images is\nproposed. The input image is first pre-processed in five steps to be prepared\nfor feature extraction. In the second stage, methods for extracting different\narchitectural features are studied using various mathematical and computational\nmethods. Also, the classification rules for mapping the calculated values of\neach feature to semantic botanical terms in proposed. Compared with previous\nstudies, the proposed method combines extracted features of an image with\nspecific knowledge of leaf architecture in the domain of botany to provide a\ncomprehensive framework for both computer engineers and botanist. Finally,\nBased on the proposed method, experiments on the classification of the\nImagerCLEF 2012 dataset has been performed with promising results.","primary_category":"cs","categories":["cs.CV"],"authors":["Sadeghi Mahmoud","Zakerolhosseini Ali","Sonboli Ali"],"created":"2018-01-06","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02123","title":"TimeWeaver: Opportunistic One Way Delay Measurement via NTP","abstract":"One-way delay (OWD) between end hosts has important implications for Internet\napplications, protocols, and measurement-based analyses. We describe a new\napproach for identifying OWDs via passive measurement of Network Time Protocol\n(NTP) traffic. NTP traffic offers the opportunity to measure OWDs accurately\nand continuously from hosts throughout the Internet. Based on detailed examina-\ntion of NTP implementations and in-situ behavior, we develop an analysis tool\nthat we call TimeWeaver, which enables assessment of precision and accuracy of\nOWD measurements from NTP. We apply TimeWeaver to a ~1TB corpus of NTP traffic\ncollected from 19 servers located in the US and report on the characteristics\nof hosts and their associated OWDs, which we classify in a precision\/accuracy\nhierarchy. To demonstrate the utility of these measurements, we apply iterative\nhard-threshold singular value decomposition to estimate OWDs between arbitrary\nhosts from the high- est tier in the hierarchy. We show that this approach\nresults in highly accurate estimates of OWDs, with average error rates on the\norder of less than 2%. Finally, we outline a number of applications---in\nparticular, IP geolocation, network operations and management---for hosts in\nlower tiers of the precision hierarchy that can benefit from TimeWeaver,\noffering directions for future work.","primary_category":"cs","categories":["cs.NI"],"authors":["Durairajan Ramakrishnan","Mani Sathiya Kumaran","Barford Paul","Nowak Rob","Sommers Joel"],"created":"2018-01-06","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02129","title":"Placement of EV Charging Stations --- Balancing Benefits among Multiple\n  Entities","abstract":"This paper studies the problem of multi-stage placement of electric vehicle\n(EV) charging stations with incremental EV penetration rates. A nested logit\nmodel is employed to analyze the charging preference of the individual consumer\n(EV owner), and predict the aggregated charging demand at the charging\nstations. The EV charging industry is modeled as an oligopoly where the entire\nmarket is dominated by a few charging service providers (oligopolists). At the\nbeginning of each planning stage, an optimal placement policy for each service\nprovider is obtained through analyzing strategic interactions in a Bayesian\ngame. To derive the optimal placement policy, we consider both the\ntransportation network graph and the electric power network graph. A simulation\nsoftware --- The EV Virtual City 1.0 --- is developed using Java to investigate\nthe interactions among the consumers (EV owner), the transportation network\ngraph, the electric power network graph, and the charging stations. Through a\nseries of experiments using the geographic and demographic data from the city\nof San Pedro District of Los Angeles, we show that the charging station\nplacement is highly consistent with the heatmap of the traffic flow. In\naddition, we observe a spatial economic phenomenon that service providers\nprefer clustering instead of separation in the EV charging market.","primary_category":"cs","categories":["eess.SP","cs.GT","econ.EM","math.OC"],"authors":["Luo Chao","Huang Yih-Fang","Gupta Vijay"],"created":"2018-01-06","updated":" ","doi":"10.1109\/TSG.2015.2508740"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02134","title":"FlexONC: Joint Cooperative Forwarding and Network Coding with Precise\n  Encoding Conditions","abstract":"In recent years, network coding has emerged as an innovative method that\nhelps a wireless network approach its maximum capacity, by combining multiple\nunicasts in one broadcast. However, the majority of research conducted in this\narea is yet to fully utilize the broadcasting nature of wireless networks, and\nstill assumes fixed route between the source and destination that every packet\nshould travel through. This assumption not only limits coding opportunities,\nbut can also cause buffer overflow in some specific intermediate nodes.\nAlthough some studies considered scattering of the flows dynamically in the\nnetwork, they still face some limitations. This paper explains pros and cons of\nsome prominent research in network coding and proposes a Flexible and\nOpportunistic Network Coding scheme (FlexONC) as a solution to such issues.\nFurthermore, this research discovers that the conditions used in previous\nstudies to combine packets of different flows are overly optimistic and would\naffect the network performance adversarially. Therefore, we provide a more\naccurate set of rules for packet encoding. The experimental results show that\nFlexONC outperforms previous methods especially in networks with high bit error\nrate, by better utilizing redundant packets spread in the network.","primary_category":"cs","categories":["cs.NI"],"authors":["Kafaie Somayeh","Chen Yuanzhu","Ahmed Mohamed Hossam","Dobre Octavia A."],"created":"2018-01-07","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02135","title":"A Consumer Behavior Based Approach to Multi-Stage EV Charging Station\n  Placement","abstract":"This paper presents a multi-stage approach to the placement of charging\nstations under the scenarios of different electric vehicle (EV) penetration\nrates. The EV charging market is modeled as the oligopoly. A consumer behavior\nbased approach is applied to forecast the charging demand of the charging\nstations using a nested logit model. The impacts of both the urban road network\nand the power grid network on charging station planning are also considered. At\neach planning stage, the optimal station placement strategy is derived through\nsolving a Bayesian game among the service providers. To investigate the\ninterplay of the travel pattern, the consumer behavior, urban road network,\npower grid network, and the charging station placement, a simulation platform\n(The EV Virtual City 1.0) is developed using Java on Repast.We conduct a case\nstudy in the San Pedro District of Los Angeles by importing the geographic and\ndemographic data of that region into the platform. The simulation results\ndemonstrate a strong consistency between the charging station placement and the\ntraffic flow of EVs. The results also reveal an interesting phenomenon that\nservice providers prefer clustering instead of spatial separation in this\noligopoly market.","primary_category":"cs","categories":["eess.SP","cs.GT","econ.EM","math.OC"],"authors":["Luo Chao","Huang Yih-Fang","Gupta Vijay"],"created":"2018-01-07","updated":" ","doi":"10.1109\/VTCSpring.2015.7145593"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02143","title":"Deep Bidirectional and Unidirectional LSTM Recurrent Neural Network for\n  Network-wide Traffic Speed Prediction","abstract":"Short-term traffic forecasting based on deep learning methods, especially\nlong short-term memory (LSTM) neural networks, has received much attention in\nrecent years. However, the potential of deep learning methods in traffic\nforecasting has not yet fully been exploited in terms of the depth of the model\narchitecture, the spatial scale of the prediction area, and the predictive\npower of spatial-temporal data. In this paper, a deep stacked bidirectional and\nunidirectional LSTM (SBU- LSTM) neural network architecture is proposed, which\nconsiders both forward and backward dependencies in time series data, to\npredict network-wide traffic speed. A bidirectional LSTM (BDLSM) layer is\nexploited to capture spatial features and bidirectional temporal dependencies\nfrom historical data. To the best of our knowledge, this is the first time that\nBDLSTMs have been applied as building blocks for a deep architecture model to\nmeasure the backward dependency of traffic data for prediction. The proposed\nmodel can handle missing values in input data by using a masking mechanism.\nFurther, this scalable model can predict traffic speed for both freeway and\ncomplex urban traffic networks. Comparisons with other classical and\nstate-of-the-art models indicate that the proposed SBU-LSTM neural network\nachieves superior prediction performance for the whole traffic network in both\naccuracy and robustness.","primary_category":"cs","categories":["cs.LG"],"authors":["Cui Zhiyong","Ke Ruimin","Wang Yinhai"],"created":"2018-01-07","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02144","title":"Covariant Compositional Networks For Learning Graphs","abstract":"Most existing neural networks for learning graphs address permutation\ninvariance by conceiving of the network as a message passing scheme, where each\nnode sums the feature vectors coming from its neighbors. We argue that this\nimposes a limitation on their representation power, and instead propose a new\ngeneral architecture for representing objects consisting of a hierarchy of\nparts, which we call Covariant Compositional Networks (CCNs). Here, covariance\nmeans that the activation of each neuron must transform in a specific way under\npermutations, similarly to steerability in CNNs. We achieve covariance by\nmaking each activation transform according to a tensor representation of the\npermutation group, and derive the corresponding tensor aggregation rules that\neach neuron must implement. Experiments show that CCNs can outperform competing\nmethods on standard graph learning benchmarks.","primary_category":"cs","categories":["cs.LG"],"authors":["Kondor Risi","Son Hy Truong","Pan Horace","Anderson Brandon","Trivedi Shubhendu"],"created":"2018-01-07","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02148","title":"Australia's long-term electricity demand forecasting using deep neural\n  networks","abstract":"Accurate prediction of long-term electricity demand has a significant role in\ndemand side management and electricity network planning and operation. Demand\nover-estimation results in over-investment in network assets, driving up the\nelectricity prices, while demand under-estimation may lead to under-investment\nresulting in unreliable and insecure electricity. In this manuscript, we apply\ndeep neural networks to predict Australia's long-term electricity demand. A\nstacked autoencoder is used in combination with multilayer perceptrons or\ncascade-forward multilayer perceptrons to predict the nation-wide electricity\nconsumption rates for 1-24 months ahead of time. The experimental results show\nthat the deep structures have better performance than classical neural\nnetworks, especially for 12-month to 24-month prediction horizon.","primary_category":"cs","categories":["cs.NE"],"authors":["Hamedmoghadam Homayoun","Joorabloo Nima","Jalili Mahdi"],"created":"2018-01-07","updated":"2018-01-10","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02149","title":"Applying an Ensemble Learning Method for Improving Multi-label\n  Classification Performance","abstract":"In recent years, multi-label classification problem has become a\ncontroversial issue. In this kind of classification, each sample is associated\nwith a set of class labels. Ensemble approaches are supervised learning\nalgorithms in which an operator takes a number of learning algorithms, namely\nbase-level algorithms and combines their outcomes to make an estimation. The\nsimplest form of ensemble learning is to train the base-level algorithms on\nrandom subsets of data and then let them vote for the most popular\nclassifications or average the predictions of the base-level algorithms. In\nthis study, an ensemble learning method is proposed for improving multi-label\nclassification evaluation criteria. We have compared our method with well-known\nbase-level algorithms on some data sets. Experiment results show the proposed\napproach outperforms the base well-known classifiers for the multi-label\nclassification problem.","primary_category":"cs","categories":["cs.LG","stat.ML"],"authors":["Mahdavi-Shahri Amirreza","Houshmand Mahboobeh","Yaghoobi Mahdi","Jalali Mehrdad"],"created":"2018-01-07","updated":" ","doi":"10.1109\/ICSPIS.2016.7869900"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02150","title":"Time-projection control to recover inter-sample disturbances,\n  application to bipedal walking control","abstract":"We present a new walking controller based on 3LP, a 3D model of bipedal\nwalking that is composed of three pendulums to simulate falling, swing and\ntorso dynamics. Taking advantage of linear equations and closed-form solutions\nof 3LP, the proposed controller projects intermediate states of the biped back\nto the beginning of the phase for which a discrete LQR controller is designed.\nAfter the projection, a proper control policy is generated by this LQR\ncontroller and used at the intermediate time. The projection controller reacts\nto disturbances immediately and compared to the discrete LQR controller, it\nprovides superior performance in recovering intermittent external pushes.\nFurther analysis of closed-loop eigenvalues and disturbance rejection strength\nshow strong stabilization properties for this architecture. An analysis of\nviable regions also show that the proposed controller covers most of the\nmaximal viable set of states. It is computationally much faster than Model\nPredictive Controllers (MPC) and yet optimal over an infinite horizon.","primary_category":"cs","categories":["cs.RO"],"authors":["Faraji Salman","Muellhaupt Philippe","Ijspeert Auke J."],"created":"2018-01-07","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02151","title":"Push recovery with stepping strategy based on time-projection control","abstract":"In this paper, we present a simple control framework for on-line push\nrecovery with dynamic stepping properties. Due to relatively heavy legs in our\nrobot, we need to take swing dynamics into account and thus use a linear model\ncalled 3LP which is composed of three pendulums to simulate swing and torso\ndynamics. Based on 3LP equations, we formulate discrete LQR controllers and use\na particular time-projection method to adjust the next footstep location\non-line during the motion continuously. This adjustment, which is found based\non both pelvis and swing foot tracking errors, naturally takes the swing\ndynamics into account. Suggested adjustments are added to the Cartesian 3LP\ngaits and converted to joint-space trajectories through inverse kinematics.\nFixed and adaptive foot lift strategies also ensure enough ground clearance in\nperturbed walking conditions. The proposed structure is robust, yet uses very\nsimple state estimation and basic position tracking. We rely on the physical\nseries elastic actuators to absorb impacts while introducing simple laws to\ncompensate their tracking bias. Extensive experiments demonstrate the\nfunctionality of different control blocks and prove the effectiveness of\ntime-projection in extreme push recovery scenarios. We also show self-produced\nand emergent walking gaits when the robot is subject to continuous dragging\nforces. These gaits feature dynamic walking robustness due to relatively soft\nsprings in the ankles and avoiding any Zero Moment Point (ZMP) control in our\nproposed architecture.","primary_category":"cs","categories":["cs.RO"],"authors":["Faraji Salman","Razavi Hamed","Ijspeert Auke J."],"created":"2018-01-07","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02154","title":"Publish-Subscribe Framework for Event Management in IoT-based\n  Applications","abstract":"The incredible growth of sensors and microcontroller units makes the task of\nreal-time event monitoring in the Internet of Things (IoT) based applications\neasier and more practical. In order to effectively support the event management\nin IoT-based applications, we propose a framework that is based on the\npublish-subscribe model for detecting events from IoT sensor nodes and sending\nnotifications to subscribers (end-users) via Internet, SMS, and Calling. With\nthe exception of the advantages inherited from the publish-subscribe model, the\nfurther advantages of the proposed framework are the ease of use in terms of\nuser configuration without any need of technical skills, the aid of security\nmechanisms to prevent network intrusion, and the minimum hardware resource\nrequirement. Additionally, the proposed framework is applicable and adaptable\nto various platforms since it has been developed by using Boost C++ Libraries\nand CMake. To evaluate the proposed framework, we develop a prototype of a\nreal-time event monitoring system that is also presented in this paper.","primary_category":"cs","categories":["cs.NI"],"authors":["Nguyen Truc D. T.","Nguyen Quan M. B.","Pham Hoang-Anh"],"created":"2018-01-07","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02155","title":"Binning based algorithm for Pitch Detection in Hindustani Classical\n  Music","abstract":"Speech coding forms a crucial element in speech communications. An important\narea concerning it lies in feature extraction which can be used for analyzing\nHindustani Classical Music. An important feature in this respect is the\nfundamental frequency often referred to as the pitch. In this work, the terms\npitch and its acoustical sensation, the frequency is used interchangeably.\nThere exists numerous pitch detection algorithms which detect the main\/\nfundamental frequency in a given musical piece, but we have come up with a\nunique algorithm for pitch detection using the binning method as described in\nthe paper using appropriate bin size. Previous work on this subject throws\nlight on pitch identification for Hindustani Classical Music. Pitch Class\nDistribution has been employed in this work. It can be used to identify pitches\nin Hindustani Classical Music which is based on suitable intonations and\nswaras. It follows a particular ratio pattern which is a tuning for diatonic\nscale proposed by Ptolemy and confirmed by Zarlino is explored in this paper.\nWe have also given our estimated of these ratios and compared the error with\nthe above. The error produced by varying the bin size in our algorithm is\ninvestigated and an estimate for an appropriate bin size is suggested and\ntested. The binning algorithm thus helps to segregate the important pitches in\na given musical piece.","primary_category":"cs","categories":["cs.SD","eess.AS"],"authors":["Singh Malvika"],"created":"2018-01-07","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02171","title":"Detection and segmentation of the Left Ventricle in Cardiac MRI using\n  Deep Learning","abstract":"Manual segmentation of the Left Ventricle (LV) is a tedious and meticulous\ntask that can vary depending on the patient, the Magnetic Resonance Images\n(MRI) cuts and the experts. Still today, we consider manual delineation done by\nexperts as being the ground truth for cardiac diagnosticians. Thus, we are\nreviewing the paper - written by Avendi and al. - who presents a combined\napproach with Convolutional Neural Networks, Stacked Auto-Encoders and\nDeformable Models, to try and automate the segmentation while performing more\naccurately. Furthermore, we have implemented parts of the paper (around three\nquarts) and experimented both the original method and slightly modified\nversions when changing the architecture and the parameters.","primary_category":"cs","categories":["cs.CV","stat.ML"],"authors":["Attia Alexandre","Dayan Sharone"],"created":"2018-01-07","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02172","title":"Market-based Control of Air-Conditioning Loads with Switching\n  Constraints for Providing Ancillary Services","abstract":"Air-conditioning loads (ACLs) are among the most promising demand side\nresources for their thermal storage capacity and fast response potential. This\npaper adopts the principle of market-based control (MBC) for the ACLs to\nparticipate in the ancillary services. The MBC method is suitable for the\ncontrol of distributed ACLs because it can satisfy diversified requirements,\nreduce the communication bandwidth and protect users' privacy. The modified\nbidding and clearing strategies proposed in this paper makes it possible to\nadjust the switching frequency and strictly satisfy the lockout time constraint\nfor mechanical wear reduction and device protection, without increasing the\ncommunication traffic and computational cost of the control center. The\nperformance of the ACL cluster in two typical ancillary services is studied to\ndemonstrate the effect of the proposed method. The case studies also\ninvestigate how the control parameters affect the response performance, comfort\nlevel and switching frequency.","primary_category":"cs","categories":["math.OC","cs.SY"],"authors":["Yao Yao","Cheng Yizhi","Zhang Peichao"],"created":"2018-01-07","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02178","title":"Neural Networks for Information Retrieval","abstract":"Machine learning plays a role in many aspects of modern IR systems, and deep\nlearning is applied in all of them. The fast pace of modern-day research has\ngiven rise to many approaches to many IR problems. The amount of information\navailable can be overwhelming both for junior students and for experienced\nresearchers looking for new research topics and directions. The aim of this\nfull-day tutorial is to give a clear overview of current tried-and-trusted\nneural methods in IR and how they benefit IR.","primary_category":"cs","categories":["cs.IR"],"authors":["Kenter Tom","Borisov Alexey","Van Gysel Christophe","Dehghani Mostafa","de Rijke Maarten","Mitra Bhaskar"],"created":"2018-01-07","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02186","title":"Clique-coloring of $K_{3,3}$-minor free graphs","abstract":"A clique-coloring of a given graph $G$ is a coloring of the vertices of $G$\nsuch that no maximal clique of size at least two is monocolored. The\nclique-chromatic number of $G$ is the least number of colors for which $G$\nadmits a clique-coloring. It has been proved that every planar graph is\n$3$-clique colorable and every claw-free planar graph, different from an odd\ncycle, is $2$-clique colorable. In this paper, we generalize these results to\n$K_{3,3}$-minor free ($K_{3,3}$-subdivision free) graphs.","primary_category":"cs","categories":["math.CO","cs.DM"],"authors":["Omoomi Behnaz","Taleb Maryam"],"created":"2018-01-07","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02190","title":"Approximate FPGA-based LSTMs under Computation Time Constraints","abstract":"Recurrent Neural Networks and in particular Long Short-Term Memory (LSTM)\nnetworks have demonstrated state-of-the-art accuracy in several emerging\nArtificial Intelligence tasks. However, the models are becoming increasingly\ndemanding in terms of computational and memory load. Emerging latency-sensitive\napplications including mobile robots and autonomous vehicles often operate\nunder stringent computation time constraints. In this paper, we address the\nchallenge of deploying computationally demanding LSTMs at a constrained time\nbudget by introducing an approximate computing scheme that combines iterative\nlow-rank compression and pruning, along with a novel FPGA-based LSTM\narchitecture. Combined in an end-to-end framework, the approximation method's\nparameters are optimised and the architecture is configured to address the\nproblem of high-performance LSTM execution in time-constrained applications.\nQuantitative evaluation on a real-life image captioning application indicates\nthat the proposed methods required up to 6.5x less time to achieve the same\napplication-level accuracy compared to a baseline method, while achieving an\naverage of 25x higher accuracy under the same computation time constraints.","primary_category":"cs","categories":["cs.CV","cs.AR","cs.LG"],"authors":["Rizakis Michalis","Venieris Stylianos I.","Kouris Alexandros","Bouganis Christos-Savvas"],"created":"2018-01-07","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02193","title":"Multi-platform Version of StarCraft: Brood War in a Docker Container:\n  Technical Report","abstract":"We present a dockerized version of a real-time strategy game StarCraft: Brood\nWar, commonly used as a domain for AI research, with a pre-installed collection\nof AI developement tools supporting all the major types of StarCraft bots. This\nprovides a convenient way to deploy StarCraft AIs on numerous hosts at once and\nacross multiple platforms despite limited OS support of StarCraft. In this\ntechnical report, we describe the design of our Docker images and present a few\nuse cases.","primary_category":"cs","categories":["cs.AI"],"authors":["\u0160ustr Michal","Mal\u00fd Jan","\u010certick\u00fd Michal"],"created":"2018-01-07","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02198","title":"Topic-Based Influence Computation in Social Networks under Resource\n  Constraints","abstract":"As social networks are constantly changing and evolving, methods to analyze\ndynamic social networks are becoming more important in understanding social\ntrends. However, due to the restrictions imposed by the social network service\nproviders, the resources available to fetch the entire contents of a social\nnetwork are typically very limited. As a result, analysis of dynamic social\nnetwork data requires maintaining an approximate copy of the social network for\neach time period, locally. In this paper, we study the problem of dynamic\nnetwork and text fetching with limited probing capacities, for identifying and\nmaintaining influential users as the social network evolves. We propose an\nalgorithm to probe the relationships (required for global influence\ncomputation) as well as posts (required for topic-based influence computation)\nof a limited number of users during each probing period, based on the influence\ntrends and activities of the users. We infer the current network based on the\nnewly probed user data and the last known version of the network maintained\nlocally. Additionally, we propose to use link prediction methods to further\nincrease the accuracy of our network inference. We employ PageRank as the\nmetric for influence computation. We illustrate how the proposed solution\nmaintains accurate PageRank scores for computing global influence, and\ntopic-sensitive weighted PageRank scores for topic-based influence. The latter\nrelies on a topic-based network constructed via weights determined by semantic\nanalysis of posts and their sharing statistics. We evaluate the effectiveness\nof our algorithms by comparing them with the true influence scores of the full\nand up-to-date version of the network, using data from the micro-blogging\nservice Twitter. Results show that our techniques significantly outperform\nbaseline methods and are superior to state-of-the-art techniques from the\nliterature.","primary_category":"cs","categories":["cs.SI","physics.soc-ph"],"authors":["Bing\u00f6l Kaan","Eravc\u0131 Bahaeddin","Etemo\u011flu \u00c7a\u011fr\u0131 \u00d6zgen\u00e7","Ferhatosmano\u011flu Hakan","Gedik Bu\u011fra"],"created":"2018-01-07","updated":" ","doi":"10.1109\/TSC.2016.2619688"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02200","title":"Cross-modal Embeddings for Video and Audio Retrieval","abstract":"The increasing amount of online videos brings several opportunities for\ntraining self-supervised neural networks. The creation of large scale datasets\nof videos such as the YouTube-8M allows us to deal with this large amount of\ndata in manageable way. In this work, we find new ways of exploiting this\ndataset by taking advantage of the multi-modal information it provides. By\nmeans of a neural network, we are able to create links between audio and visual\ndocuments, by projecting them into a common region of the feature space,\nobtaining joint audio-visual embeddings. These links are used to retrieve audio\nsamples that fit well to a given silent video, and also to retrieve images that\nmatch a given a query audio. The results in terms of Recall@K obtained over a\nsubset of YouTube-8M videos show the potential of this unsupervised approach\nfor cross-modal feature learning. We train embeddings for both scales and\nassess their quality in a retrieval problem, formulated as using the feature\nextracted from one modality to retrieve the most similar videos based on the\nfeatures computed in the other modality.","primary_category":"cs","categories":["cs.IR","cs.CV","cs.SD","eess.AS"],"authors":["Sur\u00eds Didac","Duarte Amanda","Salvador Amaia","Torres Jordi","Gir\u00f3-i-Nieto Xavier"],"created":"2018-01-07","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02216","title":"Arrows for Parallel Computation","abstract":"Arrows are a general interface for computation and an alternative to Monads\nfor API design. In contrast to Monad-based parallelism, we explore the use of\nArrows for specifying generalised parallelism. Specifically, we define an\nArrow-based language and implement it using multiple parallel Haskells.\n  As each parallel computation is an Arrow, such parallel Arrows (PArrows) can\nbe readily composed and transformed as such. To allow for more sophisticated\ncommunication schemes between computation nodes in distributed systems, we\nutilise the concept of Futures to wrap direct communication.\n  To show that PArrows have similar expressive power as existing parallel\nlanguages, we implement several algorithmic skeletons and four benchmarks.\nBenchmarks show that our framework does not induce any notable performance\noverhead. We conclude that Arrows have considerable potential for composing\nparallel programs and for producing programs that can execute on multiple\nparallel language implementations.","primary_category":"cs","categories":["cs.PL"],"authors":["Braun Martin","Lobachev Oleg","Trinder Phil"],"created":"2018-01-07","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02221","title":"Performance Analysis of Network Coding with IEEE 802.11 DCF in Multi-Hop\n  Wireless Networks","abstract":"Network coding is an effective idea to boost the capacity of wireless\nnetworks, and a variety of studies have explored its advantages in different\nscenarios. However, there is not much analytical study on throughput and\nend-to-end delay of network coding in multi-hop wireless networks considering\nthe specifications of IEEE 802.11 Distributed Coordination Function. In this\npaper, we utilize queuing theory to propose an analytical framework for\nbidirectional unicast flows in multi-hop wireless mesh networks. We study the\nthroughput and end-to-end delay of inter-flow network coding under the IEEE\n802.11 standard with CSMA\/CA random access and exponential back-off time\nconsidering clock freezing and virtual carrier sensing, and formulate several\nparameters such as the probability of successful transmission in terms of bit\nerror rate and collision probability, waiting time of packets at nodes, and\nretransmission mechanism. Our model uses a multi-class queuing network with\nstable queues, where coded packets have a non-preemptive higher priority over\nnative packets, and forwarding of native packets is not delayed if no coding\nopportunities are available. Finally, we use computer simulations to verify the\naccuracy of our analytical model.","primary_category":"cs","categories":["cs.NI"],"authors":["Kafaie Somayeh","Ahmed Mohamed Hossam","Chen Yuanzhu","Dobre Octavia A."],"created":"2018-01-07","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02226","title":"On the randomised query complexity of composition","abstract":"Let $f\\subseteq\\{0,1\\}^n\\times\\Xi$ be a relation and\n$g:\\{0,1\\}^m\\to\\{0,1,*\\}$ be a promise function. This work investigates the\nrandomised query complexity of the relation $f\\circ g^n\\subseteq\\{0,1\\}^{m\\cdot\nn}\\times\\Xi$, which can be viewed as one of the most general cases of\ncomposition in the query model (letting $g$ be a relation seems to result in a\nrather unnatural definition of $f\\circ g^n$).\n  We show that for every such $f$ and $g$, $$\\mathcal R(f\\circ g^n) \\in\n\\Omega(\\mathcal R(f)\\cdot\\sqrt{\\mathcal R(g)}),$$ where $\\mathcal R$ denotes\nthe randomised query complexity. On the other hand, we demonstrate a relation\n$f_0$ and a promise function $g_0$, such that $\\mathcal R(f_0)\\in\\Theta(\\sqrt\nn)$, $\\mathcal R(g_0)\\in\\Theta(n)$ and $\\mathcal R(f_0\\circ g_0^n)\\in\\Theta(n)$\n$-$ that is, our composition statement is tight.\n  To the best of our knowledge, there was no known composition theorem for the\nrandomised query complexity of relations or promise functions (and for the\nspecial case of total functions our lower bound gives multiplicative\nimprovement of $\\sqrt{\\log n}$).","primary_category":"cs","categories":["cs.CC"],"authors":["Gavinsky Dmitry","Lee Troy","Santha Miklos"],"created":"2018-01-07","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02236","title":"Spreading in Social Systems: Reflections","abstract":"In this final chapter, we consider the state-of-the-art for spreading in\nsocial systems and discuss the future of the field. As part of this reflection,\nwe identify a set of key challenges ahead. The challenges include the following\nquestions: how can we improve the quality, quantity, extent, and accessibility\nof datasets? How can we extract more information from limited datasets? How can\nwe take individual cognition and decision making processes into account? How\ncan we incorporate other complexity of the real contagion processes? Finally,\nhow can we translate research into positive real-world impact? In the\nfollowing, we provide more context for each of these open questions.","primary_category":"cs","categories":["physics.soc-ph","cs.SI"],"authors":["Lehmann Sune","Ahn Yong-Yeol"],"created":"2018-01-07","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02243","title":"Trading the Twitter Sentiment with Reinforcement Learning","abstract":"This paper is to explore the possibility to use alternative data and\nartificial intelligence techniques to trade stocks. The efficacy of the daily\nTwitter sentiment on predicting the stock return is examined using machine\nlearning methods. Reinforcement learning(Q-learning) is applied to generate the\noptimal trading policy based on the sentiment signal. The predicting power of\nthe sentiment signal is more significant if the stock price is driven by the\nexpectation of the company growth and when the company has a major event that\ndraws the public attention. The optimal trading strategy based on reinforcement\nlearning outperforms the trading strategy based on the machine learning\nprediction.","primary_category":"cs","categories":["cs.AI","cs.CL","cs.SI"],"authors":["Xiao Catherine","Chen Wanfeng"],"created":"2018-01-07","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02253","title":"Perfect graphs with polynomially computable kernels","abstract":"In a directed graph, a kernel is a subset of vertices that is both stable and\nabsorbing. Not all digraphs have a kernel, but a theorem due to Boros and\nGurvich guarantees the existence of a kernel in every clique-acyclic\norientation of a perfect graph. However, an open question is the complexity\nstatus of the computation of a kernel in such a digraph. Our main contribution\nis to prove new polynomiality results for subfamilies of perfect graphs, among\nwhich are claw-free perfect graphs and chordal graphs. Our results are based on\nthe design of kernel computation methods with respect to two graph operations:\nclique-cutset decomposition and augmentation of flat edges. We also prove that\ndeciding the existence of a kernel - and computing it if it exists - is\npolynomial in every orientation of a chordal or a circular-arc graph, even not\nclique-acyclic.","primary_category":"cs","categories":["cs.DM","math.CO"],"authors":["Pass-Lanneau Ad\u00e8le","Igarashi Ayumi","Meunier Fr\u00e9d\u00e9ric"],"created":"2018-01-07","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02254","title":"Theory of Deep Learning IIb: Optimization Properties of SGD","abstract":"In Theory IIb we characterize with a mix of theory and experiments the\noptimization of deep convolutional networks by Stochastic Gradient Descent. The\nmain new result in this paper is theoretical and experimental evidence for the\nfollowing conjecture about SGD: SGD concentrates in probability -- like the\nclassical Langevin equation -- on large volume, \"flat\" minima, selecting flat\nminimizers which are with very high probability also global minimizers","primary_category":"cs","categories":["cs.LG"],"authors":["Zhang Chiyuan","Liao Qianli","Rakhlin Alexander","Miranda Brando","Golowich Noah","Poggio Tomaso"],"created":"2018-01-07","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02257","title":"Denoising Dictionary Learning Against Adversarial Perturbations","abstract":"We propose denoising dictionary learning (DDL), a simple yet effective\ntechnique as a protection measure against adversarial perturbations. We\nexamined denoising dictionary learning on MNIST and CIFAR10 perturbed under two\ndifferent perturbation techniques, fast gradient sign (FGSM) and jacobian\nsaliency maps (JSMA). We evaluated it against five different deep neural\nnetworks (DNN) representing the building blocks of most recent architectures\nindicating a successive progression of model complexity of each other. We show\nthat each model tends to capture different representations based on their\narchitecture. For each model we recorded its accuracy both on the perturbed\ntest data previously misclassified with high confidence and on the denoised one\nafter the reconstruction using dictionary learning. The reconstruction quality\nof each data point is assessed by means of PSNR (Peak Signal to Noise Ratio)\nand Structure Similarity Index (SSI). We show that after applying (DDL) the\nreconstruction of the original data point from a noisy","primary_category":"cs","categories":["stat.ML","cs.LG"],"authors":["Mitro John","Bridge Derek","Prestwich Steven"],"created":"2018-01-07","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02268","title":"Sample-Efficient Reinforcement Learning through Transfer and\n  Architectural Priors","abstract":"Recent work in deep reinforcement learning has allowed algorithms to learn\ncomplex tasks such as Atari 2600 games just from the reward provided by the\ngame, but these algorithms presently require millions of training steps in\norder to learn, making them approximately five orders of magnitude slower than\nhumans. One reason for this is that humans build robust shared representations\nthat are applicable to collections of problems, making it much easier to\nassimilate new variants. This paper first introduces the idea of\nautomatically-generated game sets to aid in transfer learning research, and\nthen demonstrates the utility of shared representations by showing that models\ncan substantially benefit from the incorporation of relevant architectural\npriors. This technique affords a remarkable 50x positive transfer on a toy\nproblem-set.","primary_category":"cs","categories":["cs.LG","cs.AI"],"authors":["Spector Benjamin","Belongie Serge"],"created":"2018-01-07","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02270","title":"Perceptual Context in Cognitive Hierarchies","abstract":"Cognition does not only depend on bottom-up sensor feature abstraction, but\nalso relies on contextual information being passed top-down. Context is higher\nlevel information that helps to predict belief states at lower levels. The main\ncontribution of this paper is to provide a formalisation of perceptual context\nand its integration into a new process model for cognitive hierarchies. Several\nsimple instantiations of a cognitive hierarchy are used to illustrate the role\nof context. Notably, we demonstrate the use context in a novel approach to\nvisually track the pose of rigid objects with just a 2D camera.","primary_category":"cs","categories":["cs.AI","cs.RO"],"authors":["Hengst Bernhard","Pagnucco Maurice","Rajaratnam David","Sammut Claude","Thielscher Michael"],"created":"2018-01-07","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02281","title":"Winograd Schema - Knowledge Extraction Using Narrative Chains","abstract":"The Winograd Schema Challenge (WSC) is a test of machine intelligence,\ndesigned to be an improvement on the Turing test. A Winograd Schema consists of\na sentence and a corresponding question. To successfully answer these\nquestions, one requires the use of commonsense knowledge and reasoning. This\nwork focuses on extracting common sense knowledge which can be used to generate\nanswers for the Winograd schema challenge. Common sense knowledge is extracted\nbased on events (or actions) and their participants; called Event-Based\nConditional Commonsense (ECC). I propose an approach using Narrative Event\nChains [Chambers et al., 2008] to extract ECC knowledge. These are stored in\ntemplates, to be later used for answering the WSC questions. This approach\nworks well with respect to a subset of WSC tasks.","primary_category":"cs","categories":["cs.AI"],"authors":["Mahajan Vatsal"],"created":"2018-01-07","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02292","title":"Voronoi Diagrams for a Moderate-Sized Point-Set in a Simple Polygon","abstract":"Given a set of sites in a simple polygon, a geodesic Voronoi diagram of the\nsites partitions the polygon into regions based on distances to sites under the\ngeodesic metric. We present algorithms for computing the geodesic\nnearest-point, higher-order and farthest-point Voronoi diagrams of m point\nsites in a simple n-gon, which improve the best known ones for m <= n\/ polylog\nn. Moreover, the algorithms for the geodesic nearest-point and farthest-point\nVoronoi diagrams are optimal for m <= n\/ polylog n. This partially answers a\nquestion posed by Mitchell in the Handbook of Computational Geometry.","primary_category":"cs","categories":["cs.CG"],"authors":["Oh Eunjin","Ahn Hee-Kap"],"created":"2018-01-07","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02298","title":"Depth Sequence Coding with Hierarchical Partitioning and Spatial-domain\n  Quantisation","abstract":"Depth coding in 3D-HEVC for the multiview video plus depth (MVD) architecture\n(i) deforms object shapes due to block-level edge-approximation; (ii) misses an\nopportunity for high compressibility at near-lossless quality by failing to\nexploit strong homogeneity (clustering tendency) in depth syntax, motion vector\ncomponents, and residuals at frame-level; and (iii) restricts interactivity and\nlimits responsiveness of independent use of depth information for \"non-viewing\"\napplications due to texture-depth coding dependency. This paper presents a\nstandalone depth sequence coder, which operates in the lossless to\nnear-lossless quality range while compressing depth data superior to lossy\n3D-HEVC. It preserves edges implicitly by limiting quantisation to the\nspatial-domain and exploits clustering tendency efficiently at frame-level with\na novel binary tree based decomposition (BTBD) technique. For mono-view coding\nof standard MVD test sequences, on average, (i) lossless BTBD achieved $\\times\n42.2$ compression-ratio and $-60.0\\%$ coding gain against the pseudo-lossless\n3D-HEVC, using the lowest quantisation parameter $QP = 1$, and (ii)\nnear-lossless BTBD achieved $-79.4\\%$ and $6.98$ dB Bj{\\o}ntegaard delta\nbitrate (BD-BR) and distortion (BD-PSNR), respectively, against 3D-HEVC. In\nview-synthesis applications, decoded depth maps from BTBD rendered superior\nquality synthetic-views, compared to 3D-HEVC, with $-18.9\\%$ depth BD-BR and\n$0.43$ dB synthetic-texture BD-PSNR on average.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Shahriyar Shampa","Murshed Manzur","Ali Mortuza","Paul Manoranjan"],"created":"2018-01-07","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02300","title":"A Novel Framework for DDoS Detectionin Huge Scale Networks, Thanksto QoS\n  Features","abstract":"It is not been a long time since the advent of cloud-based technology.\nHowever, in this short period of timeseveral advantages and disadvantages have\nbeen emerged. This is a problem solving technology with some threats as well.\nThese threats and potential damages are not only limited to the cloud-based\ntechnologies, but they have always been against computer network\ninfrastructures. One of these examples is Distributed Denial-of-Service (DDoS)\nintrusion which is of course one of the most complex and the most dangerous\ntypes of attacks. The impact of this type of attack, due to its powerful\nnature, is much higher on cloud systems since in case of occurrence, the\nservice providers lose their services completely as well as their reputationand\nloyal customers. This, apparently,can even lead to the collapse of the stock\nand other destructive consequences. On the other hand, due to the properties of\ncloud service providers including large-scale infrastructures, DDoS intrusion\ndetection algorithms need high sensitivity, innovation, and general\nimprovements. Traditional structures of DDoS attack detection algorithms are\ndesigned for small-scale networks or at most for application camps. Lack of\nefficient algorithm is seemingly apparentfor the large-scale networks.\nTherefore, in this context we utilize standardmethods as well as a proposed\nhybrid protocol which is more appropriate in connection with cloud structures\nin order to detect DDoS attacks","primary_category":"cs","categories":["cs.NI","cs.CR"],"authors":["Rezaei Hamed","motlagha Nima Ghazanfari","Farjamib Yaghoub","Yektae Mohammad Hossein"],"created":"2018-01-07","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02308","title":"Joint Transmitter and Receiver Design for Pattern Division Multiple\n  Access","abstract":"In this paper, a joint transmitter and receiver design for pattern division\nmultiple access (PDMA) is proposed. At the transmitter, pattern mapping\nutilizes power allocation to improve the overall sum rate, and beam allocation\nto enhance the access connectivity. At the receiver, hybrid detection utilizes\na spatial filter to suppress the inter-beam interference caused by beam domain\nmultiplexing, and successive interference cancellation to remove the intra-beam\ninterference caused by power domain multiplexing. Furthermore, we propose a\nPDMA joint design approach to optimize pattern mapping based on both the power\ndomain and beam domain. The optimization of power allocation is achieved by\nmaximizing the overall sum rate, and the corresponding optimization problem is\nshown to be convex theoretically. The optimization of beam allocation is\nachieved by minimizing the maximum of the inner product of any two beam\nallocation vectors, and an effective dimension reduction method is proposed\nthrough the analysis of pattern structure and proper mathematical\nmanipulations. Simulation results show that the proposed PDMA approach\noutperforms the orthogonal multiple access and power-domain non-orthogonal\nmultiple access approaches even without any optimization of pattern mapping,\nand that the optimization of beam allocation yields a significant performance\nimprovement than the optimization of power allocation.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Jiang Yanxiang","Li Peng","Ding Zhiguo","Zheng Fuchun","Ma Miaoli","You Xiaohu"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02310","title":"Efficient Encoding\/Decoding of Irreducible Words for Codes Correcting\n  Tandem Duplications","abstract":"Tandem duplication is the process of inserting a copy of a segment of DNA\nadjacent to the original position. Motivated by applications that store data in\nliving organisms, Jain et al. (2017) proposed the study of codes that correct\ntandem duplications. Known code constructions are based on {\\em irreducible\nwords}.\n  We study efficient encoding\/decoding methods for irreducible words. First, we\ndescribe an $(\\ell,m)$-finite state encoder and show that when\n$m=\\Theta(1\/\\epsilon)$ and $\\ell=\\Theta(1\/\\epsilon)$, the encoder achieves rate\nthat is $\\epsilon$ away from the optimal. Next, we provide ranking\/unranking\nalgorithms for irreducible words and modify the algorithms to reduce the space\nrequirements for the finite state encoder.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Chee Yeow Meng","Chrisnata Johan","Kiah Han Mao","Nguyen Tuan Thanh"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02315","title":"Generalized Reed-Solomon Codes with Sparsest and Balanced Generator\n  Matrices","abstract":"We prove that for any positive integers $n$ and $k$ such that $n\\!\\geq\\!\nk\\!\\geq\\! 1$, there exists an $[n,k]$ generalized Reed-Solomon (GRS) code that\nhas a sparsest and balanced generator matrix (SBGM) over any finite field of\nsize $q\\!\\geq\\! n\\!+\\!\\lceil\\frac{k(k-1)}{n}\\rceil$, where sparsest means that\neach row of the generator matrix has the least possible number of nonzeros,\nwhile balanced means that the number of nonzeros in any two columns differ by\nat most one. Previous work by Dau et al (ISIT'13) showed that there always\nexists an MDS code that has an SBGM over any finite field of size $q\\geq\n{n-1\\choose k-1}$, and Halbawi et al (ISIT'16, ITW'16) showed that there exists\na cyclic Reed-Solomon code (i.e., $n=q-1$) with an SBGM for any prime power\n$q$. Hence, this work extends both of the previous results.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Song Wentu","Cai Kui"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02318","title":"HeNet: A Deep Learning Approach on Intel$^\\circledR$ Processor Trace for\n  Effective Exploit Detection","abstract":"This paper presents HeNet, a hierarchical ensemble neural network, applied to\nclassify hardware-generated control flow traces for malware detection. Deep\nlearning-based malware detection has so far focused on analyzing executable\nfiles and runtime API calls. Static code analysis approaches face challenges\ndue to obfuscated code and adversarial perturbations. Behavioral data collected\nduring execution is more difficult to obfuscate but recent research has shown\nsuccessful attacks against API call based malware classifiers. We investigate\ncontrol flow based characterization of a program execution to build robust deep\nlearning malware classifiers. HeNet consists of a low-level behavior model and\na top-level ensemble model. The low-level model is a per-application behavior\nmodel, trained via transfer learning on a time-series of images generated from\ncontrol flow trace of an execution. We use Intel$^\\circledR$ Processor Trace\nenabled processor for low overhead execution tracing and design a lightweight\nimage conversion and segmentation of the control flow trace. The top-level\nensemble model aggregates the behavior classification of all the trace segments\nand detects an attack. The use of hardware trace adds portability to our system\nand the use of deep learning eliminates the manual effort of feature\nengineering. We evaluate HeNet against real-world exploitations of PDF readers.\nHeNet achieves 100\\% accuracy and 0\\% false positive on test set, and higher\nclassification accuracy compared to classical machine learning algorithms.","primary_category":"cs","categories":["cs.CR","cs.LG"],"authors":["Chen Li","Sultana Salmin","Sahita Ravi"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02321","title":"Adaptive Bayesian Shrinkage Estimation Using Log-Scale Shrinkage Priors","abstract":"Global-local shrinkage hierarchies are an important, recent innovation in\nBayesian estimation of regression models. In this paper we propose to use\nlog-scale distributions as a basis for generating familes of flexible prior\ndistributions for the local shrinkage hyperparameters within such hierarchies.\nAn important property of the log-scale priors is that by varying the scale\nparameter one may vary the degree to which the prior distribution promotes\nsparsity in the coefficient estimates, all the way from the simple proportional\nshrinkage ridge regression model up to extremely heavy tailed, sparsity\ninducing prior distributions. By examining the class of distributions over the\nlogarithm of the local shrinkage parameter that have log-linear, or\nsub-log-linear tails, we show that many of standard prior distributions for\nlocal shrinkage parameters can be unified in terms of the tail behaviour and\nconcentration properties of their corresponding marginal distributions over the\ncoefficients $\\beta_j$. We use these results to derive upper bounds on the rate\nof concentration around $|\\beta_j|=0$, and the tail decay as $|\\beta_j| \\to\n\\infty$, achievable by this class of prior distributions. We then propose a new\ntype of ultra-heavy tailed prior, called the log-$t$ prior, which exhibits the\nproperty that, irrespective of the choice of associated scale parameter, the\ninduced marginal distribution over $\\beta_j$ always diverge at $\\beta_j = 0$,\nand always possesses super-Cauchy tails. Finally, we propose to incorporate the\nscale parameter in the log-scale prior distributions into the Bayesian\nhierarchy and derive an adaptive shrinkage procedure. Simulations show that in\ncontrast to a number of standard prior distributions, our adaptive log-$t$\nprocedure appears to always perform well, irrespective of the level of sparsity\nor signal-to-noise ratio of the underlying model.","primary_category":"cs","categories":["math.ST","cs.LG","stat.TH"],"authors":["Schmidt Daniel F.","Makalic Enes"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02325","title":"Long-term Multi-granularity Deep Framework for Driver Drowsiness\n  Detection","abstract":"For real-world driver drowsiness detection from videos, the variation of head\npose is so large that the existing methods on global face is not capable of\nextracting effective features, such as looking aside and lowering head.\nTemporal dependencies with variable length are also rarely considered by the\nprevious approaches, e.g., yawning and speaking. In this paper, we propose a\nLong-term Multi-granularity Deep Framework to detect driver drowsiness in\ndriving videos containing the frontal faces. The framework includes two key\ncomponents: (1) Multi-granularity Convolutional Neural Network (MCNN), a novel\nnetwork utilizes a group of parallel CNN extractors on well-aligned facial\npatches of different granularities, and extracts facial representations\neffectively for large variation of head pose, furthermore, it can flexibly fuse\nboth detailed appearance clues of the main parts and local to global spatial\nconstraints; (2) a deep Long Short Term Memory network is applied on facial\nrepresentations to explore long-term relationships with variable length over\nsequential frames, which is capable to distinguish the states with temporal\ndependencies, such as blinking and closing eyes. Our approach achieves 90.05%\naccuracy and about 37 fps speed on the evaluation set of the public NTHU-DDD\ndataset, which is the state-of-the-art method on driver drowsiness detection.\nMoreover, we build a new dataset named FI-DDD, which is of higher precision of\ndrowsy locations in temporal dimension.","primary_category":"cs","categories":["cs.CV"],"authors":["Lyu Jie","Yuan Zejian","Chen Dapeng"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02330","title":"Evaluation of Machine Learning Algorithms for Intrusion Detection System","abstract":"Intrusion detection system (IDS) is one of the implemented solutions against\nharmful attacks. Furthermore, attackers always keep changing their tools and\ntechniques. However, implementing an accepted IDS system is also a challenging\ntask. In this paper, several experiments have been performed and evaluated to\nassess various machine learning classifiers based on KDD intrusion dataset. It\nsucceeded to compute several performance metrics in order to evaluate the\nselected classifiers. The focus was on false negative and false positive\nperformance metrics in order to enhance the detection rate of the intrusion\ndetection system. The implemented experiments demonstrated that the decision\ntable classifier achieved the lowest value of false negative while the random\nforest classifier has achieved the highest average accuracy rate.","primary_category":"cs","categories":["cs.CR","cs.LG"],"authors":["Almseidin Mohammad","Alzubi Maen","Kovacs Szilveszter","Alkasassbeh Mouhammd"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02332","title":"Behavioural Analytics: Beyond Risk-based MFA","abstract":"This paper investigates how to effectively stop an attacker from using\ncompromised user credentials to gain authorized entry to systems that they are\notherwise not authorised to access. The proposed solution extends previous work\nto move beyond a risk-based multi-factor authentication system. It adds a\nbehavioural analytics component that uses keystroke dynamics to grant or deny\nusers access. Given the increasing number of compromised user credential\nstores, we make the assumption that criminals already know the user\ncredentials. Hence, to test our solution, users were given authentic user\ncredentials and asked to login to our proof-of-concept. Despite the fact that\nall illegitimate users in our test cases were given the correct user\ncredentials for legitimate users, none of these were granted access by the\nsystem. This demonstrates zero- tolerance to false positives. The results\ndemonstrate the uniqueness of keystroke dynamics and its use to prevent users\nwith stolen credentials from accessing systems they are not authorized to\naccess.","primary_category":"cs","categories":["cs.CR"],"authors":["Eyono Roy Henha"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02335","title":"On Enhancing Genetic Algorithms Using New Crossovers","abstract":"This paper investigates the use of more than one crossover operator to\nenhance the performance of genetic algorithms. Novel crossover operators are\nproposed such as the Collision crossover, which is based on the physical rules\nof elastic collision, in addition to proposing two selection strategies for the\ncrossover operators, one of which is based on selecting the best crossover\noperator and the other randomly selects any operator. Several experiments on\nsome Travelling Salesman Problems (TSP) have been conducted to evaluate the\nproposed methods, which are compared to the well-known Modified crossover\noperator and partially mapped Crossover (PMX) crossover. The results show the\nimportance of some of the proposed methods, such as the collision crossover, in\naddition to the significant enhancement of the genetic algorithms performance,\nparticularly when using more than one crossover operator.","primary_category":"cs","categories":["cs.NE"],"authors":["Hassanat Ahmad B. A.","Alkafaween Esra'a"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02336","title":"Step Detection Algorithm For Accurate Distance Estimation Using Dynamic\n  Step Length","abstract":"In this paper, a new Smartphone sensor based algorithm is proposed to detect\naccurate distance estimation. The algorithm consists of two phases, the first\nphase is for detecting the peaks from the Smartphone accelerometer sensor. The\nother one is for detecting the step length which varies from step to step. The\nproposed algorithm is tested and implemented in real environment and it showed\npromising results. Unlike the conventional approaches, the error of the\nproposed algorithm is fixed and is not affected by the long distance.\n  Keywords distance estimation, peaks, step length, accelerometer.","primary_category":"cs","categories":["cs.OH"],"authors":["Abadleh Ahmad","Al-Hawari Eshraq","Alkafaween Esra'a","Al-Sawalqah Hamad"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02344","title":"Optimal Time Scheduling for Wireless-Powered Backscatter Communication\n  Networks","abstract":"This letter introduces a novel wireless-powered backscatter communication\nsystem which allows sensors to utilize RF signals transmitted from a dedicated\nRF energy source to transmit data. In the proposed system, when the RF energy\nsource transmits RF signals, the sensors are able to backscatter the RF signals\nto transmit date to the gateway and\/or harvest energy from the RF signals for\ntheir operations. By integrating backscattering and energy harvesting\ntechniques, we can optimize the network throughput of the system. In\nparticular, we first formulate the time scheduling problem for the system, and\nthen propose an optimal solution using convex optimization to maximize the\noverall network throughput. Numerical results show a significant throughput\ngain achieved by our proposed design over two other baseline schemes.","primary_category":"cs","categories":["cs.NI","cs.IT","math.IT"],"authors":["Van Huynh Nguyen","Hoang Dinh Thai","Niyato Dusit","Wang Ping","Kim Dong In"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02351","title":"A Game-Theoretic Approach for NOMA-ALOHA","abstract":"Non-orthogonal multiple access (NOMA) can improve the spectral efficiency by\nexploiting the power domain and successive interference cancellation (SIC), and\nit can be applied to various transmission schemes including random access that\nplays a crucial role in the Internet of Things (IoT) to support connectivity\nfor a number of devices with sparse activity. In this paper, we formulate a\ngame when NOMA is applied to ALOHA to decide the transmission probability. We\nconsider a payoff function based on an energy-efficiency metric and drive the\nmixed strategy Nash equilibrium (NE).","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Choi Jinho"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02356","title":"Efficiently Disassemble-and-Pack for Mechanism","abstract":"In this paper, we present a disassemble-and-pack approach for a mechanism to\nseek a box which contains total mechanical parts with high space utilization.\nIts key feature is that mechanism contains not only geometric shapes but also\ninternal motion structures which can be calculated to adjust geometric shapes\nof the mechanical parts. Our system consists of two steps: disassemble\nmechanical object into a group set and pack them within a box efficiently. The\nfirst step is to create a hierarchy of possible group set of parts which is\ngenerated by disconnecting the selected joints and adjust motion structures of\nparts in groups. The aim of this step is seeking total minimum volume of each\ngroup. The second step is to exploit the hierarchy based on\nbreadth-first-search to obtain a group set. Every group in the set is inserted\ninto specified box from maximum volume to minimum based on our packing\nstrategy. Until an approximated result with satisfied efficiency is accepted,\nour approach finish exploiting the hierarchy.","primary_category":"cs","categories":["cs.CG"],"authors":["Li Mingyuan","Jiang Xiaoheng","Gu Ningbo","Xu Weiwei","Xue Junxiao","Zhou Bing","Xu Mingliang"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02362","title":"Acceleration of Mean Square Distance Calculations with Floating Close\n  Structure in Metadynamics Simulations","abstract":"Molecular dynamics simulates the~movements of atoms. Due to its high cost,\nmany methods have been developed to \"push the~simulation forward\". One of them,\nmetadynamics, can hasten the~molecular dynamics with the~help of variables\ndescribing the~simulated process. However, the~evaluation of these variables\ncan include numerous mean square distance calculations that introduce\nsubstantial computational demands, thus jeopardize the~benefit of the~approach.\nRecently, we proposed an~approximative method that significantly reduces\nthe~number of these distance calculations. Here we evaluate the~performance and\nthe~scalability on two molecular systems. We assess the~maximal theoretical\nspeed-up based on the reduction of distance computations and Ahmdal's law and\ncompare it to the~practical speed-up achieved with our implementation.","primary_category":"cs","categories":["cs.CE","cs.DC","cs.NA"],"authors":["Paz\u00farikov\u00e1 Jana","O\u013eha Jaroslav","K\u0159enek Ale\u0161","Spiwok Vojt\u011bch"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02367","title":"Deciding and Interpolating Algebraic Data Types by Reduction (Technical\n  Report)","abstract":"Recursive algebraic data types (term algebras, ADTs) are one of the most\nwell-studied theories in logic, and find application in contexts including\nfunctional programming, modelling languages, proof assistants, and\nverification. At this point, several state-of-the-art theorem provers and SMT\nsolvers include tailor-made decision procedures for ADTs, and version 2.6 of\nthe SMT-LIB standard includes support for ADTs. We study an extremely simple\napproach to decide satisfiability of ADT constraints, the reduction of ADT\nconstraints to equisatisfiable constraints over uninterpreted functions (EUF)\nand linear integer arithmetic (LIA). We show that the reduction approach gives\nrise to both decision and Craig interpolation procedures in (extensions of)\nADTs.","primary_category":"cs","categories":["cs.LO","cs.SC"],"authors":["Hojjat Hossein","R\u00fcmmer Philipp"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02377","title":"AUV Optimal Path for Leak Detection","abstract":"This paper studies an optimal autonomous underwater vehicule (AUV) path\nplanning method for both reducing average delay before pollutants detection in\nunderwater mining, oil or gas fields and reducing AUV occupancy time. The\nproposed technique, based on the bayesian search theory framework and\nmulti-objective optimization, extracts optimal boustrophedon paths for leak\ndetection in complex environment. We describe a multi-objective nonlinear mixed\ninteger optimization model for both reducing global nondetection probability\nand path duration. We then propose a hierarchical algorithm combining two\nfunctions. The main function is a multi-objective cross entropy which places\nthe tracklines. The second function sets the optimal speeds on each trackline\nby means of an interior point method. Numerical simulations show that the\nproposed framework is a very promising approach because the optimal paths cross\nspill of highly probable leaks before less probable ones. We show that our\noptimized paths outperform boustrophedon paths of same duration with uniform\nspeed and spacing of trackline. Thanks to Pareto efficiency approach, our tool\npropose optimal trajectories for numerous AUV autonomies. Hence it can be used\nfor both real time path planning and design purpose.","primary_category":"cs","categories":["cs.SY"],"authors":["Marceau Olivier","Vanpeperstraete Jean-Michel"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02381","title":"Benchmarking Crimes: An Emerging Threat in Systems Security","abstract":"Properly benchmarking a system is a difficult and intricate task.\nUnfortunately, even a seemingly innocuous benchmarking mistake can compromise\nthe guarantees provided by a given systems security defense and also put its\nreproducibility and comparability at risk. This threat is particularly\ninsidious as it is generally not a result of malice and can easily go\nundetected by both authors and reviewers. Moreover, as modern defenses often\ntrade off security for performance in an attempt to find an ideal design point\nin the performance-security space, the damage caused by benchmarking mistakes\nis increasingly worrisome.\n  To analyze the magnitude of the phenomenon, we identify a set of 22\n\"benchmarking crimes\" that threaten the validity of systems security\nevaluations and perform a survey of 50 defense papers published in top venues.\nTo ensure the validity of our results, we perform the complete survey twice,\nwith two independent readers. We find only a very small number of disagreements\nbetween readers, showing that our assessment of benchmarking crimes is highly\nreproducible.\n  We show that benchmarking crimes are widespread even in papers published at\ntier-1 venues. We find that tier-1 papers commit an average of five\nbenchmarking crimes and we find only a single paper in our sample that\ncommitted no benchmarking crimes. Moreover, we find that the scale of the\nproblem is constant over time, suggesting that the community is not yet\naddressing it despite the problem being now more relevant than ever. This\nthreatens the scientific process, which relies on reproducibility and\ncomparability to ensure that published research advances the state of the art.\nWe hope to raise awareness of these issues and provide recommendations to\nimprove benchmarking quality and safeguard the scientific process in our\ncommunity.","primary_category":"cs","categories":["cs.CR"],"authors":["van der Kouwe Erik","Andriesse Dennis","Bos Herbert","Giuffrida Cristiano","Heiser Gernot"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02383","title":"Social Media Attention Increases Article Visits: An Investigation on\n  Article-Level Referral Data of PeerJ","abstract":"In order to better understand the effect of social media in the dissemination\nof scholarly articles, employing the daily updated referral data of 110 PeerJ\narticles collected over a period of 345 days, we analyze the relationship\nbetween social media attention and article visitors directed by social media.\nOur results show that social media presence of PeerJ articles is high. About\n68.18% of the papers receive at least one tweet from Twitter accounts other\nthan @PeerJ, the official account of the journal. Social media attention\nincreases the dissemination of scholarly articles. Altmetrics could not only\nact as the complement of traditional citation measures but also play an\nimportant role in increasing the article downloads and promoting the impacts of\nscholarly articles. There also exists a significant correlation among the\nonline attention from different social media platforms. Articles with more\nFacebook shares tend to get more tweets. The temporal trends show that social\nattention comes immediately following publication but does not last long, so do\nthe social media directed article views.","primary_category":"cs","categories":["cs.DL","cs.CY"],"authors":["Wang Xianwen","Cui Yunxue","Li Qingchun","Guo Xinhui"],"created":"2018-01-08","updated":" ","doi":"10.3389\/frma.2017.00011"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02384","title":"Attacking Speaker Recognition With Deep Generative Models","abstract":"In this paper we investigate the ability of generative adversarial networks\n(GANs) to synthesize spoofing attacks on modern speaker recognition systems. We\nfirst show that samples generated with SampleRNN and WaveNet are unable to fool\na CNN-based speaker recognition system. We propose a modification of the\nWasserstein GAN objective function to make use of data that is real but not\nfrom the class being learned. Our semi-supervised learning method is able to\nperform both targeted and untargeted attacks, raising questions related to\nsecurity in speaker authentication systems.","primary_category":"cs","categories":["cs.SD","cs.LG","eess.AS"],"authors":["Cai Wilson","Doshi Anish","Valle Rafael"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02385","title":"Synthetic Data Augmentation using GAN for Improved Liver Lesion\n  Classification","abstract":"In this paper, we present a data augmentation method that generates synthetic\nmedical images using Generative Adversarial Networks (GANs). We propose a\ntraining scheme that first uses classical data augmentation to enlarge the\ntraining set and then further enlarges the data size and its diversity by\napplying GAN techniques for synthetic data augmentation. Our method is\ndemonstrated on a limited dataset of computed tomography (CT) images of 182\nliver lesions (53 cysts, 64 metastases and 65 hemangiomas). The classification\nperformance using only classic data augmentation yielded 78.6% sensitivity and\n88.4% specificity. By adding the synthetic data augmentation the results\nsignificantly increased to 85.7% sensitivity and 92.4% specificity.","primary_category":"cs","categories":["cs.CV"],"authors":["Frid-Adar Maayan","Klang Eyal","Amitai Michal","Goldberger Jacob","Greenspan Hayit"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02436","title":"Asymptotic Miss Ratio of LRU Caching with Consistent Hashing","abstract":"To efficiently scale data caching infrastructure to support emerging big data\napplications, many caching systems rely on consistent hashing to group a large\nnumber of servers to form a cooperative cluster. These servers are organized\ntogether according to a random hash function. They jointly provide a unified\nbut distributed hash table to serve swift and voluminous data item requests.\nDifferent from the single least-recently-used (LRU) server that has already\nbeen extensively studied, theoretically characterizing a cluster that consists\nof multiple LRU servers remains yet to be explored. These servers are not\nsimply added together; the random hashing complicates the behavior. To this\nend, we derive the asymptotic miss ratio of data item requests on a LRU cluster\nwith consistent hashing. We show that these individual cache spaces on\ndifferent servers can be effectively viewed as if they could be pooled together\nto form a single virtual LRU cache space parametrized by an appropriate cache\nsize. This equivalence can be established rigorously under the condition that\nthe cache sizes of the individual servers are large. For typical data caching\nsystems this condition is common. Our theoretical framework provides a\nconvenient abstraction that can directly apply the results from the simpler\nsingle LRU cache to the more complex LRU cluster with consistent hashing.","primary_category":"cs","categories":["cs.PF"],"authors":["Ji Kaiyi","Quan Guocong","Tan Jian"],"created":"2018-01-08","updated":"2018-01-10","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02442","title":"Precoding via Approximate Message Passing with Instantaneous Signal\n  Constraints","abstract":"This paper proposes a low complexity precoding algorithm based on the\nrecently proposed Generalized Least Square Error (GLSE) scheme with generic\npenalty and support. The algorithm iteratively constructs the transmit vector\nvia Approximate Message Passing (AMP). Using the asymptotic decoupling property\nof GLSE precoders, we derive closed form fixed point equations to tune the\nparameters in the proposed algorithm for a general set of instantaneous signal\nconstraints. The tuning strategy is then utilized to construct transmit vectors\nwith restricted peak-to-average power ratios and to efficiently select a subset\nof transmit antennas. The numerical investigations show that the proposed\nalgorithm tracks the large-system performance of GLSE precoders even for a\nmoderate number of antennas.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Bereyhi Ali","Sedaghat Mohammad Ali","M\u00fcller Ralf R."],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02453","title":"Reversible Harmonic Maps between Discrete Surfaces","abstract":"Information transfer between triangle meshes is of great importance in\ncomputer graphics and geometry processing. To facilitate this process, a smooth\nand accurate map is typically required between the two meshes. While such maps\ncan sometimes be computed between nearly-isometric meshes, the more general\ncase of meshes with diverse geometries remains challenging. We propose a novel\napproach for direct map computation between triangle meshes without mapping to\nan intermediate domain, which optimizes for the harmonicity and reversibility\nof the forward and backward maps. Our method is general both in the information\nit can receive as input, e.g. point landmarks, a dense map or a functional map,\nand in the diversity of the geometries to which it can be applied. We\ndemonstrate that our maps exhibit lower conformal distortion than the\nstate-of-the-art, while succeeding in correctly mapping key features of the\ninput shapes.","primary_category":"cs","categories":["cs.GR"],"authors":["Ezuz Danielle","Solomon Justin","Ben-Chen Mirela"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02457","title":"Heuristics for Selecting Predicates for Partial Predicate Abstraction","abstract":"In this paper we consider the problem of configuring partial predicate\nabstraction that combines two techniques that have been effective in analyzing\ninfinite-state systems: predicate abstraction and fixpoint approximations. A\nfundamental problem in partial predicate abstraction is deciding the variables\nto be abstracted and the predicates to be used. In this paper, we consider\nsystems modeled using linear integer arithmetic and investigate an alternative\napproach to counter-example guided abstraction refinement. We devise two\nheuristics that search for predicates that are likely to be precise. The first\nheuristic performs the search on the problem instance to be verified. The other\nheuristic leverages verification results on the smaller instances of the\nproblem. We report experimental results for CTL model checking and discuss\nadvantages and disadvantages of each approach.","primary_category":"cs","categories":["cs.LO"],"authors":["Yavuz Tuba","Metcalf Chelsea"],"created":"2017-12-30","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02466","title":"Granularity of algorithmically constructed publication-level\n  classifications of research publications: Identification of topics","abstract":"The purpose of this study is to find a theoretically grounded, practically\napplicable and useful granularity level of an algorithmically constructed\npublication-level classification of research publications (ACPLC). The level\naddressed is the level of research topics. The methodology we propose uses\nsynthesis papers and their reference articles to construct a baseline\nclassification. A dataset of about 31 million publications, and their mutual\ncitations relations, is used to obtain several ACPLCs of different granularity.\nEach ACPLC is compared to the baseline classification and the best performing\nACPLC is identified. The results of two case studies show that the topics of\nthe cases are closely associated with different classes of the identified\nACPLC, and that these classes tend to treat only one topic. Further, the class\nsize variation is moderate, and only a small proportion of the publications\nbelong to very small classes. For these reasons, we conclude that the proposed\nmethodology is suitable to determine the topic granularity level of an ACPLC\nand that the ACPLC identified by this methodology is useful for bibliometric\nanalyses.","primary_category":"cs","categories":["cs.DL"],"authors":["Sj\u00f6g\u00e5rde Peter","Ahlgren Per"],"created":"2018-01-08","updated":" ","doi":"10.1016\/j.joi.2017.12.006"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02471","title":"Gated Recurrent Networks for Seizure Detection","abstract":"Recurrent Neural Networks (RNNs) with sophisticated units that implement a\ngating mechanism have emerged as powerful technique for modeling sequential\nsignals such as speech or electroencephalography (EEG). The latter is the focus\non this paper. A significant big data resource, known as the TUH EEG Corpus\n(TUEEG), has recently become available for EEG research, creating a unique\nopportunity to evaluate these recurrent units on the task of seizure detection.\nIn this study, we compare two types of recurrent units: long short-term memory\nunits (LSTM) and gated recurrent units (GRU). These are evaluated using a state\nof the art hybrid architecture that integrates Convolutional Neural Networks\n(CNNs) with RNNs. We also investigate a variety of initialization methods and\nshow that initialization is crucial since poorly initialized networks cannot be\ntrained. Furthermore, we explore regularization of these convolutional gated\nrecurrent networks to address the problem of overfitting. Our experiments\nrevealed that convolutional LSTM networks can achieve significantly better\nperformance than convolutional GRU networks. The convolutional LSTM\narchitecture with proper initialization and regularization delivers 30%\nsensitivity at 6 false alarms per 24 hours.","primary_category":"cs","categories":["eess.SP","cs.AI","stat.ML"],"authors":["Golmohammadi Meysam","Ziyabari Saeedeh","Shah Vinit","Von Weltin Eva","Campbell Christopher","Obeid Iyad","Picone Joseph"],"created":"2018-01-02","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02472","title":"Optimizing Channel Selection for Seizure Detection","abstract":"Interpretation of electroencephalogram (EEG) signals can be complicated by\nobfuscating artifacts. Artifact detection plays an important role in the\nobservation and analysis of EEG signals. Spatial information contained in the\nplacement of the electrodes can be exploited to accurately detect artifacts.\nHowever, when fewer electrodes are used, less spatial information is available,\nmaking it harder to detect artifacts. In this study, we investigate the\nperformance of a deep learning algorithm, CNN-LSTM, on several channel\nconfigurations. Each configuration was designed to minimize the amount of\nspatial information lost compared to a standard 22-channel EEG. Systems using a\nreduced number of channels ranging from 8 to 20 achieved sensitivities between\n33% and 37% with false alarms in the range of [38, 50] per 24 hours. False\nalarms increased dramatically (e.g., over 300 per 24 hours) when the number of\nchannels was further reduced. Baseline performance of a system that used all 22\nchannels was 39% sensitivity with 23 false alarms. Since the 22-channel system\nwas the only system that included referential channels, the rapid increase in\nthe false alarm rate as the number of channels was reduced underscores the\nimportance of retaining referential channels for artifact reduction. This\ncautionary result is important because one of the biggest differences between\nvarious types of EEGs administered is the type of referential channel used.","primary_category":"cs","categories":["eess.SP","cs.CV","q-bio.NC","stat.ML"],"authors":["Shah Vinit","Golmohammadi Meysam","Ziyabari Saeedeh","Von Weltin Eva","Obeid Iyad","Picone Joseph"],"created":"2018-01-02","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02474","title":"An Analysis of Two Common Reference Points for EEGs","abstract":"Clinical electroencephalographic (EEG) data varies significantly depending on\na number of operational conditions (e.g., the type and placement of electrodes,\nthe type of electrical grounding used). This investigation explores the\nstatistical differences present in two different referential montages: Linked\nEar (LE) and Averaged Reference (AR). Each of these accounts for approximately\n45% of the data in the TUH EEG Corpus. In this study, we explore the impact\nthis variability has on machine learning performance. We compare the\nstatistical properties of features generated using these two montages, and\nexplore the impact of performance on our standard Hidden Markov Model (HMM)\nbased classification system. We show that a system trained on LE data\nsignificantly outperforms one trained only on AR data (77.2% vs. 61.4%). We\nalso demonstrate that performance of a system trained on both data sets is\nsomewhat compromised (71.4% vs. 77.2%). A statistical analysis of the data\nsuggests that mean, variance and channel normalization should be considered.\nHowever, cepstral mean subtraction failed to produce an improvement in\nperformance, suggesting that the impact of these statistical differences is\nsubtler.","primary_category":"cs","categories":["eess.SP","cs.LG","stat.ML"],"authors":["Lopez Silvia","Gross Aaron","Yang Scott","Golmohammadi Meysam","Obeid Iyad","Picone Joseph"],"created":"2018-01-02","updated":" ","doi":"10.1109\/SPMB.2016.7846854"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02476","title":"Semi-automated Annotation of Signal Events in Clinical EEG Data","abstract":"To be effective, state of the art machine learning technology needs large\namounts of annotated data. There are numerous compelling applications in\nhealthcare that can benefit from high performance automated decision support\nsystems provided by deep learning technology, but they lack the comprehensive\ndata resources required to apply sophisticated machine learning models.\nFurther, for economic reasons, it is very difficult to justify the creation of\nlarge annotated corpora for these applications. Hence, automated annotation\ntechniques become increasingly important. In this study, we investigated the\neffectiveness of using an active learning algorithm to automatically annotate a\nlarge EEG corpus. The algorithm is designed to annotate six types of EEG\nevents. Two model training schemes, namely threshold-based and volume-based,\nare evaluated. In the threshold-based scheme the threshold of confidence scores\nis optimized in the initial training iteration, whereas for the volume-based\nscheme only a certain amount of data is preserved after each iteration.\nRecognition performance is improved 2% absolute and the system is capable of\nautomatically annotating previously unlabeled data. Given that the\ninterpretation of clinical EEG data is an exceedingly difficult task, this\nstudy provides some evidence that the proposed method is a viable alternative\nto expensive manual annotation.","primary_category":"cs","categories":["eess.SP","cs.DB","cs.LG","stat.ML"],"authors":["Yang Scott","Lopez Silvia","Golmohammadi Meysam","Obeid Iyad","Picone Joseph"],"created":"2018-01-02","updated":" ","doi":"10.1109\/SPMB.2016.7846855"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02477","title":"Improved EEG Event Classification Using Differential Energy","abstract":"Feature extraction for automatic classification of EEG signals typically\nrelies on time frequency representations of the signal. Techniques such as\ncepstral-based filter banks or wavelets are popular analysis techniques in many\nsignal processing applications including EEG classification. In this paper, we\npresent a comparison of a variety of approaches to estimating and\npostprocessing features. To further aid in discrimination of periodic signals\nfrom aperiodic signals, we add a differential energy term. We evaluate our\napproaches on the TUH EEG Corpus, which is the largest publicly available EEG\ncorpus and an exceedingly challenging task due to the clinical nature of the\ndata. We demonstrate that a variant of a standard filter bank-based approach,\ncoupled with first and second derivatives, provides a substantial reduction in\nthe overall error rate. The combination of differential energy and derivatives\nproduces a 24% absolute reduction in the error rate and improves our ability to\ndiscriminate between signal events and background noise. This relatively simple\napproach proves to be comparable to other popular feature extraction approaches\nsuch as wavelets, but is much more computationally efficient.","primary_category":"cs","categories":["eess.SP","cs.CV","stat.ML"],"authors":["Harati Amir","Golmohammadi Meysam","Lopez Silvia","Obeid Iyad","Picone Joseph"],"created":"2018-01-02","updated":" ","doi":"10.1109\/SPMB.2015.7405421"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02478","title":"Autonomous Tracking of Intermittent RF Source Using a UAV Swarm","abstract":"Localization of a radio frequency (RF) transmitter with intermittent\ntransmissions is considered via a group of unmanned aerial vehicles (UAVs)\nequipped with omnidirectional received signal strength (RSS) sensors. This\ngroup embarks on an autonomous patrol to localize and track the target with a\nspecified accuracy, as quickly as possible. The challenge can be decomposed\ninto two stages: 1) estimation of the target position given previous\nmeasurements (localization), and 2) planning the future trajectory of the\ntracking UAVs to get lower expected localization error given current estimation\n(path planning). For each stage we compare two algorithms in terms of\nperformance and computational load. For the localization stage, we compare a\ndetection based extended Kalman filter (EKF) and a recursive Bayesian\nestimator. For the path planning stage, we compare steepest descent posterior\nCramer-Rao lower bound (CRLB) path planning and a bio-inspired heuristic path\nplanning. Our results show that the steepest descent path planning outperforms\nthe bio-inspired path planning by an order of magnitude, and recursive Bayesian\nestimator narrowly outperforms detection based EKF.","primary_category":"cs","categories":["eess.SP","cs.MA","cs.SY"],"authors":["Koohifar Farshad","Guvenc Ismail","Sichitiu Mihail L."],"created":"2018-01-03","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02484","title":"Monitoring Data Minimisation","abstract":"Data minimisation is a privacy enhancing principle, stating that personal\ndata collected should be no more than necessary for the specific purpose\nconsented by the user. Checking that a program satisfies the data minimisation\nprinciple is not easy, even for the simple case when considering deterministic\nprograms-as-functions. In this paper we prove (im)possibility results\nconcerning runtime monitoring of (non-)minimality for deterministic programs\nboth when the program has one input source (monolithic) and for the more\ngeneral case when inputs come from independent sources (distributed case). We\npropose monitoring mechanisms where a monitor observes the inputs and the\noutputs of a program, to detect violation of data minimisation policies. We\nshow that monitorability of (non) minimality is decidable only for specific\ncases, and detection of satisfaction of different notions of minimality in\nundecidable in general. That said, we show that under certain conditions\nmonitorability is decidable and we provide an algorithm and a bound to check\nsuch properties in a pre-deployment controlled environment, also being able to\ncompute a minimiser for the given program. Finally, we provide a\nproof-of-concept implementation for both offline and online monitoring and\napply that to some case studies.","primary_category":"cs","categories":["cs.LO","cs.CR","cs.FL"],"authors":["Pinisetty Srinivas","Antignac Thibaud","Sands David","Schneider Gerardo"],"created":"2018-01-05","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02496","title":"Cumulant Generating Function of Codeword Lengths in Variable-Length\n  Lossy Compression Allowing Positive Excess Distortion Probability","abstract":"This paper considers the problem of variable-length lossy source coding. The\nperformance criteria are the excess distortion probability and the cumulant\ngenerating function of codeword lengths. We derive a non-asymptotic fundamental\nlimit of the cumulant generating function of codeword lengths allowing positive\nexcess distortion probability. It is shown that the achievability and converse\nbounds are characterized by the R\\'enyi entropy-based quantity. In the proof of\nthe achievability result, the explicit code construction is provided. Further,\nwe investigate an asymptotic single-letter characterization of the fundamental\nlimit for a stationary memoryless source.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Saito Shota","Matsushima Toshiyasu"],"created":"2018-01-05","updated":"2018-01-11","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02507","title":"Blockchain Technology as a Regulatory Technology: From Code is Law to\n  Law is Code","abstract":"\"Code is law\" refers to the idea that, with the advent of digital technology,\ncode has progressively established itself as the predominant way to regulate\nthe behavior of Internet users. Yet, while computer code can enforce rules more\nefficiently than legal code, it also comes with a series of limitations, mostly\nbecause it is difficult to transpose the ambiguity and flexibility of legal\nrules into a formalized language which can be interpreted by a machine. With\nthe advent of blockchain technology and associated smart contracts, code is\nassuming an even stronger role in regulating people's interactions over the\nInternet, as many contractual transactions get transposed into smart contract\ncode. In this paper, we describe the shift from the traditional notion of \"code\nis law\" (i.e. code having the effect of law) to the new conception of \"law is\ncode\" (i.e. law being defined as code).","primary_category":"cs","categories":["cs.CY","cs.DC"],"authors":["De Filippi Primavera","Hassan Samer"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02508","title":"Spiking memristor logic gates are a type of time-variant perceptron","abstract":"Memristors are low-power memory-holding resistors thought to be useful for\nneuromophic computing, which can compute via spike-interactions mediated\nthrough the device's short-term memory. Using interacting spikes, it is\npossible to build an AND gate that computes OR at the same time, similarly a\nfull adder can be built that computes the arithmetical sum of its inputs. Here\nwe show how these gates can be understood by modelling the memristors as a\nnovel type of perceptron: one which is sensitive to input order. The\nmemristor's memory can change the input weights for later inputs, and thus the\nmemristor gates cannot be accurately described by a single perceptron,\nrequiring either a network of time-invarient perceptrons or a complex\ntime-varying self-reprogrammable perceptron. This work demonstrates the high\nfunctionality of memristor logic gates, and also that the addition of\ntheasholding could enable the creation of a standard perceptron in hardware,\nwhich may have use in building neural net chips.","primary_category":"cs","categories":["cs.ET","cs.AR","cs.NE"],"authors":["Gale Ella M."],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02534","title":"Optimizing TCP Loss Recovery Performance Over Mobile Data Networks","abstract":"Recent advances in high-speed mobile networks have revealed new bottlenecks\nin ubiquitous TCP protocol deployed in the Internet. In addition to\ndifferentiating non-congestive loss from congestive loss, our experiments\nrevealed two significant performance bottlenecks during the loss recovery\nphase: flow control bottleneck and application stall, resulting in degradation\nin QoS performance. To tackle these two problems we firstly develop a novel\nopportunistic retransmission algorithm to eliminate the flow control\nbottleneck, which enables TCP sender to transmit new packets even if receiver's\nreceiving window is exhausted. Secondly, application stall can be significantly\nalleviated by carefully monitoring and tuning the TCP sending buffer growth\nmechanism. We implemented and modularized the proposed algorithms in the Linux\nkernel thus they can plug-and-play with the existing TCP loss recovery\nalgorithms easily. Using emulated experiments we showed that, compared to the\nexisting TCP loss recovery algorithms, the proposed optimization algorithms\nimprove the bandwidth efficiency by up to 133% and completely mitigate RTT\nspikes, i.e., over 50% RTT reduction, over the loss recovery phase.","primary_category":"cs","categories":["cs.NI"],"authors":["Liu Ke","Zha Zhongbin","Wan Wenkai","Aggarwal Vaneet","Fu Binzhang","Chen Mingyu"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02546","title":"Quality Control in Crowdsourcing: A Survey of Quality Attributes,\n  Assessment Techniques and Assurance Actions","abstract":"Crowdsourcing enables one to leverage on the intelligence and wisdom of\npotentially large groups of individuals toward solving problems. Common\nproblems approached with crowdsourcing are labeling images, translating or\ntranscribing text, providing opinions or ideas, and similar - all tasks that\ncomputers are not good at or where they may even fail altogether. The\nintroduction of humans into computations and\/or everyday work, however, also\nposes critical, novel challenges in terms of quality control, as the crowd is\ntypically composed of people with unknown and very diverse abilities, skills,\ninterests, personal objectives and technological resources. This survey studies\nquality in the context of crowdsourcing along several dimensions, so as to\ndefine and characterize it and to understand the current state of the art.\nSpecifically, this survey derives a quality model for crowdsourcing tasks,\nidentifies the methods and techniques that can be used to assess the attributes\nof the model, and the actions and strategies that help prevent and mitigate\nquality problems. An analysis of how these features are supported by the state\nof the art further identifies open issues and informs an outlook on hot future\nresearch directions.","primary_category":"cs","categories":["cs.HC"],"authors":["Daniel Florian","Kucherbaev Pavel","Cappiello Cinzia","Benatallah Boualem","Allahbakhsh Mohammad"],"created":"2018-01-08","updated":" ","doi":"10.1145\/3148148"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02548","title":"Bridging the Gap: Simultaneous Fine Tuning for Data Re-Balancing","abstract":"There are many real-world classification problems wherein the issue of data\nimbalance (the case when a data set contains substantially more samples for\none\/many classes than the rest) is unavoidable. While under-sampling the\nproblematic classes is a common solution, this is not a compelling option when\nthe large data class is itself diverse and\/or the limited data class is\nespecially small. We suggest a strategy based on recent work concerning limited\ndata problems which utilizes a supplemental set of images with similar\nproperties to the limited data class to aid in the training of a neural\nnetwork. We show results for our model against other typical methods on a\nreal-world synthetic aperture sonar data set. Code can be found at\ngithub.com\/JohnMcKay\/dataImbalance.","primary_category":"cs","categories":["cs.CV"],"authors":["McKay John","Gerg Isaac","Monga Vishal"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02571","title":"Tamarin: Concolic Disequivalence for MIPS","abstract":"Given two MIPS programs, when are they equivalent? At first glance, this is\ntricky to define, because of the unstructured nature of assembly code. We\npropose the use of alternating concolic execution to detect whether two\nprograms are disequivalent. We have implemented our approach in a tool called\nTamarin, which includes a MIPS emulator instrumented to record symbolic traces,\nas well as a concolic execution engine that integrates with the Z3 solver. We\nshow that Tamarin is able to reason about program disequivalence in a number of\nscenarios, without any a-priori knowledge about the MIPS programs under\nconsideration.","primary_category":"cs","categories":["cs.PL"],"authors":["Nieto Abel"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02592","title":"Simulations to Analyze Cellular Voting Systems for Side Effects of\n  Democratic Redistricting","abstract":"Motivated by the problem of partisan gerrymandering, we introduce an\nelectoral system for a representative democracy called democratic cellular\nvoting, designed to make modern packing and cracking strategies irrelevant by\nallowing districts to be influenced directly by voters through elections. We\nintroduce an example of a democratic cellular voting system, called CV0, that\nis suitable for dynamic modelling. We develop a modification of the theory of\ndiscrete Markov chains using the algebraic structure of the semiring\n$[0,\\infty]$, which is used as a space of correlation coefficients. We use this\nto measure voter preferences and model representatives, voters, and districts\nin computationally feasible models with a guarantee of long-term stability.","primary_category":"cs","categories":["physics.soc-ph","cs.MA","nlin.AO"],"authors":["Schoenbaum Lucius T."],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02598","title":"Codes induced by alternative codes","abstract":"Alternative codes, an extension of the notion of ordinary codes, have been\nfirst introduced and considered by P. T. Huy et al. in 2004. As seen below,\nevery alternative code, in its turn, defines an ordinary code. Such codes are\ncalled codes induced by alternative codes or alt-induced codes, for short. In\nthis paper we consider these alt-induced codes and subclasses of them. In\nparticular, characteristic properties of such codes are established, and an\nalgorithm to check whether a finite code is alt-induced or not is proposed.","primary_category":"cs","categories":["cs.FL"],"authors":["Hien Ngo Thi","Van Do Long"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02602","title":"Three Puzzles on Mathematics, Computation, and Games","abstract":"In this lecture I will talk about three mathematical puzzles involving\nmathematics and computation that have preoccupied me over the years. The first\npuzzle is to understand the amazing success of the simplex algorithm for linear\nprogramming. The second puzzle is about errors made when votes are counted\nduring elections. The third puzzle is: are quantum computers possible?","primary_category":"cs","categories":["math.CO","cs.CC","math.OC","quant-ph"],"authors":["Kalai Gil"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02603","title":"On strong alt-induced codes","abstract":"Strong alt-induced codes, a particular case of alt-induced codes, has been\nintroduced and considered by D. L. Van and the author in earlier papers. In\nthis note, an algorithm to check whether a regular code is strong alt-induced\nor not is proposed, and the embedding problem for the classes of prefix\n(suffix, bifix) strong alt-induced codes in both the finite and regular case is\nalso exhibited.","primary_category":"cs","categories":["cs.FL"],"authors":["Hien Ngo Thi"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02609","title":"Secure Beamforming in Full-Duplex SWIPT Systems With Loopback\n  Self-Interference Cancellation","abstract":"Security is a critical issue in full duplex (FD) communication systems due to\nthe broadcast nature of wireless channels. In this paper, joint design of\ninformation and artificial noise beamforming vectors is proposed for the FD\nsimultaneous wireless information and power transferring (FD-SWIPT) systems\nwith loopback self-interference cancellation. To guarantee high security and\nenergy harvesting performance of the FD-SWIPT system, the proposed design is\nformulated as a secrecy rate maximization problem under energy transfer rate\nconstraints. Although the secrecy rate maximization problem is non-convex, we\nsolve it via semidefinite relaxation and a two-dimensional search. We prove the\noptimality of our proposed algorithm and demonstrate its performance via\nsimulations.","primary_category":"cs","categories":["cs.NI","cs.IT","math.IT"],"authors":["Dong Yanjie","Shafie Ahmed El","Hossain Md. Jahangir","Cheng Julian","Al-Dhahir Naofal","Leung Victor C. M."],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02612","title":"Spatially Transformed Adversarial Examples","abstract":"Recent studies show that widely used deep neural networks (DNNs) are\nvulnerable to carefully crafted adversarial examples. Many advanced algorithms\nhave been proposed to generate adversarial examples by leveraging the\n$\\mathcal{L}_p$ distance for penalizing perturbations. Researchers have\nexplored different defense methods to defend against such adversarial attacks.\nWhile the effectiveness of $\\mathcal{L}_p$ distance as a metric of perceptual\nquality remains an active research area, in this paper we will instead focus on\na different type of perturbation, namely spatial transformation, as opposed to\nmanipulating the pixel values directly as in prior works. Perturbations\ngenerated through spatial transformation could result in large $\\mathcal{L}_p$\ndistance measures, but our extensive experiments show that such spatially\ntransformed adversarial examples are perceptually realistic and more difficult\nto defend against with existing defense systems. This potentially provides a\nnew direction in adversarial example generation and the design of corresponding\ndefenses. We visualize the spatial transformation based perturbation for\ndifferent examples and show that our technique can produce realistic\nadversarial examples with smooth image deformation. Finally, we visualize the\nattention of deep networks with different types of adversarial examples to\nbetter understand how these examples are interpreted.","primary_category":"cs","categories":["cs.CR","cs.CV","stat.ML"],"authors":["Xiao Chaowei","Zhu Jun-Yan","Li Bo","He Warren","Liu Mingyan","Song Dawn"],"created":"2018-01-08","updated":"2018-01-09","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02620","title":"A Machine Learning Framework for Register Placement Optimization in\n  Digital Circuit Design","abstract":"In modern digital circuit back-end design, designers heavily rely on\nelectronic-design-automoation (EDA) tool to close timing. However, the\nheuristic algorithms used in the place and route tool usually does not result\nin optimal solution. Thus, significant design effort is used to tune parameters\nor provide user constraints or guidelines to improve the tool performance. In\nthis paper, we targeted at those optimization space left behind by the EDA\ntools and propose a machine learning framework that helps to define what are\nthe guidelines and constraints for registers placement, which can yield better\nperformance and quality for back-end design. In other words, the framework is\ntrying to learn what are the flaws of the existing EDA tools and tries to\noptimize it by providing additional information. We discuss what is the proper\ninput feature vector to be extracted, and what is metric to be used for\nreference output. We also develop a scheme to generate perturbed training\nsamples using existing design based on Gaussian randomization. By applying our\nmethodology, we are able to improve the design runtime by up to 36% and timing\nquality by up to 23%.","primary_category":"cs","categories":["cs.LG"],"authors":["Airani Karthik","Guttal Rohit"],"created":"2018-01-06","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02621","title":"An Energy Conserving Routing Scheme for Wireless Body Sensor Nanonetwork\n  Communication","abstract":"Current developments in nanotechnology make electromagnetic communication\n(EC) possible at the nanoscale for applications involving Wireless [Body]\nSensor Networks (W[B]SNs). This specialized branch of WSN has emerged as an\nimportant research area contributing to medical treatment, social welfare, and\nsports. The concept is based on the interaction of integrated nanoscale\nmachines by means of wireless communications. One key hurdle for advancing\nnanocommunications is the lack of an apposite networking protocol to address\nthe upcoming needs of the nanonetworks. Recently, some key challenges have been\nidentified, such as nanonodes with extreme energy constraints, limited\ncomputational capabilities, Terahertz frequency bands with limited transmission\nrange, etc., in designing protocols for wireless nanosensor networks (WNN).\nThis work proposes an improved performance scheme of nanocommunication over\nTerahertz bands for wireless BSNs making it suitable for smart e-health\napplications. The scheme contains -- a new energy-efficient forwarding routine\nfor EC in WNN consisting of hybrid clusters with centralized scheduling, a\nmodel designed for channel behavior taking into account the aggregated impact\nof molecular absorption, spreading loss, and shadowing, and an energy model for\nenergy harvesting and consumption. The outage probability is derived for both\nsingle and multilinks and extended to determine the outage capacity. The outage\nprobability for a multilink is derived using a cooperative fusion technique at\na predefined fusion node. Simulated using a Nano-Sim simulator, performance of\nthe proposed model has been evaluated for energy efficiency, outage capacity,\nand outage probability. The results demonstrate the efficiency of the proposed\nscheme through maximized energy utilization in both single and multihop\ncommunication, multisensor fusion enhances the link quality of the\ntransmission.","primary_category":"cs","categories":["cs.NI"],"authors":["Afsana Fariha","Asif-Ur-Rahman Md.","Ahmed Muhammad R.","Mahmud Mufti","Kaiser M. Shamim"],"created":"2018-01-07","updated":" ","doi":"10.1109\/ACCESS.2018.2789437"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02651","title":"Towards General Distributed Resource Selection","abstract":"The advantages of distributing workloads and utilizing multiple distributed\nresources are now well established. The type and degree of heterogeneity of\ndistributed resources is increasing, and thus determining how to distribute the\nworkloads becomes increasingly difficult, in particular with respect to the\nselection of suitable resources. We formulate and investigate the resource\nselection problem in a way that it is agnostic of specific task and resource\nproperties, and which is generalizable to range of metrics. Specifically, we\ndeveloped a model to describe the requirements of tasks and to estimate the\ncost of running that task on an arbitrary resource using baseline measurements\nfrom a reference machine. We integrated our cost model with the Condor\nmatchmaking algorithm to enable resource selection. Experimental validation of\nour model shows that it provides execution time estimates with 157-171% error\non XSEDE resources and 18-31% on OSG resources. We use the task execution cost\nmodel to select resources for a bag-of-tasks of up to 1024 GROMACS MD\nsimulations across the target resources. Experiments show that using the\nmodel's estimates reduces the workload's time-to-completion up to ~85% when\ncompared to the random distribution of workload across the same resources.","primary_category":"cs","categories":["cs.DC"],"authors":["Ha Ming Tai","Turilli Matteo","Merzky Andre","Jha Shantenu"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02668","title":"Evorus: A Crowd-powered Conversational Assistant Built to Automate\n  Itself Over Time","abstract":"Crowd-powered conversational assistants have been shown to be more robust\nthan automated systems, but do so at the cost of higher response latency and\nmonetary costs. A promising direction is to combine the two approaches for high\nquality, low latency, and low cost solutions. In this paper, we introduce\nEvorus, a crowd-powered conversational assistant built to automate itself over\ntime by (i) allowing new chatbots to be easily integrated to automate more\nscenarios, (ii) reusing prior crowd answers, and (iii) learning to\nautomatically approve response candidates. Our 5-month-long deployment with 80\nparticipants and 281 conversations shows that Evorus can automate itself\nwithout compromising conversation quality. Crowd-AI architectures have long\nbeen proposed as a way to reduce cost and latency for crowd-powered systems;\nEvorus demonstrates how automation can be introduced successfully in a deployed\nsystem. Its architecture allows future researchers to make further innovation\non the underlying automated components in the context of a deployed open domain\ndialog system.","primary_category":"cs","categories":["cs.HC","cs.AI","cs.CL"],"authors":["Huang Ting-Hao 'Kenneth'","Chang Joseph Chee","Bigham Jeffrey P."],"created":"2018-01-08","updated":"2018-01-09","doi":"10.1145\/3173574.3173869"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02672","title":"Violable Contracts and Governance for Blockchain Applications","abstract":"We examine blockchain technologies, especially smart contracts, as a platform\nfor decentralized applications. By providing a basis for consensus, blockchain\npromises to upend business models that presuppose a central authority. However,\nblockchain suffers from major shortcomings arising from an over-regimented way\nof organizing computation that limits its prospects. We propose a\nsociotechnical, yet computational, perspective that avoids those shortcomings.\nA centerpiece of our vision is the notion of a declarative, violable contract\nin contradistinction to smart contracts. This new way of thinking enables\nflexible governance, by formalizing organizational structures; verification of\ncorrectness without obstructing autonomy; and a meaningful basis for trust.","primary_category":"cs","categories":["cs.CY","cs.MA"],"authors":["Singh Munindar P.","Chopra Amit K."],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02679","title":"Graph-Based Radio Resource Management for Vehicular Networks","abstract":"This paper investigates the resource allocation problem in device-to-device\n(D2D)-based vehicular communications, based on slow fading statistics of\nchannel state information (CSI), to alleviate signaling overhead for reporting\nrapidly varying accurate CSI of mobile links. We consider the case when each\nvehicle-to-infrastructure (V2I) link shares spectrum with multiple\nvehicle-to-vehicle (V2V) links. Leveraging the slow fading statistical CSI of\nmobile links, we maximize the sum V2I capacity while guaranteeing the\nreliability of all V2V links. We propose a graph-based algorithm that uses\ngraph partitioning tools to divide highly interfering V2V links into different\nclusters before formulating the spectrum sharing problem as a weighted\n3-dimensional matching problem, which is then solved through adapting a\nhigh-performance approximation algorithm.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Liang Le","Xie Shijie","Li Geoffrey Ye","Ding Zhi","Yu Xingxing"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02684","title":"Generative Sensing: Transforming Unreliable Sensor Data for Reliable\n  Recognition","abstract":"This paper introduces a deep learning enabled generative sensing framework\nwhich integrates low-end sensors with computational intelligence to attain a\nhigh recognition accuracy on par with that attained with high-end sensors. The\nproposed generative sensing framework aims at transforming low-end, low-quality\nsensor data into higher quality sensor data in terms of achieved classification\naccuracy. The low-end data can be transformed into higher quality data of the\nsame modality or into data of another modality. Different from existing methods\nfor image generation, the proposed framework is based on discriminative models\nand targets to maximize the recognition accuracy rather than a similarity\nmeasure. This is achieved through the introduction of selective feature\nregeneration in a deep neural network (DNN). The proposed generative sensing\nwill essentially transform low-quality sensor data into high-quality\ninformation for robust perception. Results are presented to illustrate the\nperformance of the proposed framework.","primary_category":"cs","categories":["cs.CV","eess.IV"],"authors":["Karam Lina","Borkar Tejas","Cao Yu","Chae Junseok"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02685","title":"P-MOD: Secure Privilege-Based Multilevel Organizational Data-Sharing in\n  Cloud Computing","abstract":"Cloud computing has changed the way enterprises store, access and share data.\nData is constantly being uploaded to the cloud and shared within an\norganization built on a hierarchy of many different individuals that are given\ncertain data access privileges. With more data storage needs turning over to\nthe cloud, finding a secure and efficient data access structure has become a\nmajor research issue. With different access privileges, individuals with more\nprivileges (at higher levels of the hierarchy) are granted access to more\nsensitive data than those with fewer privileges (at lower levels of the\nhierarchy). In this paper, a Privilege-based Multilevel Organizational\nData-sharing scheme~(P-MOD) is proposed that incorporates a privilege-based\naccess structure into an attribute-based encryption mechanism to handle these\nconcerns. Each level of the privilege-based access structure is affiliated with\nan access policy that is uniquely defined by specific attributes. Data is then\nencrypted under each access policy at every level to grant access to specific\ndata users based on their data access privileges. An individual ranked at a\ncertain level can decrypt the ciphertext (at that specific level) if and only\nif that individual owns a correct set of attributes that can satisfy the access\npolicy of that level. The user may also decrypt the ciphertexts at the lower\nlevels with respect to the user's level. Security analysis shows that P-MOD is\nsecure against adaptively chosen plaintext attack assuming the DBDH assumption\nholds.The comprehensive performance analysis demonstrates that P-MOD is more\nefficient in computational complexity and storage space than the existing\nschemes in secure data sharing within an organization.","primary_category":"cs","categories":["cs.CR"],"authors":["Zaghloul Ehab","Zhou Kai","Ren Jian"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02687","title":"Term Relevance Feedback for Contextual Named Entity Retrieval","abstract":"We address the role of a user in Contextual Named Entity Retrieval (CNER),\nshowing (1) that user identification of important context-bearing terms is\nsuperior to automated approaches, and (2) that further gains are possible if\nthe user indicates the relative importance of those terms. CNER is similar in\nspirit to List Question answering and Entity disambiguation. However, the main\nfocus of CNER is to obtain user feedback for constructing a profile for a class\nof entities on the fly and use that to retrieve entities from free text. Given\na sentence, and an entity selected from that sentence, CNER aims to retrieve\nsentences that have entities similar to query entity. This paper explores\nobtaining term relevance feedback and importance weighting from humans in order\nto improve a CNER system. We report our findings based on the efforts of IR\nresearchers as well as crowdsourced workers.","primary_category":"cs","categories":["cs.IR"],"authors":["Sarwar Sheikh Muhammad","Foley John","Allan James"],"created":"2018-01-08","updated":" ","doi":"10.1145\/3176349.3176886"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02690","title":"DCASE 2017 Task 1: Acoustic Scene Classification Using Shift-Invariant\n  Kernels and Random Features","abstract":"Acoustic scene recordings are represented by different types of handcrafted\nor Neural Network-derived features. These features, typically of thousands of\ndimensions, are classified in state of the art approaches using kernel\nmachines, such as the Support Vector Machines (SVM). However, the complexity of\ntraining these methods increases with the dimensionality of these input\nfeatures and the size of the dataset. A solution is to map the input features\nto a randomized lower-dimensional feature space. The resulting random features\ncan approximate non-linear kernels with faster linear kernel computation. In\nthis work, we computed a set of 6,553 input features and used them to compute\nrandom features to approximate three types of kernels, Gaussian, Laplacian and\nCauchy. We compared their performance using an SVM in the context of the DCASE\nTask 1 - Acoustic Scene Classification. Experiments show that both, input and\nrandom features outperformed the DCASE baseline by an absolute 4%. Moreover,\nthe random features reduced the dimensionality of the input by more than three\ntimes with minimal loss of performance and by more than six times and still\noutperformed the baseline. Hence, random features could be employed by state of\nthe art approaches to compute low-storage features and perform faster kernel\ncomputations.","primary_category":"cs","categories":["cs.SD","eess.AS"],"authors":["Jimenez Abelino","Elizalde Benjamin","Raj Bhiksha"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02691","title":"A Trip to the Moon: Personalized Animated Movies for Self-reflection","abstract":"Self-tracking physiological and psychological data poses the challenge of\npresentation and interpretation. Insightful narratives for self-tracking data\ncan motivate the user towards constructive self-reflection. One powerful form\nof narrative that engages audience across various culture and age groups is\nanimated movies. We collected a week of self-reported mood and behavior data\nfrom each user and created in Unity a personalized animation based on their\ndata. We evaluated the impact of their video in a randomized control trial with\na non-personalized animated video as control. We found that personalized videos\ntend to be more emotionally engaging, encouraging greater and lengthier writing\nthat indicated self-reflection about moods and behaviors, compared to\nnon-personalized control videos.","primary_category":"cs","categories":["cs.HC"],"authors":["Peng Fengjiao","LaBelle Veronica","Yue Emily","Picard Rosalind"],"created":"2018-01-08","updated":" ","doi":"10.1145\/3173574.3173827"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02693","title":"Stable Marriage with Multi-Modal Preferences","abstract":"We introduce a generalized version of the famous Stable Marriage problem, now\nbased on multi-modal preference lists. The central twist herein is to allow\neach agent to rank its potentially matching counterparts based on more than one\n\"evaluation mode\" (e.g., more than one criterion); thus, each agent is equipped\nwith multiple preference lists, each ranking the counterparts in a possibly\ndifferent way. We introduce and study three natural concepts of stability,\ninvestigate their mutual relations and focus on computational complexity\naspects with respect to computing stable matchings in these new scenarios.\nMostly encountering computational hardness (NP-hardness), we can also spot few\nislands of tractability and make a surprising connection to the \\textsc{Graph\nIsomorphism} problem.","primary_category":"cs","categories":["cs.MA","cs.DS"],"authors":["Chen Jiehua","Niedermeier Rolf","Skowron Piotr"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02710","title":"Modeling urbanization patterns with generative adversarial networks","abstract":"In this study we propose a new method to simulate hyper-realistic urban\npatterns using Generative Adversarial Networks trained with a global urban\nland-use inventory. We generated a synthetic urban \"universe\" that\nqualitatively reproduces the complex spatial organization observed in global\nurban patterns, while being able to quantitatively recover certain key\nhigh-level urban spatial metrics.","primary_category":"cs","categories":["cs.LG"],"authors":["Albert Adrian","Strano Emanuele","Kaur Jasleen","Gonzalez Marta"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02722","title":"End-to-end detection-segmentation network with ROI convolution","abstract":"We propose an end-to-end neural network that improves the segmentation\naccuracy of fully convolutional networks by incorporating a localization unit.\nThis network performs object localization first, which is then used as a cue to\nguide the training of the segmentation network. We test the proposed method on\na segmentation task of small objects on a clinical dataset of ultrasound\nimages. We show that by jointly learning for detection and segmentation, the\nproposed network is able to improve the segmentation accuracy compared to only\nlearning for segmentation.","primary_category":"cs","categories":["cs.CV"],"authors":["Zhang Zichen","Tang Min","Cobzas Dana","Zonoobi Dornoosh","Jagersand Martin","Jaremko Jacob L."],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02726","title":"Near Maximum Likelihood Decoding with Deep Learning","abstract":"A novel and efficient neural decoder algorithm is proposed. The proposed\ndecoder is based on the neural Belief Propagation algorithm and the\nAutomorphism Group. By combining neural belief propagation with permutations\nfrom the Automorphism Group we achieve near maximum likelihood performance for\nHigh Density Parity Check codes. Moreover, the proposed decoder significantly\nimproves the decoding complexity, compared to our earlier work on the topic. We\nalso investigate the training process and show how it can be accelerated.\nSimulations of the hessian and the condition number show why the learning\nprocess is accelerated. We demonstrate the decoding algorithm for various\nlinear block codes of length up to 63 bits.","primary_category":"cs","categories":["cs.IT","cs.NE","math.IT"],"authors":["Nachmani Eliya","Bachar Yaron","Marciano Elad","Burshtein David","Be'ery Yair"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02730","title":"Data Augmentation for Brain-Computer Interfaces: Analysis on\n  Event-Related Potentials Data","abstract":"On image data, data augmentation is becoming less relevant due to the large\namount of available training data and regularization techniques. Common\napproaches are moving windows (cropping), scaling, affine distortions, random\nnoise, and elastic deformations. For electroencephalographic data, the lack of\nsufficient training data is still a major issue. We suggest and evaluate\ndifferent approaches to generate augmented data using temporal and\nspatial\/rotational distortions. Our results on the perception of rare stimuli\n(P300 data) and movement prediction (MRCP data) show that these approaches are\nfeasible and can significantly increase the performance of signal processing\nchains for brain-computer interfaces by 1% to 6%.","primary_category":"cs","categories":["cs.CV","q-bio.NC"],"authors":["Krell Mario Michael","Seeland Anett","Kim Su Kyoung"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02741","title":"Towards Stability Analysis of Data Transport Mechanisms: a Fluid Model\n  and an Application","abstract":"The Transmission Control Protocol (TCP) utilizes congestion avoidance and\ncontrol mechanisms as a preventive measure against congestive collapse and as\nan adaptive measure in the presence of changing network conditions. The set of\navailable congestion control algorithms is diverse, and while many have been\nstudied from empirical and simulation perspectives, there is a notable lack of\nanalytical work for some variants. To gain more insight into the dynamics of\nthese algorithms, we: (1) propose a general modeling scheme consisting of a set\nof functional differential equations of retarded type (RFDEs) and of the\ncongestion window as a function of time; (2) apply this scheme to TCP Reno and\ndemonstrate its equivalence to a previous, well known model for TCP Reno; (3)\nshow an application of the new framework to the widely-deployed congestion\ncontrol algorithm TCP CUBIC, for which analytical models are few and limited;\nand (4) validate the model using simulations. Our modeling framework yields a\nfluid model for TCP CUBIC. From a theoretical analysis of this model, we\ndiscover that TCP CUBIC is locally uniformly asymptotically stable -- a\nproperty of the algorithm previously unknown.","primary_category":"cs","categories":["cs.NI"],"authors":["Vardoyan Gayane","Hollot C. V.","Towsley Don"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02743","title":"Enhancing Performance of Random Caching in Large-Scale Wireless Networks\n  with Multiple Receive Antennas","abstract":"To improve signal-to-interference ratio (SIR) and make better use of file\ndiversity provided by random caching, we consider two types of linear\nreceivers, i.e., maximal ratio combining (MRC) receiver and partial zero\nforcing (PZF) receiver, at users in a large-scale cache-enabled single-input\nmulti-output (SIMO) network. First, for each receiver, by utilizing tools from\nstochastic geometry, we derive a tractable expression and a tight upper bound\nfor the successful transmission probability (STP). In the case of the MRC\nreceiver, we also derive a closed-form expression for the asymptotic outage\nprobability in the low SIR threshold regime. Then, for each receiver, we\nmaximize the STP. In the case of the MRC receiver, we consider the maximization\nof the tight upper bound on the STP by optimizing the caching distribution,\nwhich is a non-convex problem. We obtain a stationary point, by solving an\nequivalent difference of convex (DC) programming problem using concave-convex\nprocedure (CCCP). We also obtain a closed-form asymptotically optimal solution\nin the low SIR threshold regime. In the case of the PZF receiver, we consider\nthe maximization of the tight upper bound on the STP by optimizing the caching\ndistribution and the degrees of freedom (DoF) allocation (for boosting the\nsignal power), which is a mixed discrete-continuous problem. Based on\nstructural properties, we obtain a low-complexity near optimal solution by\nusing an alternating optimization approach. The analysis and optimization\nresults reveal the impact of antenna resource at users on random caching.\nFinally, by numerical results, we show that the random caching design with the\nPZF receiver achieves significant performance gains over the random caching\ndesign with the MRC receiver and some baseline caching designs.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Jiang Dongdong","Cui Ying"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02746","title":"Fusion of ANN and SVM Classifiers for Network Attack Detection","abstract":"With the progressive increase of network application and electronic devices\n(computers, mobile phones, android, etc.) attack and intrusion, detection has\nbecome a very challenging task in cybercrime detection area. in this context,\nmost of the existing approaches of attack detection rely mainly on a finite set\nof attacks. These solutions are vulnerable, that is, they fail in detecting\nsome attacks when sources of informations are ambiguous or imperfect. However,\nfew approaches started investigating in this direction. This paper investigates\nthe role of machine learning approach (ANN, SVM) in detecting a TCP connection\ntraffic as a normal or a suspicious one. But, using ANN and SVM is an expensive\ntechnique individually. In this paper, combining two classifiers are proposed,\nwhere artificial neural network (ANN) classifier and support vector machine\n(SVM) are both employed. Additionally, our proposed solution allows to\nvisualize obtained classification results. Accuracy of the proposed solution\nhas been compared with other classifier results. Experiments have been\nconducted with different network connections selected from NSL-KDD DARPA\ndataset. Empirical results show that combining ANN and SVM techniques for\nattack detection is a promising direction.","primary_category":"cs","categories":["cs.CR","cs.LG"],"authors":["Omrani Takwa","Dallali Adel","Rhaimi Bilgacem Chibani","Fattahi Jaouhar"],"created":"2018-01-08","updated":"2018-01-09","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02781","title":"Minimum Throughput Maximization in UAV-Aided Wireless Powered\n  Communication Networks","abstract":"This paper investigates unmanned aerial vehicle (UAV)-aided wireless powered\ncommunication network (WPCN) systems where a mobile access point (AP) at the\nUAV serves multiple energy-constrained ground terminals (GTs). Specifically,\nthe UAVs first charge the GTs by transmitting the wireless energy transfer\n(WET) signals in the downlink. Then, by utilizing the harvested wireless energy\nfrom the UAVs, the GTs send their uplink wireless information transmission\n(WIT) signals to the UAVs. In this paper, depending on the operations of the\nUAVs, we adopt two different scenarios, namely integrated UAV and separated UAV\nWPCNs. First, in the integrated UAV WPCN, a UAV acts as a hybrid AP in which\nboth energy transfer and information reception are processed at a single UAV.\nIn contrast, for the separated UAV WPCN, we consider two UAVs each of which\nbehaves as an energy AP and an information AP independently, and thus the\nenergy transfer and the information decoding are separately performed at two\ndifferent UAVs. For both systems, we jointly optimize the trajectories of the\nUAVs, the uplink power control, and the time resource allocation for the WET\nand the WIT to maximize the minimum throughput of the GTs. Since the formulated\nproblems are non-convex, we apply the concave-convex procedure by deriving\nappropriate convex bounds for non-convex constraints. As a result, we propose\niterative algorithms which efficiently identify a local optimal solution for\nthe minimum throughput maximization problems. Simulation results verify the\nefficiency of the proposed algorithms compared to conventional schemes.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Park Junhee","Lee Hoon","Eom Subin","Lee Inkyu"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02782","title":"UAV-Aided Wireless Communication Designs With Propulsion Energy\n  Limitations","abstract":"This paper studies unmanned aerial vehicle (UAV) aided wireless communication\nsystems where a UAV supports uplink communications of multiple ground nodes\n(GNs) while flying over the area of the interest. In this system, the\npropulsion energy consumption at the UAV is taken into account so that the\nUAV's velocity and acceleration should not exceed a certain threshold. We\nformulate the minimum average rate maximization problem and the energy\nefficiency (EE) maximization problem by jointly optimizing the trajectory,\nvelocity, and acceleration of the UAV and the uplink transmit power at the GNs.\nAs these problems are non-convex in general, we employ the successive convex\napproximation (SCA) techniques. To this end, proper convex approximations for\nthe non-convex constraints are derived, and iterative algorithms are proposed\nwhich converge to a local optimal point. Numerical results demonstrate that the\nproposed algorithms outperform baseline schemes for both problems. Especially\nfor the EE maximization problem, the proposed algorithm exhibits about 109 %\ngain over the baseline scheme.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Eom Subin","Lee Hoon","Park Junhee","Lee Inkyu"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02788","title":"Sequential Preference-Based Optimization","abstract":"Many real-world engineering problems rely on human preferences to guide their\ndesign and optimization. We present PrefOpt, an open source package to simplify\nsequential optimization tasks that incorporate human preference feedback. Our\napproach extends an existing latent variable model for binary preferences to\nallow for observations of equivalent preference from users.","primary_category":"cs","categories":["cs.LG","cs.CE","cs.HC","stat.ML"],"authors":["Dewancker Ian","Bauer Jakob","McCourt Michael"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02789","title":"An efficient and secure two-party key agreement protocol based on\n  chaotic maps","abstract":"Secure communication is a matter of genuine concern that includes means\nwhereby entities can share information without a third party's interception.\nKey agreement protocols are one of the common approaches in which two or more\nparties can agree upon a key, which precludes undesired third parties from\nforcing a key choice on them. Over the past decade, chaos-based key agreement\nprotocols have been studied and employed widely. Recently, Yoon and Jeon\nproposed a novel key agreement protocol based on chaotic maps and claimed\nsecurity and practicality for their protocol. We find that Yoon-Jeon's protocol\nsuffers certain issues: (1) It introduces a trusted third party whose very\npresence increases the implementation cost. (2) requires a multiplicity of\nencryption\/decryption computations and (3) does not protect the user's\nanonymity. In order to overcome these problems, we present an enhanced key\nagreement protocol with user anonymity. Theoretical analysis demonstrates that\nthe proposed protocol is efficient and resists current attacks.","primary_category":"cs","categories":["cs.CR"],"authors":["Yahyapoor Nahid","Yaghoobian Hamed","Keshtgari Manijeh"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02797","title":"Dendritic-Inspired Processing Enables Bio-Plausible STDP in Compound\n  Binary Synapses","abstract":"Brain-inspired learning mechanisms, e.g. spike timing dependent plasticity\n(STDP), enable agile and fast on-the-fly adaptation capability in a spiking\nneural network. When incorporating emerging nanoscale resistive non-volatile\nmemory (NVM) devices, with ultra-low power consumption and high-density\nintegration capability, a spiking neural network hardware would result in\nseveral orders of magnitude reduction in energy consumption at a very small\nform factor and potentially herald autonomous learning machines. However,\nactual memory devices have shown to be intrinsically binary with stochastic\nswitching, and thus impede the realization of ideal STDP with continuous analog\nvalues. In this work, a dendritic-inspired processing architecture is proposed\nin addition to novel CMOS neuron circuits. The utilization of spike\nattenuations and delays transforms the traditionally undesired stochastic\nbehavior of binary NVMs into a useful leverage that enables\nbiologically-plausible STDP learning. As a result, this work paves a pathway to\nadopt practical binary emerging NVM devices in brain-inspired neuromorphic\ncomputing.","primary_category":"cs","categories":["cs.NE","cs.ET"],"authors":["Wu Xinyu","Saxena Vishal"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02808","title":"Lifelong Learning for Sentiment Classification","abstract":"This paper proposes a novel lifelong learning (LL) approach to sentiment\nclassification. LL mimics the human continuous learning process, i.e.,\nretaining the knowledge learned from past tasks and use it to help future\nlearning. In this paper, we first discuss LL in general and then LL for\nsentiment classification in particular. The proposed LL approach adopts a\nBayesian optimization framework based on stochastic gradient descent. Our\nexperimental results show that the proposed method outperforms baseline methods\nsignificantly, which demonstrates that lifelong learning is a promising\nresearch direction.","primary_category":"cs","categories":["cs.CL","cs.IR","cs.LG"],"authors":["Chen Zhiyuan","Ma Nianzu","Liu Bing"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02811","title":"Wi-Fi Teeter-Totter: Overclocking OFDM for Internet of Things","abstract":"The conventional high-speed Wi-Fi has recently become a contender for\nlow-power Internet-of-Things (IoT) communications. OFDM continues its adoption\nin the new IoT Wi-Fi standard due to its spectrum efficiency that can support\nthe demand of massive IoT connectivity. While the IoT Wi-Fi standard offers\nmany new features to improve power and spectrum efficiency, the basic physical\nlayer (PHY) structure of transceiver design still conforms to its conventional\ndesign rationale where access points (AP) and clients employ the same OFDM PHY.\nIn this paper, we argue that current Wi-Fi PHY design does not take full\nadvantage of the inherent asymmetry between AP and IoT. To fill the gap, we\npropose an asymmetric design where IoT devices transmit uplink packets using\nthe lowest power while pushing all the decoding burdens to the AP side. Such a\ndesign utilizes the sufficient power and computational resources at AP to trade\nfor the transmission (TX) power of IoT devices. The core technique enabling\nthis asymmetric design is that the AP takes full power of its high clock rate\nto boost the decoding ability. We provide an implementation of our design and\nshow that it can reduce the IoT's TX power by boosting the decoding capability\nat the receivers.","primary_category":"cs","categories":["cs.NI"],"authors":["Wang Wei","He Shiyue","Yang Lin","Zhang Qian","Jiang Tao"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02815","title":"A Planar Tracking Game with Sensing Delays and its MATLAB Implementation","abstract":"This paper proposes a new perspective on the conventional planar target\ntracking problem. One evader and one pursuer are considered in the dynamics. In\nthe planar tracking, pursuer has the ability to measure the position and the\nvelocity information of the evader but with sensing delays. The modeling and\nthe controller design of the system are presented with details. Then, a\ncomputer game is developed and implemented using MATLAB\/Simulink, which\nconstitutes the main contribution of the paper.","primary_category":"cs","categories":["cs.SY"],"authors":["Yu Nan","Yang Chifu","Li Miao"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02816","title":"Adaptive Boolean Monotonicity Testing in Total Influence Time","abstract":"The problem of testing monotonicity of a Boolean function $f:\\{0,1\\}^n \\to\n\\{0,1\\}$ has received much attention recently. Denoting the proximity parameter\nby $\\varepsilon$, the best tester is the non-adaptive\n$\\widetilde{O}(\\sqrt{n}\/\\varepsilon^2)$ tester of Khot-Minzer-Safra (FOCS\n2015). Let $I(f)$ denote the total influence of $f$. We give an adaptive tester\nwhose running time is $I(f)poly(\\varepsilon^{-1}\\log n)$.","primary_category":"cs","categories":["cs.DS","cs.CC","cs.DM"],"authors":["Chakrabarty Deeparnab","Seshadhri C."],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02818","title":"k-connectivity of Random Graphs and Random Geometric Graphs in Node\n  Fault Model","abstract":"k-connectivity of random graphs is a fundamental property indicating\nreliability of multi-hop wireless sensor networks (WSN). WSNs comprising of\nsensor nodes with limited power resources are modeled by random graphs with\nunreliable nodes, which is known as the node fault model. In this paper, we\ninvestigate k-connectivity of random graphs in the node fault model by\nevaluating the network breakdown probability, i.e., the disconnectivity\nprobability of random graphs after stochastic node removals. Using the notion\nof a strongly typical set, we obtain universal asymptotic upper and lower\nbounds of the network breakdown probability. The bounds are applicable both to\nrandom graphs and to random geometric graphs. We then consider three\nrepresentative random graph ensembles: the Erdos-Renyi random graph as the\nsimplest case, the random intersection graph for WSNs with random key\npredistribution schemes, and the random geometric graph as a model of WSNs\ngenerated by random sensor node deployment. The bounds unveil the existence of\nthe phase transition of the network breakdown probability for those ensembles.","primary_category":"cs","categories":["cs.IT","cs.SI","math.IT","physics.soc-ph"],"authors":["Takabe Satoshi","Wadayama Tadashi"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02830","title":"Beam domain secure transmission for massive MIMO communications","abstract":"We investigate the optimality and power allocation algorithm of beam domain\ntransmission for single-cell massive multiple-input multiple-output (MIMO)\nsystems with a multi-antenna passive eavesdropper. Focusing on the secure\nmassive MIMO downlink transmission with only statistical channel state\ninformation of legitimate users and the eavesdropper at base station, we\nintroduce a lower bound on the achievable ergodic secrecy sum-rate, from which\nwe derive the condition for eigenvectors of the optimal input covariance\nmatrices. The result shows that beam domain transmission can achieve optimal\nperformance in terms of secrecy sum-rate lower bound maximization. For the case\nof single-antenna legitimate users, we prove that it is optimal to allocate no\npower to the beams where the beam gains of the eavesdropper are stronger than\nthose of legitimate users in order to maximize the secrecy sum-rate lower\nbound. Then, motivated by the concave-convex procedure and the large dimension\nrandom matrix theory, we develop an efficient iterative and convergent\nalgorithm to optimize power allocation in the beam domain. Numerical\nsimulations demonstrate the tightness of the secrecy sum-rate lower bound and\nthe near-optimal performance of the proposed iterative algorithm.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Wu Wenqian","Gao Xiqi","Wu Yongpeng","Xiao Chengshan"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02832","title":"Biomedical Question Answering via Weighted Neural Network Passage\n  Retrieval","abstract":"The amount of publicly available biomedical literature has been growing\nrapidly in recent years, yet question answering systems still struggle to\nexploit the full potential of this source of data. In a preliminary processing\nstep, many question answering systems rely on retrieval models for identifying\nrelevant documents and passages. This paper proposes a weighted cosine distance\nretrieval scheme based on neural network word embeddings. Our experiments are\nbased on publicly available data and tasks from the BioASQ biomedical question\nanswering challenge and demonstrate significant performance gains over a wide\nrange of state-of-the-art models.","primary_category":"cs","categories":["cs.IR","cs.AI","cs.CL"],"authors":["Galk\u00f3 Ferenc","Eickhoff Carsten"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02833","title":"Connecting the World of Embedded Mobiles: The RIOT Approach to\n  Ubiquitous Networking for the Internet of Things","abstract":"The Internet of Things (IoT) is rapidly evolving based on low-power compliant\nprotocol standards that extend the Internet into the embedded world. Pioneering\nimplementations have proven it is feasible to inter-network very constrained\ndevices, but had to rely on peculiar cross-layered designs and offer a\nminimalistic set of features. In the long run, however, professional use and\nmassive deployment of IoT devices require full-featured, cleanly composed, and\nflexible network stacks.\n  This paper introduces the networking architecture that turns RIOT into a\npowerful IoT system, to enable low-power wireless scenarios. RIOT networking\noffers (i) a modular architecture with generic interfaces for plugging in\ndrivers, protocols, or entire stacks, (ii) support for multiple heterogeneous\ninterfaces and stacks that can concurrently operate, and (iii) GNRC, its\ncleanly layered, recursively composed default network stack. We contribute an\nin-depth analysis of the communication performance and resource efficiency of\nRIOT, both on a micro-benchmarking level as well as by comparing IoT\ncommunication across different platforms. Our findings show that, though it is\nbased on significantly different design trade-offs, the networking subsystem of\nRIOT achieves a performance equivalent to that of Contiki and TinyOS, the two\noperating systems which pioneered IoT software platforms.","primary_category":"cs","categories":["cs.NI","cs.OS"],"authors":["Lenders Martine","Kietzmann Peter","Hahm Oliver","Petersen Hauke","G\u00fcndo\u011fan Cenk","Baccelli Emmanuel","Schleiser Kaspar","Schmidt Thomas C.","W\u00e4hlisch Matthias"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02837","title":"Malware detection techniques for mobile devices","abstract":"Mobile devices have become very popular nowadays, due to its portability and\nhigh performance, a mobile device became a must device for persons using\ninformation and communication technologies. In addition to hardware rapid\nevolution, mobile applications are also increasing in their complexity and\nperformance to cover most needs of their users. Both software and hardware\ndesign focused on increasing performance and the working hours of a mobile\ndevice. Different mobile operating systems are being used today with different\nplatforms and different market shares. Like all information systems, mobile\nsystems are prone to malware attacks. Due to the personality feature of mobile\ndevices, malware detection is very important and is a must tool in each device\nto protect private data and mitigate attacks. In this paper, analysis of\ndifferent malware detection techniques used for mobile operating systems is\nprovides. The focus of the analysis will be on the to two competing mobile\noperating systems - Android and iOS. Finally, an assessment of each technique\nand a summary of its advantages and disadvantages is provided. The aim of the\nwork is to establish a basis for developing a mobile malware detection tool\nbased on user profiling.","primary_category":"cs","categories":["cs.CR"],"authors":["Amro Bela"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02853","title":"An enhanced Multipath Strategy in Mobile Ad hoc Routing Protocols","abstract":"The various routing protocols in Mobile Ad hoc Networks follow different\nstrategies to send the information from one node to another. The nodes in the\nnetwork are non static and they move randomly and are prone to link failure\nwhich makes always to find new routes to the destination. This research mainly\nfocused on the study of the characteristics of multipath routing protocols in\nMANETS. Two of the multipath routing protocols were investigated and a\ncomparative study along with simulation using NS2 was done between DSR and AODV\nto propose an enhanced approach to reach the destination maintaining the QoS. A\npossible optimization to the DSR and AODV routing protocols was proposed to\nmake no node to be overburdened by distributing the load after finding the\nalternate multipath routes which were discovered in the Route discovery\nprocess. The simulation shows that the differences in the protocol highlighted\nmajor differences with the protocol performance. These differences have been\nanalyzed with various network size, mobility, and network load. A new search\ntable named Search of Next Node Enquiry Table (SONNET) was proposed to find the\nbest neighbor node. Using SONNET the node selects the neighbor which can be\nreached in less number of hops and with less time delay and maintaining the\nQoS.","primary_category":"cs","categories":["cs.NI"],"authors":["Alfawaer Zeyad M.","Belgaum Mohammad Riyaz"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02860","title":"Channel Estimation with Systematic Polar Codes","abstract":"Study of polar codes in fading channels is of great importance when applying\npolar codes in wireless communications. Channel estimation is a fundamental\nstep for communication to be possible in fading channels. For both systematic\nand non-systematic polar codes, construction of them is based on an information\nset and the known frozen bits. Efficient implementation of systematic and\nnon-systematic polar codes exists. When it comes to channel estimation or\nchannel tracking, additional pilot symbols are inserted in the codeword\ntraditionally. In this paper, to improve the performance of polar codes in the\nfinite domain, pilot symbols are selected from the coded symbols themselves. In\norder to keep the existing efficient structure of polar code encoding, pilot\nselection is critical since not all selections can reuse the existing\nstructure. In this paper, two pilot selections denoted as Uneven Pilot\nSelection (UEPS) and Even Pilot Selection (EPS) are proposed, which do not\nchange the efficient polar encoding structure. The proposed UEPS and EPS is\nproven to satisfy the efficient construction condition. The performance of EPS\nis shown in this paper to outperform both the UEPS and the traditional pilot\ninsertion scheme. Simulation results are provided which verify the performance\nof the proposed pilot selection schemes.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Li Liping","Xu Zuzheng","Hu Yanjun"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02868","title":"Linear Codes for Broadcasting with Noisy Side Information","abstract":"We consider network coding for a noiseless broadcast channel where each\nreceiver demands a subset of messages available at the transmitter and is\nequipped with noisy side information in the form an erroneous version of the\nmessage symbols it demands. We view the message symbols as elements from a\nfinite field and assume that the number of symbol errors in the noisy side\ninformation is upper bounded by a known constant. This communication problem,\nwhich we refer to as 'broadcasting with noisy side information' (BNSI), has\napplications in the re-transmission phase of downlink networks. We derive a\nnecessary and sufficient condition for a linear coding scheme to satisfy the\ndemands of all the receivers in a given BNSI network, and show that syndrome\ndecoding can be used at the receivers to decode the demanded messages from the\nreceived codeword and the available noisy side information. We represent BNSI\nproblems as bipartite graphs, and using this representation, classify the\nfamily of problems where linear coding provides bandwidth savings compared to\nuncoded transmission. We provide a simple algorithm to determine if a given\nBNSI network belongs to this family of problems, i.e., to identify if linear\ncoding provides an advantage over uncoded transmission for the given BNSI\nproblem. We provide lower bounds and upper bounds on the optimal codelength and\nconstructions of linear coding schemes based on linear error correcting codes.\nFor any given BNSI problem, we construct an equivalent index coding problem. A\nlinear code is a valid scheme for a BNSI problem if and only if it is valid for\nthe constructed index coding problem.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Ghosh Suman","Natarajan Lakshmi"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02875","title":"Multi-Terminal Codes Using Constrained-Random-Number Generators","abstract":"A general multi-terminal source code and a general multi-terminal channel\ncode are presented. Constrained-random-number generators with sparse matrices,\nwhich are building blocks for the code construction, are used in the\nconstruction of both encoders and decoders. Achievable regions for source\ncoding and channel coding are derived in terms of entropy functions, where the\ncapacity region for channel coding provides an alternative to the region of\n[Somekh-Baruch and Verd\\'u, ISIT2006].","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Muramatsu Jun","Miyake Shigeki"],"created":"2018-01-09","updated":"2018-01-10","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02888","title":"Analysis of Massive MIMO and Base Station Cooperation in an Indoor\n  Scenario","abstract":"The performance of centralized and distributed massive MIMO deployments are\nanalyzed for indoor office scenarios. The distributed deployments use one of\nthe following precoding methods: (1) local precoding with local channel state\ninformation (CSI) to the user equipments (UEs) that it serves; (2) large-scale\nMIMO with local CSI to all UEs in the network; (3) network MIMO with global\nCSI. For the distributed deployments (2) and (3), it is shown that using twice\nas many base station antennas as data streams provides many of the massive MIMO\nbenefits in terms of spectral efficiency and fairness. This is in contrast to\nthe centralized deployment and the distributed deployment (1) where more\nantennas are needed. Two of the main conclusions are that distributing base\nstations helps to overcome wall penetration loss; however, a backhaul is\nrequired to mitigate inter-cell interference. The effect of estimation errors\non the performance is also quantified.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Dierks Stefan","Kramer Gerhard","Panzner Berthold","Zirwas Wolfgang"],"created":"2018-01-09","updated":"2018-01-10","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02889","title":"Optimal Content Replication and Request Matching in Large Caching\n  Systems","abstract":"We consider models of content delivery networks in which the servers are\nconstrained by two main resources: memory and bandwidth. In such systems, the\nthroughput crucially depends on how contents are replicated across servers and\nhow the requests of specific contents are matched to servers storing those\ncontents. In this paper, we first formulate the problem of computing the\noptimal replication policy which if combined with the optimal matching policy\nmaximizes the throughput of the caching system in the stationary regime. It is\nshown that computing the optimal replication policy for a given system is an\nNP-hard problem. A greedy replication scheme is proposed and it is shown that\nthe scheme provides a constant factor approximation guarantee. We then propose\na simple randomized matching scheme which avoids the problem of interruption in\nservice of the ongoing requests due to re-assignment or repacking of the\nexisting requests in the optimal matching policy. The dynamics of the caching\nsystem is analyzed under the combination of proposed replication and matching\nschemes. We study a limiting regime, where the number of servers and the\narrival rates of the contents are scaled proportionally, and show that the\nproposed policies achieve asymptotic optimality. Extensive simulation results\nare presented to evaluate the performance of different policies and study the\nbehavior of the caching system under different service time distributions of\nthe requests.","primary_category":"cs","categories":["cs.PF"],"authors":["Mukhopadhyay Arpan","Hegde Nidhi","Lelarge Marc"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02903","title":"Polarization of the Vaccination Debate on Facebook","abstract":"Vaccine hesitancy has been recognized as a major global health threat. Having\naccess to any type of information in social media has been suggested as a\npotential powerful influence factor to hesitancy. Recent studies in other\nfields than vaccination show that access to a wide amount of content through\nthe Internet without intermediaries resolved into major segregation of the\nusers in polarized groups. Users select the information adhering to theirs\nsystem of beliefs and tend to ignore dissenting information. In this paper we\nassess whether there is polarization in Social Media use in the field of\nvaccination. We perform a thorough quantitative analysis on Facebook analyzing\n2.6M users interacting with 298.018 posts over a time span of seven years and 5\nmonths. We used community detection algorithms to automatically detect the\nemergent communities from the users activity and to quantify the cohesiveness\nover time of the communities. Our findings show that content consumption about\nvaccines is dominated by the echo-chamber effect and that polarization\nincreased over years. Communities emerge from the users consumption habits,\ni.e. the majority of users only consumes information in favor or against\nvaccines, not both. The existence of echo-chambers may explain why social-media\ncampaigns providing accurate information may have limited reach, may be\neffective only in sub-groups and might even foment further polarization of\nopinions. The introduction of dissenting information into a sub-group is\ndisregarded and can have a backfire effect, further reinforcing the existing\nopinions within the sub-group.","primary_category":"cs","categories":["cs.SI"],"authors":["Schmidt Ana Lucia","Zollo Fabiana","Scala Antonio","Betsch Cornelia","Quattrociocchi Walter"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02908","title":"99\\% Revenue via Enhanced Competition","abstract":"A sequence of recent studies show that even in the simple setting of a single\nseller and a single buyer with additive, independent valuations over $m$ items,\nthe revenue-maximizing mechanism is prohibitively complex. This problem has\nbeen addressed using two main approaches: (i) Approximation: the best of two\nsimple mechanisms (sell each item separately, or sell all the items as one\nbundle) gives $1\/6$ of the optimal revenue [BILW14]. (ii) Enhanced competition:\nrunning the simple VCG mechanism with additional $m$ buyers extracts at least\nthe optimal revenue in the original market [EFFTW17]. Both approaches, however,\nsuffer from severe drawbacks: On the one hand, losing $83\\%$ of the revenue is\nhardly acceptable in any application. On the other hand, attracting a linear\nnumber of new buyers may be prohibitive. Our main result is that by combining\nthe two approaches one can achieve the best of both worlds. Specifically, for\nany constant $\\epsilon$ one can obtain a $(1-\\epsilon)$ fraction of the optimal\nrevenue by running simple mechanisms --- either selling each item separately or\nselling all items as a single bundle --- with substantially fewer additional\nbuyers: logarithmic, constant, or even none in some cases.","primary_category":"cs","categories":["cs.GT"],"authors":["Feldman Michal","Friedler Ophir","Rubinstein Aviad"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02909","title":"SDN-enabled Tactical Ad Hoc Networks: Extending Programmable Control to\n  the Edge","abstract":"Modern tactical operations have complex communication and computing\nrequirements, often involving different coalition teams, that cannot be\nsupported by today's mobile ad hoc networks. To this end, the emerging Software\nDefined Networking (SDN) paradigm has the potential to enable the redesign and\nsuccessful deployment of these systems. In this paper, we propose a set of\nnovel architecture designs for SDN-enabled mobile ad hoc networks in the\ntactical field. We discuss in detail the challenges raised by the ad hoc and\ncoalition network environment, and we present specific solutions to address\nthem. The proposed approaches build on evidence from experimental evaluation of\nsuch architectures and leverage recent theoretical results from SDN deployments\nin large backbone networks.","primary_category":"cs","categories":["cs.NI"],"authors":["Poularakis Konstantinos","Iosifidis George","Tassiulas Leandros"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02913","title":"The DMT classification of real and quaternionic lattice codes","abstract":"In this paper we consider space-time codes where the code-words are\nrestricted to either real or quaternion matrices. We prove two separate\ndiversity-multiplexing gain trade-off (DMT) upper bounds for such codes and\nprovide a criterion for a lattice code to achieve these upper bounds. We also\npoint out that lattice codes based on Q-central division algebras satisfy this\noptimality criterion. As a corollary this result provides a DMT classification\nfor all Q-central division algebra codes that are based on standard embeddings.","primary_category":"cs","categories":["cs.IT","math.IT","math.NT"],"authors":["Luzzi Laura","Vehkalahti Roope"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02916","title":"Denotation Extraction for Interactive Learning in Dialogue Systems","abstract":"This paper presents a novel task using real user data obtained in\nhuman-machine conversation. The task concerns with denotation extraction from\nanswer hints collected interactively in a dialogue. The task is motivated by\nthe need for large amounts of training data for question answering dialogue\nsystem development, where the data is often expensive and hard to collect.\nBeing able to collect denotation interactively and directly from users, one\ncould improve, for example, natural understanding components on-line and ease\nthe collection of the training data. This paper also presents introductory\nresults of evaluation of several denotation extraction models including\nattention-based neural network approaches.","primary_category":"cs","categories":["cs.CL"],"authors":["Vodol\u00e1n Miroslav","Jur\u010d\u00ed\u010dek Filip"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02918","title":"A Survey among Network Operators on BGP Prefix Hijacking","abstract":"BGP prefix hijacking is a threat to Internet operators and users. Several\nmechanisms or modifications to BGP that protect the Internet against it have\nbeen proposed. However, the reality is that most operators have not deployed\nthem and are reluctant to do so in the near future. Instead, they rely on basic\n- and often inefficient - proactive defenses to reduce the impact of hijacking\nevents, or on detection based on third party services and reactive approaches\nthat might take up to several hours. In this work, we present the results of a\nsurvey we conducted among 75 network operators to study: (a) the operators'\nawareness of BGP prefix hijacking attacks, (b) presently used defenses (if any)\nagainst BGP prefix hijacking, (c) the willingness to adopt new defense\nmechanisms, and (d) reasons that may hinder the deployment of BGP prefix\nhijacking defenses. We expect the findings of this survey to increase the\nunderstanding of existing BGP hijacking defenses and the needs of network\noperators, as well as contribute towards designing new defense mechanisms that\nsatisfy the requirements of the operators.","primary_category":"cs","categories":["cs.NI","cs.CR"],"authors":["Sermpezis Pavlos","Kotronis Vasileios","Dainotti Alberto","Dimitropoulos Xenofontas"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02930","title":"An Improved Analysis of Least Squares Superposition Codes with Bernoulli\n  Dictionary","abstract":"For the additive white Gaussian noise channel with average power constraint,\nsparse superposition codes, proposed by Barron and Joseph in 2010, achieve the\ncapacity. While the codewords of the original sparse superposition codes are\nmade with a dictionary matrix drawn from a Gaussian distribution, we consider\nthe case that it is drawn from a Bernoulli distribution. We show an improved\nupper bound on its block error probability with least squares decoding, which\nis fairly simplified and tighter bound than our previous result in 2014.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Takeishi Yoshinari","Takeuchi Jun'ichi"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02937","title":"Online Cluster Validity Indices for Streaming Data","abstract":"Cluster analysis is used to explore structure in unlabeled data sets in a\nwide range of applications. An important part of cluster analysis is validating\nthe quality of computationally obtained clusters. A large number of different\ninternal indices have been developed for validation in the offline setting.\nHowever, this concept has not been extended to the online setting. A key\nchallenge is to find an efficient incremental formulation of an index that can\ncapture both cohesion and separation of the clusters over potentially infinite\ndata streams. In this paper, we develop two online versions (with and without\nforgetting factors) of the Xie-Beni and Davies-Bouldin internal validity\nindices, and analyze their characteristics, using two streaming clustering\nalgorithms (sk-means and online ellipsoidal clustering), and illustrate their\nuse in monitoring evolving clusters in streaming data. We also show that\nincremental cluster validity indices are capable of sending a distress signal\nto online monitors when evolving clusters go awry. Our numerical examples\nindicate that the incremental Xie-Beni index with forgetting factor is superior\nto the other three indices tested.","primary_category":"cs","categories":["stat.ML","cs.LG"],"authors":["Moshtaghi Masud","Bezdek James C.","Erfani Sarah M.","Leckie Christopher","Bailey James"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02938","title":"Systematic design methodology for development and flight testing of a\n  variable pitch quadrotor biplane VTOL UAV for payload delivery","abstract":"This paper discusses the conceptual design and proof-of-concept flight\ndemonstration of a novel variable pitch quadrotor biplane Unmanned Aerial\nVehicle concept for payload delivery. The proposed design combines vertical\ntakeoff and landing (VTOL), precise hover capabilities of a quadrotor\nhelicopter and high range, endurance and high forward cruise speed\ncharacteristics of a fixed wing aircraft. The proposed UAV is designed for a\nmission requirement of carrying and delivering 6 kg payload to a destination at\n16 km from the point of origin. First, the design of proprotors is carried out\nusing a physics based modified Blade Element Momentum Theory (BEMT) analysis,\nwhich is validated using experimental data generated for the purpose.\nProprotors have conflicting requirement for optimal hover and forward flight\nperformance. Next, the biplane wings are designed using simple lifting line\ntheory. The airframe design is followed by power plant selection and\ntransmission design. Finally, weight estimation is carried out to complete the\ndesign process. The proprotor design with 24 deg preset angle and -24 deg twist\nis designed based on 70% weightage to forward flight and 30% weightage to\nhovering flight conditions. The operating RPM of the proprotors is reduced from\n3200 during hover to 2000 during forward flight to ensure optimal performance\nduring cruise flight. The estimated power consumption during forward flight\nmode is 64% less than that required for hover, establishing the benefit of this\nhybrid concept. A proof-of-concept scaled prototype is fabricated using\ncommercial-off-the-shelf parts. A PID controller is developed and implemented\non the PixHawk board to enable stable hovering flight and attitude tracking.","primary_category":"cs","categories":["cs.SY"],"authors":["Chipade Vishnu S.","Kothari Mangal","Chaudhari Rushikesh R."],"created":"2018-01-07","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02940","title":"An Ontology for Satellite Databases","abstract":"This paper demonstrates the development of ontology for satellite databases.\nFirst, I create a computational ontology for the Union of Concerned Scientists\n(UCS) Satellite Database (UCSSD for short), called the UCS Satellite Ontology\n(or UCSSO). Second, in developing UCSSO I show that The Space Situational\nAwareness Ontology (SSAO) (Rovetto and Kelso 2016)--an existing space domain\nreference ontology--and related ontology work by the author (Rovetto 2015,\n2016) can be used either (i) with a database-specific local ontology such as\nUCSSO, or (ii) in its stead. In case (i), local ontologies such as UCSSO can\nreuse SSAO terms, perform term mappings, or extend it. In case (ii), the\nauthor's orbital space ontology work, such as the SSAO, is usable by the UCSSD\nand organizations with other space object catalogs, as a reference ontology\nsuite providing a common semantically-rich domain model. The SSAO, UCSSO, and\nthe broader Orbital Space Environment Domain Ontology project is online at\nhttp:\/\/purl.org\/space-ontology and GitHub. This ontology effort aims, in part,\nto provide accurate formal representations of the domain for various\napplications. Ontology engineering has the potential to facilitate the sharing\nand integration of satellite data from federated databases and sensors for\nsafer spaceflight.","primary_category":"cs","categories":["cs.AI","cs.DB"],"authors":["Rovetto Robert J."],"created":"2018-01-06","updated":" ","doi":"10.1007\/s12145-017-0290-x"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02949","title":"An efficient K -means clustering algorithm for massive data","abstract":"The analysis of continously larger datasets is a task of major importance in\na wide variety of scientific fields. In this sense, cluster analysis algorithms\nare a key element of exploratory data analysis, due to their easiness in the\nimplementation and relatively low computational cost. Among these algorithms,\nthe K -means algorithm stands out as the most popular approach, besides its\nhigh dependency on the initial conditions, as well as to the fact that it might\nnot scale well on massive datasets. In this article, we propose a recursive and\nparallel approximation to the K -means algorithm that scales well on both the\nnumber of instances and dimensionality of the problem, without affecting the\nquality of the approximation. In order to achieve this, instead of analyzing\nthe entire dataset, we work on small weighted sets of points that mostly intend\nto extract information from those regions where it is harder to determine the\ncorrect cluster assignment of the original instances. In addition to different\ntheoretical properties, which deduce the reasoning behind the algorithm,\nexperimental results indicate that our method outperforms the state-of-the-art\nin terms of the trade-off between number of distance computations and the\nquality of the solution obtained.","primary_category":"cs","categories":["stat.ML","cs.LG"],"authors":["Cap\u00f3 Marco","P\u00e9rez Aritz","Lozano Jose A."],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02961","title":"A Predictive Approach Using Deep Feature Learning for Electronic Medical\n  Records: A Comparative Study","abstract":"Massive amount of electronic medical records accumulating from patients and\npopulations motivates clinicians and data scientists to collaborate for the\nadvanced analytics to extract knowledge that is essential to address the\nextensive personalized insights needed for patients, clinicians, providers,\nscientists, and health policy makers. In this paper, we propose a new\npredictive approach based on feature representation using deep feature learning\nand word embedding techniques. Our method uses different deep architectures for\nfeature representation in higher-level abstraction to obtain effective and more\nrobust features from EMRs, and then build prediction models on the top of them.\nOur approach is particularly useful when the unlabeled data is abundant whereas\nlabeled one is scarce. We investigate the performance of representation\nlearning through a supervised approach. First, we apply our method on a small\ndataset related to a specific precision medicine problem, which focuses on\nprediction of left ventricular mass indexed to body surface area (LVMI) as an\nindicator of heart damage risk in a vulnerable demographic subgroup\n(African-Americans). Then we use two large datasets from eICU collaborative\nresearch database to predict the length of stay in Cardiac-ICU and Neuro-ICU\nbased on high dimensional features. Finally we provide a comparative study and\nshow that our predictive approach leads to better results in comparison with\nothers.","primary_category":"cs","categories":["cs.LG","stat.ML"],"authors":["Nezhad Milad Zafar","Zhu Dongxiao","Sadati Najibesadat","Yang Kai"],"created":"2018-01-06","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02974","title":"Search on Secondary Attributes in Geo-Distributed Systems","abstract":"In the age of big data, more and more applications need to query and analyse\nlarge volumes of continuously updated data in real-time. In response,\ncloud-scale storage systems can extend their interface that allows fast lookups\non the primary key with the ability to retrieve data based on non-primary\nattributes. However, the need to ingest content rapidly and make it searchable\nimmediately while supporting low-latency, high-throughput query evaluation, as\nwell as the geo-distributed nature and weak consistency guarantees of modern\nstorage systems pose several challenges to the implementation of indexing and\nsearch systems. We present our early-stage work on the design and\nimplementation of an indexing and query processing system that enables realtime\nqueries on secondary attributes of data stored in geo-distributed, weakly\nconsistent storage systems.","primary_category":"cs","categories":["cs.DC"],"authors":["Vasilas Dimitrios"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02976","title":"Binary CEO Problem under Log-Loss with BSC Test-Channel Model","abstract":"In this paper, we propose an efficient coding scheme for the two-link binary\nChief Executive Officer (CEO) problem under logarithmic loss criterion. The\nexact rate-distortion bound for a two-link binary CEO problem under the\nlogarithmic loss has been obtained by Courtade and Weissman. We propose an\nencoding scheme based on compound LDGM-LDPC codes to achieve the theoretical\nbounds. In the proposed encoding, a binary quantizer using LDGM codes and a\nsyndrome-coding employing LDPC codes are applied. An iterative joint decoding\nis also designed as a fusion center. The proposed CEO decoder is based on the\nsum-product algorithm and a soft estimator.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Nangir Mahdi","Asvadi Reza","Ahmadian-Attari Mahmoud","Chen Jun"],"created":"2018-01-06","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.02977","title":"Utilising Deep Learning and Genome Wide Association Studies for\n  Epistatic-Driven Preterm Birth Classification in African-American Women","abstract":"Genome Wide Association Studies (GWAS) are used to identify statistically\nsignificant genetic variants in case-control studies. GWAS typically use a\np-value threshold of 5 x 10-8 to identify highly ranked single nucleotide\npolymorphisms (SNPs). However, evidence has shown that many of these are, in\nfact, false positives. Using lower p-values it is possible to to investigate\nthe joint epistatic interactions between SNPs and provide better insights into\nphenotype expression. However, computational complexity is increased\nexponentially as a function of higher-order combinations. In this paper, we\npropose a novel framework, based on nonlinear transformations of\ncombinatorically large SNP data, using stacked autoencoders, to identify\nhigher-order SNP interactions. We focus on the challenging problem of\nclassifying preterm births. Evidence suggests that this complex condition has a\nstrong genetic component with unexplained heritability reportedly between\n20%-40%. This claim is substantiated using a GWAS data set, obtained from\ndbGap, which contains predominantly urban low-income African-American women who\nhad normal deliveries (between 37 and 42 weeks of gestation) and preterm\ndeliveries (less than 37 weeks of gestation). Latent representations from\noriginal SNP sequences are used to initialize a deep learning classifier before\nit is fine-tuned for classification tasks (term and preterm births). The\ncomplete network models the epistatic effects of major and minor SNP\nperturbations. All models are evaluated using standard binary classifier\nperformance metrics. The findings show that important information pertaining to\nSNPs and epistasis can be extracted from 4666 raw SNPs generated using logistic\nregression (p-value=5 x 10-3) and used to fit a deep learning model and obtain\nresults (Sen=0.9289, Spec=0.9591, Gini=0.9651, Logloss=0.3080, AUC=0.9825,\nMSE=0.0942) using 500 hidden nodes.","primary_category":"cs","categories":["cs.CE"],"authors":["Fergus Paul","Montanez Casimiro Curbelo","Abdulaimma Basma","Lisboa Paulo","Chalmers Carl"],"created":"2018-01-06","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03003","title":"Between collective intelligence and semantic web : hypermediating sites.\n  Contribution to technologies of intelligence","abstract":"In this paper we present a new form of access to knowledge through what we\ncall \"hypermediator websites\". These hypermediator sites are intermediate\nbetween information devices that just scan the book culture and a \"real\"\nhypertext writing format.","primary_category":"cs","categories":["cs.AI","cs.IT","math.IT"],"authors":["Verlaet Lise","Gallot Sidonie"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03018","title":"Predict Forex Trend via Convolutional Neural Networks","abstract":"Deep learning is an effective approach to solving image recognition problems.\nPeople draw intuitive conclusions from trading charts; this study uses the\ncharacteristics of deep learning to train computers in imitating this kind of\nintuition in the context of trading charts. The three steps involved are as\nfollows: 1. Before training, we pre-process the input data from quantitative\ndata to images. 2. We use a convolutional neural network (CNN), a type of deep\nlearning, to train our trading model. 3. We evaluate the model's performance in\nterms of the accuracy of classification. A trading model is obtained with this\napproach to help devise trading strategies. The main application is designed to\nhelp clients automatically obtain personalized trading strategies.","primary_category":"cs","categories":["cs.CE","q-fin.CP"],"authors":["Tsai Yun-Cheng","Chen Jun-Hao","Wang Jun-Jie"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03032","title":"Topical Stance Detection for Twitter: A Two-Phase LSTM Model Using\n  Attention","abstract":"The topical stance detection problem addresses detecting the stance of the\ntext content with respect to a given topic: whether the sentiment of the given\ntext content is in FAVOR of (positive), is AGAINST (negative), or is NONE\n(neutral) towards the given topic. Using the concept of attention, we develop a\ntwo-phase solution. In the first phase, we classify subjectivity - whether a\ngiven tweet is neutral or subjective with respect to the given topic. In the\nsecond phase, we classify sentiment of the subjective tweets (ignoring the\nneutral tweets) - whether a given subjective tweet has a FAVOR or AGAINST\nstance towards the topic. We propose a Long Short-Term memory (LSTM) based deep\nneural network for each phase, and embed attention at each of the phases. On\nthe SemEval 2016 stance detection Twitter task dataset, we obtain a best-case\nmacro F-score of 68.84% and a best-case accuracy of 60.2%, outperforming the\nexisting deep learning based solutions. Our framework, T-PAN, is the first in\nthe topical stance detection literature, that uses deep learning within a\ntwo-phase architecture.","primary_category":"cs","categories":["cs.CL","cs.IR","cs.SI"],"authors":["Dey Kuntal","Shrivastava Ritvik","Kaushik Saroj"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03065","title":"Multi-threaded Sparse Matrix-Matrix Multiplication for Many-Core and GPU\n  Architectures","abstract":"Sparse Matrix-Matrix multiplication is a key kernel that has applications in\nseveral domains such as scientific computing and graph analysis. Several\nalgorithms have been studied in the past for this foundational kernel. In this\npaper, we develop parallel algorithms for sparse matrix-matrix multiplication\nwith a focus on performance portability across different high performance\ncomputing architectures. The performance of these algorithms depend on the data\nstructures used in them. We compare different types of accumulators in these\nalgorithms and demonstrate the performance difference between these data\nstructures. Furthermore, we develop a meta-algorithm, kkSpGEMM, to choose the\nright algorithm and data structure based on the characteristics of the problem.\nWe show performance comparisons on three architectures and demonstrate the need\nfor the community to develop two phase sparse matrix-matrix multiplication\nimplementations for efficient reuse of the data structures involved.","primary_category":"cs","categories":["cs.DC"],"authors":["Deveci Mehmet","Trott Christian","Rajamanickam Sivasankaran"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03074","title":"Game of Drones - Detecting Streamed POI from Encrypted FPV Channel","abstract":"Drones have created a new threat to people's privacy. We are now in an era in\nwhich anyone with a drone equipped with a video camera can use it to invade a\nsubject's privacy by streaming the subject in his\/her private space over an\nencrypted first person view (FPV) channel. Although many methods have been\nsuggested to detect nearby drones, they all suffer from the same shortcoming:\nthey cannot identify exactly what is being captured, and therefore they fail to\ndistinguish between the legitimate use of a drone (for example, to use a drone\nto film a selfie from the air) and illegitimate use that invades someone's\nprivacy (when the same operator uses the drone to stream the view into the\nwindow of his neighbor's apartment), a distinction that in some cases depends\non the orientation of the drone's video camera rather than on the drone's\nlocation. In this paper we shatter the commonly held belief that the use of\nencryption to secure an FPV channel prevents an interceptor from extracting the\nPOI that is being streamed. We show methods that leverage physical stimuli to\ndetect whether the drone's camera is directed towards a target in real time. We\ninvestigate the influence of changing pixels on the FPV channel (in a lab\nsetup). Based on our observations we demonstrate how an interceptor can perform\na side-channel attack to detect whether a target is being streamed by analyzing\nthe encrypted FPV channel that is transmitted from a real drone (DJI Mavic) in\ntwo use cases: when the target is a private house and when the target is a\nsubject.","primary_category":"cs","categories":["cs.CR"],"authors":["Nassi Ben","Ben-Netanel Raz","Shamir Adi","Elovici Yuval"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03079","title":"Asymmetry Hurts: Private Information Retrieval Under Asymmetric Traffic\n  Constraints","abstract":"We consider the classical setting of private information retrieval (PIR) of a\nsingle message (file) out of $M$ messages from $N$ distributed databases under\nthe new constraint of \\emph{asymmetric traffic} from databases. In this\nproblem, the \\emph{ratios between the traffic} from the databases are\nconstrained, i.e., the ratio of the length of the answer string that the user\n(retriever) receives from the $n$th database to the total length of all answer\nstrings from all databases is constrained to be $\\tau_n$. This may happen if\nthe user's access to the databases is restricted due database availability,\nchannel quality to the databases, and other factors. For this problem, for\nfixed $M$, $N$, we develop a general upper bound $\\bar{C}(\\boldsymbol{\\tau})$,\nwhich generalizes the converse proof of Sun-Jafar, where database symmetry was\ninherently used. Our converse bound is a piece-wise affine function in the\ntraffic ratio vector $\\boldsymbol{\\tau}=(\\tau_1, \\cdots, \\tau_N)$. For the\nlower bound, we explicitly show the achievability of $\\binom{M+N-1}{M}$ corner\npoints. For the remaining traffic ratio vectors, we perform time-sharing\nbetween these corner points. The recursive structure of our achievability\nscheme is captured via a system of difference equations. The upper and lower\nbounds exactly match for $M=2$ and $M=3$ for any $N$ and any\n$\\boldsymbol{\\tau}$. The results show strict loss of PIR capacity due to the\nasymmetric traffic constraints compared with the symmetric case of Sun-Jafar\nwhich implicitly uses $\\tau_n=\\frac{1}{N}$ for all $n$.","primary_category":"cs","categories":["cs.IT","cs.CR","math.IT"],"authors":["Banawan Karim","Ulukus Sennur"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03106","title":"Why informatics and general science need a conjoint basic definition of\n  information","abstract":"First the basic definition of information as a selection from a set of\npossibilities resp. domain is recalled. This also applies to digital\ninformation. The bits of digital information are parts of number sequences\nwhich represent a selection from a set of possibilities resp. domain. For\nfaultless conversation sender and receiver of information must have the same\ndefinition of the domain (e.g. of language vocabulary). Up to now the\ndefinition of the domain and of its elements is derived from context and\nknowledge. The internet provides an additional important possibility: A link to\na conjoint uniform definition of the domain at unique location on the internet.\nThe associated basic information structure is called \"Domain Vector\" (DV) and\nhas the structure \"UL (of the domain definition) plus sequence of numbers\". The\n\"UL\" is not only \"Uniform Locator\" of the domain definition. It also identifies\na certain kind of information for later comparison and search. It can be a\nUniform Resource Locator (URL) or an abbreviated equivalent, e.g. a hierarchic\nnumeric pointer or a short local pointer to a table with global internet\npointers. The DV structure can be used as general carrier of information which\nis language independent and more precise than language. A domain which contains\nDVs is called \"Domain Space\" (DS) and is defined as metric space. This allows\nsimilarity search according to user defined criteria, so that any kind of\ndefinable information can be made comparable and searchable according to user\nselected (relevant) and objectifiable (globally uniform) criteria. DS\ndefinitions can be reused in new DS definitions. Their elements, the DVs, are\nautomatically globally uniformly identified and defined. Obviously such\nconjoint definition of comparable information has great potential. It also can\navoid interoperability problems and redundant programming and so save high\ncosts.","primary_category":"cs","categories":["cs.DL"],"authors":["Orthuber Wolfgang"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03127","title":"Recognizing Material Properties from Images","abstract":"Humans rely on properties of the materials that make up objects to guide our\ninteractions with them. Grasping smooth materials, for example, requires care,\nand softness is an ideal property for fabric used in bedding. Even when these\nproperties are not visual (e.g. softness is a physical property), we may still\ninfer their presence visually. We refer to such material properties as visual\nmaterial attributes. Recognizing these attributes in images can contribute\nvaluable information for general scene understanding and material recognition.\nUnlike well-known object and scene attributes, visual material attributes are\nlocal properties with no fixed shape or spatial extent. We show that given a\nset of images annotated with known material attributes, we may accurately\nrecognize the attributes from small local image patches. Obtaining such\nannotations in a consistent fashion at scale, however, is challenging. To\naddress this, we introduce a method that allows us to probe the human visual\nperception of materials by asking simple yes\/no questions comparing pairs of\nimage patches. This provides sufficient weak supervision to build a set of\nattributes and associated classifiers that, while unnamed, serve the same\nfunction as the named attributes we use to describe materials. Doing so allows\nus to recognize visual material attributes without resorting to exhaustive\nmanual annotation of a fixed set of named attributes. Furthermore, we show that\nthis method may be integrated in the end-to-end learning of a material\nclassification CNN to simultaneously recognize materials and discover their\nvisual attributes. Our experimental results show that visual material\nattributes, whether named or automatically discovered, provide a useful\nintermediate representation for known material categories themselves as well as\na basis for transfer learning when recognizing previously-unseen categories.","primary_category":"cs","categories":["cs.CV"],"authors":["Schwartz Gabriel","Nishino Ko"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03132","title":"Robust Propensity Score Computation Method based on Machine Learning\n  with Label-corrupted Data","abstract":"In biostatistics, propensity score is a common approach to analyze the\nimbalance of covariate and process confounding covariates to eliminate\ndifferences between groups. While there are an abundant amount of methods to\ncompute propensity score, a common issue of them is the corrupted labels in the\ndataset. For example, the data collected from the patients could contain\nsamples that are treated mistakenly, and the computing methods could\nincorporate them as a misleading information. In this paper, we propose a\nMachine Learning-based method to handle the problem. Specifically, we utilize\nthe fact that the majority of sample should be labeled with the correct\ninstance and design an approach to first cluster the data with spectral\nclustering and then sample a new dataset with a distribution processed from the\nclustering results. The propensity score is computed by Xgboost, and a\nmathematical justification of our method is provided in this paper. The\nexperimental results illustrate that xgboost propensity scores computing with\nthe data processed by our method could outperform the same method with original\ndata, and the advantages of our method increases as we add some artificial\ncorruptions to the dataset. Meanwhile, the implementation of xgboost to compute\npropensity score for multiple treatments is also a pioneering work in the area.","primary_category":"cs","categories":["stat.ME","cs.AI","stat.ML"],"authors":["Wang Chen","Wang Suzhen","Shi Fuyan","Wang Zaixiang"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03137","title":"Convergence Analysis of Gradient Descent Algorithms with Proportional\n  Updates","abstract":"The rise of deep learning in recent years has brought with it increasingly\nclever optimization methods to deal with complex, non-linear loss functions.\nThese methods are often designed with convex optimization in mind, but have\nbeen shown to work well in practice even for the highly non-convex optimization\nassociated with neural networks. However, one significant drawback of these\nmethods when they are applied to deep learning is that the magnitude of the\nupdate step is sometimes disproportionate to the magnitude of the weights (much\nsmaller or larger), leading to training instabilities such as vanishing and\nexploding gradients. An idea to combat this issue is gradient descent with\nproportional updates. Gradient descent with proportional updates was introduced\nin 2017. It was independently developed by You et al (Layer-wise Adaptive Rate\nScaling (LARS) algorithm) and by Abu-El-Haija (PercentDelta algorithm). The\nbasic idea of both of these algorithms is to make each step of the gradient\ndescent proportional to the current weight norm and independent of the gradient\nmagnitude. It is common in the context of new optimization methods to prove\nconvergence or derive regret bounds under the assumption of Lipschitz\ncontinuity and convexity. However, even though LARS and PercentDelta were shown\nto work well in practice, there is no theoretical analysis of the convergence\nproperties of these algorithms. Thus it is not clear if the idea of gradient\ndescent with proportional updates is used in the optimal way, or if it could be\nimproved by using a different norm or specific learning rate schedule, for\nexample. Moreover, it is not clear if these algorithms can be extended to other\nproblems, besides neural networks. We attempt to answer these questions by\nestablishing the theoretical analysis of gradient descent with proportional\nupdates, and verifying this analysis with empirical examples.","primary_category":"cs","categories":["cs.LG","cs.AI","stat.ML"],"authors":["Gitman Igor","Dilipkumar Deepak","Parr Ben"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03138","title":"Deep In-GPU Experience Replay","abstract":"Experience replay allows a reinforcement learning agent to train on samples\nfrom a large amount of the most recent experiences. A simple in-RAM experience\nreplay stores these most recent experiences in a list in RAM, and then copies\nsampled batches to the GPU for training. I moved this list to the GPU, thus\ncreating an in-GPU experience replay, and a training step that no longer has\ninputs copied from the CPU. I trained an agent to play Super Smash Bros. Melee,\nusing internal game memory values as inputs and outputting controller button\npresses. A single state in Melee contains 27 floats, so the full experience\nreplay fits on a single GPU. For a batch size of 128, the in-GPU experience\nreplay trained twice as fast as the in-RAM experience replay. As far as I know,\nthis is the first in-GPU implementation of experience replay. Finally, I note a\nfew ideas for fitting the experience replay inside the GPU when the environment\nstate requires more memory.","primary_category":"cs","categories":["cs.AI"],"authors":["Parr Ben"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03143","title":"Comparing heterogeneous entities using artificial neural networks of\n  trainable weighted structural components and machine-learned activation\n  functions","abstract":"To compare entities of differing types and structural components, the\nartificial neural network paradigm was used to cross-compare structural\ncomponents between heterogeneous documents. Trainable weighted structural\ncomponents were input into machine-learned activation functions of the neurons.\nThe model was used for matching news articles and videos, where the inputs and\nactivation functions respectively consisted of term vectors and cosine\nsimilarity measures between the weighted structural components. The model was\ntested with different weights, achieving as high as 59.2% accuracy for matching\nvideos to news articles. A mobile application user interface for recommending\nrelated videos for news articles was developed to demonstrate consumer value,\nincluding its potential usefulness for cross-selling products from unrelated\ncategories.","primary_category":"cs","categories":["stat.ML","cs.AI","cs.IR","cs.LG","cs.NE"],"authors":["Wangperawong Artit","Kriangchaivech Kettip","Lanari Austin","Lam Supui","Wangperawong Panthong"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03153","title":"A New Coding Paradigm for the Primitive Relay Channel","abstract":"We present a coding paradigm that provides a new achievable rate for the\nprimitive relay channel by combining compress-and-forward and\ndecode-and-forward with a chaining construction.\n  In the primitive relay channel model, the source broadcasts a message to the\nrelay and to the destination; and the relay facilitates this communication by\nsending an additional message to the destination through a separate channel.\nTwo well-known coding approaches for this setting are decode-and-forward and\ncompress-and-forward: in the former, the relay decodes the message and sends\nsome of the information to the destination; in the latter, the relay does not\nattempt to decode, but it sends a compressed description of the received\nsequence to the destination via Wyner-Ziv coding.\n  In our scheme, we transmit over pairs of blocks and we use\ncompress-and-forward for the first block and decode-and-forward for the second.\nIn particular, in the first block, the relay does not attempt to decode and it\nsends only a part of the compressed description of the received sequence; in\nthe second block, the relay decodes the message and sends this information plus\nthe remaining part of the compressed sequence relative to the first block. As a\nresult, we strictly outperform both compress-and-forward and\ndecode-and-forward. Furthermore, this paradigm can be implemented with a\nlow-complexity polar coding scheme that has the typical attractive features of\npolar codes, i.e., quasi-linear encoding\/decoding complexity and\nsuper-polynomial decay of the error probability. Throughout the paper we\nconsider as a running example the special case of the erasure relay channel and\nwe compare the rates achievable by our proposed scheme with the existing upper\nand lower bounds.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Mondelli Marco","Hassani S. Hamed","Urbanke R\u00fcdiger"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03161","title":"Resolving zero-divisors using Hensel lifting","abstract":"Algorithms which compute modulo triangular sets must respect the presence of\nzero-divisors. We present Hensel lifting as a tool for dealing with them. We\ngive an application: a modular algorithm for computing GCDs of univariate\npolynomials with coefficients modulo a radical triangular set over the\nrationals. Our modular algorithm naturally generalizes previous work from\nalgebraic number theory. We have implemented our algorithm using Maple's RECDEN\npackage. We compare our implementation with the procedure RegularGcd in the\nRegularChains package.","primary_category":"cs","categories":["cs.SC"],"authors":["Kluesner John","Monagan Michael"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03164","title":"Paranom: A Parallel Anomaly Dataset Generator","abstract":"In this paper, we present Paranom, a parallel anomaly dataset generator. We\ndiscuss its design and provide brief experimental results demonstrating its\nusefulness in improving the classification correctness of LSTM-AD, a\nstate-of-the-art anomaly detection model.","primary_category":"cs","categories":["cs.LG","cs.AI","stat.ML"],"authors":["Gottschlich Justin"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03182","title":"A Benchmark for Breast Ultrasound Image Segmentation (BUSIS)","abstract":"Breast ultrasound (BUS) image segmentation is challenging and critical for\nBUS Computer-Aided Diagnosis (CAD) systems. Many BUS segmentation approaches\nhave been proposed in the last two decades, but the performances of most\napproaches have been assessed using relatively small private datasets with\ndiffer-ent quantitative metrics, which result in discrepancy in performance\ncomparison. Therefore, there is a pressing need for building a benchmark to\ncompare existing methods using a public dataset objectively, and to determine\nthe performance of the best breast tumor segmentation algorithm available today\nand to investigate what segmentation strategies are valuable in clinical\npractice and theoretical study. In this work, we will publish a B-mode BUS\nimage segmentation benchmark (BUSIS) with 562 images and compare the\nperformance of five state-of-the-art BUS segmentation methods quantitatively.","primary_category":"cs","categories":["cs.CV"],"authors":["Xian Min","Zhang Yingtao","Cheng H. D.","Xu Fei","Huang Kuan","Zhang Boyu","Ding Jianrui","Ning Chunping","Wang Ying"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03186","title":"Measure-valued spline curves: an optimal transport viewpoint","abstract":"The aim of this article is to introduce and address the problem to smoothly\ninterpolate (empirical) probability measures. To this end, we lift the concept\nof a spline curve from the setting of points in a Euclidean space that that of\nprobability measures, using the framework of optimal transport.","primary_category":"cs","categories":["math.OC","cs.SY","math.FA"],"authors":["Chen Yongxin","Conforti Giovanni","Georgiou Tryphon T."],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03190","title":"Risk-Averse Matchings over Uncertain Graph Databases","abstract":"A large number of applications such as querying sensor networks, and\nanalyzing protein-protein interaction (PPI) networks, rely on mining uncertain\ngraph and hypergraph databases. In this work we study the following problem:\ngiven an uncertain, weighted (hyper)graph, how can we efficiently find a\n(hyper)matching with high expected reward, and low risk?\n  This problem naturally arises in the context of several important\napplications, such as online dating, kidney exchanges, and team formation. We\nintroduce a novel formulation for finding matchings with maximum expected\nreward and bounded risk under a general model of uncertain weighted\n(hyper)graphs that we introduce in this work. Our model generalizes\nprobabilistic models used in prior work, and captures both continuous and\ndiscrete probability distributions, thus allowing to handle privacy related\napplications that inject appropriately distributed noise to (hyper)edge\nweights. Given that our optimization problem is NP-hard, we turn our attention\nto designing efficient approximation algorithms. For the case of uncertain\nweighted graphs, we provide a $\\frac{1}{3}$-approximation algorithm, and a\n$\\frac{1}{5}$-approximation algorithm with near optimal run time. For the case\nof uncertain weighted hypergraphs, we provide a\n$\\Omega(\\frac{1}{k})$-approximation algorithm, where $k$ is the rank of the\nhypergraph (i.e., any hyperedge includes at most $k$ nodes), that runs in\nalmost (modulo log factors) linear time.\n  We complement our theoretical results by testing our approximation algorithms\non a wide variety of synthetic experiments, where we observe in a controlled\nsetting interesting findings on the trade-off between reward, and risk. We also\nprovide an application of our formulation for providing recommendations of\nteams that are likely to collaborate, and have high impact.","primary_category":"cs","categories":["cs.DS","cs.DB","cs.DM","cs.SI"],"authors":["Tsourakakis Charalampos E.","Sekar Shreyas","Lam Johnson","Yang Liu"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03200","title":"An Entropy Lower Bound for Non-Malleable Extractors","abstract":"A $(k,\\varepsilon)$-non-malleable extractor is a function ${\\sf nmExt} :\n\\{0,1\\}^n \\times \\{0,1\\}^d \\to \\{0,1\\}$ that takes two inputs, a weak source $X\n\\sim \\{0,1\\}^n$ of min-entropy $k$ and an independent uniform seed $s \\in\n\\{0,1\\}^d$, and outputs a bit ${\\sf nmExt}(X, s)$ that is $\\varepsilon$-close\nto uniform, even given the seed $s$ and the value ${\\sf nmExt}(X, s')$ for an\nadversarially chosen seed $s' \\neq s$. Dodis and Wichs~(STOC 2009) showed the\nexistence of $(k, \\varepsilon)$-non-malleable extractors with seed length $d =\n\\log(n-k-1) + 2\\log(1\/\\varepsilon) + 6$ that support sources of entropy $k >\n\\log(d) + 2 \\log(1\/\\varepsilon) + 8$.\n  We show that the foregoing bound is essentially tight, by proving that any\n$(k,\\varepsilon)$-non-malleable extractor must satisfy the entropy bound $k >\n\\log(d) + 2 \\log(1\/\\varepsilon) - \\log\\log(1\/\\varepsilon) - C$ for an absolute\nconstant $C$. In particular, this implies that non-malleable extractors require\nmin-entropy at least $\\Omega(\\log\\log(n))$. This is in stark contrast to the\nexistence of strong seeded extractors that support sources of entropy $k =\nO(\\log(1\/\\varepsilon))$.\n  Our techniques strongly rely on coding theory. In particular, we reveal an\ninherent connection between non-malleable extractors and error correcting\ncodes, by proving a new lemma which shows that any\n$(k,\\varepsilon)$-non-malleable extractor with seed length $d$ induces a code\n$C \\subseteq \\{0,1\\}^{2^k}$ with relative distance $0.5 - 2\\varepsilon$ and\nrate $\\frac{d-1}{2^k}$.","primary_category":"cs","categories":["cs.CC"],"authors":["Gur Tom","Shinkar Igor"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03226","title":"Adaptive Graph Convolutional Neural Networks","abstract":"Graph Convolutional Neural Networks (Graph CNNs) are generalizations of\nclassical CNNs to handle graph data such as molecular data, point could and\nsocial networks. Current filters in graph CNNs are built for fixed and shared\ngraph structure. However, for most real data, the graph structures varies in\nboth size and connectivity. The paper proposes a generalized and flexible graph\nCNN taking data of arbitrary graph structure as input. In that way a\ntask-driven adaptive graph is learned for each graph data while training. To\nefficiently learn the graph, a distance metric learning is proposed. Extensive\nexperiments on nine graph-structured datasets have demonstrated the superior\nperformance improvement on both convergence speed and predictive accuracy.","primary_category":"cs","categories":["cs.LG","stat.ML"],"authors":["Li Ruoyu","Wang Sheng","Zhu Feiyun","Huang Junzhou"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03233","title":"Eliciting Worker Preference for Task Completion","abstract":"Current crowdsourcing platforms provide little support for worker feedback.\nWorkers are sometimes invited to post free text describing their experience and\npreferences in completing tasks. They can also use forums such as Turker\nNation1 to exchange preferences on tasks and requesters. In fact, crowdsourcing\nplatforms rely heavily on observing workers and inferring their preferences\nimplicitly. In this work, we believe that asking workers to indicate their\npreferences explicitly improve their experience in task completion and hence,\nthe quality of their contributions. Explicit elicitation can indeed help to\nbuild more accurate worker models for task completion that captures the\nevolving nature of worker preferences. We design a worker model whose accuracy\nis improved iteratively by requesting preferences for task factors such as\nrequired skills, task payment, and task relevance. We propose a generic\nframework, develop efficient solutions in realistic scenarios, and run\nextensive experiments that show the benefit of explicit preference elicitation\nover implicit ones with statistical significance.","primary_category":"cs","categories":["cs.DB","cs.AI"],"authors":["Esfandiari Mohammadreza","Roy Senjuti Basu","Amer-Yahia Sihem"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03235","title":"Combating Error Propagation in Window Decoding of Braided Convolutional\n  Codes","abstract":"In this paper, we study sliding window decoding of braided convolutional\ncodes (BCCs) in the context of a streaming application, where decoder error\npropagation can be a serious problem. A window extension algorithm and a\nresynchronization mechanism are introduced to mitigate the effect of error\npropagation. In addition, we introduce a soft bit-error-rate stopping rule to\nreduce computational complexity, and the tradeoff between performance and\ncomplexity is examined. Simulation results show that, using the proposed window\nextension algorithm and resynchronization mechanism, the error performance of\nBCCs can be improved by up to three orders of magnitude with reduced\ncomputational complexity.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Zhu Min","Mitchell David G. M.","Lentmaier Michael","Costello, Daniel J.","Bai Baoming"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03239","title":"Chameleon: A Hybrid Secure Computation Framework for Machine Learning\n  Applications","abstract":"We present Chameleon, a novel hybrid (mixed-protocol) framework for secure\nfunction evaluation (SFE) which enables two parties to jointly compute a\nfunction without disclosing their private inputs. Chameleon combines the best\naspects of generic SFE protocols with the ones that are based upon additive\nsecret sharing. In particular, the framework performs linear operations in the\nring $\\mathbb{Z}_{2^l}$ using additively secret shared values and nonlinear\noperations using Yao's Garbled Circuits or the Goldreich-Micali-Wigderson\nprotocol. Chameleon departs from the common assumption of additive or linear\nsecret sharing models where three or more parties need to communicate in the\nonline phase: the framework allows two parties with private inputs to\ncommunicate in the online phase under the assumption of a third node generating\ncorrelated randomness in an offline phase. Almost all of the heavy\ncryptographic operations are precomputed in an offline phase which\nsubstantially reduces the communication overhead. Chameleon is both scalable\nand significantly more efficient than the ABY framework (NDSS'15) it is based\non. Our framework supports signed fixed-point numbers. In particular,\nChameleon's vector dot product of signed fixed-point numbers improves the\nefficiency of mining and classification of encrypted data for algorithms based\nupon heavy matrix multiplications. Our evaluation of Chameleon on a 5 layer\nconvolutional deep neural network shows 133x and 4.2x faster executions than\nMicrosoft CryptoNets (ICML'16) and MiniONN (CCS'17), respectively.","primary_category":"cs","categories":["cs.CR","cs.AI"],"authors":["Riazi M. Sadegh","Weinert Christian","Tkachenko Oleksandr","Songhori Ebrahim M.","Schneider Thomas","Koushanfar Farinaz"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03244","title":"eCommerceGAN : A Generative Adversarial Network for E-commerce","abstract":"E-commerce companies such as Amazon, Alibaba and Flipkart process billions of\norders every year. However, these orders represent only a small fraction of all\nplausible orders. Exploring the space of all plausible orders could help us\nbetter understand the relationships between the various entities in an\ne-commerce ecosystem, namely the customers and the products they purchase. In\nthis paper, we propose a Generative Adversarial Network (GAN) for orders made\nin e-commerce websites. Once trained, the generator in the GAN could generate\nany number of plausible orders. Our contributions include: (a) creating a dense\nand low-dimensional representation of e-commerce orders, (b) train an\necommerceGAN (ecGAN) with real orders to show the feasibility of the proposed\nparadigm, and (c) train an ecommerce-conditional-GAN (ec^2GAN) to generate the\nplausible orders involving a particular product. We propose several qualitative\nmethods to evaluate ecGAN and demonstrate its effectiveness. The ec^2GAN is\nused for various kinds of characterization of possible orders involving a\nproduct that has just been introduced into the e-commerce system. The proposed\napproach ec^2GAN performs significantly better than the baseline in most of the\nscenarios.","primary_category":"cs","categories":["cs.LG"],"authors":["Kumar Ashutosh","Biswas Arijit","Sanyal Subhajit"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03252","title":"Instance Map based Image Synthesis with a Denoising Generative\n  Adversarial Network","abstract":"Semantic layouts based Image synthesizing, which has benefited from the\nsuccess of Generative Adversarial Network (GAN), has drawn much attention in\nthese days. How to enhance the synthesis image equality while keeping the\nstochasticity of the GAN is still a challenge. We propose a novel denoising\nframework to handle this problem. The overlapped objects generation is another\nchallenging task when synthesizing images from a semantic layout to a realistic\nRGB photo. To overcome this deficiency, we include a one-hot semantic label map\nto force the generator paying more attention on the overlapped objects\ngeneration. Furthermore, we improve the loss function of the discriminator by\nconsidering perturb loss and cascade layer loss to guide the generation\nprocess. We applied our methods on the Cityscapes, Facades and NYU datasets and\ndemonstrate the image generation ability of our model.","primary_category":"cs","categories":["cs.CV"],"authors":["Zheng Ziqiang","Wang Chao","Yu Zhibin","Zheng Haiyong","Zheng Bing"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03257","title":"Translating Pro-Drop Languages with Reconstruction Models","abstract":"Pronouns are frequently omitted in pro-drop languages, such as Chinese,\ngenerally leading to significant challenges with respect to the production of\ncomplete translations. To date, very little attention has been paid to the\ndropped pronoun (DP) problem within neural machine translation (NMT). In this\nwork, we propose a novel reconstruction-based approach to alleviating DP\ntranslation problems for NMT models. Firstly, DPs within all source sentences\nare automatically annotated with parallel information extracted from the\nbilingual training corpus. Next, the annotated source sentence is reconstructed\nfrom hidden representations in the NMT model. With auxiliary training\nobjectives, in terms of reconstruction scores, the parameters associated with\nthe NMT model are guided to produce enhanced hidden representations that are\nencouraged as much as possible to embed annotated DP information. Experimental\nresults on both Chinese-English and Japanese-English dialogue translation tasks\nshow that the proposed approach significantly and consistently improves\ntranslation performance over a strong NMT baseline, which is directly built on\nthe training data annotated with DPs.","primary_category":"cs","categories":["cs.CL"],"authors":["Wang Longyue","Tu Zhaopeng","Shi Shuming","Zhang Tong","Graham Yvette","Liu Qun"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03261","title":"Exploring Stereotypes and Biased Data with the Crowd","abstract":"The goal of our research is to contribute information about how useful the\ncrowd is at anticipating stereotypes that may be biasing a data set without a\nresearcher's knowledge. The results of the crowd's prediction can potentially\nbe used during data collection to help prevent the suspected stereotypes from\nintroducing bias to the dataset. We conduct our research by asking the crowd on\nAmazon's Mechanical Turk (AMT) to complete two similar Human Intelligence Tasks\n(HITs) by suggesting stereotypes relating to their personal experience. Our\nanalysis of these responses focuses on determining the level of diversity in\nthe workers' suggestions and their demographics. Through this process we begin\na discussion on how useful the crowd can be in tackling this difficult problem\nwithin machine learning data collection.","primary_category":"cs","categories":["cs.HC"],"authors":["Hu Zeyuan","Strout Julia"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03285","title":"A Composition Theorem via Conflict Complexity","abstract":"Let $\\R(\\cdot)$ stand for the bounded-error randomized query complexity. We\nshow that for any relation $f \\subseteq \\{0,1\\}^n \\times \\mathcal{S}$ and\npartial Boolean function $g \\subseteq \\{0,1\\}^n \\times \\{0,1\\}$, $\\R_{1\/3}(f\n\\circ g^n) = \\Omega(\\R_{4\/9}(f) \\cdot \\sqrt{\\R_{1\/3}(g)})$. Independently of\nus, Gavinsky, Lee and Santha \\cite{newcomp} proved this result. By an example\ndemonstrated in their work, this bound is optimal. We prove our result by\nintroducing a novel complexity measure called the \\emph{conflict complexity} of\na partial Boolean function $g$, denoted by $\\chi(g)$, which may be of\nindependent interest. We show that $\\chi(g) = \\Omega(\\sqrt{\\R(g)})$ and $\\R(f\n\\circ g^n) = \\Omega(\\R(f) \\cdot \\chi(g))$.","primary_category":"cs","categories":["cs.CC"],"authors":["Sanyal Swagato"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03294","title":"A First Look at Identity Management Schemes on the Blockchain","abstract":"The emergence of distributed ledger technology (DLT) based upon a blockchain\ndata structure, has given rise to new approaches to identity management that\naim to upend dominant approaches to providing and consuming digital identities.\nThese new approaches to identity management (IdM) propose to enhance\ndecentralisation, transparency and user control in transactions that involve\nidentity information; but, given the historical challenge to design IdM, can\nthese new DLT-based schemes deliver on their lofty goals? We introduce the\nemerging landscape of DLT-based IdM, and evaluate three representative\nproposals: uPort; ShoCard; and Sovrin; using the analytic lens of a seminal\nframework that characterises the nature of successful IdM schemes.","primary_category":"cs","categories":["cs.CR"],"authors":["Dunphy Paul","Petitcolas Fabien A. P."],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03299","title":"Simultaneous Tensor Completion and Denoising by Noise Inequality\n  Constrained Convex Optimization","abstract":"Tensor completion is a technique of filling missing elements of the\nincomplete data tensors. It being actively studied based on the convex\noptimization scheme such as nuclear-norm minimization. When given data tensors\ninclude some noises, the nuclear-norm minimization problem is usually converted\nto the nuclear-norm `regularization' problem which simultaneously minimize\npenalty and error terms with some trade-off parameter. However, the good value\nof trade-off is not easily determined because of the difference of two units\nand the data dependence. In the sense of trade-off tuning, the noisy tensor\ncompletion problem with the `noise inequality constraint' is better choice than\nthe `regularization' because the good noise threshold can be easily bounded\nwith noise standard deviation. In this study, we tackle to solve the convex\ntensor completion problems with two types of noise inequality constraints:\nGaussian and Laplace distributions. The contributions of this study are\nfollows: (1) New tensor completion and denoising models using tensor total\nvariation and nuclear-norm are proposed which can be characterized as a\ngeneralization\/extension of many past matrix and tensor completion models, (2)\nproximal mappings for noise inequalities are derived which are analytically\ncomputable with low computational complexity, (3) convex optimization algorithm\nis proposed based on primal-dual splitting framework, (4) new step-size\nadaptation method is proposed to accelerate the optimization, and (5) extensive\nexperiments demonstrated the advantages of the proposed method for visual data\nretrieval such as for color images, movies, and 3D-volumetric data.","primary_category":"cs","categories":["cs.CV"],"authors":["Yokota Tatsuya","Hontani Hidekata"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03314","title":"BigRoots: An Effective Approach for Root-cause Analysis of Stragglers in\n  Big Data System","abstract":"Stragglers are commonly believed to have a great impact on the performance of\nbig data system. However, the reason to cause straggler is complicated.\nPrevious works mostly focus on straggler detection, schedule level optimization\nand coarse-grained cause analysis. These methods cannot provide valuable\ninsights to help users optimize their programs. In this paper, we propose\nBigRoots, a general method incorporating both framework and system features for\nroot-cause analysis of stragglers in big data system. BigRoots considers\nfeatures from big data framework such as shuffle read\/write bytes and JVM\ngarbage collection time, as well as system resource utilization such as CPU,\nI\/O and network, which is able to detect both internal and external root causes\nof stragglers. We verify BigRoots by injecting high resource utilization across\ndifferent system components and perform case studies to analyze different\nworkloads in Hibench. The experimental results demonstrate that BigRoots is\neffective to identify the root cause of stragglers and provide useful guidance\nfor performance optimization.","primary_category":"cs","categories":["cs.DC"],"authors":["Zhou Honggang","Li Yunchun","Yang Hailong","Jia Jie","Li Wei"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03318","title":"Unsupervised Despeckling","abstract":"Contrast and quality of ultrasound images are adversely affected by the\nexcessive presence of speckle. However, being an inherent imaging property,\nspeckle helps in tissue characterization and tracking. Thus, despeckling of the\nultrasound images requires the reduction of speckle extent without any\noversmoothing. In this letter, we aim to address the despeckling problem using\nan unsupervised deep adversarial approach. A despeckling residual neural\nnetwork (DRNN) is trained with an adversarial loss imposed by a discriminator.\nThe discriminator tries to differentiate between the despeckled images\ngenerated by the DRNN and the set of high-quality images. Further to prevent\nthe developed DRNN from oversmoothing, a structural loss term is used along\nwith the adversarial loss. Experimental evaluations show that the proposed DRNN\nis able to outperform the state-of-the-art despeckling approaches.","primary_category":"cs","categories":["cs.CV"],"authors":["Mishra Deepak","Chaudhury Santanu","Sarkar Mukul","Soin Arvinder Singh"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03326","title":"Expected Policy Gradients for Reinforcement Learning","abstract":"We propose expected policy gradients (EPG), which unify stochastic policy\ngradients (SPG) and deterministic policy gradients (DPG) for reinforcement\nlearning. Inspired by expected sarsa, EPG integrates (or sums) across actions\nwhen estimating the gradient, instead of relying only on the action in the\nsampled trajectory. For continuous action spaces, we first derive a practical\nresult for Gaussian policies and quadric critics and then extend it to an\nanalytical method for the universal case, covering a broad class of actors and\ncritics, including Gaussian, exponential families, and reparameterised policies\nwith bounded support. For Gaussian policies, we show that it is optimal to\nexplore using covariance proportional to the matrix exponential of the scaled\nHessian of the critic with respect to the actions. EPG also provides a general\nframework for reasoning about policy gradient methods, which we use to\nestablish a new general policy gradient theorem, of which the stochastic and\ndeterministic policy gradient theorems are special cases. Furthermore, we prove\nthat EPG reduces the variance of the gradient estimates without requiring\ndeterministic policies and with little computational overhead. Finally, we show\nthat EPG outperforms existing approaches on six challenging domains involving\nthe simulated control of physical systems.","primary_category":"cs","categories":["stat.ML","cs.AI"],"authors":["Ciosek Kamil","Whiteson Shimon"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03331","title":"Reasoning about Unforeseen Possibilities During Policy Learning","abstract":"Methods for learning optimal policies in autonomous agents often assume that\nthe way the domain is conceptualised---its possible states and actions and\ntheir causal structure---is known in advance and does not change during\nlearning. This is an unrealistic assumption in many scenarios, because new\nevidence can reveal important information about what is possible, possibilities\nthat the agent was not aware existed prior to learning. We present a model of\nan agent which both discovers and learns to exploit unforeseen possibilities\nusing two sources of evidence: direct interaction with the world and\ncommunication with a domain expert. We use a combination of probabilistic and\nsymbolic reasoning to estimate all components of the decision problem,\nincluding its set of random variables and their causal dependencies. Agent\nsimulations show that the agent converges on optimal polices even when it\nstarts out unaware of factors that are critical to behaving optimally.","primary_category":"cs","categories":["cs.AI"],"authors":["Innes Craig","Lascarides Alex","Albrecht Stefano V","Ramamoorthy Subramanian","Rosman Benjamin"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03337","title":"Distribution of the absolute indicator of random Boolean functions","abstract":"The absolute indicator is one of the measures used to determine the\nresistance offered by a Boolean function when used in the design of a symmetric\ncryptosystem. It was proposed along with the sum of square indicator to\nevaluate the quality of the diffusion property of block ciphers and hash\nfunctions. While the behaviour of the sum of square of random Boolean functions\nwas already known, what remained was the study of the comportment of the\nabsolute indicator of random Boolean functions. As an application, we show that\nthe absolute indicator can distinguish a nonrandom binary sequence from a\nrandom one.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Caullery Florian","Rodier Fran\u00e7ois"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03346","title":"Statistical Blockage Modeling and Robustness of Beamforming in\n  Millimeter Wave Systems","abstract":"There has been a growing interest in the commercialization of millimeter wave\n(mmW) technology as a part of the Fifth-Generation New Radio (5G-NR) wireless\nstandardization efforts. In this direction, many sets of independent\nmeasurement campaigns show that wireless propagation at mmW carrier frequencies\nis only marginally worse than propagation at sub-6 GHz carrier frequencies for\nsmall-cell coverage --- one of the most important use-cases for 5G-NR. On the\nother hand, the biggest determinants of viability of mmW systems in practice\nare penetration and blockage of mmW signals through different materials in the\nscattering environment. With this background, the focus of this paper is on\nunderstanding the impact of blockage of mmW signals and reduced spatial\ncoverage due to penetration through the human hand, body, vehicles, etc.\nLeveraging measurements with a 28 GHz mmW experimental prototype and\nelectromagnetic simulation studies, we first propose statistical blockage\nmodels to capture the impact of the hand, human body and vehicles. We then\nstudy the time-scales at which mmW signals are disrupted by blockage (hand and\nhuman body). Our results show that these events can be attributed to physical\nmovements and the time-scales corresponding to blockage are hence on the order\nof a few 100 ms or more. Building on this fundamental understanding, we finally\nconsider the broader question of robustness of mmW beamforming to handle\nblockage. Network densification, subarray switching in a user equipment (UE)\ndesigned with multiple subarrays, fall back mechanisms such as codebook\nenhancements and switching to legacy carriers in non-standalone deployments,\netc. can address blockage before it leads to a deleterious impact on the mmW\nlink margin.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Raghavan Vasanthan","Akhoondzadeh-asl Lida","Podshivalov Vladimir","Hulten Joakim","Tassoudji M. Ali","Koymen Ozge Hizir","Sampath Ashwin","Li Junyi"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03354","title":"Planning with Pixels in (Almost) Real Time","abstract":"Recently, width-based planning methods have been shown to yield\nstate-of-the-art results in the Atari 2600 video games. For this, the states\nwere associated with the (RAM) memory states of the simulator. In this work, we\nconsider the same planning problem but using the screen instead. By using the\nsame visual inputs, the planning results can be compared with those of humans\nand learning methods. We show that the planning approach, out of the box and\nwithout training, results in scores that compare well with those obtained by\nhumans and learning methods, and moreover, by developing an episodic, rollout\nversion of the IW(k) algorithm, we show that such scores can be obtained in\nalmost real time.","primary_category":"cs","categories":["cs.AI"],"authors":["Bandres Wilmer","Bonet Blai","Geffner Hector"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03366","title":"On the Availability of ESO Data Papers on arXiv\/astro-ph","abstract":"Using the ESO Telescope Bibliography database telbib, we have investigated\nthe percentage of ESO data papers that were submitted to the arXiv\/astro-ph\ne-print server and that are therefore free to read. Our study revealed an\navailability of up to 96% of telbib papers on arXiv over the years 2010 to\n2017. We also compared the citation counts of arXiv vs. non-arXiv papers and\nfound that on average, papers submitted to arXiv are cited 2.8 times more often\nthan those not on arXiv. While simulations suggest that these findings are\nstatistically significant, we cannot yet draw firm conclusions as to the main\ncause of these differences.","primary_category":"cs","categories":["astro-ph.IM","cs.DL"],"authors":["Grothkopf Uta","Bordelon Dominic","Meakins Silvia","Emsellem Eric"],"created":"2018-01-10","updated":" ","doi":"10.18727\/0722-6691\/5056"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03373","title":"Data-driven forecasting of solar irradiance","abstract":"This paper describes a flexible approach to short term prediction of\nmeteorological variables. In particular, we focus on the prediction of the\nsolar irradiance one hour ahead, a task that has high practical value when\noptimizing solar energy resources. As D\\'efi EGC 2018 provides us with time\nseries data for multiple sensors (e.g. solar irradiance, temperature,\nhygrometry), recorded every minute for two years and 5 geographical sites from\nLa R\\'eunion island, we test the value of using recently observed data as input\nfor prediction models, as well as the performance of models across sites. After\ndescribing our data cleaning and normalization process, we combine a variable\nselection step based on AutoRegressive Integrated Moving Average (ARIMA)\nmodels, to using general purpose regression techniques such as neural networks\nand regression trees.","primary_category":"cs","categories":["cs.NE"],"authors":["Bruneau Pierrick","Pinheiro Philippe","Didry Yoann"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03379","title":"On Maximally Recoverable Codes for Product Topologies","abstract":"Given a topology of local parity-check constraints, a maximally recoverable\ncode (MRC) can correct all erasure patterns that are information-theoretically\ncorrectable. In a grid-like topology, there are $a$ local constraints in every\ncolumn forming a column code, $b$ local constraints in every row forming a row\ncode, and $h$ global constraints in an $(m \\times n)$ grid of codeword.\nRecently, Gopalan et al. initiated the study of MRCs under grid-like topology,\nand derived a necessary and sufficient condition, termed as the regularity\ncondition, for an erasure pattern to be recoverable when $a=1, h=0$.\n  In this paper, we consider MRCs for product topology ($h=0$). First, we\nconstruct a certain bipartite graph based on the erasure pattern satisfying the\nregularity condition for product topology (any $a, b$, $h=0$) and show that\nthere exists a complete matching in this graph. We then present an alternate\ndirect proof of the sufficient condition when $a=1, h=0$. We later extend our\ntechnique to study the topology for $a=2, h=0$, and characterize a subset of\nrecoverable erasure patterns in that case. For both $a=1, 2$, our method of\nproof is uniform, i.e., by constructing tensor product $G_{\\text{col}} \\otimes\nG_{\\text{row}}$ of generator matrices of column and row codes such that certain\nsquare sub-matrices retain full rank. The full-rank condition is proved by\nresorting to the matching identified earlier and also another set of matchings\nin erasure sub-patterns.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Shivakrishna D.","Rameshwar V. Arvind","Lalitha V.","Sasidharan Birenjith"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03385","title":"Uncovering Hierarchical Structure in Social Networks using Isospectral\n  Reductions","abstract":"We employ the recently developed theory of isospectral network reductions to\nanalyze multi-mode social networks. This procedure allows us to uncover the\nhierarchical structure of the networks we consider as well as the hierarchical\nstructure of each mode of the network. Additionally, by performing a dynamical\nanalysis of these networks we are able to analyze the evolution of their\nstructure allowing us to find a number of other network features. We apply both\nof these approaches to the Southern Women Data Set, one of the most studied\nsocial networks and demonstrate that these techniques provide new information,\nwhich complements previous findings.","primary_category":"cs","categories":["cs.SI","math.CO"],"authors":["Wang Chi-Jen","Chae Seokjoo","Bunimovich Leonid A.","Webb Benjamin Z."],"created":"2017-12-05","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03404","title":"Structure Entropy and Resistor Graphs","abstract":"We propose the notion of {\\it resistance of a graph} as an accompanying\nnotion of the structure entropy to measure the force of the graph to resist\ncascading failure of strategic virus attacks. We show that for any connected\nnetwork $G$, the resistance of $G$ is\n$\\mathcal{R}(G)=\\mathcal{H}^1(G)-\\mathcal{H}^2(G)$, where $\\mathcal{H}^1(G)$\nand $\\mathcal{H}^2(G)$ are the one- and two-dimensional structure entropy of\n$G$, respectively. According to this, we define the notion of {\\it security\nindex of a graph} to be the normalized resistance, that is, $\\theta\n(G)=\\frac{\\mathcal{R}(G)}{\\mathcal{H}^1(H)}$. We say that a connected graph is\nan $(n,\\theta)$-{\\it resistor graph}, if $G$ has $n$ vertices and has security\nindex $\\theta (G)\\geq\\theta$. We show that trees and grid graphs are\n$(n,\\theta)$-resistor graphs for large constant $\\theta$, that the graphs with\nbounded degree $d$ and $n$ vertices, are $(n,\\frac{2}{d}-o(1))$-resistor\ngraphs, and that for a graph $G$ generated by the security model\n\\cite{LLPZ2015, LP2016}, with high probability, $G$ is an $(n,\\theta)$-resistor\ngraph, for a constant $\\theta$ arbitrarily close to $1$, provided that $n$ is\nsufficiently large. To the opposite side, we show that expander graphs are not\ngood resistor graphs, in the sense that, there is a global constant\n$\\theta_0<1$ such that expander graphs cannot be $(n,\\theta)$-resistor graph\nfor any $\\theta\\geq\\theta_0$. In particular, for the complete graph $G$, the\nresistance of $G$ is a constant $O(1)$, and hence the security index of $G$ is\n$\\theta (G)=o(1)$. Finally, we show that for any simple and connected graph\n$G$, if $G$ is an $(n, 1-o(1))$-resistor graph, then there is a large $k$ such\nthat the $k$-th largest eigenvalue of the Laplacian of $G$ is $o(1)$, giving\nrise to an algebraic characterization for the graphs that are secure against\nintentional virus attack.","primary_category":"cs","categories":["cs.DM","cs.IT","math.IT"],"authors":["Li Angsheng","Pan Yicheng"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03406","title":"DeepSeek: Content Based Image Search & Retrieval","abstract":"Most of the internet today is composed of digital media that includes videos\nand images. With pixels becoming the currency in which most transactions happen\non the internet, it is becoming increasingly important to have a way of\nbrowsing through this ocean of information with relative ease. YouTube has 400\nhours of video uploaded every minute and many million images are browsed on\nInstagram, Facebook, etc. Inspired by recent advances in the field of deep\nlearning and success that it has gained on various problems like image\ncaptioning and, machine translation , word2vec , skip thoughts, etc, we present\nDeepSeek a natural language processing based deep learning model that allows\nusers to enter a description of the kind of images that they want to search,\nand in response the system retrieves all the images that semantically and\ncontextually relate to the query. Two approaches are described in the following\nsections.","primary_category":"cs","categories":["cs.IR"],"authors":["Piplani Tanya","Bamman David"],"created":"2018-01-09","updated":"2018-01-11","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03407","title":"Numerical Analysis of Automodel Solutions for Superdiffusive Transport","abstract":"The distributed computing analysis of the accuracy of automodel solutions for\nthe Green's function of a wide class of superdiffusive transport of\nperturbation on a uniform background is carried out. The approximate automodel\nsolutions have been suggested for the 1D transport equation with a model\nlong-tailed step-length probability distribution function (PDF) with various\npower-law exponents. These PDFs describe the transport dominated by the L\\'evy\nflights. Massive computing experiments were done to verify automodel solutions.\nThe Everest distributed computing platform and the cluster at NRC Kurchatov\nInstitute were used. The results verify the high accuracy of automodel\nsolutions in a wide range of space-time variables and suggest extending the\ndeveloped method of automodel solutions to a wider class of stochastic\nphenomena.","primary_category":"cs","categories":["cs.NA","physics.comp-ph"],"authors":["Kukushkin Alexander B.","Neverov Vladislav S.","Sdvizhenskii Petr A.","Voloshinov Vladimir V."],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03412","title":"Assessment of SFSDP Cooperative Localization Algorithm for WLAN\n  Environment","abstract":"Cooperative localization for indoor WiFi networks have received little\nattention thus far. Many cooperative location algorithms exist for Wireless\nSensor Network Applications but their suitability for WiFi based networks has\nnot been studied. In this paper the performance of the Sparse Finite Semi\nDefinite Program (SFSDP) has been examined using real measurements data and\nunder different indoor conditions. Effects of other network parameters such as\nvarying number of anchors and blind nodes are also included.","primary_category":"cs","categories":["eess.SP","cs.NI"],"authors":["Almazrouei Ebtesam","Ali Nazar","Al-Araji Saleh"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03419","title":"Instance Scale, Numerical Properties and Design of Metaheuristics: A\n  Study for the Facility Location Problem","abstract":"Metaheuristics are known to be strong in solving large-scale instances of\ncomputationally hard problems. However, their efficiency still needs\nexploration in the context of instance structure, scale and numerical\nproperties for many of these problems. In this paper, we present an in-depth\ncomputational study of two local search metaheuristics for the classical\nuncapacitated facility location problem. We investigate four problem instance\nmodels, studied for the same problem size, for which the two metaheuristics\nexhibit intriguing and contrasting behaviours. The metaheuristics explored\ninclude a local search (LS) algorithm that chooses the best moves in the\ncurrent neighbourhood, while a randomised local search (RLS) algorithm chooses\nthe first move that does not lead to a worsening. The experimental results\nindicate that the right choice between these two algorithms depends heavily on\nthe distribution of coefficients within the problem instance. This is also put\nfurther into context by finding optimal or near-optimal solutions using a\nmixed-integer linear programming problem solver. Since the facility location\nproblem is a relatively simple example of a choice-and-assignment problem,\nsimilar phenomena are likely to be discovered in a number of other, possibly\nmore complex computational problems in science and engineering.","primary_category":"cs","categories":["cs.CE"],"authors":["Chalupa David","Nielsen Peter"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03423","title":"A Smoothed Analysis of the Greedy Algorithm for the Linear Contextual\n  Bandit Problem","abstract":"Bandit learning is characterized by the tension between long-term exploration\nand short-term exploitation. However, as has recently been noted, in settings\nin which the choices of the learning algorithm correspond to important\ndecisions about individual people (such as criminal recidivism prediction,\nlending, and sequential drug trials), exploration corresponds to explicitly\nsacrificing the well-being of one individual for the potential future benefit\nof others. This raises a fairness concern. In such settings, one might like to\nrun a \"greedy\" algorithm, which always makes the (myopically) optimal decision\nfor the individuals at hand - but doing this can result in a catastrophic\nfailure to learn. In this paper, we consider the linear contextual bandit\nproblem and revisit the performance of the greedy algorithm. We give a smoothed\nanalysis, showing that even when contexts may be chosen by an adversary, small\nperturbations of the adversary's choices suffice for the algorithm to achieve\n\"no regret\", perhaps (depending on the specifics of the setting) with a\nconstant amount of initial training data. This suggests that \"generically\"\n(i.e. in slightly perturbed environments), exploration and exploitation need\nnot be in conflict in the linear setting.","primary_category":"cs","categories":["cs.LG"],"authors":["Kannan Sampath","Morgenstern Jamie","Roth Aaron","Waggoner Bo","Wu Zhiwei Steven"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03429","title":"Monolithic simulation of convection-coupled phase-change - verification\n  and reproducibility","abstract":"Phase interfaces in melting and solidification processes are strongly\naffected by the presence of convection in the liquid. One way of modeling their\ntransient evolution is to couple an incompressible flow model to an energy\nbalance in enthalpy formulation. Two strong nonlinearities arise, which account\nfor the viscosity variation between phases and the latent heat of fusion at the\nphase interface.\n  The resulting coupled system of PDE's can be solved by a single-domain\nsemi-phase-field, variable viscosity, finite element method with monolithic\nsystem coupling and global Newton linearization. A robust computational model\nfor realistic phase-change regimes furthermore requires a flexible\nimplementation based on sophisticated mesh adaptivity. In this article, we\npresent first steps towards implementing such a computational model into a\nsimulation tool which we call Phaseflow.\n  Phaseflow utilizes the finite element software FEniCS, which includes a\ndual-weighted residual method for goal-oriented adaptive mesh refinement.\nPhaseflow is an open-source, dimension-independent implementation that, upon an\nappropriate parameter choice, reduces to classical benchmark situations\nincluding the lid-driven cavity and the Stefan problem. We present and discuss\nnumerical results for these, an octadecane PCM convection-coupled melting\nbenchmark, and a preliminary 3D convection-coupled melting example,\ndemonstrating the flexible implementation. Though being preliminary, the latter\nis, to our knowledge, the first published 3D result for this method. In our\nwork, we especially emphasize reproducibility and provide an easy-to-use\nportable software container using Docker.","primary_category":"cs","categories":["physics.flu-dyn","cs.CE"],"authors":["Zimmerman Alexander G.","Kowalski Julia"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03431","title":"Inferring a Third Spatial Dimension from 2D Histological Images","abstract":"Histological images are obtained by transmitting light through a tissue\nspecimen that has been stained in order to produce contrast. This process\nresults in 2D images of the specimen that has a three-dimensional structure. In\nthis paper, we propose a method to infer how the stains are distributed in the\ndirection perpendicular to the surface of the slide for a given 2D image in\norder to obtain a 3D representation of the tissue. This inference is achieved\nby decomposition of the staining concentration maps under constraints that\nensure realistic decomposition and reconstruction of the original 2D images.\nOur study shows that it is possible to generate realistic 3D images making this\nmethod a potential tool for data augmentation when training deep learning\nmodels.","primary_category":"cs","categories":["cs.CV"],"authors":["Lafarge Maxime W.","Pluim Josien P. W.","Eppenhof Koen A. J.","Moeskops Pim","Veta Mitko"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03457","title":"A class of $L_1$-to-$L_1$ and $L_\\infty$-to-$L_\\infty$ interval\n  observers for (delayed) Markov jump linear systems","abstract":"We exploit recent results on the stability and performance analysis of\npositive Markov jump linear systems (MJLS) for the design of interval observers\nfor MJLS with and without delays. While the conditions for the $L_1$\nperformance are necessary and sufficient, those for the $L_\\infty$ performance\nare only sufficient. All the conditions are stated as linear programs that can\nbe solved very efficiently. Two examples are given for illustration.","primary_category":"cs","categories":["math.OC","cs.SY"],"authors":["Briat Corentin"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03460","title":"MilkQA: a Dataset of Consumer Questions for the Task of Answer Selection","abstract":"We introduce MilkQA, a question answering dataset from the dairy domain\ndedicated to the study of consumer questions. The dataset contains 2,657 pairs\nof questions and answers, written in the Portuguese language and originally\ncollected by the Brazilian Agricultural Research Corporation (Embrapa). All\nquestions were motivated by real situations and written by thousands of authors\nwith very different backgrounds and levels of literacy, while answers were\nelaborated by specialists from Embrapa's customer service. Our dataset was\nfiltered and anonymized by three human annotators. Consumer questions are a\nchallenging kind of question that is usually employed as a form of seeking\ninformation. Although several question answering datasets are available, most\nof such resources are not suitable for research on answer selection models for\nconsumer questions. We aim to fill this gap by making MilkQA publicly\navailable. We study the behavior of four answer selection models on MilkQA: two\nbaseline models and two convolutional neural network archictetures. Our results\nshow that MilkQA poses real challenges to computational models, particularly\ndue to linguistic characteristics of its questions and to their unusually\nlonger lengths. Only one of the experimented models gives reasonable results,\nat the cost of high computational requirements.","primary_category":"cs","categories":["cs.CL"],"authors":["Criscuolo Marcelo","Fonseca Erick Rocha","Alu\u00edsio Sandra Maria","Speran\u00e7a-Criscuolo Ana Carolina"],"created":"2018-01-10","updated":" ","doi":"10.1109\/BRACIS.2017.12"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03484","title":"ONETS: Online Network Slice Broker From Theory to Practice","abstract":"Network slicing allows mobile network operators to open their physical\nnetwork infrastructure platform to the concurrent deployment of multiple\nlogical self-contained networks, i.e., network slices. In this paper we propose\nand analyze ONETS: an Online NETwork Slicing solution that (i) builds on the\nbudgeted lock-up multi-armed bandit mathematical model and properties, (ii)\nderives its analytical bounds in our proposed extension for network slicing,\n(iii) seamlessly integrates into the 3GPP architecture, (iv) proves its\nfeasibility through a proof-of-concept implementation on commercial hardware\nconsidering three network slices and (v) allows for the design of a\nlow-complexity online network slice brokering solution that maximizes\nmultiplexing gains.","primary_category":"cs","categories":["cs.NI"],"authors":["Sciancalepore Vincenzo","Zanzi Lanfranco","Costa-Perez Xavier","Capone Antonio"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03493","title":"Focus: Querying Large Video Datasets with Low Latency and Low Cost","abstract":"Large volumes of videos are continuously recorded from cameras deployed for\ntraffic control and surveillance with the goal of answering \"after the fact\"\nqueries: identify video frames with objects of certain classes (cars, bags)\nfrom many days of recorded video. While advancements in convolutional neural\nnetworks (CNNs) have enabled answering such queries with high accuracy, they\nare too expensive and slow. We build Focus, a system for low-latency and\nlow-cost querying on large video datasets. Focus uses cheap ingestion\ntechniques to index the videos by the objects occurring in them. At\ningest-time, it uses compression and video-specific specialization of CNNs.\nFocus handles the lower accuracy of the cheap CNNs by judiciously leveraging\nexpensive CNNs at query-time. To reduce query time latency, we cluster similar\nobjects and hence avoid redundant processing. Using experiments on video\nstreams from traffic, surveillance and news channels, we see that Focus uses\n58X fewer GPU cycles than running expensive ingest processors and is 37X faster\nthan processing all the video at query time.","primary_category":"cs","categories":["cs.DB","cs.CV","cs.DC"],"authors":["Hsieh Kevin","Ananthanarayanan Ganesh","Bodik Peter","Bahl Paramvir","Philipose Matthai","Gibbons Phillip B.","Mutlu Onur"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03513","title":"Proceedings of the Workshop on High Performance Energy Efficient\n  Embedded Systems (HIP3ES) 2018","abstract":"Proceedings of the Workshop on High Performance Energy Efficient Embedded\nSystems (HIP3ES) 2018. Manchester, United Kingdom, January 22nd. Collocated\nwith HIPEAC 2018 Conference.","primary_category":"cs","categories":["cs.DC"],"authors":["Castells-Rufas David","Bastoul C\u00e9dric"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03523","title":"Generative Models for Stochastic Processes Using Convolutional Neural\n  Networks","abstract":"The present paper aims to demonstrate the usage of Convolutional Neural\nNetworks as a generative model for stochastic processes, enabling researchers\nfrom a wide range of fields (such as quantitative finance and physics) to\ndevelop a general tool for forecasts and simulations without the need to\nidentify\/assume a specific system structure or estimate its parameters.","primary_category":"cs","categories":["stat.ML","cs.NE","physics.comp-ph","q-fin.CP"],"authors":["Neto Fernando Fernandes"],"created":"2018-01-08","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03529","title":"Autism Children's App using PECS","abstract":"Since autistic children suffers from learning disabilities and communication\nbarriers, this research aim to design, develop and evaluate an Android based\nmobile application (app) providing better learning environment with inclusion\nof graphical representation in a cost effective manner. This research evaluate\nvarious supporting technologies and finds Picture Exchange Communication System\n(PECS) to be better choice for integrating with the app. Evaluation results\nreveal that the inclusion of PECS helped the children suffering from Autistic\nSpectrum Disorder (ASD) to better communicate with others. The study included\nautistic children who do not speak, who are unintelligible and who are\nminimally effective communicators with their present communication system. The\nevolution results showed encouraging impacts of the Autism App in supporting\nautistic children to adapt to normal life and improve the standard of their\nlife.","primary_category":"cs","categories":["cs.CY"],"authors":["Soomro Nareena","Soomro Safeeullah"],"created":"2018-01-09","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03533","title":"Selection Problems in the Presence of Implicit Bias","abstract":"Over the past two decades, the notion of implicit bias has come to serve as\nan important component in our understanding of discrimination in activities\nsuch as hiring, promotion, and school admissions. Research on implicit bias\nposits that when people evaluate others -- for example, in a hiring context --\ntheir unconscious biases about membership in particular groups can have an\neffect on their decision-making, even when they have no deliberate intention to\ndiscriminate against members of these groups. A growing body of experimental\nwork has pointed to the effect that implicit bias can have in producing adverse\noutcomes.\n  Here we propose a theoretical model for studying the effects of implicit bias\non selection decisions, and a way of analyzing possible procedural remedies for\nimplicit bias within this model. A canonical situation represented by our model\nis a hiring setting: a recruiting committee is trying to choose a set of\nfinalists to interview among the applicants for a job, evaluating these\napplicants based on their future potential, but their estimates of potential\nare skewed by implicit bias against members of one group. In this model, we\nshow that measures such as the Rooney Rule, a requirement that at least one of\nthe finalists be chosen from the affected group, can not only improve the\nrepresentation of this affected group, but also lead to higher payoffs in\nabsolute terms for the organization performing the recruiting. However,\nidentifying the conditions under which such measures can lead to improved\npayoffs involves subtle trade-offs between the extent of the bias and the\nunderlying distribution of applicant characteristics, leading to novel\ntheoretical questions about order statistics in the presence of probabilistic\nside information.","primary_category":"cs","categories":["cs.CY","cs.LG","stat.ML"],"authors":["Kleinberg Jon","Raghavan Manish"],"created":"2018-01-04","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03536","title":"On B. Moss\\'e's unilateral recognizability theorem","abstract":"We complete statement and proof for B. Moss\\'e's unilateral recognizability\ntheorem. We also provide an algorithm for deciding the unilateral\nnon-recognizability of a given primitive substitution.","primary_category":"cs","categories":["math.DS","cs.FL"],"authors":["Akiyama Shigeki","Tan Bo","Yuasa Hisatoshi"],"created":"2017-12-27","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03551","title":"From Superpixel to Human Shape Modelling for Carried Object Detection","abstract":"Detecting carried objects is one of the requirements for developing systems\nto reason about activities involving people and objects. We present an approach\nto detect carried objects from a single video frame with a novel method that\nincorporates features from multiple scales. Initially, a foreground mask in a\nvideo frame is segmented into multi-scale superpixels. Then the human-like\nregions in the segmented area are identified by matching a set of extracted\nfeatures from superpixels against learned features in a codebook. A carried\nobject probability map is generated using the complement of the matching\nprobabilities of superpixels to human-like regions and background information.\nA group of superpixels with high carried object probability and strong edge\nsupport is then merged to obtain the shape of the carried object. We applied\nour method to two challenging datasets, and results show that our method is\ncompetitive with or better than the state-of-the-art.","primary_category":"cs","categories":["cs.CV"],"authors":["Ghadiri Farnoosh","Bergevin Robert","Bilodeau Guillaume-Alexandre"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03552","title":"An evolutionary algorithm for online, resource constrained,\n  multi-vehicle sensing mission planning","abstract":"Mobile robotic platforms are an indispensable tool for various scientific and\nindustrial applications. Robots are used to undertake missions whose execution\nis constrained by various factors, such as the allocated time or their\nremaining energy. Existing solutions for resource constrained multi-robot\nsensing mission planning provide optimal plans at a prohibitive computational\ncomplexity for online application [1],[2],[3]. A heuristic approach exists for\nan online, resource constrained sensing mission planning for a single vehicle\n[4]. This work proposes a Genetic Algorithm (GA) based heuristic for the\nCorrelated Team Orienteering Problem (CTOP) that is used for planning sensing\nand monitoring missions for robotic teams that operate under resource\nconstraints. The heuristic is compared against optimal Mixed Integer Quadratic\nProgramming (MIQP) solutions. Results show that the quality of the heuristic\nsolution is at the worst case equal to the 5% optimal solution. The heuristic\nsolution proves to be at least 300 times more time efficient in the worst\ntested case. The GA heuristic execution required in the worst case less than a\nsecond making it suitable for online execution.","primary_category":"cs","categories":["cs.RO"],"authors":["Tsiogkas Nikolaos","Lane David M."],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03553","title":"On the Noise-Information Separation of a Private Principal Component\n  Analysis Scheme","abstract":"In a survey disclosure model, we consider an additive noise privacy mechanism\nand study the trade-off between privacy guarantees and statistical utility.\nPrivacy is approached from two different but complementary viewpoints:\ninformation and estimation theoretic. Motivated by the performance of principal\ncomponent analysis, statistical utility is measured via the spectral gap of a\ncertain covariance matrix. This formulation and its motivation rely on\nclassical results from random matrix theory. We prove some properties of this\nstatistical utility function and discuss a simple numerical method to evaluate\nit.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Diaz Mario","Asoodeh Shahab","Alajaji Fady","Linder Tam\u00e1s","Belinschi Serban","Mingo James"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03557","title":"Rate Selection and Power Adaptation using Maximal Ratio Combining for\n  the Random Access Gaussian Channel","abstract":"With the emergence of machine-driven communi- cation, there is a renewed\ninterest in the design of random multiple access schemes for networks with\nlarge number of active devices. Many of the recently proposed access paradigms\nare enhancements to slotted ALOHA. One of the popular schemes, irregular\nrepetition slotted ALOHA (IRSA), is based on an analogy between multiple access\nwith successive interference cancellation and message-passing decoding on\nbipartite graphs. Most of the results on IRSA and its variants focus on the\ncollision channel and they ignore physical limitations such as transmit power\nconstraints and additive Gaussian noise at the physical layer. As such, naive\nextensions of IRSA to the Gaussian multiple access channel are not power\nefficient in the low signal-to-noise- ratio regime. This work introduces a\nnovel paradigm whereby devices adapt their rates and\/or transmit powers based\non their chosen repetition profiles. The receiver performs maximal ratio\ncombining over all the replicas prior to decoding a message. Numerical results\nfor finite number of users show that the proposed scheme can provide\nsubstantial improvements in terms of power efficiency and average rate over\nstandard IRSA.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Hasanzadeh Arman","Chamberland Jean-Francois","Narayanan Krishna"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03562","title":"Discrete symbolic optimization and Boltzmann sampling by continuous\n  neural dynamics: Gradient Symbolic Computation","abstract":"Gradient Symbolic Computation is proposed as a means of solving discrete\nglobal optimization problems using a neurally plausible continuous stochastic\ndynamical system. Gradient symbolic dynamics involves two free parameters that\nmust be adjusted as a function of time to obtain the global maximizer at the\nend of the computation. We provide a summary of what is known about the GSC\ndynamics for special cases of settings of the parameters, and also establish\nthat there is a schedule for the two parameters for which convergence to the\ncorrect answer occurs with high probability. These results put the empirical\nresults already obtained for GSC on a sound theoretical footing.","primary_category":"cs","categories":["cs.CL"],"authors":["Tupper Paul","Smolensky Paul","Cho Pyeong Whan"],"created":"2018-01-04","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03564","title":"Unsupervised Part-of-Speech Induction","abstract":"Part-of-Speech (POS) tagging is an old and fundamental task in natural\nlanguage processing. While supervised POS taggers have shown promising\naccuracy, it is not always feasible to use supervised methods due to lack of\nlabeled data. In this project, we attempt to unsurprisingly induce POS tags by\niteratively looking for a recurring pattern of words through a hierarchical\nagglomerative clustering process. Our approach shows promising results when\ncompared to the tagging results of the state-of-the-art unsupervised POS\ntaggers.","primary_category":"cs","categories":["cs.CL"],"authors":["Kashefi Omid"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03572","title":"Learning Aided Optimization for Energy Harvesting Devices with Outdated\n  State Information","abstract":"This paper considers utility optimal power control for energy harvesting\nwireless devices with a finite capacity battery. The distribution information\nof the underlying wireless environment and harvestable energy is unknown and\nonly outdated system state information is known at the device controller. This\nscenario shares similarity with Lyapunov opportunistic optimization and online\nlearning but is different from both. By a novel combination of Zinkevich's\nonline gradient learning technique and the drift-plus-penalty technique from\nLyapunov opportunistic optimization, this paper proposes a learning-aided\nalgorithm that achieves utility within $O(\\epsilon)$ of the optimal, for any\ndesired $\\epsilon>0$, by using a battery with an $O(1\/\\epsilon)$ capacity. The\nproposed algorithm has low complexity and makes power investment decisions\nbased on system history, without requiring knowledge of the system state or its\nprobability distribution.","primary_category":"cs","categories":["math.OC","cs.PF","cs.SY"],"authors":["Yu Hao","Neely Michael J."],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03588","title":"Deterministic search for CNF satisfying assignments in almost polynomial\n  time","abstract":"We consider the fundamental derandomization problem of deterministically\nfinding a satisfying assignment to a CNF formula that has many satisfying\nassignments. We give a deterministic algorithm which, given an $n$-variable\n$\\mathrm{poly}(n)$-clause CNF formula $F$ that has at least $\\varepsilon 2^n$\nsatisfying assignments, runs in time \\[ n^{\\tilde{O}(\\log\\log n)^2} \\] for\n$\\varepsilon \\ge 1\/\\mathrm{polylog}(n)$ and outputs a satisfying assignment of\n$F$. Prior to our work the fastest known algorithm for this problem was simply\nto enumerate over all seeds of a pseudorandom generator for CNFs; using the\nbest known PRGs for CNFs [DETT10], this takes time $n^{\\tilde{\\Omega}(\\log n)}$\neven for constant $\\varepsilon$. Our approach is based on a new general\nframework relating deterministic search and deterministic approximate counting,\nwhich we believe may find further applications.","primary_category":"cs","categories":["cs.CC"],"authors":["Servedio Rocco A.","Tan Li-Yang"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03589","title":"Task parallel implementation of a solver for electromagnetic scattering\n  problems","abstract":"Electromagnetic computations, where the wavelength is small in relation to\nthe geometry of interest, become computationally demanding. In order to manage\ncomputations for realistic problems like electromagnetic scattering from\naircraft, the use of parallel computing is essential. In this paper, we\ndescribe how a solver based on a hierarchical nested equivalent source\napproximation can be implemented in parallel using a task based programming\nmodel. We show that the effort for moving from the serial implementation to a\nparallel implementation is modest due to the task based programming paradigm,\nand that the performance achieved on a multicore system is excellent provided\nthat the task size, depending on the method parameters, is large enough.","primary_category":"cs","categories":["cs.CE","cs.DC","cs.PF"],"authors":["Zafari Afshin","Larsson Elisabeth","Righero Marco","Francavilla M. Alessandro","Giordanengo Giorgio","Vipiana Francesca","Vecchi Giuseppe"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03590","title":"Improved pseudorandom generators from pseudorandom multi-switching\n  lemmas","abstract":"We give the best known pseudorandom generators for two touchstone classes in\nunconditional derandomization: an $\\varepsilon$-PRG for the class of size-$M$\ndepth-$d$ $\\mathsf{AC}^0$ circuits with seed length $\\log(M)^{d+O(1)}\\cdot\n\\log(1\/\\varepsilon)$, and an $\\varepsilon$-PRG for the class of $S$-sparse\n$\\mathbb{F}_2$ polynomials with seed length $2^{O(\\sqrt{\\log S})}\\cdot\n\\log(1\/\\varepsilon)$. These results bring the state of the art for\nunconditional derandomization of these classes into sharp alignment with the\nstate of the art for computational hardness for all parameter settings:\nimproving on the seed lengths of either PRG would require breakthrough progress\non longstanding and notorious circuit lower bounds.\n  The key enabling ingredient in our approach is a new \\emph{pseudorandom\nmulti-switching lemma}. We derandomize recently-developed\n\\emph{multi}-switching lemmas, which are powerful generalizations of\nH{\\aa}stad's switching lemma that deal with \\emph{families} of depth-two\ncircuits. Our pseudorandom multi-switching lemma---a randomness-efficient\nalgorithm for sampling restrictions that simultaneously simplify all circuits\nin a family---achieves the parameters obtained by the (full randomness)\nmulti-switching lemmas of Impagliazzo, Matthews, and Paturi [IMP12] and\nH{\\aa}stad [H{\\aa}s14]. This optimality of our derandomization translates into\nthe optimality (given current circuit lower bounds) of our PRGs for\n$\\mathsf{AC}^0$ and sparse $\\mathbb{F}_2$ polynomials.","primary_category":"cs","categories":["cs.CC"],"authors":["Servedio Rocco A.","Tan Li-Yang"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03594","title":"Finite Blocklength and Dispersion Bounds for the Arbitrarily-Varying\n  Channel","abstract":"Finite blocklength and second-order (dispersion) results are presented for\nthe arbitrarily-varying channel (AVC), a classical model wherein an adversary\ncan transmit arbitrary signals into the channel. A novel finite blocklength\nachievability bound is presented, roughly analogous to the random coding union\nbound for non-adversarial channels. This finite blocklength bound, along with a\nknown converse bound, is used to derive bounds on the dispersion of discrete\nmemoryless AVCs without shared randomness, and with cost constraints on the\ninput and the state. These bounds are tight for many channels of interest,\nincluding the binary symmetric AVC. However, the bounds are not tight if the\ndeterministic and random code capacities differ.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Kosut Oliver","Kliewer Joerg"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03595","title":"Local Map-assisted Positioning for Flying Wireless Relays","abstract":"This paper considers the exploitation of unmanned aerial vehicles (UAVs) in\nwireless networking, with which communication-enabled robots operate as flying\nwireless relays to provide connectivity or a capacity boost to a ground user.\nWe focus on the particular problem of (automatic) UAV positioning, which\ngreatly affects the end-to-end throughput performance. While existing methods\nrely on propagation distance minimiza- tion and statistical models for the\npresence or absence of a line-of-sight (LOS), we propose an approach capable of\nleveraging local topological information so as to offer better performance\nguarantees. The proposed method allows to strike a trade-off between minimizing\ndistance path loss and discovering (near) LOS opportunities at locations away\nfrom the base station (BS)-user axis. Furthermore, the algorithm is shown to\nfind the global optimal UAV position, although it only requires a local\nexploration of a signal strength map and the length of search trajectory is\nonly linear to the geographical scale. Hence, it lends itself to online\nimplementation. Significant throughput gains are found when compared to other\npositioning approaches based on LOS statistical models.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Chen Junting","Gesbert David"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03597","title":"Secrecy by Witness-Functions on Increasing Protocols","abstract":"In this paper, we present a new formal method to analyze cryptographic\nprotocols statically for the property of secrecy. It consists in inspecting the\nlevel of security of every component in the protocol and making sure that it\ndoes not diminish during its life cycle. If yes, it concludes that the protocol\nkeeps its secret inputs. We analyze in this paper an amended version of the\nWoo-Lam protocol using this new method.","primary_category":"cs","categories":["cs.CR"],"authors":["Fattahi Jaouhar","Mejri Mohamed","Houmani Hanane"],"created":"2018-01-10","updated":" ","doi":"10.1109\/ECAI.2014.7090214"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03603","title":"SEE: Syntax-aware Entity Embedding for Neural Relation Extraction","abstract":"Distant supervised relation extraction is an efficient approach to scale\nrelation extraction to very large corpora, and has been widely used to find\nnovel relational facts from plain text. Recent studies on neural relation\nextraction have shown great progress on this task via modeling the sentences in\nlow-dimensional spaces, but seldom considered syntax information to model the\nentities. In this paper, we propose to learn syntax-aware entity embedding for\nneural relation extraction. First, we encode the context of entities on a\ndependency tree as sentence-level entity embedding based on tree-GRU. Then, we\nutilize both intra-sentence and inter-sentence attentions to obtain sentence\nset-level entity embedding over all sentences containing the focus entity pair.\nFinally, we combine both sentence embedding and entity embedding for relation\nclassification. We conduct experiments on a widely used real-world dataset and\nthe experimental results show that our model can make full use of all\ninformative instances and achieve state-of-the-art performance of relation\nextraction.","primary_category":"cs","categories":["cs.CL"],"authors":["He Zhengqiu","Chen Wenliang","Li Zhenghua","Zhang Meishan","Zhang Wei","Zhang Min"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03604","title":"Conversational AI: The Science Behind the Alexa Prize","abstract":"Conversational agents are exploding in popularity. However, much work remains\nin the area of social conversation as well as free-form conversation over a\nbroad range of domains and topics. To advance the state of the art in\nconversational AI, Amazon launched the Alexa Prize, a 2.5-million-dollar\nuniversity competition where sixteen selected university teams were challenged\nto build conversational agents, known as socialbots, to converse coherently and\nengagingly with humans on popular topics such as Sports, Politics,\nEntertainment, Fashion and Technology for 20 minutes. The Alexa Prize offers\nthe academic community a unique opportunity to perform research with a live\nsystem used by millions of users. The competition provided university teams\nwith real user conversational data at scale, along with the user-provided\nratings and feedback augmented with annotations by the Alexa team. This enabled\nteams to effectively iterate and make improvements throughout the competition\nwhile being evaluated in real-time through live user interactions. To build\ntheir socialbots, university teams combined state-of-the-art techniques with\nnovel strategies in the areas of Natural Language Understanding, Context\nModeling, Dialog Management, Response Generation, and Knowledge Acquisition. To\nsupport the efforts of participating teams, the Alexa Prize team made\nsignificant scientific and engineering investments to build and improve\nConversational Speech Recognition, Topic Tracking, Dialog Evaluation, Voice\nUser Experience, and tools for traffic management and scalability. This paper\noutlines the advances created by the university teams as well as the Alexa\nPrize team to achieve the common goal of solving the problem of Conversational\nAI.","primary_category":"cs","categories":["cs.AI","cs.CL","cs.CY","cs.HC","cs.MA"],"authors":["Ram Ashwin","Prasad Rohit","Khatri Chandra","Venkatesh Anu","Gabriel Raefer","Liu Qing","Nunn Jeff","Hedayatnia Behnam","Cheng Ming","Nagar Ashish","King Eric","Bland Kate","Wartick Amanda","Pan Yi","Song Han","Jayadevan Sk","Hwang Gene","Pettigrue Art"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03607","title":"Quadrature compressive sampling SAR imaging","abstract":"This paper presents a quadrature compressive sampling (QuadCS) and associated\nfast imaging scheme for synthetic aperture radar (SAR). Different from other\nanalog-to-information conversions (AIC), QuadCS AICs using independent\nspreading signals sample the SAR echoes due to different transmitted pulses.\nThen the resulting sensing matrix has lower correlation between any two columns\nthan that by a fixed spreading signal, and better SAR image can be\nreconstructed. With proper setting of the spreading signals in QuadCS, the\nsensing matrix has the structures suitable for fast computation of\nmatrix-vector multiplication operations, which leads to the fast image\nreconstruction. The performance of the proposed scheme is assessed using real\nSAR image. The reconstructed SAR images with only one-fourth of the Nyquist\ndata achieve the image quality similar to that of the classical SAR images with\nNyquist samples.","primary_category":"cs","categories":["cs.IT","eess.SP","math.IT"],"authors":["Yang Huizhang","Chen Shengyao","Xi Feng","Liu Zhong"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03609","title":"A Zero-stealthy Attack for Sampled-data Control Systems via Input\n  Redundancy","abstract":"In this paper, we introduce a new vulnerability of cyber-physical systems to\nmalicious attack. It arises when the physical plant, that is modeled as a\ncontinuous-time LTI system, is controlled by a digital controller. In the\nsampled-data framework, most anomaly detectors monitor the plant's output only\nat discrete time instants, and thus, nothing abnormal can be detected as long\nas the sampled output behaves normal. This implies that if an actuator attack\ndrives the plant's state to pass through the kernel of the output matrix at\neach sensing time, then the attack compromises the system while remaining\nstealthy. We show that this type of attack always exists when the sampled-data\nsystem has an input redundancy, i.e., the number of inputs being larger than\nthat of the outputs or the sampling rate of the actuators being higher than\nthat of the sensors. Simulation results for the X-38 vehicle and for the other\nnumerical examples illustrate this new attack strategy possibly brings\ndisastrous consequences.","primary_category":"cs","categories":["cs.SY"],"authors":["Kim Jihan","Park Gyunghoon","Shim Hyungbo","Eun Yongsoon"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03611","title":"Multi-path Route Determination Method for Network Load Balancing in\n  FAP-Based WSNs Using Fuzzy Logic","abstract":"A flooding attack in wireless sensor networks is a type of threat that\nshortens the lifetimes of the sensor networks. Although flooding attack\nprevention techniques have been proposed, if a continuous flooding attack\noccurs, the sensor node energy is depleted during detection. In this paper, we\nuse multi-path routing to solve this problem. In order to balance the load of\nthe sensor node, energy balancing of the sensor node is controlled by\ndetermining the number of pathways using fuzzy logic. By adjusting the energy\nbalancing of the sensor nodes, the number of energy-exhausting sensor nodes can\nbe reduced. As a result, when a flooding attack occurs, the energy efficiency\nof the sensor node is increased by determining the number of pathways.","primary_category":"cs","categories":["cs.NI"],"authors":["Chung Won-Jin","Cho Tea-Ho"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03615","title":"Improved English to Russian Translation by Neural Suffix Prediction","abstract":"Neural machine translation (NMT) suffers a performance deficiency when a\nlimited vocabulary fails to cover the source or target side adequately, which\nhappens frequently when dealing with morphologically rich languages. To address\nthis problem, previous work focused on adjusting translation granularity or\nexpanding the vocabulary size. However, morphological information is relatively\nunder-considered in NMT architectures, which may further improve translation\nquality. We propose a novel method, which can not only reduce data sparsity but\nalso model morphology through a simple but effective mechanism. By predicting\nthe stem and suffix separately during decoding, our system achieves an\nimprovement of up to 1.98 BLEU compared with previous work on English to\nRussian translation. Our method is orthogonal to different NMT architectures\nand stably gains improvements on various domains.","primary_category":"cs","categories":["cs.CL"],"authors":["Song Kai","Zhang Yue","Zhang Min","Luo Weihua"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03616","title":"Parity-Check Polar Coding for 5G and Beyond","abstract":"In this paper, we propose a comprehensive Polar coding solution that\nintegrates reliability calculation, rate matching and parity-check coding.\nJudging a channel coding design from the industry's viewpoint, there are two\nprimary concerns: (i) low-complexity implementation in application-specific\nintegrated circuit (ASIC), and (ii) superior \\& stable performance under a wide\nrange of code lengths and rates. The former provides cost- \\& power-efficiency\nwhich are vital to any commercial system; the latter ensures flexible and\nrobust services. Our design respects both criteria. It demonstrates better\nperformance than existing schemes in literature, but requires only a fraction\nof implementation cost. With easily-reproducible code construction for\narbitrary code rates and lengths, we are able to report \"1-bit\"\nfine-granularity simulation results for thousands of cases. The released\nresults can serve as a baseline for future optimization of Polar codes.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Zhang Huazi","Li Rong","Wang Jian","Dai Shengchen","Zhang Gongzheng","Chen Ying","Luo Hejia","Wang Jun"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03619","title":"RAF: Robust Adaptive Multi-Feedback Channel Estimation for Millimeter\n  Wave MIMO Systems","abstract":"Millimeter wave is a promising technology for the next generation of wireless\nsystems. As it is well-known for its high path loss, the systems working in\nthis spectrum tend to exploit the shorter wavelength to equip the transceivers\nwith a large number of antennas to overcome the path loss issue. The large\nnumber of antennas leads to large channel matrices and consequently a\nchallenging channel estimation problem. The channel estimation algorithms that\nhave been proposed so far either neglect the probability of estimation error or\nrequire a high feedback overload from receivers to ensure the target\nprobability of estimation error. In this paper, we propose a multi-stage\nadaptive channel estimation algorithm called robust adaptive multi-feedback\n(RAF). The algorithm is based on using the estimated channel coefficient to\npredict a lower bound for the required number of measurements. Our simulations\ndemonstrate that compared with existing algorithms, RAF can achieve the desired\nprobability of estimation error while on average reducing the feedback overhead\nby 75.5% and the total channel estimation time by 14%.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Shaham Sina","Kokshoorn Matthew","Lin Zihuai","Ding Ming"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03622","title":"Topic-based Evaluation for Conversational Bots","abstract":"Dialog evaluation is a challenging problem, especially for non task-oriented\ndialogs where conversational success is not well-defined. We propose to\nevaluate dialog quality using topic-based metrics that describe the ability of\na conversational bot to sustain coherent and engaging conversations on a topic,\nand the diversity of topics that a bot can handle. To detect conversation\ntopics per utterance, we adopt Deep Average Networks (DAN) and train a topic\nclassifier on a variety of question and query data categorized into multiple\ntopics. We propose a novel extension to DAN by adding a topic-word attention\ntable that allows the system to jointly capture topic keywords in an utterance\nand perform topic classification. We compare our proposed topic based metrics\nwith the ratings provided by users and show that our metrics both correlate\nwith and complement human judgment. Our analysis is performed on tens of\nthousands of real human-bot dialogs from the Alexa Prize competition and\nhighlights user expectations for conversational bots.","primary_category":"cs","categories":["cs.CL","cs.AI","cs.CY","cs.HC","cs.MA"],"authors":["Guo Fenfei","Metallinou Angeliki","Khatri Chandra","Raju Anirudh","Venkatesh Anu","Ram Ashwin"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03623","title":"Optimal locally repairable codes of distance $3$ and $4$ via cyclic\n  codes","abstract":"Like classical block codes, a locally repairable code also obeys the\nSingleton-type bound (we call a locally repairable code {\\it optimal} if it\nachieves the Singleton-type bound). In the breakthrough work of \\cite{TB14},\nseveral classes of optimal locally repairable codes were constructed via\nsubcodes of Reed-Solomon codes. Thus, the lengths of the codes given in\n\\cite{TB14} are upper bounded by the code alphabet size $q$. Recently, it was\nproved through extension of construction in \\cite{TB14} that length of $q$-ary\noptimal locally repairable codes can be $q+1$ in \\cite{JMX17}. Surprisingly,\n\\cite{BHHMV16} presented a few examples of $q$-ary optimal locally repairable\ncodes of small distance and locality with code length achieving roughly $q^2$.\nVery recently, it was further shown in \\cite{LMX17} that there exist $q$-ary\noptimal locally repairable codes with length bigger than $q+1$ and distance\npropositional to $n$.\n  Thus, it becomes an interesting and challenging problem to construct new\nfamilies of $q$-ary optimal locally repairable codes of length bigger than\n$q+1$.\n  In this paper, we construct a class of optimal locally repairable codes of\ndistance $3$ and $4$ with unbounded length (i.e., length of the codes is\nindependent of the code alphabet size). Our technique is through cyclic codes\nwith particular generator and parity-check polynomials that are carefully\nchosen.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Luo Yuan","Xing Chaoping","Yuan Chen"],"created":"2018-01-10","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03645","title":"A tool framework for tweaking features in synthetic datasets","abstract":"Researchers and developers use benchmarks to compare their algorithms and\nproducts. A database benchmark must have a dataset D. To be\napplication-specific, this dataset D should be empirical. However, D may be too\nsmall, or too large, for the benchmarking experiments. D must, therefore, be\nscaled to the desired size.\n  To ensure the scaled D' is similar to D, previous work typically specifies or\nextracts a fixed set of features F = {F_1, F_2, . . . , F_n} from D, then uses\nF to generate synthetic data for D'. However, this approach (D -> F -> D')\nbecomes increasingly intractable as F gets larger, so a new solution is\nnecessary.\n  Different from existing approaches, this paper proposes ASPECT to scale D to\nenforce similarity. ASPECT first uses a size-scaler (S0) to scale D to D'. Then\nthe user selects a set of desired features F'_1, . . . , F'_n. For each desired\nfeature F'_k, there is a tweaking tool T_k that tweaks D' to make sure D' has\nthe required feature F'_k. ASPECT coordinates the tweaking of T_1,...,T_n to\nD', so T_n(...(T_1(D'))...) has the required features F'_1,...,F'_n.\n  By shifting from D -> F -> D' to D -> D' -> F', data scaling becomes\nflexible. The user can customise the scaled dataset with their own interested\nfeatures. Extensive experiments on real datasets show that ASPECT can enforce\nsimilarity in the dataset effectively and efficiently.","primary_category":"cs","categories":["cs.DB"],"authors":["Zhang J. W.","Tay Y. C."],"created":"2018-01-11","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03655","title":"Can Negligible Cooperation Increase Network Capacity? The Average-Error\n  Case","abstract":"In communication networks, cooperative strategies are coding schemes where\nnetwork nodes work together to improve network performance metrics such as\nsum-rate. This work studies encoder cooperation in the setting of a discrete\nmultiple access channel with two encoders and a single decoder. A node in the\nnetwork that is connected to both encoders via rate-limited links, referred to\nas the cooperation facilitator (CF), enables the cooperation strategy.\nPreviously, the authors presented a class of multiple access channels where the\naverage-error sum-capacity has an infinite derivative in the limit where CF\noutput link capacities approach zero. The authors also demonstrated that for\nsome channels, the maximal-error sum-capacity is not continuous at the point\nwhere the output link capacities of the CF equal zero. This work shows that the\nthe average-error sum-capacity is continuous when CF output link capacities\nconverge to zero; that is, the infinite derivative of the average-error\nsum-capacity is not a result of its discontinuity as in the maximal-error case.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Noorzad Parham","Effros Michelle","Langberg Michael"],"created":"2018-01-11","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03695","title":"Graphene-Based terahertz antennas for area-constrained applications","abstract":"Terahertz technology has made significant advances in the fields of\nspectroscopy, imaging and, more recently, wireless communications. In the\nlatter, the use of this frequency band between 0.1 and 10 THz becomes extremely\nattractive due to the abundance of bandwidth and the potential for low area and\npower footprints, yet challenging given the large propagation losses and the\nlack of mature devices and circuits for terahertz operation. Maturity issues\naside, this combination of features renders terahertz wireless communications\ndesirable for highly integrated applications where area may be a decisive\nmetric.","primary_category":"cs","categories":["cs.ET","physics.app-ph"],"authors":["Abadal Sergi","Hosseininejad Seyed E.","Cabellos-Aparicio Albert","Alarc\u00f3n Eduard"],"created":"2018-01-11","updated":" ","doi":"10.1109\/TSP.2017.8076102"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03698","title":"On a Stackelberg Subset Sum Game","abstract":"This contribution deals with a two-level discrete decision problem, a\nso-called Stackelberg strategic game: A Subset Sum setting is addressed with a\nset $N$ of items with given integer weights. One distinguished player, the\nleader, may alter the weights of the items in a given subset $L\\subset N$, and\na second player, the follower, selects a solution $A\\subseteq N$ in order to\nutilize a bounded resource in the best possible way. Finally, the leader\nreceives a payoff from those items of its subset $L$ that were included in the\noverall solution $A$, chosen by the follower. We assume that the follower\napplies a publicly known, simple, heuristic algorithm to determine its solution\nset, which avoids having to solve NP-hard problems.\n  Two variants of the problem are considered, depending on whether the leader\nis able to control (i.e., change) the weights of its items (i) in the objective\nfunction or (ii) in the bounded resource constraint. The leader's objective is\nthe maximization of the overall weight reduction, for the first variant, or the\nmaximization of the weight increase for the latter one. In both variants there\nis a trade-off for each item between the contribution value to the leader's\nobjective and the chance of being included in the follower's solution set.\n  We analyze the leader's pricing problem for a natural greedy strategy of the\nfollower and discuss the complexity of the corresponding problems. We show that\nsetting the optimal weight values for the leader is, in general, NP-hard. It is\neven NP-hard to provide a solution within a constant factor of the best\npossible solution. Exact algorithms, based on dynamic programming and running\nin pseudopolynomial time, are provided. The additional cases, in which the\nfollower faces a continuous (linear relaxation) version of the above problems,\nare shown to be straightforward to solve.","primary_category":"cs","categories":["cs.DM"],"authors":["Pferschy Ulrich","Nicosia Gaia","Pacifici Andrea"],"created":"2018-01-11","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03710","title":"Polypus: a Big Data Self-Deployable Architecture for Microblogging Text\n  Extraction and Real-Time Sentiment Analysis","abstract":"In this paper we propose a new parallel architecture based on Big Data\ntechnologies for real-time sentiment analysis on microblogging posts. Polypus\nis a modular framework that provides the following functionalities: (1) massive\ntext extraction from Twitter, (2) distributed non-relational storage optimized\nfor time range queries, (3) memory-based intermodule buffering, (4) real-time\nsentiment classification, (5) near real-time keyword sentiment aggregation in\ntime series, (6) a HTTP API to interact with the Polypus cluster and (7) a web\ninterface to analyze results visually. The whole architecture is\nself-deployable and based on Docker containers.","primary_category":"cs","categories":["cs.DC"],"authors":["Mart\u00ednez-Casta\u00f1o Rodrigo","Pichel Juan C.","Gamallo Pablo"],"created":"2018-01-11","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03712","title":"A Software-defined SoC Memory Bus Bridge Architecture for Disaggregated\n  Computing","abstract":"Disaggregation and rack-scale systems have the potential of drastically\ndecreasing TCO and increasing utilization of cloud datacenters, while\nmaintaining performance. While the concept of organising resources in separate\npools and interconnecting them together on demand is straightforward, its\nmaterialisation can be radically different in terms of performance and scale\npotential.\n  In this paper, we present a memory bus bridge architecture which enables\ncommunication between 100s of masters and slaves in todays complex\nmultiprocessor SoCs, that are physically intregrated in different chips and\neven different mainboards. The bridge tightly couples serial transceivers and a\ncircuit network for chip-to-chip transfers. A key property of the proposed\nbridge architecture is that it is software-defined and thus can be configured\nat runtime, via a software control plane, to prepare and steer memory access\ntransactions to remote slaves. This is particularly important because it\nenables datacenter orchestration tools to manage the disaggregated resource\nallocation. Moreover, we evaluate a bridge prototype we have build for ARM AXI4\nmemory bus interconnect and we discuss application-level observed performance.","primary_category":"cs","categories":["cs.AR","cs.ET"],"authors":["Syrivelis Dimitris","Reale Andrea","Katrinis Kostas","Pinto Christian"],"created":"2018-01-11","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03714","title":"Multi-Band Covariance Interpolation with Applications in Massive MIMO","abstract":"In this paper, we study the problem of multi-band (frequency-variant)\ncovariance interpolation with a particular emphasis towards massive MIMO\napplications. In a massive MIMO system, the communication between each BS with\n$M \\gg 1$ antennas and each single-antenna user occurs through a collection of\nscatterers in the environment, where the channel vector of each user at BS\nantennas consists in a weighted linear combination of the array responses of\nthe scatterers, where each scatterer has its own angle of arrival (AoA) and\ncomplex channel gain. The array response at a given AoA depends on the\nwavelength of the incoming planar wave and is naturally frequency dependent.\nThis results in a frequency-dependent distortion where the second order\nstatistics, i.e., the covariance matrix, of the channel vectors varies with\nfrequency. In this paper, we show that although this effect is generally\nnegligible for a small number of antennas $M$, it results in a considerable\ndistortion of the covariance matrix and especially its dominant signal subspace\nin the massive MIMO regime where $M \\to \\infty$, and can generally incur a\nserious degradation of the performance especially in frequency division\nduplexing (FDD) massive MIMO systems where the uplink (UL) and the downlink\n(DL) communication occur over different frequency bands. We propose a novel\nUL-DL covariance interpolation technique that is able to recover the covariance\nmatrix in the DL from an estimate of the covariance matrix in the UL under a\nmild reciprocity condition on the angular power spread function (PSF) of the\nusers. We analyze the performance of our proposed scheme mathematically and\nprove its robustness under a sufficiently large spatial oversampling of the\narray. We also propose several simple off-the-shelf algorithms for UL-DL\ncovariance interpolation and evaluate their performance via numerical\nsimulations.","primary_category":"cs","categories":["cs.IT","math.IT","stat.ML"],"authors":["Haghighatshoar Saeid","Khalilsarai Mahdi Barzegar","Caire Giuseppe"],"created":"2018-01-11","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03734","title":"PALE: Partially Asynchronous Agile Leader Election","abstract":"Many tasks executed in dynamic distributed systems, such as sensor networks\nor enterprise environments with bring-your-own-device policy, require central\ncoordination by a leader node. In the past it has been proven that distributed\nleader election in dynamic environments with constant changes and asynchronous\ncommunication is not possible. Thus, state-of-the-art leader election\nalgorithms are not applicable in asynchronous environments with constant\nnetwork changes. Some algorithms converge only after the network stabilizes (an\nunrealistic requirement in many dynamic environments). Other algorithms reach\nconsensus in the presence of network changes but require a global clock or some\nlevel of communication synchronization.\n  Determining the weakest assumptions, under which leader election is possible,\nremains an unresolved problem. In this study we present a leader election\nalgorithm that operates in the presence of changes and under weak (realistic)\nassumptions regarding message delays and regarding the clock drifts of the\ndistributed nodes. The proposed algorithm is self-sufficient, easy to implement\nand can be extended to support multiple regions, self-stabilization, and\nwireless ad-hoc networks. We prove the algorithm's correctness and provide a\ncomplexity analysis of the time, space, and number of messages required to\nelect a leader.","primary_category":"cs","categories":["cs.DC"],"authors":["Sidik Bronislav","Puzis Rami","Zilberman Polina","Elovici Yuval"],"created":"2018-01-11","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03748","title":"Performance Evaluation of Advanced Relaying Protocols in Large Wireless\n  Networks","abstract":"This paper studies the performance of some state-of-the-art cooperative\nfull-duplex relaying protocols in the context of a large wireless network\nmodelled using stochastic geometry tools. We investigate the outage behaviour\nfor different cooperative schemes, namely, decode-and-forward, noisy-network\ncoding and mixed noisy-network coding, considering fading, path loss and\ninterference from other sources and relays. Due to the high complexity of the\nnetwork topology and the protocols considered, a closed-form analysis is not\npossible, so our study is performed through extensive but careful numerical\nsimulations, sweeping a large number of relevant parameters. Several scenarios\nof particular interest are investigated. In this way, insightful conclusions\nare drawn regarding the network regimes in which relay-assisted cooperation is\nmost beneficial and the potential gains that could be achieved through it.","primary_category":"cs","categories":["cs.IT","cs.NI","math.IT"],"authors":["Altieri Andres","Piantanida Pablo"],"created":"2018-01-11","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03754","title":"Soft Locality Preserving Map (SLPM) for Facial Expression Recognition","abstract":"For image recognition, an extensive number of methods have been proposed to\novercome the high-dimensionality problem of feature vectors being used. These\nmethods vary from unsupervised to supervised, and from statistics to\ngraph-theory based. In this paper, the most popular and the state-of-the-art\nmethods for dimensionality reduction are firstly reviewed, and then a new and\nmore efficient manifold-learning method, named Soft Locality Preserving Map\n(SLPM), is presented. Furthermore, feature generation and sample selection are\nproposed to achieve better manifold learning. SLPM is a graph-based\nsubspace-learning method, with the use of k-neighbourhood information and the\nclass information. The key feature of SLPM is that it aims to control the level\nof spread of the different classes, because the spread of the classes in the\nunderlying manifold is closely connected to the generalizability of the learned\nsubspace. Our proposed manifold-learning method can be applied to various\npattern recognition applications, and we evaluate its performances on facial\nexpression recognition. Experiments on databases, such as the Bahcesehir\nUniversity Multilingual Affective Face Database (BAUM-2), the Extended\nCohn-Kanade (CK+) Database, the Japanese Female Facial Expression (JAFFE)\nDatabase, and the Taiwanese Facial Expression Image Database (TFEID), show that\nSLPM can effectively reduce the dimensionality of the feature vectors and\nenhance the discriminative power of the extracted features for expression\nrecognition. Furthermore, the proposed feature-generation method can improve\nthe generalizability of the underlying manifolds for facial expression\nrecognition.","primary_category":"cs","categories":["cs.CV"],"authors":["Turan Cigdem","Lam Kin-Man","He Xiangjian"],"created":"2018-01-11","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03758","title":"Breaking Mignotte's Sequence Based Secret Sharing Scheme Using SMT\n  Solver","abstract":"The secret sharing schemes are the important tools in cryptography that are\nused as building blocks in many secured protocols. It is a method used for\ndistributing a secret among the participants in a manner that only the\nthreshold number of participants together can recover the secret and the\nremaining set of participants cannot get any information about the secret.\nSecret sharing schemes are absolute for storing highly sensitive and important\ninformation. In a secret sharing scheme, a secret is divided into several\nshares. These shares are then distributed to the participants one each and thus\nonly the threshold (t) number of participants can recover the secret. In this\npaper we have used Mignotte's Sequence based Secret Sharing for distribution of\nshares to the participants. A (k, m) Mignotte's sequence is a sequence of pair\nwise co-prime positive integers. We have proposed a new method for\nreconstruction of secret even with t-1 shares using the SMT solver.","primary_category":"cs","categories":["cs.CR"],"authors":["Priyanka K. Vishnu","Gowthami M.","Susmitha O.","Prathyusha G.","Muppalaneni Naresh Babu"],"created":"2018-01-11","updated":" ","doi":"10.5121\/ijcsit.2017.9603"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03773","title":"Polar $n$-Complex and $n$-Bicomplex Singular Value Decomposition and\n  Principal Component Pursuit","abstract":"Informed by recent work on tensor singular value decomposition and circulant\nalgebra matrices, this paper presents a new theoretical bridge that unifies the\nhypercomplex and tensor-based approaches to singular value decomposition and\nrobust principal component analysis. We begin our work by extending the\nprincipal component pursuit to Olariu's polar $n$-complex numbers as well as\ntheir bicomplex counterparts. In so doing, we have derived the polar\n$n$-complex and $n$-bicomplex proximity operators for both the $\\ell_1$- and\ntrace-norm regularizers, which can be used by proximal optimization methods\nsuch as the alternating direction method of multipliers. Experimental results\non two sets of audio data show that our algebraically-informed formulation\noutperforms tensor robust principal component analysis. We conclude with the\nmessage that an informed definition of the trace norm can bridge the gap\nbetween the hypercomplex and tensor-based approaches. Our approach can be seen\nas a general methodology for generating other principal component pursuit\nalgorithms with proper algebraic structures.","primary_category":"cs","categories":["eess.SP","cs.MM","cs.SD","eess.AS","stat.ML"],"authors":["Chan Tak-Shing T.","Yang Yi-Hsuan"],"created":"2018-01-08","updated":" ","doi":"10.1109\/TSP.2016.2612171"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03800","title":"Cortical-inspired image reconstruction via sub-Riemannian geometry and\n  hypoelliptic diffusion","abstract":"In this paper we review several algorithms for image inpainting based on the\nhypoelliptic diffusion naturally associated with a mathematical model of the\nprimary visual cortex. In particular, we present one algorithm that does not\nexploit the information of where the image is corrupted, and others that do it.\nWhile the first algorithm is able to reconstruct only images that our visual\nsystem is still capable of recognize, we show that those of the second type\ncompletely transcend such limitation providing reconstructions at the\nstate-of-the-art in image inpainting. This can be interpreted as a validation\nof the fact that our visual cortex actually encodes the first type of\nalgorithm.","primary_category":"cs","categories":["cs.CV","math.NA"],"authors":["Boscain Ugo","Chertovskih Roman","Gauthier Jean-Paul","Prandi Dario","Remizov Alexey"],"created":"2018-01-11","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03815","title":"Informed Group-Sparse Representation for Singing Voice Separation","abstract":"Singing voice separation attempts to separate the vocal and instrumental\nparts of a music recording, which is a fundamental problem in music information\nretrieval. Recent work on singing voice separation has shown that the low-rank\nrepresentation and informed separation approaches are both able to improve\nseparation quality. However, low-rank optimizations are computationally\ninefficient due to the use of singular value decompositions. Therefore, in this\npaper, we propose a new linear-time algorithm called informed group-sparse\nrepresentation, and use it to separate the vocals from music using pitch\nannotations as side information. Experimental results on the iKala dataset\nconfirm the efficacy of our approach, suggesting that the music accompaniment\nfollows a group-sparse structure given a pre-trained instrumental dictionary.\nWe also show how our work can be easily extended to accommodate multiple\ndictionaries using the DSD100 dataset.","primary_category":"cs","categories":["eess.AS","cs.IR","cs.SD","eess.SP","stat.ML"],"authors":["Chan Tak-Shing T.","Yang Yi-Hsuan"],"created":"2018-01-08","updated":" ","doi":"10.1109\/LSP.2017.2647810"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03816","title":"Complex and Quaternionic Principal Component Pursuit and Its Application\n  to Audio Separation","abstract":"Recently, the principal component pursuit has received increasing attention\nin signal processing research ranging from source separation to video\nsurveillance. So far, all existing formulations are real-valued and lack the\nconcept of phase, which is inherent in inputs such as complex spectrograms or\ncolor images. Thus, in this letter, we extend principal component pursuit to\nthe complex and quaternionic cases to account for the missing phase\ninformation. Specifically, we present both complex and quaternionic proximity\noperators for the $\\ell_1$- and trace-norm regularizers. These operators can be\nused in conjunction with proximal minimization methods such as the inexact\naugmented Lagrange multiplier algorithm. The new algorithms are then applied to\nthe singing voice separation problem, which aims to separate the singing voice\nfrom the instrumental accompaniment. Results on the iKala and MSD100 datasets\nconfirmed the usefulness of phase information in principal component pursuit.","primary_category":"cs","categories":["eess.SP","cs.MM","cs.SD","eess.AS","stat.ML"],"authors":["Chan Tak-Shing T.","Yang Yi-Hsuan"],"created":"2018-01-08","updated":" ","doi":"10.1109\/LSP.2016.2514845"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03834","title":"Terahertz Dielectric Resonator Antenna Coupled to Graphene Plasmonic\n  Dipole","abstract":"This paper presents an efficient approach for exciting a dielectric resonator\nantenna (DRA) in the terahertz frequencies by means of a graphene plasmonic\ndipole. Design and analysis are performed in two steps. First, the propagation\nproperties of hybrid plasmonic onedimensional and two-dimensional structures\nare obtained by using transfer matrix theory and the finite-element method. The\ncoupling amount between the plasmonic graphene mode and the dielectric wave\nmode is explored based on different parameters. These results, together with\nDRA and plasmonic antenna theory, are then used to design a DRA antenna that\nsupports the $TE_{y}^{112}$ mode at 2.4 THz and achieves a gain (IEEE) of up to\n7 dBi and a radiation efficiency of up 70%. This gain is 6.5 dB higher than\nthat of the graphene dipole alone and achieved with a moderate area overhead,\ndemonstrating the value of the proposed structure.","primary_category":"cs","categories":["cs.ET","physics.app-ph"],"authors":["Hosseininejad Seyed E.","Neshat Mohammad","Faraji-Dana Reza","Abadal Sergi","Lemme Max C.","Bol\u00edvar Peter Haring","Alarc\u00f3n Eduard","Cabellos-Aparicio Albert"],"created":"2018-01-11","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03844","title":"Enhancing Translation Language Models with Word Embedding for\n  Information Retrieval","abstract":"In this paper, we explore the usage of Word Embedding semantic resources for\nInformation Retrieval (IR) task. This embedding, produced by a shallow neural\nnetwork, have been shown to catch semantic similarities between words (Mikolov\net al., 2013). Hence, our goal is to enhance IR Language Models by addressing\nthe term mismatch problem. To do so, we applied the model presented in the\npaper Integrating and Evaluating Neural Word Embedding in Information Retrieval\nby Zuccon et al. (2015) that proposes to estimate the translation probability\nof a Translation Language Model using the cosine similarity between Word\nEmbedding. The results we obtained so far did not show a statistically\nsignificant improvement compared to classical Language Model.","primary_category":"cs","categories":["cs.IR"],"authors":["Frej Jibril","Chevallet Jean-Pierre","Schwab Didier"],"created":"2018-01-11","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03855","title":"MXNET-MPI: Embedding MPI parallelism in Parameter Server Task Model for\n  scaling Deep Learning","abstract":"Existing Deep Learning frameworks exclusively use either Parameter Server(PS)\napproach or MPI parallelism. In this paper, we discuss the drawbacks of such\napproaches and propose a generic framework supporting both PS and MPI\nprogramming paradigms, co-existing at the same time. The key advantage of the\nnew model is to embed the scaling benefits of MPI parallelism into the loosely\ncoupled PS task model. Apart from providing a practical usage model of MPI in\ncloud, such framework allows for novel communication avoiding algorithms that\ndo parameter averaging in Stochastic Gradient Descent(SGD) approaches. We show\nhow MPI and PS models can synergestically apply algorithms such as Elastic SGD\nto improve the rate of convergence against existing approaches. These new\nalgorithms directly help scaling SGD clusterwide. Further, we also optimize the\ncritical component of the framework, namely global aggregation or allreduce\nusing a novel concept of tensor collectives. These treat a group of vectors on\na node as a single object allowing for the existing single vector algorithms to\nbe directly applicable. We back our claims with sufficient emperical evidence\nusing large scale ImageNet 1K data. Our framework is built upon MXNET but the\ndesign is generic and can be adapted to other popular DL infrastructures.","primary_category":"cs","categories":["cs.DC","cs.LG"],"authors":["Mamidala Amith R","Kollias Georgios","Ward Chris","Artico Fausto"],"created":"2018-01-11","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03865","title":"A Monetary Mechanism for Stabilizing Cooperative Data Exchange with\n  Selfish Users","abstract":"This paper considers the problem of stabilizing cooperative data exchange\nwith selfish users. In this setting, each user has a subset of packets in the\nground set $X$, and wants all other packets in $X$. The users can exchange\ntheir packets by broadcasting coded or uncoded packets over a lossless\nbroadcast channel, and monetary transactions are allowed between any pair of\nusers. We define the utility of each user as the sum of two sub-utility\nfunctions: (i) the difference between the total payment received by the user\nand the total transmission rate of the user, and (ii) the difference between\nthe total number of required packets by the user and the total payment made by\nthe user. A rate-vector and payment-matrix pair $(r,p)$ is said to stabilize\nthe grand coalition (i.e., the set of all users) if $(r,p)$ is Pareto optimal\nover all minor coalitions (i.e., all proper subsets of users who collectively\nknow all packets in $X$). Our goal is to design a stabilizing rate-payment pair\nwith minimum total sum-rate and minimum total sum-payment for any given\ninstance of the problem. In this work, we propose two algorithms that find such\na solution. Moreover, we show that both algorithms maximize the sum of utility\nof all users (over all solutions), and one of the algorithms also maximizes the\nminimum utility among all users (over all solutions).","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Heidarzadeh Anoosheh","Tyagi Ishan","Shakkottai Srinivas","Sprintson Alex"],"created":"2018-01-11","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03872","title":"The archive solution for distributed workflow management agents of the\n  CMS experiment at LHC","abstract":"The CMS experiment at the CERN LHC developed the Workflow Management Archive\nsystem to persistently store unstructured framework job report documents\nproduced by distributed workflow management agents. In this paper we present\nits architecture, implementation, deployment, and integration with the CMS and\nCERN computing infrastructures, such as central HDFS and Hadoop Spark cluster.\nThe system leverages modern technologies such as a document oriented database\nand the Hadoop eco-system to provide the necessary flexibility to reliably\nprocess, store, and aggregate $\\mathcal{O}$(1M) documents on a daily basis. We\ndescribe the data transformation, the short and long term storage layers, the\nquery language, along with the aggregation pipeline developed to visualize\nvarious performance metrics to assist CMS data operators in assessing the\nperformance of the CMS computing system.","primary_category":"cs","categories":["hep-ex","cs.DL"],"authors":["Kuznetsov Valentin","Fischer Nils Leif","Guo Yuyi"],"created":"2018-01-11","updated":" ","doi":"10.1007\/s41781-018-0005-0"}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03879","title":"Parameterized (Approximate) Defective Coloring","abstract":"In Defective Coloring we are given a graph $G = (V, E)$ and two integers\n$\\chi_d, \\Delta^*$ and are asked if we can partition $V$ into $\\chi_d$ color\nclasses, so that each class induces a graph of maximum degree $\\Delta^*$. We\ninvestigate the complexity of this generalization of Coloring with respect to\nseveral well-studied graph parameters, and show that the problem is W-hard\nparameterized by treewidth, pathwidth, tree-depth, or feedback vertex set, if\n$\\chi_d = 2$. As expected, this hardness can be extended to larger values of\n$\\chi_d$ for most of these parameters, with one surprising exception: we show\nthat the problem is FPT parameterized by feedback vertex set for any $\\chi_d\n\\ge 2$, and hence 2-coloring is the only hard case for this parameter. In\naddition to the above, we give an ETH-based lower bound for treewidth and\npathwidth, showing that no algorithm can solve the problem in $n^{o(pw)}$,\nessentially matching the complexity of an algorithm obtained with standard\ntechniques.\n  We complement these results by considering the problem's approximability and\nshow that, with respect to $\\Delta^*$, the problem admits an algorithm which\nfor any $\\epsilon > 0$ runs in time $(tw\/\\epsilon)^{O(tw)}$ and returns a\nsolution with exactly the desired number of colors that approximates the\noptimal $\\Delta^*$ within $(1 + \\epsilon)$. We also give a $(tw)^{O(tw)}$\nalgorithm which achieves the desired $\\Delta^*$ exactly while 2-approximating\nthe minimum value of $\\chi_d$. We show that this is close to optimal, by\nestablishing that no FPT algorithm can (under standard assumptions) achieve a\nbetter than $3\/2$-approximation to $\\chi_d$, even when an extra constant\nadditive error is also allowed.","primary_category":"cs","categories":["cs.DS","cs.CC"],"authors":["Belmonte R\u00e9my","Lampis Michael","Mitsou Valia"],"created":"2018-01-11","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03890","title":"HoPP: Robust and Resilient Publish-Subscribe for an Information-Centric\n  Internet of Things","abstract":"This paper revisits NDN deployment in the IoT with a special focus on the\ninteraction of sensors and actuators. Such scenarios require high\nresponsiveness and limited control state at the constrained nodes. We argue\nthat the NDN request-response pattern which prevents data push is vital for IoT\nnetworks. We contribute HoP-and-Pull (HoPP), a robust publish-subscribe scheme\nfor typical IoT scenarios that targets IoT networks consisting of hundreds of\nresource constrained devices at intermittent connectivity. Our approach limits\nthe FIB tables to a minimum and naturally supports mobility, temporary network\npartitioning, data aggregation and near real-time reactivity. We experimentally\nevaluate the protocol in a real-world deployment using the IoT-Lab testbed with\nvarying numbers of constrained devices, each wirelessly interconnected via IEEE\n802.15.4 LowPANs. Implementations are built on CCN-lite with RIOT and support\nexperiments using various single- and multi-hop scenarios.","primary_category":"cs","categories":["cs.NI"],"authors":["G\u00fcndo\u011fan Cenk","Kietzmann Peter","Schmidt Thomas C.","W\u00e4hlisch Matthias"],"created":"2018-01-11","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03895","title":"On Locally Decodable Index Codes","abstract":"Index coding achieves bandwidth savings by jointly encoding the messages\ndemanded by all the clients in a broadcast channel. The encoding is performed\nin such a way that each client can retrieve its demanded message from its side\ninformation and the broadcast codeword. In general, in order to decode its\ndemanded message symbol, a receiver may have to observe the entire transmitted\ncodeword. Querying or downloading the codeword symbols might involve costs to a\nclient -- such as network utilization costs and storage requirements for the\nqueried symbols to perform decoding. In traditional index coding solutions,\nthis 'client aware' perspective is not considered during code design. As a\nresult, for these codes, the number of codeword symbols queried by a client per\ndecoded message symbol, which we refer to as 'locality', could be large. In\nthis paper, considering locality as a cost parameter, we view index coding as a\ntrade-off between the achievable broadcast rate (codeword length normalized by\nthe message length) and locality, where the objective is to minimize the\nbroadcast rate for a given value of locality and vice versa. We show that the\nsmallest possible locality for any index coding problem is 1, and that the\noptimal index coding solution with locality 1 is the coding scheme based on\nfractional coloring of the interference graph. We propose index coding schemes\nwith small locality by covering the side information graph using acyclic\nsubgraphs and subgraphs with small minrank. We also show how locality can be\naccounted for in conventional partition multicast and cycle covering solutions\nto index coding. Finally, applying these new techniques, we characterize the\nlocality-broadcast rate trade-off of the index coding problem whose side\ninformation graph is the directed 3-cycle.","primary_category":"cs","categories":["cs.IT","math.IT"],"authors":["Natarajan Lakshmi","Krishnan Prasad","Lalitha V."],"created":"2018-01-11","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03898","title":"A parallel workload has extreme variability in a production environment","abstract":"Writing data in parallel is a common operation in some computing environments\nand a good proxy for a number of other parallel processing patterns. The\nduration of time taken to write data in large-scale compute environments can\nvary considerably. This variation comes from a number of sources, both\nsystematic and transient. The result is a highly complex behavior that is\ndifficult to characterize. This paper further develops the model for parallel\ntask variability proposed in the paper \"A parallel workload has extreme\nvariability\" (Henwood et. al 2016). This model is the Generalized Extreme Value\n(GEV) distribution. This paper further develops the systematic analysis that\nleads to the GEV model with the addition of a traffic congestion term.\nObservations of a parallel workload are presented from a High Performance\nComputing environment under typical production conditions, which include\ntraffic congestion. An analysis of the workload is performed and shows the\nvariability tends towards GEV as the order of parallelism is increased. The\nresults are presented in the context of Amdahl's law and the predictive\nproperties of a GEV models are discussed. A optimization for certain machine\ndesigns is also suggested.","primary_category":"cs","categories":["cs.DC"],"authors":["Henwood R.","Watkins N. W.","Chapman S. C.","McLay R."],"created":"2018-01-11","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"1801.03904","title":"Towards dynamic interaction-based model","abstract":"In this paper, we investigate how dynamic properties of reputation can\ninfluence the quality of users ranking. Reputation systems should be based on\nrules that can guarantee a high level of trust and help identifying unreliable\nunits. To understand the effectiveness of dynamic properties in the evaluation\nof reputation, we propose our own model (DIB-RM) that is based on three\nfactors: forgetting, cumulative, and activity period. In order to evaluate the\nmodel, we use data from StackOverflow, which also has its own reputation model.\nWe estimate similarity of ratings between DIB-RM and the StackOverflow model so\nto check our hypothesis. We use two values to calculate our metric: DIB-RM\nreputation and $historical$ reputation. We found that $historical$ reputation\ngives better metric values. Our preliminary results are presented for different\nsets of values of the aforementioned factors in order to analyze how\neffectively the model can be used for modeling reputation systems.","primary_category":"cs","categories":["cs.SI"],"authors":["Melnikov Almaz","Mazzara Manuel","Rivera Victor","Lee JooYoung","Longo Luca"],"created":"2018-01-11","updated":" ","doi":null}
{ "index": { "_index": "arxiv_db", "_type": "papers" }}
{"arxiv_id":"cs\/0602009","title":"Efficient Teamwork","abstract":"Our goal is to solve both problems of adverse selection and moral hazard for\nmulti-agent projects. In our model, each selected agent can work according to\nhis private \"capability tree\". This means a process involving hidden actions,\nhidden chance events and hidden costs in a dynamic manner, and providing\ncontractible consequences which are affecting each other's working process and\nthe outcome of the project. We will construct a mechanism that induces truthful\nrevelation of the agents' capability trees and chance events and to follow the\ninstructions about their hidden decisions. This enables the planner to select\nthe optimal subset of agents and obtain the efficient joint execution. We will\nconstruct another mechanism that is collusion-resistant but implements an only\napproximately efficient outcome. The latter mechanism is widely applicable, and\nthe major application details will be elaborated.","primary_category":"cs","categories":["cs.OH"],"authors":["Cs\u00f3ka Endre"],"created":"2006-02-06","updated":"2018-01-10","doi":null}
